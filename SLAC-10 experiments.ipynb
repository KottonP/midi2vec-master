{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import winsound\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.optim import Adam, NAdam\n",
    "from torch.optim.lr_scheduler import OneCycleLR as OCR\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HGTConv, SAGEConv, GATConv, Linear, to_hetero\n",
    "from torch_geometric.nn import models as pyg_models\n",
    "from torch_geometric.sampler import HGTSampler\n",
    "from torch_geometric.loader import DataLoader, HGTLoader, NeighborLoader, NodeLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from UltilityFunctions import *\n",
    "\n",
    "\n",
    "# print(matplotlib.__version__)\n",
    "# print(nx.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 960\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLAC 10-Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading edgelists...\n",
      "- notes.edgelist\n",
      "- program.edgelist\n",
      "- tempo.edgelist\n",
      "- time.signature.edgelist\n",
      "Nodes: 93553\n",
      "Edges: 786635\n"
     ]
    }
   ],
   "source": [
    "# # Complete Dataset\n",
    "G = complete_graph(\".\\\\slac\\\\embeddings\\\\all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame((list(G.nodes)), columns=['name'])\n",
    "edges = pd.DataFrame(np.array(list(G.edges)), columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_cat_dict took 0.18 secs to run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['note_group', 'pitch', 'program', 'MIDI', 'duration', 'velocity', 'time_sig', 'tempo'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_categories = node_cat_dict(nodes)\n",
    "node_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "nodes_df_complete = pd.read_csv('.\\slac\\Contents of Slac\\\\nodes_complete.csv')\n",
    "edges_df_complete = pd.read_csv('.\\slac\\Contents of Slac\\edges_complete.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MIDI',\n",
       " 'duration',\n",
       " 'note_group',\n",
       " 'pitch',\n",
       " 'program',\n",
       " 'tempo',\n",
       " 'time_sig',\n",
       " 'velocity'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_types = set(nodes_df_complete['node_type'])\n",
    "node_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = [\"MIDI__has__tempo\",\n",
    "                   \"MIDI__in__time_sig\",\n",
    "                   \"MIDI__has__program\",\n",
    "                   \"MIDI__has__note_group\",\n",
    "                   \"note_group__has__velocity\",\n",
    "                   \"note_group__has__duration\",\n",
    "                   \"note_group__contains__pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = flatten_lol(node_categories.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(names_list, n_labels=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_nodes took 3.49 secs to run\n",
      "encode_nodes took 0.02 secs to run\n",
      "encode_nodes took 0.01 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n"
     ]
    }
   ],
   "source": [
    "input_node_dict = {node_type: {'x': encoder.\n",
    "                    encode_nodes(nodes_df_complete.\n",
    "                    loc[nodes_df_complete['node_type'] == node_type, ['name']])}\n",
    "                    for node_type in node_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_enc_to_idx = {node_type: {encoder.decode_value(node_enc.item()): i for i, node_enc in enumerate(input_node_dict[node_type]['x'])} for node_type in node_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_edge_dict = dict()\n",
    "for edge_type in edge_types:\n",
    "    node_type_s, node_type_t = edge_type.split('__')[0], edge_type.split('__')[2]\n",
    "\n",
    "    edge_df = edges_df_complete.loc[edges_df_complete['edge_type'] == edge_type, ['source', 'target']].copy()\n",
    "\n",
    "    edge_df['source'], edge_df['target'] = edge_df['source'].map(node_enc_to_idx[node_type_s]), edge_df['target'].map(node_enc_to_idx[node_type_t])\n",
    "\n",
    "    input_edge_dict[edge_type] = {'edge_index': torch.tensor(edge_df.values).T}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alternative', 'Baroque', 'Bop', 'Hardcore_Rap', 'Metal', 'Modern',\n",
       "       'Pop_Rap', 'Romantic', 'Swing', 'Traditional'], dtype='<U12')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the label of each Midi.\n",
    "midi_val = nodes_df_complete.loc[nodes_df_complete['node_type'] == 'MIDI', ['name']].values\n",
    "midi_class_10 = [midi_type(s[0], 10) for s in midi_val]\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_10 = torch.from_numpy(lb.fit_transform(midi_class_10))  # .type(torch.LongTensor)\n",
    "\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_dict_10 = input_node_dict.copy()\n",
    "\n",
    "input_node_dict_10['MIDI']['y'] = y_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mnote_group\u001b[0m={ x=[92484, 1] },\n",
      "  \u001b[1mduration\u001b[0m={ x=[570, 1] },\n",
      "  \u001b[1mMIDI\u001b[0m={\n",
      "    x=[250, 1],\n",
      "    y=[250]\n",
      "  },\n",
      "  \u001b[1mtempo\u001b[0m={ x=[23, 1] },\n",
      "  \u001b[1mpitch\u001b[0m={ x=[93, 1] },\n",
      "  \u001b[1mtime_sig\u001b[0m={ x=[14, 1] },\n",
      "  \u001b[1mvelocity\u001b[0m={ x=[11, 1] },\n",
      "  \u001b[1mprogram\u001b[0m={ x=[108, 1] },\n",
      "  \u001b[1m(MIDI, has, tempo)\u001b[0m={ edge_index=[2, 250] },\n",
      "  \u001b[1m(MIDI, in, time_sig)\u001b[0m={ edge_index=[2, 239] },\n",
      "  \u001b[1m(MIDI, has, program)\u001b[0m={ edge_index=[2, 1392] },\n",
      "  \u001b[1m(MIDI, has, note_group)\u001b[0m={ edge_index=[2, 135160] },\n",
      "  \u001b[1m(note_group, has, velocity)\u001b[0m={ edge_index=[2, 118626] },\n",
      "  \u001b[1m(note_group, has, duration)\u001b[0m={ edge_index=[2, 92484] },\n",
      "  \u001b[1m(note_group, contains, pitch)\u001b[0m={ edge_index=[2, 438484] },\n",
      "  \u001b[1m(tempo, rev_has, MIDI)\u001b[0m={ edge_index=[2, 250] },\n",
      "  \u001b[1m(time_sig, rev_in, MIDI)\u001b[0m={ edge_index=[2, 239] },\n",
      "  \u001b[1m(program, rev_has, MIDI)\u001b[0m={ edge_index=[2, 1392] },\n",
      "  \u001b[1m(note_group, rev_has, MIDI)\u001b[0m={ edge_index=[2, 135160] },\n",
      "  \u001b[1m(velocity, rev_has, note_group)\u001b[0m={ edge_index=[2, 118626] },\n",
      "  \u001b[1m(duration, rev_has, note_group)\u001b[0m={ edge_index=[2, 92484] },\n",
      "  \u001b[1m(pitch, rev_contains, note_group)\u001b[0m={ edge_index=[2, 438484] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "H_10 = HeteroData(input_node_dict_10, **input_edge_dict)\n",
    "H_10 = T.ToUndirected()(H_10)\n",
    "print(H_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = pyg_models.GraphSAGE(in_channels=-1, hidden_channels=64, num_layers=2, out_channels=len(set(lb.classes_)))\n",
    "\n",
    "model_10 = to_hetero(model_10, H_10.metadata(), aggr='sum')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfering dataset to device cuda\n",
      "Done\n",
      "________________________________________________________________________________\n",
      "Starting Cross Validation\n",
      "________________________________________________________________________________\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 0 | epoch : 1 | train_loss : 865293.6875 | val_loss : 1111599.0 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 2 | train_loss : 865257.6875 | val_loss : 755717.25 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 3 | train_loss : 640309.125 | val_loss : 836978.625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 4 | train_loss : 774985.1875 | val_loss : 1092968.125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 5 | train_loss : 1016048.25 | val_loss : 1220977.125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 6 | train_loss : 1201338.125 | val_loss : 1334533.5 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 7 | train_loss : 1347625.25 | val_loss : 1753855.875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 8 | train_loss : 1674618.375 | val_loss : 1441820.0 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 9 | train_loss : 1412773.125 | val_loss : 1088902.75 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 10 | train_loss : 1011255.1875 | val_loss : 867443.625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 11 | train_loss : 750708.25 | val_loss : 671609.0625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 12 | train_loss : 507619.96875 | val_loss : 532691.0625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 13 | train_loss : 379500.40625 | val_loss : 494806.40625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 14 | train_loss : 370290.40625 | val_loss : 479642.625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 15 | train_loss : 393011.75 | val_loss : 488048.6875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 16 | train_loss : 420961.84375 | val_loss : 421694.15625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 17 | train_loss : 344403.8125 | val_loss : 315448.625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 18 | train_loss : 319514.25 | val_loss : 223692.265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 19 | train_loss : 179653.0 | val_loss : 251700.3125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 20 | train_loss : 198534.5 | val_loss : 271638.21875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 21 | train_loss : 260089.6875 | val_loss : 331245.0 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 22 | train_loss : 280814.0625 | val_loss : 332623.4375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 23 | train_loss : 271594.4375 | val_loss : 202393.78125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 24 | train_loss : 208500.8125 | val_loss : 201197.796875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 25 | train_loss : 190783.78125 | val_loss : 225368.734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 26 | train_loss : 157923.734375 | val_loss : 212575.8125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 27 | train_loss : 152331.390625 | val_loss : 147888.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 28 | train_loss : 143006.40625 | val_loss : 170592.546875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 29 | train_loss : 139702.71875 | val_loss : 146888.4375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 30 | train_loss : 155405.859375 | val_loss : 179001.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 31 | train_loss : 207524.0625 | val_loss : 207865.265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 32 | train_loss : 220262.40625 | val_loss : 133464.203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 33 | train_loss : 124815.0 | val_loss : 85399.140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 34 | train_loss : 85777.8203125 | val_loss : 174058.4375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 35 | train_loss : 128319.71875 | val_loss : 150458.796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 36 | train_loss : 160323.46875 | val_loss : 134141.40625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 37 | train_loss : 99941.0390625 | val_loss : 102113.203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 38 | train_loss : 104989.84375 | val_loss : 163880.84375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 39 | train_loss : 133613.953125 | val_loss : 196007.640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 40 | train_loss : 205333.84375 | val_loss : 162827.140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 41 | train_loss : 181146.15625 | val_loss : 137400.984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 42 | train_loss : 136295.0625 | val_loss : 77484.78125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 43 | train_loss : 115537.7109375 | val_loss : 90735.203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 44 | train_loss : 105523.828125 | val_loss : 156653.4375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 45 | train_loss : 121399.78125 | val_loss : 174459.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 46 | train_loss : 179293.734375 | val_loss : 137914.953125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 47 | train_loss : 143831.921875 | val_loss : 182585.703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 48 | train_loss : 179935.3125 | val_loss : 156746.6875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 49 | train_loss : 161952.90625 | val_loss : 98762.5234375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 50 | train_loss : 91251.0 | val_loss : 161628.40625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 51 | train_loss : 150723.296875 | val_loss : 104958.78125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 52 | train_loss : 125243.7421875 | val_loss : 163028.09375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 53 | train_loss : 114141.75 | val_loss : 157979.6875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 54 | train_loss : 118222.1015625 | val_loss : 94496.8671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 55 | train_loss : 83768.765625 | val_loss : 106026.7578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 56 | train_loss : 88937.78125 | val_loss : 78627.171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 57 | train_loss : 90617.8203125 | val_loss : 100177.1171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 58 | train_loss : 88151.7578125 | val_loss : 115178.0234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 59 | train_loss : 124688.0078125 | val_loss : 109578.7421875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 60 | train_loss : 98352.59375 | val_loss : 92950.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 61 | train_loss : 108924.90625 | val_loss : 125418.3203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 62 | train_loss : 102430.6875 | val_loss : 90663.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 63 | train_loss : 78933.1484375 | val_loss : 56745.703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 64 | train_loss : 88360.8984375 | val_loss : 76229.3359375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 65 | train_loss : 75515.40625 | val_loss : 146255.59375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 66 | train_loss : 122275.671875 | val_loss : 87237.5 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 67 | train_loss : 94142.609375 | val_loss : 124084.40625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 68 | train_loss : 109484.6328125 | val_loss : 87300.859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 69 | train_loss : 88198.34375 | val_loss : 130949.96875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 70 | train_loss : 107956.0 | val_loss : 136158.234375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 71 | train_loss : 129964.0703125 | val_loss : 101003.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 72 | train_loss : 132405.46875 | val_loss : 161987.140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 73 | train_loss : 143648.75 | val_loss : 98638.3984375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 74 | train_loss : 79929.5234375 | val_loss : 73645.03125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 75 | train_loss : 72487.0390625 | val_loss : 64241.46875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 76 | train_loss : 65591.2578125 | val_loss : 86741.5625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 77 | train_loss : 89269.8828125 | val_loss : 66440.2578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 78 | train_loss : 58854.15625 | val_loss : 68487.3515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 79 | train_loss : 58521.60546875 | val_loss : 104786.7421875 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 80 | train_loss : 88279.6875 | val_loss : 52694.55859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 81 | train_loss : 74694.296875 | val_loss : 79954.3828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 82 | train_loss : 62902.62109375 | val_loss : 64823.44921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 83 | train_loss : 50638.328125 | val_loss : 90099.7578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 84 | train_loss : 86330.7109375 | val_loss : 82455.0078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 85 | train_loss : 84086.1484375 | val_loss : 97194.4375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 86 | train_loss : 86285.828125 | val_loss : 62474.6484375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 87 | train_loss : 48130.6796875 | val_loss : 73259.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 88 | train_loss : 65574.078125 | val_loss : 67104.5625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 89 | train_loss : 58650.0234375 | val_loss : 73007.3515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 90 | train_loss : 73583.828125 | val_loss : 68702.9921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 91 | train_loss : 64381.9296875 | val_loss : 34521.0 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 92 | train_loss : 45333.5 | val_loss : 117660.6875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 93 | train_loss : 85874.03125 | val_loss : 78229.484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 94 | train_loss : 74579.0859375 | val_loss : 103801.6875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 95 | train_loss : 86954.15625 | val_loss : 54013.35546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 96 | train_loss : 59866.26953125 | val_loss : 112834.5390625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 97 | train_loss : 93412.53125 | val_loss : 80684.703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 98 | train_loss : 105337.0 | val_loss : 60362.8515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 99 | train_loss : 69855.6640625 | val_loss : 166150.0 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 100 | train_loss : 133890.953125 | val_loss : 61362.3359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 101 | train_loss : 104897.9296875 | val_loss : 66766.75 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 102 | train_loss : 94636.71875 | val_loss : 100303.359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 103 | train_loss : 102693.65625 | val_loss : 102640.15625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 104 | train_loss : 99925.1015625 | val_loss : 78752.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 105 | train_loss : 71988.8203125 | val_loss : 90956.65625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 106 | train_loss : 78070.5546875 | val_loss : 39443.3046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 107 | train_loss : 56604.55078125 | val_loss : 80259.5078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 108 | train_loss : 73048.3125 | val_loss : 47065.9609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 109 | train_loss : 56889.51171875 | val_loss : 47419.62109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 110 | train_loss : 48209.359375 | val_loss : 74375.609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 111 | train_loss : 66976.8203125 | val_loss : 96724.5625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 112 | train_loss : 68614.9296875 | val_loss : 49348.53125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 113 | train_loss : 46361.8984375 | val_loss : 92499.4609375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 114 | train_loss : 82470.078125 | val_loss : 47293.44921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 115 | train_loss : 63976.40625 | val_loss : 86704.140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 116 | train_loss : 83701.140625 | val_loss : 68334.9375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 117 | train_loss : 61322.046875 | val_loss : 89059.6484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 118 | train_loss : 77446.53125 | val_loss : 88243.5078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 119 | train_loss : 96234.6796875 | val_loss : 86549.1796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 120 | train_loss : 85798.90625 | val_loss : 68868.03125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 121 | train_loss : 72442.6171875 | val_loss : 51900.73828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 122 | train_loss : 56723.75390625 | val_loss : 59706.56640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 123 | train_loss : 65367.03125 | val_loss : 52633.4609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 124 | train_loss : 49102.13671875 | val_loss : 57014.83984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 125 | train_loss : 65806.390625 | val_loss : 83523.3125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 126 | train_loss : 79604.21875 | val_loss : 74073.5625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 127 | train_loss : 78724.03125 | val_loss : 72727.140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 128 | train_loss : 74036.421875 | val_loss : 65566.03125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 129 | train_loss : 63347.0 | val_loss : 75273.8515625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 130 | train_loss : 61003.1484375 | val_loss : 37411.20703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 131 | train_loss : 44693.49609375 | val_loss : 84725.1875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 132 | train_loss : 72228.5859375 | val_loss : 61347.390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 133 | train_loss : 50536.93359375 | val_loss : 48221.23828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 134 | train_loss : 43414.3515625 | val_loss : 34394.8046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 135 | train_loss : 50874.19921875 | val_loss : 61022.578125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 136 | train_loss : 64546.6953125 | val_loss : 79647.4609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 137 | train_loss : 83058.2421875 | val_loss : 80553.9609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 138 | train_loss : 72021.4375 | val_loss : 78426.640625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 139 | train_loss : 62728.078125 | val_loss : 61766.359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 140 | train_loss : 66445.046875 | val_loss : 65532.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 141 | train_loss : 66049.828125 | val_loss : 81073.890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 142 | train_loss : 72317.3125 | val_loss : 69933.1171875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 143 | train_loss : 68024.796875 | val_loss : 39580.546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 144 | train_loss : 47398.140625 | val_loss : 50395.9296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 145 | train_loss : 39550.53125 | val_loss : 36399.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 146 | train_loss : 51043.21484375 | val_loss : 49369.4140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 147 | train_loss : 47113.9140625 | val_loss : 48812.46875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 148 | train_loss : 35719.89453125 | val_loss : 47671.3515625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 149 | train_loss : 45971.0390625 | val_loss : 42868.33984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 150 | train_loss : 49577.75 | val_loss : 67486.65625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 151 | train_loss : 54132.44921875 | val_loss : 63143.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 152 | train_loss : 66725.6953125 | val_loss : 66439.6875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 153 | train_loss : 54679.07421875 | val_loss : 29796.294921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 154 | train_loss : 45014.7890625 | val_loss : 60222.0859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 155 | train_loss : 54097.62109375 | val_loss : 27588.828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 156 | train_loss : 38252.953125 | val_loss : 78904.4921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 157 | train_loss : 54222.12109375 | val_loss : 48924.14453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 158 | train_loss : 45181.9296875 | val_loss : 36095.35546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 159 | train_loss : 32800.70703125 | val_loss : 54753.578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 160 | train_loss : 55867.58984375 | val_loss : 23448.4765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 161 | train_loss : 21981.421875 | val_loss : 30911.404296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 162 | train_loss : 39515.53515625 | val_loss : 44048.94140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 163 | train_loss : 43483.546875 | val_loss : 29621.130859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 164 | train_loss : 35263.3984375 | val_loss : 64576.80078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 165 | train_loss : 48557.96484375 | val_loss : 33054.34765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 166 | train_loss : 34101.99609375 | val_loss : 74530.8984375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 167 | train_loss : 58036.73828125 | val_loss : 57147.13671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 168 | train_loss : 62893.00390625 | val_loss : 65367.203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 169 | train_loss : 58997.9609375 | val_loss : 70051.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 170 | train_loss : 69883.140625 | val_loss : 56360.171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 171 | train_loss : 53330.9609375 | val_loss : 39587.62890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 172 | train_loss : 52097.32421875 | val_loss : 47476.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 173 | train_loss : 46898.1484375 | val_loss : 43772.96875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 174 | train_loss : 38494.9140625 | val_loss : 50009.109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 175 | train_loss : 48631.3203125 | val_loss : 40742.890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 176 | train_loss : 48153.75 | val_loss : 47048.0703125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 177 | train_loss : 40831.875 | val_loss : 51003.94140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 178 | train_loss : 58412.7734375 | val_loss : 72826.859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 179 | train_loss : 76546.453125 | val_loss : 60769.01953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 180 | train_loss : 63567.76953125 | val_loss : 39646.17578125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 181 | train_loss : 35202.734375 | val_loss : 27400.41796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 182 | train_loss : 42620.43359375 | val_loss : 42891.390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 183 | train_loss : 34389.16015625 | val_loss : 36253.80078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 184 | train_loss : 34644.875 | val_loss : 42653.8515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 185 | train_loss : 39821.07421875 | val_loss : 43519.37890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 186 | train_loss : 37290.21875 | val_loss : 36883.5703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 187 | train_loss : 43127.1015625 | val_loss : 48490.265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 188 | train_loss : 42718.82421875 | val_loss : 40525.54296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 189 | train_loss : 50641.1796875 | val_loss : 50367.4296875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 190 | train_loss : 32104.375 | val_loss : 25454.796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 191 | train_loss : 29228.642578125 | val_loss : 38715.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 192 | train_loss : 36881.74609375 | val_loss : 42952.3203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 193 | train_loss : 49692.94921875 | val_loss : 40956.09375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 194 | train_loss : 42253.4765625 | val_loss : 63621.01171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 195 | train_loss : 54530.125 | val_loss : 32546.171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 196 | train_loss : 26063.787109375 | val_loss : 42619.80859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 197 | train_loss : 40356.89453125 | val_loss : 43282.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 198 | train_loss : 44118.9765625 | val_loss : 31520.91796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 199 | train_loss : 36437.1796875 | val_loss : 34542.42578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 200 | train_loss : 29996.44921875 | val_loss : 27635.427734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 201 | train_loss : 30863.4609375 | val_loss : 52715.328125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 202 | train_loss : 39943.15625 | val_loss : 29024.509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 203 | train_loss : 36327.85546875 | val_loss : 34810.40625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 204 | train_loss : 33406.3515625 | val_loss : 19268.28125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 205 | train_loss : 22661.265625 | val_loss : 32189.029296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 206 | train_loss : 30971.748046875 | val_loss : 31762.775390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 207 | train_loss : 28213.193359375 | val_loss : 29130.052734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 208 | train_loss : 28825.26953125 | val_loss : 34429.30078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 209 | train_loss : 36646.19921875 | val_loss : 30017.025390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 210 | train_loss : 26110.568359375 | val_loss : 27806.056640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 211 | train_loss : 31518.689453125 | val_loss : 45192.01953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 212 | train_loss : 43109.3515625 | val_loss : 28733.060546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 213 | train_loss : 29384.607421875 | val_loss : 26313.91015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 214 | train_loss : 40893.42578125 | val_loss : 15610.6337890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 215 | train_loss : 15216.5029296875 | val_loss : 30172.490234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 216 | train_loss : 26783.755859375 | val_loss : 45707.265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 217 | train_loss : 37555.41015625 | val_loss : 16820.537109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 218 | train_loss : 27163.2578125 | val_loss : 29174.828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 219 | train_loss : 26464.6875 | val_loss : 22274.044921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 220 | train_loss : 26974.615234375 | val_loss : 37236.18359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 221 | train_loss : 29976.189453125 | val_loss : 17092.830078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 222 | train_loss : 22252.873046875 | val_loss : 31219.001953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 223 | train_loss : 26437.66015625 | val_loss : 17195.1171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 224 | train_loss : 22120.40234375 | val_loss : 33733.48828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 225 | train_loss : 28017.23828125 | val_loss : 25647.716796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 226 | train_loss : 31785.658203125 | val_loss : 53866.90625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 227 | train_loss : 48385.75 | val_loss : 47029.9609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 228 | train_loss : 46970.32421875 | val_loss : 30386.447265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 229 | train_loss : 28602.412109375 | val_loss : 27928.20703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 230 | train_loss : 26569.283203125 | val_loss : 34427.08203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 231 | train_loss : 28801.966796875 | val_loss : 39359.75390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 232 | train_loss : 39994.79296875 | val_loss : 33526.03125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 233 | train_loss : 31026.251953125 | val_loss : 29502.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 234 | train_loss : 35923.859375 | val_loss : 38660.05078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 235 | train_loss : 27206.892578125 | val_loss : 28847.884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 236 | train_loss : 33308.92578125 | val_loss : 23850.0234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 237 | train_loss : 20599.755859375 | val_loss : 98578.9375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 238 | train_loss : 119504.9921875 | val_loss : 26095.435546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 239 | train_loss : 24684.439453125 | val_loss : 39056.9921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 240 | train_loss : 31740.068359375 | val_loss : 35418.88671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 241 | train_loss : 40204.8515625 | val_loss : 28641.435546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 242 | train_loss : 26294.0546875 | val_loss : 35673.7890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 243 | train_loss : 41104.21875 | val_loss : 38156.640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 244 | train_loss : 31029.2890625 | val_loss : 24895.45703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 245 | train_loss : 29842.66015625 | val_loss : 46614.75390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 246 | train_loss : 43963.69921875 | val_loss : 19221.318359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 247 | train_loss : 22538.13671875 | val_loss : 32350.57421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 248 | train_loss : 26676.724609375 | val_loss : 28196.98046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 249 | train_loss : 27338.2890625 | val_loss : 30798.515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 250 | train_loss : 29244.546875 | val_loss : 22402.4765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 251 | train_loss : 31930.279296875 | val_loss : 52103.19921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 252 | train_loss : 38604.74609375 | val_loss : 39102.78125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 253 | train_loss : 48286.578125 | val_loss : 42483.96875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 254 | train_loss : 36388.0390625 | val_loss : 29506.205078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 255 | train_loss : 35900.69140625 | val_loss : 45200.87109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 256 | train_loss : 33981.97265625 | val_loss : 24531.490234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 257 | train_loss : 27665.572265625 | val_loss : 40541.40625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 258 | train_loss : 37223.50390625 | val_loss : 21890.58984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 259 | train_loss : 24784.0703125 | val_loss : 32459.904296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 260 | train_loss : 26508.994140625 | val_loss : 22531.671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 261 | train_loss : 21967.265625 | val_loss : 34821.8046875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 262 | train_loss : 30230.970703125 | val_loss : 31316.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 263 | train_loss : 36419.36328125 | val_loss : 29243.29296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 264 | train_loss : 25020.3125 | val_loss : 22840.3359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 265 | train_loss : 25248.912109375 | val_loss : 39308.1015625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 266 | train_loss : 28379.95703125 | val_loss : 22599.802734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 267 | train_loss : 30814.376953125 | val_loss : 28398.5859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 268 | train_loss : 27640.4921875 | val_loss : 24714.7265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 269 | train_loss : 29079.0390625 | val_loss : 34748.55078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 270 | train_loss : 26934.72265625 | val_loss : 18291.908203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 271 | train_loss : 22142.224609375 | val_loss : 32249.5859375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 272 | train_loss : 27134.619140625 | val_loss : 14238.138671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 273 | train_loss : 19196.994140625 | val_loss : 34458.28125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 274 | train_loss : 25244.69921875 | val_loss : 20202.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 275 | train_loss : 27698.5078125 | val_loss : 29892.8671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 276 | train_loss : 22782.1640625 | val_loss : 14256.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 277 | train_loss : 17335.41796875 | val_loss : 27924.544921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 278 | train_loss : 19751.599609375 | val_loss : 17192.287109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 279 | train_loss : 21137.30078125 | val_loss : 25701.48046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 280 | train_loss : 18283.146484375 | val_loss : 19871.712890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 281 | train_loss : 23384.35546875 | val_loss : 37545.3046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 282 | train_loss : 32582.560546875 | val_loss : 25110.189453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 283 | train_loss : 27501.2421875 | val_loss : 24977.55078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 284 | train_loss : 21076.20703125 | val_loss : 17036.904296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 285 | train_loss : 24692.947265625 | val_loss : 27054.234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 286 | train_loss : 20278.201171875 | val_loss : 18758.107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 287 | train_loss : 18948.880859375 | val_loss : 29111.4453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 288 | train_loss : 17896.43359375 | val_loss : 32820.40625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 289 | train_loss : 28908.419921875 | val_loss : 22210.185546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 290 | train_loss : 20541.099609375 | val_loss : 17174.87890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 291 | train_loss : 23051.11328125 | val_loss : 34034.0703125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 292 | train_loss : 27816.2578125 | val_loss : 16259.201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 293 | train_loss : 20658.126953125 | val_loss : 33017.58203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 294 | train_loss : 25261.5546875 | val_loss : 10455.78515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 295 | train_loss : 15445.611328125 | val_loss : 27544.14453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 296 | train_loss : 22807.9765625 | val_loss : 16479.896484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 297 | train_loss : 23800.876953125 | val_loss : 23680.939453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 298 | train_loss : 18462.95703125 | val_loss : 21371.5078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 299 | train_loss : 21538.056640625 | val_loss : 28661.4921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 300 | train_loss : 30166.154296875 | val_loss : 23386.41015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 301 | train_loss : 32205.802734375 | val_loss : 19231.341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 302 | train_loss : 20745.587890625 | val_loss : 23168.20703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 303 | train_loss : 19660.7734375 | val_loss : 20799.15625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 304 | train_loss : 17637.54296875 | val_loss : 17150.6796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 305 | train_loss : 22433.875 | val_loss : 14948.611328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 306 | train_loss : 13376.6748046875 | val_loss : 20579.34765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 307 | train_loss : 24228.384765625 | val_loss : 33887.18359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 308 | train_loss : 28672.0859375 | val_loss : 21755.716796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 309 | train_loss : 21707.251953125 | val_loss : 31068.9140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 310 | train_loss : 28316.470703125 | val_loss : 27127.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 311 | train_loss : 35860.19140625 | val_loss : 34064.3046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 312 | train_loss : 26854.755859375 | val_loss : 15478.50390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 313 | train_loss : 16678.552734375 | val_loss : 7992.70263671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 314 | train_loss : 7786.16259765625 | val_loss : 14386.361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 315 | train_loss : 15915.0625 | val_loss : 14228.3291015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 316 | train_loss : 17360.11328125 | val_loss : 29560.55078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 317 | train_loss : 22172.32421875 | val_loss : 30224.359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 318 | train_loss : 30327.71484375 | val_loss : 34811.21875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 319 | train_loss : 33220.83984375 | val_loss : 23216.837890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 320 | train_loss : 32654.810546875 | val_loss : 31678.310546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 321 | train_loss : 27815.275390625 | val_loss : 13824.0595703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 322 | train_loss : 16190.0498046875 | val_loss : 20404.5546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 323 | train_loss : 16383.5947265625 | val_loss : 14012.90625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 324 | train_loss : 18368.54296875 | val_loss : 25187.296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 325 | train_loss : 22090.046875 | val_loss : 19522.533203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 326 | train_loss : 22353.8984375 | val_loss : 12572.6328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 327 | train_loss : 11014.66796875 | val_loss : 21433.681640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 328 | train_loss : 21629.314453125 | val_loss : 27112.876953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 329 | train_loss : 26952.84765625 | val_loss : 14490.169921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 330 | train_loss : 21308.7109375 | val_loss : 16042.462890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 331 | train_loss : 17170.41015625 | val_loss : 19482.060546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 332 | train_loss : 16721.841796875 | val_loss : 19911.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 333 | train_loss : 19349.333984375 | val_loss : 19243.33984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 334 | train_loss : 21277.33984375 | val_loss : 26778.283203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 335 | train_loss : 24770.14453125 | val_loss : 17649.82421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 336 | train_loss : 17714.623046875 | val_loss : 14229.3115234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 337 | train_loss : 12915.2177734375 | val_loss : 11378.71875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 338 | train_loss : 14916.5751953125 | val_loss : 22172.572265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 339 | train_loss : 20811.8515625 | val_loss : 14705.0009765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 340 | train_loss : 15016.45703125 | val_loss : 12952.44140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 341 | train_loss : 10177.947265625 | val_loss : 11933.43359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 342 | train_loss : 14815.08203125 | val_loss : 26161.935546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 343 | train_loss : 20365.068359375 | val_loss : 19641.421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 344 | train_loss : 20146.24609375 | val_loss : 22550.8828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 345 | train_loss : 20606.44921875 | val_loss : 16392.69921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 346 | train_loss : 23791.72265625 | val_loss : 24428.10546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 347 | train_loss : 19684.4296875 | val_loss : 17737.544921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 348 | train_loss : 20408.783203125 | val_loss : 26672.8671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 349 | train_loss : 20469.650390625 | val_loss : 13550.02734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 350 | train_loss : 16908.345703125 | val_loss : 29051.48046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 351 | train_loss : 22145.453125 | val_loss : 12372.1552734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 352 | train_loss : 14228.9697265625 | val_loss : 25091.369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 353 | train_loss : 19283.51171875 | val_loss : 12146.4033203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 354 | train_loss : 12858.0283203125 | val_loss : 18769.435546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 355 | train_loss : 14590.66796875 | val_loss : 10182.02734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 356 | train_loss : 13810.87890625 | val_loss : 24446.9765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 357 | train_loss : 19043.861328125 | val_loss : 14801.3115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 358 | train_loss : 15419.513671875 | val_loss : 18362.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 359 | train_loss : 14920.4716796875 | val_loss : 12256.130859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 360 | train_loss : 14321.787109375 | val_loss : 19087.8671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 361 | train_loss : 16887.994140625 | val_loss : 16957.62109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 362 | train_loss : 15761.8671875 | val_loss : 22745.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 363 | train_loss : 19937.81640625 | val_loss : 10665.8671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 364 | train_loss : 10243.2861328125 | val_loss : 17023.1796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 365 | train_loss : 14509.5146484375 | val_loss : 13957.8359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 366 | train_loss : 18453.908203125 | val_loss : 14640.8935546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 367 | train_loss : 12063.0400390625 | val_loss : 11992.240234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 368 | train_loss : 13838.29296875 | val_loss : 23337.109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 369 | train_loss : 18039.111328125 | val_loss : 8501.86328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 370 | train_loss : 9534.0634765625 | val_loss : 12909.4677734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 371 | train_loss : 10659.666015625 | val_loss : 12425.02734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 372 | train_loss : 9343.14453125 | val_loss : 17319.7421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 373 | train_loss : 15414.3154296875 | val_loss : 18332.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 374 | train_loss : 16744.00390625 | val_loss : 12326.6103515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 375 | train_loss : 12345.583984375 | val_loss : 23055.880859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 376 | train_loss : 17139.654296875 | val_loss : 16256.05859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 377 | train_loss : 16319.17578125 | val_loss : 22049.505859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 378 | train_loss : 18353.10546875 | val_loss : 14915.5986328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 379 | train_loss : 19449.998046875 | val_loss : 27992.919921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 380 | train_loss : 22216.134765625 | val_loss : 21720.34765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 381 | train_loss : 24370.140625 | val_loss : 25683.38671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 382 | train_loss : 23302.14453125 | val_loss : 18443.951171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 383 | train_loss : 27151.517578125 | val_loss : 27682.171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 384 | train_loss : 22567.130859375 | val_loss : 8835.853515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 385 | train_loss : 8896.052734375 | val_loss : 18082.662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 386 | train_loss : 13194.642578125 | val_loss : 10145.8837890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 387 | train_loss : 9162.326171875 | val_loss : 15674.7021484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 388 | train_loss : 11626.28125 | val_loss : 14352.080078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 389 | train_loss : 15827.8671875 | val_loss : 26731.779296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 390 | train_loss : 20148.181640625 | val_loss : 11162.8798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 391 | train_loss : 13630.0322265625 | val_loss : 94973.3125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 392 | train_loss : 77395.4921875 | val_loss : 37639.2109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 393 | train_loss : 39172.9921875 | val_loss : 19022.396484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 394 | train_loss : 25789.703125 | val_loss : 29318.97265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 395 | train_loss : 24830.130859375 | val_loss : 7927.2373046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 396 | train_loss : 8948.4853515625 | val_loss : 16921.8359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 397 | train_loss : 12508.7578125 | val_loss : 7998.728515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 398 | train_loss : 8064.98486328125 | val_loss : 13856.318359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 399 | train_loss : 11679.1796875 | val_loss : 8961.01953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 400 | train_loss : 10963.412109375 | val_loss : 57758.140625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 401 | train_loss : 46712.50390625 | val_loss : 9548.5341796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 402 | train_loss : 31458.28515625 | val_loss : 10196.3671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 403 | train_loss : 21888.4140625 | val_loss : 13999.205078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 404 | train_loss : 16611.146484375 | val_loss : 22427.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 405 | train_loss : 16866.927734375 | val_loss : 11186.33203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 406 | train_loss : 14886.759765625 | val_loss : 16786.4453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 407 | train_loss : 14682.197265625 | val_loss : 16815.5 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 408 | train_loss : 20861.90234375 | val_loss : 22203.67578125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 409 | train_loss : 20137.728515625 | val_loss : 15707.3701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 410 | train_loss : 21316.14453125 | val_loss : 22328.130859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 411 | train_loss : 16695.05078125 | val_loss : 17597.40625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 412 | train_loss : 19763.7578125 | val_loss : 24207.955078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 413 | train_loss : 21038.72265625 | val_loss : 16074.634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 414 | train_loss : 20664.5703125 | val_loss : 20190.541015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 415 | train_loss : 15063.73046875 | val_loss : 17575.505859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 416 | train_loss : 20419.443359375 | val_loss : 24268.08984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 417 | train_loss : 21112.2109375 | val_loss : 14455.95703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 418 | train_loss : 18635.34765625 | val_loss : 16833.244140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 419 | train_loss : 14123.37890625 | val_loss : 14606.130859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 420 | train_loss : 19831.341796875 | val_loss : 19360.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 421 | train_loss : 16586.94140625 | val_loss : 10517.5087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 422 | train_loss : 11412.01171875 | val_loss : 14525.37109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 423 | train_loss : 8823.142578125 | val_loss : 34520.86328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 424 | train_loss : 58968.73828125 | val_loss : 41267.328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 425 | train_loss : 37692.515625 | val_loss : 38287.8046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 426 | train_loss : 24498.740234375 | val_loss : 25653.10546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 427 | train_loss : 19831.0859375 | val_loss : 24147.580078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 428 | train_loss : 14144.00390625 | val_loss : 16817.62109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 429 | train_loss : 13908.4326171875 | val_loss : 28305.0859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 430 | train_loss : 20938.439453125 | val_loss : 20987.779296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 431 | train_loss : 21467.123046875 | val_loss : 27062.0859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 432 | train_loss : 23581.142578125 | val_loss : 13421.48828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 433 | train_loss : 15873.2587890625 | val_loss : 20324.55078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 434 | train_loss : 18544.640625 | val_loss : 10223.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 435 | train_loss : 16386.642578125 | val_loss : 16873.205078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 436 | train_loss : 14392.9853515625 | val_loss : 8707.9921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 437 | train_loss : 11632.7353515625 | val_loss : 10921.5888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 438 | train_loss : 8563.5791015625 | val_loss : 8047.5185546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 439 | train_loss : 12703.6064453125 | val_loss : 13930.009765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 440 | train_loss : 11910.8798828125 | val_loss : 6635.65380859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 441 | train_loss : 12930.2041015625 | val_loss : 16245.7109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 442 | train_loss : 14415.0888671875 | val_loss : 6226.208984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 443 | train_loss : 9582.5966796875 | val_loss : 13764.1826171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 444 | train_loss : 11369.9208984375 | val_loss : 4014.273681640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 445 | train_loss : 8633.9921875 | val_loss : 16990.8203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 446 | train_loss : 13056.96875 | val_loss : 9279.6611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 447 | train_loss : 13834.45703125 | val_loss : 13838.5439453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 448 | train_loss : 11714.15234375 | val_loss : 9679.0322265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 449 | train_loss : 13166.927734375 | val_loss : 12812.3828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 450 | train_loss : 11040.5927734375 | val_loss : 7993.55859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 451 | train_loss : 11648.259765625 | val_loss : 20017.212890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 452 | train_loss : 13442.6376953125 | val_loss : 9112.92578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 453 | train_loss : 12070.51953125 | val_loss : 17176.623046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 454 | train_loss : 12047.25390625 | val_loss : 6908.0 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 455 | train_loss : 9815.341796875 | val_loss : 14788.80859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 456 | train_loss : 10964.259765625 | val_loss : 5746.40869140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 457 | train_loss : 8703.9384765625 | val_loss : 9631.6123046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 458 | train_loss : 7986.78271484375 | val_loss : 8847.96484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 459 | train_loss : 10826.86328125 | val_loss : 14818.85546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 460 | train_loss : 13017.193359375 | val_loss : 8937.2958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 461 | train_loss : 12218.2275390625 | val_loss : 18007.626953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 462 | train_loss : 12615.1103515625 | val_loss : 5130.427734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 463 | train_loss : 7602.0732421875 | val_loss : 16653.265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 464 | train_loss : 11631.3251953125 | val_loss : 7714.759765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 465 | train_loss : 9738.51171875 | val_loss : 16978.87109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 466 | train_loss : 13792.6845703125 | val_loss : 7230.39892578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 467 | train_loss : 9831.0068359375 | val_loss : 13455.5439453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 468 | train_loss : 9539.0185546875 | val_loss : 6640.2685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 469 | train_loss : 8749.7265625 | val_loss : 17304.11328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 470 | train_loss : 13659.5439453125 | val_loss : 9984.7353515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 471 | train_loss : 10175.9072265625 | val_loss : 14283.611328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 472 | train_loss : 12860.9384765625 | val_loss : 11834.787109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 473 | train_loss : 14301.9150390625 | val_loss : 19500.5234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 474 | train_loss : 13746.5810546875 | val_loss : 7474.25390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 475 | train_loss : 8844.9189453125 | val_loss : 12599.548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 476 | train_loss : 12566.9462890625 | val_loss : 10563.9404296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 477 | train_loss : 14458.4677734375 | val_loss : 17489.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 478 | train_loss : 15505.662109375 | val_loss : 8846.240234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 479 | train_loss : 9182.994140625 | val_loss : 11683.8779296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 480 | train_loss : 11633.2158203125 | val_loss : 9827.7041015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 481 | train_loss : 12947.7001953125 | val_loss : 21308.369140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 482 | train_loss : 16781.712890625 | val_loss : 11345.8525390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 483 | train_loss : 12560.580078125 | val_loss : 16527.373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 484 | train_loss : 14996.1826171875 | val_loss : 10136.181640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 485 | train_loss : 14503.6083984375 | val_loss : 13650.009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 486 | train_loss : 9866.94921875 | val_loss : 6336.736328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 487 | train_loss : 8514.1533203125 | val_loss : 13290.7978515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 488 | train_loss : 10539.7646484375 | val_loss : 8572.537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 489 | train_loss : 11308.5185546875 | val_loss : 16970.45703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 490 | train_loss : 14843.1962890625 | val_loss : 10223.1611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 491 | train_loss : 10527.19921875 | val_loss : 15126.8876953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 492 | train_loss : 11281.7021484375 | val_loss : 4147.15380859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 493 | train_loss : 6285.10302734375 | val_loss : 13130.9052734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 494 | train_loss : 10397.416015625 | val_loss : 6044.27978515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 495 | train_loss : 8164.1962890625 | val_loss : 8155.29931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 496 | train_loss : 5880.7783203125 | val_loss : 6349.82763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 497 | train_loss : 7241.68603515625 | val_loss : 15663.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 498 | train_loss : 13613.166015625 | val_loss : 7347.1650390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 499 | train_loss : 8238.7900390625 | val_loss : 14767.236328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 500 | train_loss : 9867.572265625 | val_loss : 10327.3740234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 501 | train_loss : 11023.2138671875 | val_loss : 13045.8154296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 502 | train_loss : 10377.0478515625 | val_loss : 9663.6552734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 503 | train_loss : 11199.943359375 | val_loss : 17505.16796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 504 | train_loss : 11470.3662109375 | val_loss : 9606.9970703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 505 | train_loss : 10134.2529296875 | val_loss : 14017.1552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 506 | train_loss : 12144.7060546875 | val_loss : 11739.5146484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 507 | train_loss : 12879.4521484375 | val_loss : 20719.869140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 508 | train_loss : 15836.8876953125 | val_loss : 5568.224609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 509 | train_loss : 5976.84423828125 | val_loss : 9206.619140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 510 | train_loss : 6902.92431640625 | val_loss : 7084.66796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 511 | train_loss : 9508.2890625 | val_loss : 10988.22265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 512 | train_loss : 8236.9853515625 | val_loss : 8590.78125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 513 | train_loss : 9741.93359375 | val_loss : 13221.0185546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 514 | train_loss : 10279.6083984375 | val_loss : 6806.81005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 515 | train_loss : 8106.6220703125 | val_loss : 11929.5791015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 516 | train_loss : 8117.75 | val_loss : 7939.14208984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 517 | train_loss : 11102.8740234375 | val_loss : 17787.341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 518 | train_loss : 13555.951171875 | val_loss : 5880.41015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 519 | train_loss : 5779.8623046875 | val_loss : 13262.75 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 520 | train_loss : 7137.97509765625 | val_loss : 6142.13623046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 521 | train_loss : 8164.44189453125 | val_loss : 11784.0341796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 522 | train_loss : 7226.49267578125 | val_loss : 3750.054443359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 523 | train_loss : 5527.41015625 | val_loss : 9537.501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 524 | train_loss : 7253.37451171875 | val_loss : 7535.69677734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 525 | train_loss : 10017.16796875 | val_loss : 13811.16796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 526 | train_loss : 10495.9521484375 | val_loss : 6938.17919921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 527 | train_loss : 10159.228515625 | val_loss : 15640.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 528 | train_loss : 12506.201171875 | val_loss : 6860.4423828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 529 | train_loss : 10096.513671875 | val_loss : 13700.5703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 530 | train_loss : 10153.7294921875 | val_loss : 7086.0380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 531 | train_loss : 7105.11865234375 | val_loss : 11290.2021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 532 | train_loss : 9412.412109375 | val_loss : 10941.912109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 533 | train_loss : 7110.857421875 | val_loss : 7621.9345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 534 | train_loss : 6654.259765625 | val_loss : 11725.4248046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 535 | train_loss : 7445.46044921875 | val_loss : 10058.8984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 536 | train_loss : 11040.291015625 | val_loss : 13132.2275390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 537 | train_loss : 12388.7333984375 | val_loss : 5833.2529296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 538 | train_loss : 4434.98583984375 | val_loss : 5636.0810546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 539 | train_loss : 5658.81103515625 | val_loss : 8050.095703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 540 | train_loss : 7559.23046875 | val_loss : 11472.30078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 541 | train_loss : 10042.3916015625 | val_loss : 8042.78564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 542 | train_loss : 7822.72314453125 | val_loss : 10320.6328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 543 | train_loss : 6741.75 | val_loss : 4067.733154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 544 | train_loss : 4855.17333984375 | val_loss : 10468.30078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 545 | train_loss : 8992.0859375 | val_loss : 5516.5126953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 546 | train_loss : 5720.61865234375 | val_loss : 7897.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 547 | train_loss : 6975.29296875 | val_loss : 7054.853515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 548 | train_loss : 7359.28564453125 | val_loss : 5805.3974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 549 | train_loss : 6025.720703125 | val_loss : 9454.94921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 550 | train_loss : 8499.8271484375 | val_loss : 13103.1171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 551 | train_loss : 9289.349609375 | val_loss : 7914.818359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 552 | train_loss : 6840.0537109375 | val_loss : 8487.3740234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 553 | train_loss : 6688.76123046875 | val_loss : 12773.9921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 554 | train_loss : 11374.8740234375 | val_loss : 10028.2802734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 555 | train_loss : 11360.1748046875 | val_loss : 15666.85546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 556 | train_loss : 13281.6162109375 | val_loss : 10723.5498046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 557 | train_loss : 11037.3154296875 | val_loss : 8285.8740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 558 | train_loss : 7345.6337890625 | val_loss : 4722.216796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 559 | train_loss : 6731.47119140625 | val_loss : 10389.3779296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 560 | train_loss : 10707.6708984375 | val_loss : 4499.279296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 561 | train_loss : 7855.7470703125 | val_loss : 8987.0712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 562 | train_loss : 7481.27978515625 | val_loss : 5015.46142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 563 | train_loss : 7930.88134765625 | val_loss : 9196.7373046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 564 | train_loss : 7352.7900390625 | val_loss : 7277.13818359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 565 | train_loss : 11128.697265625 | val_loss : 12056.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 566 | train_loss : 12619.92578125 | val_loss : 7024.95751953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 567 | train_loss : 11431.9453125 | val_loss : 14192.4453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 568 | train_loss : 12613.5791015625 | val_loss : 10280.45703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 569 | train_loss : 12986.8759765625 | val_loss : 11913.7275390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 570 | train_loss : 11836.263671875 | val_loss : 8249.498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 571 | train_loss : 12337.0947265625 | val_loss : 18125.458984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 572 | train_loss : 12102.462890625 | val_loss : 6301.2470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 573 | train_loss : 6814.49755859375 | val_loss : 10593.51171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 574 | train_loss : 7153.365234375 | val_loss : 5196.349609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 575 | train_loss : 7790.84619140625 | val_loss : 11954.1220703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 576 | train_loss : 9804.080078125 | val_loss : 8074.08251953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 577 | train_loss : 10209.580078125 | val_loss : 10243.5966796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 578 | train_loss : 8112.5654296875 | val_loss : 4868.537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 579 | train_loss : 7779.47509765625 | val_loss : 9416.8076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 580 | train_loss : 7444.5810546875 | val_loss : 3412.094970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 581 | train_loss : 4904.27734375 | val_loss : 7790.46875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 582 | train_loss : 6423.60205078125 | val_loss : 4539.77978515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 583 | train_loss : 6141.712890625 | val_loss : 9808.990234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 584 | train_loss : 7237.61767578125 | val_loss : 5599.9501953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 585 | train_loss : 6566.111328125 | val_loss : 10116.130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 586 | train_loss : 10020.5126953125 | val_loss : 6113.7685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 587 | train_loss : 8109.0908203125 | val_loss : 12813.103515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 588 | train_loss : 10087.6318359375 | val_loss : 6405.765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 589 | train_loss : 8060.1923828125 | val_loss : 10001.787109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 590 | train_loss : 7919.70703125 | val_loss : 13832.4697265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 591 | train_loss : 11561.0615234375 | val_loss : 11002.2578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 592 | train_loss : 9410.48828125 | val_loss : 3100.08447265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 593 | train_loss : 5262.97021484375 | val_loss : 8142.04541015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 594 | train_loss : 6844.7548828125 | val_loss : 5819.73681640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 595 | train_loss : 7720.00927734375 | val_loss : 11334.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 596 | train_loss : 9388.3828125 | val_loss : 4202.8525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 597 | train_loss : 5195.69482421875 | val_loss : 10719.03515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 598 | train_loss : 7717.2099609375 | val_loss : 7497.33056640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 599 | train_loss : 8950.66015625 | val_loss : 19109.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 600 | train_loss : 14417.3251953125 | val_loss : 8919.099609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 601 | train_loss : 10415.447265625 | val_loss : 12295.625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 602 | train_loss : 9427.6708984375 | val_loss : 2939.49365234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 603 | train_loss : 5350.94921875 | val_loss : 10768.6474609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 604 | train_loss : 8781.6240234375 | val_loss : 4887.19921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 605 | train_loss : 8332.6123046875 | val_loss : 9053.0595703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 606 | train_loss : 7429.5068359375 | val_loss : 4155.3330078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 607 | train_loss : 6850.6005859375 | val_loss : 13615.34375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 608 | train_loss : 10604.76171875 | val_loss : 5161.4287109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 609 | train_loss : 6331.4033203125 | val_loss : 7334.728515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 610 | train_loss : 5350.205078125 | val_loss : 3025.5693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 611 | train_loss : 5702.28759765625 | val_loss : 13450.775390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 612 | train_loss : 9556.19140625 | val_loss : 5881.8369140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 613 | train_loss : 6110.78369140625 | val_loss : 10070.5576171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 614 | train_loss : 10033.93359375 | val_loss : 11566.6376953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 615 | train_loss : 12551.017578125 | val_loss : 6220.587890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 616 | train_loss : 5740.22998046875 | val_loss : 7517.02734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 617 | train_loss : 5805.7099609375 | val_loss : 9949.482421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 618 | train_loss : 8266.1015625 | val_loss : 11185.2138671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 619 | train_loss : 9144.6865234375 | val_loss : 7068.189453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 620 | train_loss : 6673.75927734375 | val_loss : 8467.369140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 621 | train_loss : 8079.69384765625 | val_loss : 6667.0693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 622 | train_loss : 6285.98291015625 | val_loss : 8039.60498046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 623 | train_loss : 7918.5595703125 | val_loss : 5299.4892578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 624 | train_loss : 5715.91748046875 | val_loss : 4538.53857421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 625 | train_loss : 5219.9404296875 | val_loss : 4857.06396484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 626 | train_loss : 4731.8388671875 | val_loss : 5342.68603515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 627 | train_loss : 5571.10986328125 | val_loss : 6670.26318359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 628 | train_loss : 6035.0107421875 | val_loss : 5894.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 629 | train_loss : 6199.43994140625 | val_loss : 8132.724609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 630 | train_loss : 8521.83984375 | val_loss : 14364.3984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 631 | train_loss : 10211.7802734375 | val_loss : 6355.8017578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 632 | train_loss : 6680.47119140625 | val_loss : 9564.2802734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 633 | train_loss : 6817.6201171875 | val_loss : 4055.4111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 634 | train_loss : 6750.8623046875 | val_loss : 11740.142578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 635 | train_loss : 8305.6552734375 | val_loss : 4102.701171875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 636 | train_loss : 7003.5849609375 | val_loss : 8480.712890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 637 | train_loss : 6914.984375 | val_loss : 3525.769287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 638 | train_loss : 6016.55859375 | val_loss : 8462.349609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 639 | train_loss : 6929.775390625 | val_loss : 5981.87255859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 640 | train_loss : 8606.0078125 | val_loss : 8711.3740234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 641 | train_loss : 7314.7529296875 | val_loss : 4787.59423828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 642 | train_loss : 6773.89013671875 | val_loss : 13336.9365234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 643 | train_loss : 9673.73046875 | val_loss : 5868.34814453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 644 | train_loss : 7415.47509765625 | val_loss : 14028.080078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 645 | train_loss : 9547.11328125 | val_loss : 5845.53955078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 646 | train_loss : 8599.90234375 | val_loss : 8109.533203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 647 | train_loss : 6125.71728515625 | val_loss : 7133.6845703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 648 | train_loss : 8774.1279296875 | val_loss : 10464.2216796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 649 | train_loss : 9001.490234375 | val_loss : 7617.46630859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 650 | train_loss : 10215.8857421875 | val_loss : 17815.998046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 651 | train_loss : 11601.5966796875 | val_loss : 6761.58935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 652 | train_loss : 7180.29296875 | val_loss : 5697.076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 653 | train_loss : 4078.80224609375 | val_loss : 7475.4111328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 654 | train_loss : 7388.98828125 | val_loss : 8943.91015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 655 | train_loss : 8416.4404296875 | val_loss : 7346.6845703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 656 | train_loss : 7032.94580078125 | val_loss : 9802.91796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 657 | train_loss : 7877.02978515625 | val_loss : 7823.58544921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 658 | train_loss : 7304.85107421875 | val_loss : 5135.4501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 659 | train_loss : 3298.5361328125 | val_loss : 2198.791259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 660 | train_loss : 3163.599609375 | val_loss : 6912.82080078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 661 | train_loss : 4823.7587890625 | val_loss : 6640.65869140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 662 | train_loss : 6495.384765625 | val_loss : 8485.6591796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 663 | train_loss : 8335.6572265625 | val_loss : 5746.44921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 664 | train_loss : 7864.82763671875 | val_loss : 8060.44384765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 665 | train_loss : 7450.8251953125 | val_loss : 3382.476318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 666 | train_loss : 5920.17333984375 | val_loss : 8791.248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 667 | train_loss : 7705.29541015625 | val_loss : 5793.623046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 668 | train_loss : 7777.78857421875 | val_loss : 47504.81640625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 669 | train_loss : 35932.2265625 | val_loss : 20075.927734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 670 | train_loss : 24406.724609375 | val_loss : 16006.6416015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 671 | train_loss : 14945.193359375 | val_loss : 4793.69384765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 672 | train_loss : 6918.93310546875 | val_loss : 11536.537109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 673 | train_loss : 9007.33984375 | val_loss : 3506.701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 674 | train_loss : 6530.57421875 | val_loss : 9449.02734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 675 | train_loss : 7672.978515625 | val_loss : 4069.92626953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 676 | train_loss : 5742.78564453125 | val_loss : 10317.40625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 677 | train_loss : 7866.04248046875 | val_loss : 4283.95361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 678 | train_loss : 6288.341796875 | val_loss : 5984.15380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 679 | train_loss : 3850.172607421875 | val_loss : 5222.58642578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 680 | train_loss : 6804.234375 | val_loss : 10093.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 681 | train_loss : 9314.494140625 | val_loss : 3215.953857421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 682 | train_loss : 4391.54541015625 | val_loss : 8206.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 683 | train_loss : 6729.06005859375 | val_loss : 3460.4599609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 684 | train_loss : 5195.2080078125 | val_loss : 10772.8896484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 685 | train_loss : 7869.81884765625 | val_loss : 3311.73193359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 686 | train_loss : 4220.80322265625 | val_loss : 5058.41259765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 687 | train_loss : 4608.4794921875 | val_loss : 4274.10107421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 688 | train_loss : 4213.4951171875 | val_loss : 66966.25 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 689 | train_loss : 68591.0078125 | val_loss : 13760.6025390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 690 | train_loss : 13228.2998046875 | val_loss : 20401.7109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 691 | train_loss : 18095.638671875 | val_loss : 20398.3203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 692 | train_loss : 18631.078125 | val_loss : 10413.5166015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 693 | train_loss : 8252.4013671875 | val_loss : 6337.380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 694 | train_loss : 7148.25390625 | val_loss : 6957.44921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 695 | train_loss : 7000.58740234375 | val_loss : 2377.73193359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 696 | train_loss : 3725.11181640625 | val_loss : 8657.3984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 697 | train_loss : 5505.46630859375 | val_loss : 3105.7587890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 698 | train_loss : 5009.0400390625 | val_loss : 5958.34814453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 699 | train_loss : 3946.17333984375 | val_loss : 3425.27685546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 700 | train_loss : 6421.1376953125 | val_loss : 10174.779296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 701 | train_loss : 7277.98583984375 | val_loss : 2669.954345703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 702 | train_loss : 4465.32666015625 | val_loss : 6905.787109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 703 | train_loss : 4807.0517578125 | val_loss : 3427.686767578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 704 | train_loss : 5513.517578125 | val_loss : 9488.134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 705 | train_loss : 8110.041015625 | val_loss : 25709.384765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 706 | train_loss : 26209.85546875 | val_loss : 16493.623046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 707 | train_loss : 14297.1533203125 | val_loss : 13977.15234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 708 | train_loss : 16143.2548828125 | val_loss : 13614.0751953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 709 | train_loss : 11553.4970703125 | val_loss : 9474.44921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 710 | train_loss : 10689.107421875 | val_loss : 9553.5546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 711 | train_loss : 8967.5751953125 | val_loss : 6600.9794921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 712 | train_loss : 7773.244140625 | val_loss : 9220.3115234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 713 | train_loss : 7476.19140625 | val_loss : 4116.97119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 714 | train_loss : 4922.10986328125 | val_loss : 5685.1630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 715 | train_loss : 4310.01220703125 | val_loss : 7044.0654296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 716 | train_loss : 8179.68359375 | val_loss : 8813.2431640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 717 | train_loss : 7947.62109375 | val_loss : 5108.86572265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 718 | train_loss : 5896.44482421875 | val_loss : 9434.12890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 719 | train_loss : 7473.46875 | val_loss : 3678.3388671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 720 | train_loss : 4490.18603515625 | val_loss : 10107.158203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 721 | train_loss : 6619.14013671875 | val_loss : 6450.20361328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 722 | train_loss : 6213.31298828125 | val_loss : 5332.587890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 723 | train_loss : 4013.271484375 | val_loss : 4813.646484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 724 | train_loss : 4092.078857421875 | val_loss : 5276.64111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 725 | train_loss : 6584.8994140625 | val_loss : 4845.70947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 726 | train_loss : 4686.4296875 | val_loss : 3871.906982421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 727 | train_loss : 4248.1064453125 | val_loss : 6277.123046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 728 | train_loss : 5169.55419921875 | val_loss : 5686.021484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 729 | train_loss : 5451.73291015625 | val_loss : 4832.72607421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 730 | train_loss : 4297.54638671875 | val_loss : 5038.34521484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 731 | train_loss : 5813.17822265625 | val_loss : 6710.36083984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 732 | train_loss : 5779.8701171875 | val_loss : 4927.29296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 733 | train_loss : 4842.3125 | val_loss : 3953.963134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 734 | train_loss : 3761.7548828125 | val_loss : 3500.6064453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 735 | train_loss : 5218.93896484375 | val_loss : 10885.6201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 736 | train_loss : 7427.1064453125 | val_loss : 4656.0654296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 737 | train_loss : 3978.243408203125 | val_loss : 2685.451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 738 | train_loss : 4298.017578125 | val_loss : 6649.33251953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 739 | train_loss : 4610.2236328125 | val_loss : 2389.193115234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 740 | train_loss : 6130.02197265625 | val_loss : 7031.994140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 741 | train_loss : 5420.75 | val_loss : 1544.699951171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 742 | train_loss : 5365.52001953125 | val_loss : 8599.90234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 743 | train_loss : 6253.2880859375 | val_loss : 2684.840576171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 744 | train_loss : 5442.81005859375 | val_loss : 6409.00732421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 745 | train_loss : 4814.36279296875 | val_loss : 2554.62939453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 746 | train_loss : 4483.03955078125 | val_loss : 9008.5205078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 747 | train_loss : 7126.4130859375 | val_loss : 2172.951904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 748 | train_loss : 3934.774658203125 | val_loss : 7342.05517578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 749 | train_loss : 5150.37158203125 | val_loss : 4306.75048828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 750 | train_loss : 6005.18798828125 | val_loss : 11210.92578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 751 | train_loss : 7204.572265625 | val_loss : 2622.6806640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 752 | train_loss : 3357.256591796875 | val_loss : 10820.4033203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 753 | train_loss : 6565.4111328125 | val_loss : 4699.4150390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 754 | train_loss : 4654.103515625 | val_loss : 5855.03173828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 755 | train_loss : 3533.8037109375 | val_loss : 4400.90234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 756 | train_loss : 6769.94140625 | val_loss : 7077.869140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 757 | train_loss : 5951.83203125 | val_loss : 3201.0361328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 758 | train_loss : 4626.37255859375 | val_loss : 6289.744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 759 | train_loss : 6154.5087890625 | val_loss : 1652.54443359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 760 | train_loss : 3838.383056640625 | val_loss : 7680.7451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 761 | train_loss : 6241.60888671875 | val_loss : 4317.33251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 762 | train_loss : 5487.515625 | val_loss : 5393.6494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 763 | train_loss : 4474.08154296875 | val_loss : 4607.60546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 764 | train_loss : 6431.81103515625 | val_loss : 10008.2978515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 765 | train_loss : 7660.3974609375 | val_loss : 5144.72802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 766 | train_loss : 6350.01513671875 | val_loss : 7826.28564453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 767 | train_loss : 5453.1005859375 | val_loss : 4825.46826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 768 | train_loss : 6536.8095703125 | val_loss : 13403.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 769 | train_loss : 8266.9716796875 | val_loss : 6080.7314453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 770 | train_loss : 4852.9990234375 | val_loss : 4080.79248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 771 | train_loss : 4734.564453125 | val_loss : 22071.693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 772 | train_loss : 21349.419921875 | val_loss : 17362.080078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 773 | train_loss : 14727.6240234375 | val_loss : 13530.3154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 774 | train_loss : 15211.4091796875 | val_loss : 5830.2119140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 775 | train_loss : 6048.72021484375 | val_loss : 5851.28515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 776 | train_loss : 4881.40673828125 | val_loss : 6477.91455078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 777 | train_loss : 5223.541015625 | val_loss : 6081.2763671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 778 | train_loss : 5788.9501953125 | val_loss : 3707.4169921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 779 | train_loss : 3371.379638671875 | val_loss : 2774.558837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 780 | train_loss : 2860.888427734375 | val_loss : 3414.068115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 781 | train_loss : 3042.0634765625 | val_loss : 3717.758056640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 782 | train_loss : 4316.53515625 | val_loss : 3576.737548828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 783 | train_loss : 4131.15380859375 | val_loss : 3064.008056640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 784 | train_loss : 3219.10693359375 | val_loss : 3637.085693359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 785 | train_loss : 4061.046630859375 | val_loss : 6278.51611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 786 | train_loss : 6319.76953125 | val_loss : 3280.078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 787 | train_loss : 5269.98388671875 | val_loss : 6386.36376953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 788 | train_loss : 4743.10498046875 | val_loss : 1789.2261962890625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 789 | train_loss : 5917.63330078125 | val_loss : 6225.38427734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 790 | train_loss : 4515.02978515625 | val_loss : 1890.6580810546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 791 | train_loss : 5109.08740234375 | val_loss : 6658.7314453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 792 | train_loss : 4936.30908203125 | val_loss : 1330.7806396484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 793 | train_loss : 4510.41552734375 | val_loss : 7721.94189453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 794 | train_loss : 5581.83740234375 | val_loss : 2069.235595703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 795 | train_loss : 5466.5966796875 | val_loss : 6547.11865234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 796 | train_loss : 4728.2158203125 | val_loss : 2044.7305908203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 797 | train_loss : 4301.8544921875 | val_loss : 133982.8125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 798 | train_loss : 89737.7578125 | val_loss : 4324.82080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 799 | train_loss : 9371.859375 | val_loss : 7511.61767578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 800 | train_loss : 4807.71533203125 | val_loss : 7133.279296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 801 | train_loss : 6424.96630859375 | val_loss : 41086.0625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 802 | train_loss : 37587.765625 | val_loss : 17442.720703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 803 | train_loss : 15667.701171875 | val_loss : 7877.96484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 804 | train_loss : 10599.2197265625 | val_loss : 12592.8271484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 805 | train_loss : 9601.3125 | val_loss : 9495.634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 806 | train_loss : 9167.3515625 | val_loss : 9148.697265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 807 | train_loss : 7523.87939453125 | val_loss : 6416.40576171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 808 | train_loss : 6987.017578125 | val_loss : 5661.7724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 809 | train_loss : 4724.275390625 | val_loss : 2765.353759765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 810 | train_loss : 5203.24658203125 | val_loss : 5625.8408203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 811 | train_loss : 4759.7060546875 | val_loss : 2573.18505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 812 | train_loss : 5204.49560546875 | val_loss : 6235.18359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 813 | train_loss : 5287.04296875 | val_loss : 4384.443359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 814 | train_loss : 7243.072265625 | val_loss : 6999.365234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 815 | train_loss : 5920.27294921875 | val_loss : 2522.68115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 816 | train_loss : 4512.2177734375 | val_loss : 5512.080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 817 | train_loss : 4483.39501953125 | val_loss : 2437.264892578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 818 | train_loss : 4222.3037109375 | val_loss : 5562.23486328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 819 | train_loss : 4986.2490234375 | val_loss : 3484.27197265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 820 | train_loss : 4767.4609375 | val_loss : 6000.86572265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 821 | train_loss : 4419.140625 | val_loss : 1028.0731201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 822 | train_loss : 3103.654296875 | val_loss : 6279.19482421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 823 | train_loss : 4429.16015625 | val_loss : 1436.0931396484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 824 | train_loss : 3306.198974609375 | val_loss : 5831.08251953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 825 | train_loss : 3897.374267578125 | val_loss : 2043.3131103515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 826 | train_loss : 4667.49365234375 | val_loss : 6361.13232421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 827 | train_loss : 4636.02001953125 | val_loss : 1613.36376953125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 828 | train_loss : 2869.048828125 | val_loss : 4963.564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 829 | train_loss : 3847.9306640625 | val_loss : 2154.659423828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 830 | train_loss : 3724.593994140625 | val_loss : 7779.6474609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 831 | train_loss : 5548.28857421875 | val_loss : 3410.893798828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 832 | train_loss : 5451.87744140625 | val_loss : 4283.142578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 833 | train_loss : 3221.158203125 | val_loss : 2960.4736328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 834 | train_loss : 4587.68408203125 | val_loss : 5642.91015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 835 | train_loss : 5888.8056640625 | val_loss : 1641.5406494140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 836 | train_loss : 3058.975830078125 | val_loss : 6033.16552734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 837 | train_loss : 5427.99560546875 | val_loss : 2289.06689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 838 | train_loss : 3714.647705078125 | val_loss : 5569.1748046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 839 | train_loss : 3703.9755859375 | val_loss : 1002.6456298828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 840 | train_loss : 3282.484375 | val_loss : 6328.38134765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 841 | train_loss : 4838.0205078125 | val_loss : 1457.844970703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 842 | train_loss : 2951.599365234375 | val_loss : 5869.9287109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 843 | train_loss : 4229.15771484375 | val_loss : 1267.5169677734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 844 | train_loss : 3011.531494140625 | val_loss : 5185.73583984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 845 | train_loss : 4109.89306640625 | val_loss : 1467.6287841796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 846 | train_loss : 3232.352294921875 | val_loss : 7234.90771484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 847 | train_loss : 4812.5302734375 | val_loss : 2414.97119140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 848 | train_loss : 4224.95849609375 | val_loss : 3617.58935546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 849 | train_loss : 2892.2041015625 | val_loss : 2024.4237060546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 850 | train_loss : 3487.5234375 | val_loss : 6466.654296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 851 | train_loss : 5321.95361328125 | val_loss : 1133.797607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 852 | train_loss : 2228.422607421875 | val_loss : 3928.4443359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 853 | train_loss : 3197.7294921875 | val_loss : 3742.320556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 854 | train_loss : 5649.9873046875 | val_loss : 7186.79638671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 855 | train_loss : 5540.361328125 | val_loss : 3495.951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 856 | train_loss : 4549.7314453125 | val_loss : 13444.0224609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 857 | train_loss : 8669.8076171875 | val_loss : 7103.76611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 858 | train_loss : 6458.025390625 | val_loss : 4872.916015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 859 | train_loss : 3474.1630859375 | val_loss : 2685.095703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 860 | train_loss : 3586.863525390625 | val_loss : 3297.19189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 861 | train_loss : 3299.50146484375 | val_loss : 3173.9482421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 862 | train_loss : 4497.50439453125 | val_loss : 3401.52197265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 863 | train_loss : 3392.331787109375 | val_loss : 3424.58740234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 864 | train_loss : 4348.5673828125 | val_loss : 3560.56005859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 865 | train_loss : 3130.58056640625 | val_loss : 2655.177490234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 866 | train_loss : 4013.643798828125 | val_loss : 2663.3349609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 867 | train_loss : 3230.085693359375 | val_loss : 3594.693115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 868 | train_loss : 3982.779296875 | val_loss : 4140.65234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 869 | train_loss : 3384.7080078125 | val_loss : 2237.720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 870 | train_loss : 3119.001220703125 | val_loss : 5277.67236328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 871 | train_loss : 5217.57861328125 | val_loss : 6950.05322265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 872 | train_loss : 4702.927734375 | val_loss : 8049.19140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 873 | train_loss : 5815.06396484375 | val_loss : 1325.5675048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 874 | train_loss : 4036.830322265625 | val_loss : 7298.75830078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 875 | train_loss : 5527.63671875 | val_loss : 3839.982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 876 | train_loss : 6496.20458984375 | val_loss : 4837.53955078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 877 | train_loss : 4217.4365234375 | val_loss : 3842.8212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 878 | train_loss : 5977.65673828125 | val_loss : 6812.35498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 879 | train_loss : 6670.5283203125 | val_loss : 2459.084228515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 880 | train_loss : 4978.6669921875 | val_loss : 5471.7275390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 881 | train_loss : 4144.85009765625 | val_loss : 1550.697998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 882 | train_loss : 3705.51318359375 | val_loss : 5395.86328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 883 | train_loss : 4275.5693359375 | val_loss : 3563.92626953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 884 | train_loss : 5946.14892578125 | val_loss : 5130.453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 885 | train_loss : 3745.478759765625 | val_loss : 3787.85693359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 886 | train_loss : 6124.29833984375 | val_loss : 7347.67822265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 887 | train_loss : 6468.8955078125 | val_loss : 2911.721923828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 888 | train_loss : 3435.437255859375 | val_loss : 5996.87060546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 889 | train_loss : 3709.49462890625 | val_loss : 1866.2181396484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 890 | train_loss : 4184.181640625 | val_loss : 6914.244140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 891 | train_loss : 5109.59619140625 | val_loss : 1267.751220703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 892 | train_loss : 2697.890625 | val_loss : 5693.75146484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 893 | train_loss : 4099.8935546875 | val_loss : 1961.36181640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 894 | train_loss : 3726.68408203125 | val_loss : 7063.7724609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 895 | train_loss : 6069.42431640625 | val_loss : 1819.9437255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 896 | train_loss : 3317.6171875 | val_loss : 4856.24169921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 897 | train_loss : 4430.90771484375 | val_loss : 3181.8642578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 898 | train_loss : 4189.54736328125 | val_loss : 6510.48486328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 899 | train_loss : 5217.60546875 | val_loss : 2955.85693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 900 | train_loss : 2863.940673828125 | val_loss : 6284.25927734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 901 | train_loss : 4382.29541015625 | val_loss : 3291.688720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 902 | train_loss : 2873.795654296875 | val_loss : 3478.003173828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 903 | train_loss : 2449.932861328125 | val_loss : 3692.796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 904 | train_loss : 4270.23828125 | val_loss : 2024.4637451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 905 | train_loss : 2555.937744140625 | val_loss : 4069.75927734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 906 | train_loss : 3139.11376953125 | val_loss : 2705.081298828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 907 | train_loss : 3775.53271484375 | val_loss : 3308.6201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 908 | train_loss : 3501.94189453125 | val_loss : 2556.056884765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 909 | train_loss : 3241.5498046875 | val_loss : 3346.1787109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 910 | train_loss : 3533.69287109375 | val_loss : 4832.404296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 911 | train_loss : 5195.7890625 | val_loss : 5372.24609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 912 | train_loss : 5183.7177734375 | val_loss : 3924.4150390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 913 | train_loss : 3737.7900390625 | val_loss : 2488.855712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 914 | train_loss : 4234.7685546875 | val_loss : 4653.6025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 915 | train_loss : 5087.62060546875 | val_loss : 1883.9681396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 916 | train_loss : 3884.080322265625 | val_loss : 4383.4775390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 917 | train_loss : 4415.85205078125 | val_loss : 205554.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 918 | train_loss : 272318.90625 | val_loss : 125176.53125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 919 | train_loss : 120928.6171875 | val_loss : 27050.7890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 920 | train_loss : 23158.78515625 | val_loss : 14549.9072265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 921 | train_loss : 15186.92578125 | val_loss : 14388.974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 922 | train_loss : 14083.4140625 | val_loss : 14858.4873046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 923 | train_loss : 14593.16796875 | val_loss : 9249.8408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 924 | train_loss : 11688.650390625 | val_loss : 11555.3837890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 925 | train_loss : 11801.3212890625 | val_loss : 7022.38916015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 926 | train_loss : 9332.705078125 | val_loss : 50184.75 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 927 | train_loss : 51435.515625 | val_loss : 11697.107421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 928 | train_loss : 14919.84765625 | val_loss : 16007.333984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 929 | train_loss : 16312.337890625 | val_loss : 9673.6533203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 930 | train_loss : 9711.2919921875 | val_loss : 5734.2939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 931 | train_loss : 6784.31494140625 | val_loss : 5341.94580078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 932 | train_loss : 6163.4248046875 | val_loss : 3158.87939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 933 | train_loss : 4848.7431640625 | val_loss : 3457.9462890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 934 | train_loss : 3733.226318359375 | val_loss : 1625.375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 935 | train_loss : 2647.892578125 | val_loss : 3860.66552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 936 | train_loss : 3855.8359375 | val_loss : 3919.404296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 937 | train_loss : 4533.30029296875 | val_loss : 6275.06201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 938 | train_loss : 5290.7861328125 | val_loss : 1549.3369140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 939 | train_loss : 2807.121826171875 | val_loss : 4938.39697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 940 | train_loss : 3025.13916015625 | val_loss : 2512.109619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 941 | train_loss : 4371.85498046875 | val_loss : 5367.140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 942 | train_loss : 4542.7451171875 | val_loss : 1559.51123046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 943 | train_loss : 4318.53271484375 | val_loss : 7918.60009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 944 | train_loss : 6007.35693359375 | val_loss : 2014.2581787109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 945 | train_loss : 3965.0751953125 | val_loss : 3943.789306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 946 | train_loss : 2918.1640625 | val_loss : 2087.891357421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 947 | train_loss : 4709.26953125 | val_loss : 5536.5107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 948 | train_loss : 4044.0927734375 | val_loss : 2348.55126953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 949 | train_loss : 4102.083984375 | val_loss : 3981.513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 950 | train_loss : 3314.014892578125 | val_loss : 2671.4111328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 951 | train_loss : 3913.929443359375 | val_loss : 5751.16748046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 952 | train_loss : 3815.460693359375 | val_loss : 2129.6044921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 953 | train_loss : 3801.7451171875 | val_loss : 3818.488037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 954 | train_loss : 3134.32470703125 | val_loss : 2488.836181640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 955 | train_loss : 3812.6328125 | val_loss : 4725.42724609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 956 | train_loss : 3939.883056640625 | val_loss : 2143.793701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 957 | train_loss : 3470.32373046875 | val_loss : 4215.95703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 958 | train_loss : 3563.201904296875 | val_loss : 1955.26318359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 959 | train_loss : 3215.4580078125 | val_loss : 3948.419677734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 960 | train_loss : 3139.183837890625 | val_loss : 1948.75244140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 961 | train_loss : 3919.160888671875 | val_loss : 4279.04345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 962 | train_loss : 3360.5126953125 | val_loss : 1965.2730712890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 963 | train_loss : 3443.1015625 | val_loss : 4666.68603515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 964 | train_loss : 3828.358154296875 | val_loss : 2571.76123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 965 | train_loss : 3789.83837890625 | val_loss : 7321.03564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 966 | train_loss : 4255.8330078125 | val_loss : 4121.0068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 967 | train_loss : 4473.80126953125 | val_loss : 4477.2431640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 968 | train_loss : 3523.3896484375 | val_loss : 2378.716796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 969 | train_loss : 3105.710205078125 | val_loss : 3890.757080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 970 | train_loss : 3731.442138671875 | val_loss : 1650.170654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 971 | train_loss : 3231.338134765625 | val_loss : 4165.24267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 972 | train_loss : 3681.223388671875 | val_loss : 1940.15185546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 973 | train_loss : 3651.027099609375 | val_loss : 3509.0009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 974 | train_loss : 2746.1171875 | val_loss : 2575.20068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 975 | train_loss : 4416.13818359375 | val_loss : 5673.70068359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 976 | train_loss : 4161.68212890625 | val_loss : 2210.52001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 977 | train_loss : 2493.26708984375 | val_loss : 3144.411865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 978 | train_loss : 2661.1298828125 | val_loss : 1678.77001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 979 | train_loss : 3689.746337890625 | val_loss : 3938.99072265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 980 | train_loss : 3429.6943359375 | val_loss : 29240.099609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 981 | train_loss : 40525.6015625 | val_loss : 12731.2578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 982 | train_loss : 9398.73046875 | val_loss : 1789.3712158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 983 | train_loss : 2211.850341796875 | val_loss : 2128.642822265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 984 | train_loss : 1579.3089599609375 | val_loss : 1704.6815185546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 985 | train_loss : 2137.31494140625 | val_loss : 2141.853759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 986 | train_loss : 2047.21533203125 | val_loss : 1523.5543212890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 987 | train_loss : 2816.93310546875 | val_loss : 3752.3681640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 988 | train_loss : 3108.671142578125 | val_loss : 1654.145263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 989 | train_loss : 3304.2646484375 | val_loss : 4134.556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 990 | train_loss : 3819.269775390625 | val_loss : 1760.3363037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 991 | train_loss : 4232.93896484375 | val_loss : 3656.422607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 992 | train_loss : 3086.466796875 | val_loss : 1674.6175537109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 993 | train_loss : 3344.177734375 | val_loss : 3566.3525390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 994 | train_loss : 2727.557861328125 | val_loss : 1796.217529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 995 | train_loss : 3844.909423828125 | val_loss : 4447.86376953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 996 | train_loss : 3456.114990234375 | val_loss : 1710.3555908203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 997 | train_loss : 2372.899658203125 | val_loss : 3130.383056640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 998 | train_loss : 2873.9072265625 | val_loss : 1888.467529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 999 | train_loss : 2629.965576171875 | val_loss : 2598.403076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1000 | train_loss : 2288.047119140625 | val_loss : 3366.47314453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1001 | train_loss : 3355.38818359375 | val_loss : 4456.82958984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1002 | train_loss : 3823.271484375 | val_loss : 2335.84619140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1003 | train_loss : 2507.5810546875 | val_loss : 4948.86767578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1004 | train_loss : 3919.476318359375 | val_loss : 2554.7138671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1005 | train_loss : 3544.950927734375 | val_loss : 4325.173828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1006 | train_loss : 3562.24072265625 | val_loss : 950.6962280273438 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1007 | train_loss : 2914.7353515625 | val_loss : 55776.578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1008 | train_loss : 36993.5546875 | val_loss : 9965.2294921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1009 | train_loss : 14645.2373046875 | val_loss : 13323.79296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1010 | train_loss : 11395.0029296875 | val_loss : 9740.8203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1011 | train_loss : 10135.380859375 | val_loss : 4341.45556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1012 | train_loss : 4808.47607421875 | val_loss : 4212.36572265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1013 | train_loss : 3895.356201171875 | val_loss : 2051.22998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1014 | train_loss : 2311.7880859375 | val_loss : 3219.2724609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1015 | train_loss : 2373.3251953125 | val_loss : 1134.963134765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1016 | train_loss : 2333.6162109375 | val_loss : 3816.55712890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1017 | train_loss : 3203.5068359375 | val_loss : 1033.3768310546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1018 | train_loss : 3061.322509765625 | val_loss : 4653.06005859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1019 | train_loss : 3565.1015625 | val_loss : 1090.8218994140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1020 | train_loss : 2944.117431640625 | val_loss : 5130.47607421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1021 | train_loss : 4286.88232421875 | val_loss : 740.5675048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1022 | train_loss : 2425.4111328125 | val_loss : 4627.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1023 | train_loss : 3629.483154296875 | val_loss : 776.9349975585938 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1024 | train_loss : 3290.007568359375 | val_loss : 5031.0615234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1025 | train_loss : 4139.16064453125 | val_loss : 1625.7093505859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1026 | train_loss : 2581.1767578125 | val_loss : 5019.076171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1027 | train_loss : 4394.0751953125 | val_loss : 1295.9669189453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1028 | train_loss : 2286.5927734375 | val_loss : 3395.22314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1029 | train_loss : 3230.379638671875 | val_loss : 991.4406127929688 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1030 | train_loss : 2249.00439453125 | val_loss : 4670.048828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1031 | train_loss : 4260.6279296875 | val_loss : 1842.91748046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1032 | train_loss : 3374.33349609375 | val_loss : 4028.29833984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1033 | train_loss : 3641.1005859375 | val_loss : 129161.390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1034 | train_loss : 155297.421875 | val_loss : 13967.787109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1035 | train_loss : 11963.1533203125 | val_loss : 5734.22998046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1036 | train_loss : 5748.60009765625 | val_loss : 3553.983154296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1037 | train_loss : 3915.6298828125 | val_loss : 3056.9716796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1038 | train_loss : 3022.592529296875 | val_loss : 1315.0172119140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1039 | train_loss : 2950.408447265625 | val_loss : 2342.44189453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1040 | train_loss : 2485.62255859375 | val_loss : 496.87188720703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1041 | train_loss : 1781.654541015625 | val_loss : 3443.996337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1042 | train_loss : 3182.49755859375 | val_loss : 908.78125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1043 | train_loss : 2520.706298828125 | val_loss : 3257.205322265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1044 | train_loss : 2898.84912109375 | val_loss : 623.9662475585938 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1045 | train_loss : 2489.38427734375 | val_loss : 4391.74169921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1046 | train_loss : 3692.097412109375 | val_loss : 846.6659545898438 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1047 | train_loss : 2546.597900390625 | val_loss : 4585.89453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1048 | train_loss : 4309.240234375 | val_loss : 1063.9603271484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1049 | train_loss : 2786.80712890625 | val_loss : 3783.8759765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1050 | train_loss : 3716.4482421875 | val_loss : 1719.056884765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1051 | train_loss : 3231.319091796875 | val_loss : 4086.03662109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1052 | train_loss : 3614.710693359375 | val_loss : 1339.99658203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1053 | train_loss : 3021.10595703125 | val_loss : 4958.99267578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1054 | train_loss : 4171.70458984375 | val_loss : 1291.917236328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1055 | train_loss : 2427.860107421875 | val_loss : 3900.905029296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1056 | train_loss : 3345.063720703125 | val_loss : 1719.2724609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1057 | train_loss : 2624.26318359375 | val_loss : 6091.47705078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1058 | train_loss : 5753.708984375 | val_loss : 2023.180908203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1059 | train_loss : 3412.253173828125 | val_loss : 3720.90380859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1060 | train_loss : 3648.594970703125 | val_loss : 937.7831420898438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1061 | train_loss : 2084.86962890625 | val_loss : 2969.115966796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1062 | train_loss : 3113.715087890625 | val_loss : 1768.34033203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1063 | train_loss : 3191.7421875 | val_loss : 4199.21923828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1064 | train_loss : 3846.443359375 | val_loss : 1207.203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1065 | train_loss : 2300.00634765625 | val_loss : 2889.7509765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1066 | train_loss : 2421.43115234375 | val_loss : 2120.009033203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1067 | train_loss : 3236.93115234375 | val_loss : 4511.35693359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1068 | train_loss : 3818.024169921875 | val_loss : 896.5763549804688 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1069 | train_loss : 1701.776611328125 | val_loss : 3367.44775390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1070 | train_loss : 2022.1578369140625 | val_loss : 1715.478759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1071 | train_loss : 3799.056884765625 | val_loss : 4826.302734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1072 | train_loss : 3153.125732421875 | val_loss : 847.6743774414062 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1073 | train_loss : 2013.79248046875 | val_loss : 4094.7578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1074 | train_loss : 2836.61376953125 | val_loss : 1283.764404296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1075 | train_loss : 2786.697265625 | val_loss : 2558.43212890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1076 | train_loss : 2450.3291015625 | val_loss : 1642.17431640625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1077 | train_loss : 2737.7802734375 | val_loss : 4781.31103515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1078 | train_loss : 3940.8505859375 | val_loss : 1066.196533203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1079 | train_loss : 1702.82421875 | val_loss : 3450.804443359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1080 | train_loss : 2436.26318359375 | val_loss : 2991.029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1081 | train_loss : 3658.656982421875 | val_loss : 3731.094970703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1082 | train_loss : 2781.856201171875 | val_loss : 1054.4825439453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1083 | train_loss : 2029.88525390625 | val_loss : 3953.5166015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1084 | train_loss : 3421.71533203125 | val_loss : 1234.279052734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1085 | train_loss : 2692.176513671875 | val_loss : 2842.05322265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1086 | train_loss : 2462.030029296875 | val_loss : 596.46533203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1087 | train_loss : 2126.466552734375 | val_loss : 3312.114013671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1088 | train_loss : 3072.59375 | val_loss : 1162.9200439453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1089 | train_loss : 2103.70849609375 | val_loss : 3673.3310546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1090 | train_loss : 3231.349609375 | val_loss : 1350.16064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1091 | train_loss : 2713.74658203125 | val_loss : 3435.505859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1092 | train_loss : 2928.105224609375 | val_loss : 2556.841796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1093 | train_loss : 2925.569580078125 | val_loss : 3842.13525390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1094 | train_loss : 3593.485595703125 | val_loss : 615.8440551757812 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1095 | train_loss : 2081.255615234375 | val_loss : 2836.281005859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1096 | train_loss : 2005.42578125 | val_loss : 488.7565612792969 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1097 | train_loss : 2007.9202880859375 | val_loss : 2979.8154296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1098 | train_loss : 2241.813232421875 | val_loss : 1010.9806518554688 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1099 | train_loss : 1725.828857421875 | val_loss : 4057.454345703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1100 | train_loss : 2835.023193359375 | val_loss : 4886.03515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1101 | train_loss : 5261.54931640625 | val_loss : 3193.4013671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1102 | train_loss : 2059.10595703125 | val_loss : 964.166259765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1103 | train_loss : 2254.42822265625 | val_loss : 3540.931884765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1104 | train_loss : 3351.953857421875 | val_loss : 568.693115234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1105 | train_loss : 1869.5263671875 | val_loss : 3506.6650390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1106 | train_loss : 3088.50537109375 | val_loss : 1275.9615478515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1107 | train_loss : 2596.4482421875 | val_loss : 3121.662841796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1108 | train_loss : 3179.961669921875 | val_loss : 1058.989990234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1109 | train_loss : 2190.53857421875 | val_loss : 3530.4013671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1110 | train_loss : 3414.634033203125 | val_loss : 1461.2171630859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1111 | train_loss : 2278.658203125 | val_loss : 2864.762451171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1112 | train_loss : 2855.86376953125 | val_loss : 1255.6949462890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1113 | train_loss : 2231.986083984375 | val_loss : 2594.8935546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1114 | train_loss : 2629.179443359375 | val_loss : 1936.014404296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1115 | train_loss : 2627.409912109375 | val_loss : 4683.51953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1116 | train_loss : 4028.025634765625 | val_loss : 919.9237670898438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1117 | train_loss : 1797.0159912109375 | val_loss : 2406.915283203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1118 | train_loss : 2230.8681640625 | val_loss : 2576.29833984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1119 | train_loss : 3358.243408203125 | val_loss : 5074.8896484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1120 | train_loss : 4001.318115234375 | val_loss : 1592.4931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1121 | train_loss : 1851.096435546875 | val_loss : 1421.8187255859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1122 | train_loss : 1973.88916015625 | val_loss : 3083.7587890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1123 | train_loss : 3202.709716796875 | val_loss : 3918.355712890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1124 | train_loss : 3405.235107421875 | val_loss : 1383.4471435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1125 | train_loss : 2554.492919921875 | val_loss : 4331.70947265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1126 | train_loss : 3986.544677734375 | val_loss : 3043.17724609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1127 | train_loss : 3278.24462890625 | val_loss : 3996.46337890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1128 | train_loss : 3791.812255859375 | val_loss : 483.5859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1129 | train_loss : 1910.94482421875 | val_loss : 2686.092529296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1130 | train_loss : 2312.873046875 | val_loss : 1324.42431640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1131 | train_loss : 2815.696044921875 | val_loss : 3927.405517578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1132 | train_loss : 3660.243408203125 | val_loss : 687.306884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1133 | train_loss : 2116.48779296875 | val_loss : 3082.3662109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1134 | train_loss : 2524.638671875 | val_loss : 1970.5152587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1135 | train_loss : 3132.5107421875 | val_loss : 2607.89501953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1136 | train_loss : 2298.62646484375 | val_loss : 1285.1009521484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1137 | train_loss : 1980.0595703125 | val_loss : 2705.9423828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1138 | train_loss : 1952.5057373046875 | val_loss : 2142.91748046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1139 | train_loss : 2707.632080078125 | val_loss : 4543.30224609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1140 | train_loss : 3652.3837890625 | val_loss : 1142.6378173828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1141 | train_loss : 1437.5496826171875 | val_loss : 2358.975341796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1142 | train_loss : 1988.595458984375 | val_loss : 1815.1544189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1143 | train_loss : 2676.326904296875 | val_loss : 3061.651611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1144 | train_loss : 2355.6767578125 | val_loss : 1723.802490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1145 | train_loss : 2336.5517578125 | val_loss : 4405.28515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1146 | train_loss : 3732.328857421875 | val_loss : 1985.699951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1147 | train_loss : 3463.271240234375 | val_loss : 3394.660888671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1148 | train_loss : 2750.553466796875 | val_loss : 901.953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1149 | train_loss : 2822.1875 | val_loss : 4919.73681640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1150 | train_loss : 3694.555419921875 | val_loss : 2018.0933837890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1151 | train_loss : 2535.0947265625 | val_loss : 3550.0419921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1152 | train_loss : 2279.13330078125 | val_loss : 1603.934326171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1153 | train_loss : 3125.830078125 | val_loss : 3432.83935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1154 | train_loss : 2324.36572265625 | val_loss : 1429.315673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1155 | train_loss : 2566.391845703125 | val_loss : 3040.63623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1156 | train_loss : 2535.8486328125 | val_loss : 1462.78369140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1157 | train_loss : 2460.61865234375 | val_loss : 1920.12841796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1158 | train_loss : 1648.2542724609375 | val_loss : 1537.9393310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1159 | train_loss : 2520.59130859375 | val_loss : 3265.595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1160 | train_loss : 2863.938232421875 | val_loss : 1463.4425048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1161 | train_loss : 2614.72509765625 | val_loss : 2868.45751953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1162 | train_loss : 2617.587158203125 | val_loss : 20416.1328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1163 | train_loss : 29616.6015625 | val_loss : 8852.90234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1164 | train_loss : 6843.62939453125 | val_loss : 4342.87939453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1165 | train_loss : 5193.62939453125 | val_loss : 7870.986328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1166 | train_loss : 6457.412109375 | val_loss : 2583.14697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1167 | train_loss : 3831.999267578125 | val_loss : 5983.72021484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1168 | train_loss : 4475.69482421875 | val_loss : 2112.946533203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1169 | train_loss : 3128.698974609375 | val_loss : 3134.189697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1170 | train_loss : 2770.132080078125 | val_loss : 1521.9180908203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1171 | train_loss : 2639.250732421875 | val_loss : 2373.95556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1172 | train_loss : 2315.182861328125 | val_loss : 1574.143798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1173 | train_loss : 1934.2769775390625 | val_loss : 2507.28125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1174 | train_loss : 2204.8876953125 | val_loss : 1252.5206298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1175 | train_loss : 2723.021240234375 | val_loss : 2439.623779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1176 | train_loss : 2100.459716796875 | val_loss : 1107.659423828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1177 | train_loss : 2004.819580078125 | val_loss : 2531.47021484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1178 | train_loss : 2505.737548828125 | val_loss : 1268.0450439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1179 | train_loss : 2042.582763671875 | val_loss : 1597.9447021484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1180 | train_loss : 1489.8341064453125 | val_loss : 1443.6187744140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1181 | train_loss : 2557.127685546875 | val_loss : 4198.0712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1182 | train_loss : 3344.245849609375 | val_loss : 2021.9200439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1183 | train_loss : 2999.88525390625 | val_loss : 3252.594970703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1184 | train_loss : 2757.629150390625 | val_loss : 1899.75 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1185 | train_loss : 3069.011962890625 | val_loss : 2400.02587890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1186 | train_loss : 1827.1468505859375 | val_loss : 1172.7503662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1187 | train_loss : 2742.68310546875 | val_loss : 2995.225830078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1188 | train_loss : 2499.49072265625 | val_loss : 1151.658447265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1189 | train_loss : 1941.3433837890625 | val_loss : 2060.464111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1190 | train_loss : 2191.941162109375 | val_loss : 1318.1640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1191 | train_loss : 1891.5042724609375 | val_loss : 2096.5341796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1192 | train_loss : 1845.8348388671875 | val_loss : 2195.769287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1193 | train_loss : 2478.9111328125 | val_loss : 1877.78125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1194 | train_loss : 1913.8851318359375 | val_loss : 1283.2996826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1195 | train_loss : 1848.026123046875 | val_loss : 1992.64404296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1196 | train_loss : 2173.595947265625 | val_loss : 1174.86181640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1197 | train_loss : 1878.2550048828125 | val_loss : 1823.9302978515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1198 | train_loss : 1541.5592041015625 | val_loss : 1193.2471923828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1199 | train_loss : 3031.849609375 | val_loss : 4095.2587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1200 | train_loss : 3439.193115234375 | val_loss : 2071.26318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1201 | train_loss : 2908.523681640625 | val_loss : 3704.93603515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1202 | train_loss : 2863.64697265625 | val_loss : 751.4796752929688 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1203 | train_loss : 2326.854248046875 | val_loss : 3690.10595703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1204 | train_loss : 2942.544921875 | val_loss : 855.1181030273438 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1205 | train_loss : 2039.653564453125 | val_loss : 2676.1083984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1206 | train_loss : 1935.4390869140625 | val_loss : 1731.1162109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1207 | train_loss : 3131.133056640625 | val_loss : 2469.0 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1208 | train_loss : 1935.8916015625 | val_loss : 410.3822021484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1209 | train_loss : 1371.419677734375 | val_loss : 3087.3779296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1210 | train_loss : 2238.283203125 | val_loss : 1029.7515869140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1211 | train_loss : 2184.4736328125 | val_loss : 3829.801513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1212 | train_loss : 2588.787109375 | val_loss : 1848.4815673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1213 | train_loss : 1913.5198974609375 | val_loss : 1792.9124755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1214 | train_loss : 1221.7794189453125 | val_loss : 2043.181884765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1215 | train_loss : 2275.39990234375 | val_loss : 2589.140869140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1216 | train_loss : 2480.327392578125 | val_loss : 1322.571533203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1217 | train_loss : 1820.41748046875 | val_loss : 2122.055908203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1218 | train_loss : 1953.939697265625 | val_loss : 1149.6077880859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1219 | train_loss : 1895.1175537109375 | val_loss : 1978.9493408203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1220 | train_loss : 1487.9144287109375 | val_loss : 1059.79150390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1221 | train_loss : 1647.2655029296875 | val_loss : 2856.07373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1222 | train_loss : 2262.02587890625 | val_loss : 2161.196044921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1223 | train_loss : 2294.810791015625 | val_loss : 2038.271240234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1224 | train_loss : 1265.1220703125 | val_loss : 2541.976318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1225 | train_loss : 2500.081298828125 | val_loss : 1772.0556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1226 | train_loss : 1817.5517578125 | val_loss : 728.2531127929688 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1227 | train_loss : 1945.403076171875 | val_loss : 3710.888427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1228 | train_loss : 2992.102294921875 | val_loss : 2055.128662109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1229 | train_loss : 3040.3046875 | val_loss : 2514.3349609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1230 | train_loss : 2091.3134765625 | val_loss : 890.0406494140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1231 | train_loss : 2790.400634765625 | val_loss : 4370.79736328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1232 | train_loss : 3811.7705078125 | val_loss : 982.6843872070312 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1233 | train_loss : 2019.385009765625 | val_loss : 2985.8701171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1234 | train_loss : 2442.89111328125 | val_loss : 1611.1580810546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1235 | train_loss : 2838.3193359375 | val_loss : 1539.121826171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1236 | train_loss : 1506.5648193359375 | val_loss : 886.7237548828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1237 | train_loss : 1534.9541015625 | val_loss : 2008.1700439453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1238 | train_loss : 1948.790283203125 | val_loss : 1853.014404296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1239 | train_loss : 2496.47412109375 | val_loss : 1708.2978515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1240 | train_loss : 1996.7247314453125 | val_loss : 850.6734619140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1241 | train_loss : 1053.372314453125 | val_loss : 1347.5821533203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1242 | train_loss : 1513.950927734375 | val_loss : 2178.644287109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1243 | train_loss : 2169.9091796875 | val_loss : 2642.4130859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1244 | train_loss : 3348.7744140625 | val_loss : 3032.609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1245 | train_loss : 3113.0810546875 | val_loss : 2157.255615234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1246 | train_loss : 2050.047119140625 | val_loss : 3298.935302734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1247 | train_loss : 3354.839111328125 | val_loss : 2385.903076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1248 | train_loss : 2400.71728515625 | val_loss : 2325.629150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1249 | train_loss : 2602.1044921875 | val_loss : 1579.9300537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1250 | train_loss : 2039.60986328125 | val_loss : 2604.50634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1251 | train_loss : 2201.114990234375 | val_loss : 845.2047119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1252 | train_loss : 1241.3409423828125 | val_loss : 1796.4375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1253 | train_loss : 1597.393798828125 | val_loss : 1631.510009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1254 | train_loss : 2386.259521484375 | val_loss : 2011.892822265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1255 | train_loss : 2041.532470703125 | val_loss : 1376.174072265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1256 | train_loss : 1467.459228515625 | val_loss : 2074.380615234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1257 | train_loss : 2098.36572265625 | val_loss : 2305.121337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1258 | train_loss : 2737.438720703125 | val_loss : 2452.3095703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1259 | train_loss : 2401.494140625 | val_loss : 1387.3118896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1260 | train_loss : 1690.095947265625 | val_loss : 2406.15087890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1261 | train_loss : 2748.968505859375 | val_loss : 3417.389892578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1262 | train_loss : 3669.657470703125 | val_loss : 2134.384765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1263 | train_loss : 2467.060546875 | val_loss : 2537.853515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1264 | train_loss : 2467.98486328125 | val_loss : 2248.602294921875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1265 | train_loss : 2375.52978515625 | val_loss : 3511.36865234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1266 | train_loss : 3563.64599609375 | val_loss : 2075.128173828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1267 | train_loss : 2572.732177734375 | val_loss : 2297.796630859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1268 | train_loss : 1959.1878662109375 | val_loss : 1471.079345703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1269 | train_loss : 1948.203125 | val_loss : 2513.4541015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1270 | train_loss : 2845.764892578125 | val_loss : 1281.85498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1271 | train_loss : 1713.774169921875 | val_loss : 1057.4627685546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1272 | train_loss : 1364.1676025390625 | val_loss : 2042.861572265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1273 | train_loss : 1899.912353515625 | val_loss : 1809.634033203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1274 | train_loss : 2334.1884765625 | val_loss : 2309.539306640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1275 | train_loss : 2172.7548828125 | val_loss : 1309.642822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1276 | train_loss : 1551.375 | val_loss : 2005.76318359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1277 | train_loss : 1946.143798828125 | val_loss : 1557.1722412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1278 | train_loss : 2243.078857421875 | val_loss : 1731.3121337890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1279 | train_loss : 1777.217529296875 | val_loss : 1070.5196533203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1280 | train_loss : 1260.70166015625 | val_loss : 1498.1658935546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1281 | train_loss : 1524.6544189453125 | val_loss : 4405.49267578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1282 | train_loss : 3258.929443359375 | val_loss : 4186.99169921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1283 | train_loss : 4300.41357421875 | val_loss : 3673.28662109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1284 | train_loss : 3136.9482421875 | val_loss : 1761.4393310546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1285 | train_loss : 3764.691162109375 | val_loss : 3526.795654296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1286 | train_loss : 3133.097412109375 | val_loss : 1090.359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1287 | train_loss : 2803.1650390625 | val_loss : 2838.7578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1288 | train_loss : 2936.2705078125 | val_loss : 1023.146240234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1289 | train_loss : 3065.8115234375 | val_loss : 3184.10791015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1290 | train_loss : 3094.86865234375 | val_loss : 894.135009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1291 | train_loss : 2236.7109375 | val_loss : 2648.23583984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1292 | train_loss : 2157.515869140625 | val_loss : 1444.478759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1293 | train_loss : 3048.511474609375 | val_loss : 3962.823974609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1294 | train_loss : 3375.2509765625 | val_loss : 1006.0956420898438 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1295 | train_loss : 1820.5152587890625 | val_loss : 3135.78759765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1296 | train_loss : 2584.751953125 | val_loss : 1428.6231689453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1297 | train_loss : 2378.13427734375 | val_loss : 3529.8330078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1298 | train_loss : 3178.7529296875 | val_loss : 1113.3968505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1299 | train_loss : 1814.197509765625 | val_loss : 3034.953369140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1300 | train_loss : 1958.8790283203125 | val_loss : 876.359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1301 | train_loss : 1302.9136962890625 | val_loss : 2840.3115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1302 | train_loss : 2118.065673828125 | val_loss : 1643.80712890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1303 | train_loss : 2237.279296875 | val_loss : 2037.1859130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1304 | train_loss : 1557.73681640625 | val_loss : 882.3577880859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1305 | train_loss : 1577.049072265625 | val_loss : 3200.022705078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1306 | train_loss : 2598.70849609375 | val_loss : 1087.0855712890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1307 | train_loss : 1567.6087646484375 | val_loss : 3228.889404296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1308 | train_loss : 2910.270263671875 | val_loss : 952.5728759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1309 | train_loss : 1654.76416015625 | val_loss : 2568.886962890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1310 | train_loss : 2219.64599609375 | val_loss : 1418.4971923828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1311 | train_loss : 1585.92724609375 | val_loss : 2777.2041015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1312 | train_loss : 2392.145263671875 | val_loss : 542.1009521484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1313 | train_loss : 1446.200439453125 | val_loss : 2721.78759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1314 | train_loss : 1855.467529296875 | val_loss : 955.1443481445312 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1315 | train_loss : 1643.814208984375 | val_loss : 2518.529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1316 | train_loss : 1671.407958984375 | val_loss : 1398.018798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1317 | train_loss : 2589.806640625 | val_loss : 2621.231201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1318 | train_loss : 2116.001953125 | val_loss : 3665.07958984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1319 | train_loss : 3535.814697265625 | val_loss : 6148.86376953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1320 | train_loss : 4992.0205078125 | val_loss : 2564.15869140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1321 | train_loss : 2777.04931640625 | val_loss : 3257.07666015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1322 | train_loss : 2460.465576171875 | val_loss : 612.7237548828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1323 | train_loss : 1445.84619140625 | val_loss : 2512.413330078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1324 | train_loss : 1682.686279296875 | val_loss : 809.2000122070312 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1325 | train_loss : 1702.143798828125 | val_loss : 2741.859619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1326 | train_loss : 2101.223876953125 | val_loss : 1371.743408203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1327 | train_loss : 2366.648193359375 | val_loss : 2302.056884765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1328 | train_loss : 1951.32958984375 | val_loss : 569.2059326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1329 | train_loss : 1485.0831298828125 | val_loss : 2902.8515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1330 | train_loss : 2177.097900390625 | val_loss : 1758.1240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1331 | train_loss : 2603.821044921875 | val_loss : 2475.44384765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1332 | train_loss : 2057.99462890625 | val_loss : 749.5271606445312 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1333 | train_loss : 1433.7906494140625 | val_loss : 3946.960693359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1334 | train_loss : 3202.045654296875 | val_loss : 625.7840576171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1335 | train_loss : 1649.09130859375 | val_loss : 2696.830078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1336 | train_loss : 2179.70703125 | val_loss : 557.2368774414062 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1337 | train_loss : 1735.60400390625 | val_loss : 2624.81494140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1338 | train_loss : 2401.8583984375 | val_loss : 509.353759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1339 | train_loss : 1161.828369140625 | val_loss : 2067.640380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1340 | train_loss : 1971.21435546875 | val_loss : 406.0462646484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1341 | train_loss : 1410.0526123046875 | val_loss : 2460.8154296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1342 | train_loss : 2292.195556640625 | val_loss : 346.96624755859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1343 | train_loss : 1069.7314453125 | val_loss : 2172.422119140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1344 | train_loss : 1886.5548095703125 | val_loss : 683.111572265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1345 | train_loss : 1743.540283203125 | val_loss : 2676.129150390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1346 | train_loss : 2548.853759765625 | val_loss : 889.3018798828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1347 | train_loss : 1272.016845703125 | val_loss : 2611.2314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1348 | train_loss : 2250.9306640625 | val_loss : 1606.4066162109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1349 | train_loss : 1819.8154296875 | val_loss : 2946.01416015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1350 | train_loss : 2971.0947265625 | val_loss : 832.9124755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1351 | train_loss : 1353.5948486328125 | val_loss : 2053.3330078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1352 | train_loss : 1841.74462890625 | val_loss : 793.3193969726562 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1353 | train_loss : 1738.7144775390625 | val_loss : 2750.929931640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1354 | train_loss : 2552.504638671875 | val_loss : 926.639404296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1355 | train_loss : 1710.47998046875 | val_loss : 2543.029296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1356 | train_loss : 2333.840576171875 | val_loss : 1537.752197265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1357 | train_loss : 2014.88623046875 | val_loss : 2521.471923828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1358 | train_loss : 2337.05859375 | val_loss : 504.16094970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1359 | train_loss : 1140.362548828125 | val_loss : 1921.46533203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1360 | train_loss : 1605.7144775390625 | val_loss : 1481.1368408203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1361 | train_loss : 1696.0245361328125 | val_loss : 3420.95849609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1362 | train_loss : 2278.55810546875 | val_loss : 1051.0216064453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1363 | train_loss : 1336.438232421875 | val_loss : 2827.3818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1364 | train_loss : 1684.6669921875 | val_loss : 1391.2862548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1365 | train_loss : 1513.54931640625 | val_loss : 1657.2593994140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1366 | train_loss : 1112.7861328125 | val_loss : 1061.6265869140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1367 | train_loss : 2167.424560546875 | val_loss : 4741.3642578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1368 | train_loss : 3884.008056640625 | val_loss : 1650.6656494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1369 | train_loss : 2771.271240234375 | val_loss : 2481.250244140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1370 | train_loss : 1949.9720458984375 | val_loss : 1160.72412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1371 | train_loss : 2098.21337890625 | val_loss : 2939.323486328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1372 | train_loss : 2336.4853515625 | val_loss : 1579.5244140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1373 | train_loss : 2470.249755859375 | val_loss : 2129.35791015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1374 | train_loss : 1726.65380859375 | val_loss : 535.3093872070312 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1375 | train_loss : 1224.4425048828125 | val_loss : 1882.5430908203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1376 | train_loss : 1341.928466796875 | val_loss : 682.5365600585938 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1377 | train_loss : 1589.4180908203125 | val_loss : 2580.4189453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1378 | train_loss : 2135.62109375 | val_loss : 1276.5941162109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1379 | train_loss : 1816.0010986328125 | val_loss : 1577.26220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1380 | train_loss : 1080.635986328125 | val_loss : 763.2603149414062 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1381 | train_loss : 1795.77783203125 | val_loss : 4443.53173828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1382 | train_loss : 3718.0224609375 | val_loss : 1363.5074462890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1383 | train_loss : 2414.722412109375 | val_loss : 2226.318115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1384 | train_loss : 1888.51513671875 | val_loss : 748.305908203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1385 | train_loss : 1603.9281005859375 | val_loss : 2432.199462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1386 | train_loss : 1856.7711181640625 | val_loss : 1189.31494140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1387 | train_loss : 2130.5302734375 | val_loss : 2189.937744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1388 | train_loss : 1665.651611328125 | val_loss : 483.974365234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1389 | train_loss : 1280.6243896484375 | val_loss : 2479.905029296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1390 | train_loss : 2025.57275390625 | val_loss : 1274.8809814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1391 | train_loss : 2350.0244140625 | val_loss : 2127.198486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1392 | train_loss : 1651.0322265625 | val_loss : 855.048095703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1393 | train_loss : 966.9312744140625 | val_loss : 1350.7550048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1394 | train_loss : 949.9082641601562 | val_loss : 952.9043579101562 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1395 | train_loss : 1475.385986328125 | val_loss : 2792.554931640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1396 | train_loss : 2264.42529296875 | val_loss : 745.1961059570312 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1397 | train_loss : 1084.0860595703125 | val_loss : 1710.0062255859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1398 | train_loss : 1084.8126220703125 | val_loss : 1022.14404296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1399 | train_loss : 1286.4415283203125 | val_loss : 3232.125732421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1400 | train_loss : 2128.4306640625 | val_loss : 2352.523681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1401 | train_loss : 2309.253662109375 | val_loss : 3659.443115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1402 | train_loss : 1986.47900390625 | val_loss : 3086.20654296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1403 | train_loss : 2726.0048828125 | val_loss : 770.943115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1404 | train_loss : 858.3975830078125 | val_loss : 856.67529296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1405 | train_loss : 917.9701538085938 | val_loss : 1378.5458984375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1406 | train_loss : 1428.5975341796875 | val_loss : 1599.52685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1407 | train_loss : 1912.782958984375 | val_loss : 1476.0643310546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1408 | train_loss : 1654.8885498046875 | val_loss : 1930.642822265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1409 | train_loss : 1694.9248046875 | val_loss : 1064.4306640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1410 | train_loss : 1798.3885498046875 | val_loss : 3988.025390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1411 | train_loss : 3188.62158203125 | val_loss : 1903.3746337890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1412 | train_loss : 2354.449462890625 | val_loss : 2144.47412109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1413 | train_loss : 1714.641357421875 | val_loss : 1305.40380859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1414 | train_loss : 1789.9365234375 | val_loss : 1619.1446533203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1415 | train_loss : 2148.514404296875 | val_loss : 949.3787231445312 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1416 | train_loss : 1461.4873046875 | val_loss : 1405.8074951171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1417 | train_loss : 1718.7418212890625 | val_loss : 1588.146240234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1418 | train_loss : 1723.3668212890625 | val_loss : 1776.734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1419 | train_loss : 2400.61181640625 | val_loss : 27014.365234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1420 | train_loss : 24504.98046875 | val_loss : 6137.61083984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1421 | train_loss : 5339.02978515625 | val_loss : 3515.246337890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1422 | train_loss : 3345.163330078125 | val_loss : 4830.0263671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1423 | train_loss : 4791.3994140625 | val_loss : 529.8746948242188 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1424 | train_loss : 2060.634033203125 | val_loss : 1841.81689453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1425 | train_loss : 1316.5072021484375 | val_loss : 473.4574890136719 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1426 | train_loss : 1082.569091796875 | val_loss : 2193.053466796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1427 | train_loss : 1596.6707763671875 | val_loss : 1081.85595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1428 | train_loss : 1216.207763671875 | val_loss : 2362.152587890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1429 | train_loss : 1728.06298828125 | val_loss : 1630.7794189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1430 | train_loss : 2155.129638671875 | val_loss : 1748.1005859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1431 | train_loss : 1343.4273681640625 | val_loss : 387.474365234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1432 | train_loss : 1202.7440185546875 | val_loss : 2392.484619140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1433 | train_loss : 2201.624755859375 | val_loss : 395.927490234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1434 | train_loss : 1279.6466064453125 | val_loss : 3559.0859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1435 | train_loss : 2689.702392578125 | val_loss : 946.2665405273438 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1436 | train_loss : 1526.6875 | val_loss : 3162.76904296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1437 | train_loss : 2542.31494140625 | val_loss : 217.9678192138672 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1438 | train_loss : 1172.321533203125 | val_loss : 1737.2728271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1439 | train_loss : 1649.5062255859375 | val_loss : 425.8765563964844 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1440 | train_loss : 1221.6607666015625 | val_loss : 1936.09814453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1441 | train_loss : 1872.061767578125 | val_loss : 409.2590637207031 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1442 | train_loss : 1119.1605224609375 | val_loss : 1670.39404296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1443 | train_loss : 1633.2227783203125 | val_loss : 447.7231140136719 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1444 | train_loss : 1192.2000732421875 | val_loss : 2252.373779296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1445 | train_loss : 1930.178955078125 | val_loss : 447.5478210449219 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1446 | train_loss : 1189.7958984375 | val_loss : 1977.8599853515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1447 | train_loss : 2005.34375 | val_loss : 1172.078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1448 | train_loss : 1478.0162353515625 | val_loss : 29489.783203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1449 | train_loss : 25332.560546875 | val_loss : 8391.5712890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1450 | train_loss : 8287.21484375 | val_loss : 2263.309814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1451 | train_loss : 2316.857177734375 | val_loss : 2347.14404296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1452 | train_loss : 2439.405517578125 | val_loss : 4019.872802734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1453 | train_loss : 3658.077880859375 | val_loss : 2070.655029296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1454 | train_loss : 2262.32421875 | val_loss : 1320.8106689453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1455 | train_loss : 1322.7852783203125 | val_loss : 2258.094970703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1456 | train_loss : 2169.679931640625 | val_loss : 862.1699829101562 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1457 | train_loss : 1091.846923828125 | val_loss : 1079.97998046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1458 | train_loss : 1223.850830078125 | val_loss : 1726.3834228515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1459 | train_loss : 1480.555908203125 | val_loss : 1084.951904296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1460 | train_loss : 1397.0909423828125 | val_loss : 1067.149658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1461 | train_loss : 1270.61181640625 | val_loss : 801.9834594726562 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1462 | train_loss : 1171.7601318359375 | val_loss : 1054.2496337890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1463 | train_loss : 1311.502197265625 | val_loss : 791.349365234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1464 | train_loss : 1380.7811279296875 | val_loss : 942.5505981445312 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1465 | train_loss : 1091.248291015625 | val_loss : 864.0140380859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1466 | train_loss : 1072.548095703125 | val_loss : 1634.7884521484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1467 | train_loss : 1719.0576171875 | val_loss : 1318.4002685546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1468 | train_loss : 1490.1300048828125 | val_loss : 1927.6678466796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1469 | train_loss : 1865.4473876953125 | val_loss : 1436.6556396484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1470 | train_loss : 1873.9971923828125 | val_loss : 1950.4837646484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1471 | train_loss : 1981.4144287109375 | val_loss : 1288.3631591796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1472 | train_loss : 1806.6268310546875 | val_loss : 1819.934326171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1473 | train_loss : 2062.75 | val_loss : 1095.3218994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1474 | train_loss : 1429.14013671875 | val_loss : 1291.1568603515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1475 | train_loss : 1678.84619140625 | val_loss : 1532.3409423828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1476 | train_loss : 1746.1488037109375 | val_loss : 1349.401611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1477 | train_loss : 1866.75341796875 | val_loss : 1376.9312744140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1478 | train_loss : 1685.2984619140625 | val_loss : 1359.4080810546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1479 | train_loss : 1651.043701171875 | val_loss : 899.09375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1480 | train_loss : 1105.90576171875 | val_loss : 1423.05810546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1481 | train_loss : 1757.3416748046875 | val_loss : 1109.877197265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1482 | train_loss : 1558.68212890625 | val_loss : 1942.2618408203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1483 | train_loss : 1823.823486328125 | val_loss : 1027.5418701171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1484 | train_loss : 1341.28564453125 | val_loss : 2220.026611328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1485 | train_loss : 2066.99658203125 | val_loss : 1115.9527587890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1486 | train_loss : 1528.1087646484375 | val_loss : 2110.4521484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1487 | train_loss : 1718.8868408203125 | val_loss : 2677.921142578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1488 | train_loss : 2155.168212890625 | val_loss : 4768.05859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1489 | train_loss : 3705.906982421875 | val_loss : 815.21875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1490 | train_loss : 2048.144775390625 | val_loss : 3082.812255859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1491 | train_loss : 2160.383544921875 | val_loss : 1663.9052734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1492 | train_loss : 2280.745849609375 | val_loss : 3213.21728515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1493 | train_loss : 2248.20703125 | val_loss : 1752.009033203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1494 | train_loss : 2485.724853515625 | val_loss : 2238.848388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1495 | train_loss : 1489.0858154296875 | val_loss : 722.14404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1496 | train_loss : 1043.0093994140625 | val_loss : 2430.96240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1497 | train_loss : 1872.98095703125 | val_loss : 1319.9490966796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1498 | train_loss : 1597.9776611328125 | val_loss : 1359.142822265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1499 | train_loss : 982.8125610351562 | val_loss : 412.4984436035156 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1500 | train_loss : 1172.8924560546875 | val_loss : 2656.867919921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1501 | train_loss : 2024.6683349609375 | val_loss : 1833.0887451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1502 | train_loss : 1962.036376953125 | val_loss : 3355.651611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1503 | train_loss : 2721.475830078125 | val_loss : 711.158447265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1504 | train_loss : 1478.797607421875 | val_loss : 1856.4022216796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1505 | train_loss : 1574.23291015625 | val_loss : 776.3646850585938 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1506 | train_loss : 2259.968017578125 | val_loss : 2435.45166015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1507 | train_loss : 2206.74365234375 | val_loss : 827.5421752929688 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1508 | train_loss : 2415.873046875 | val_loss : 2072.960205078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1509 | train_loss : 1774.8165283203125 | val_loss : 544.0293579101562 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1510 | train_loss : 1543.69287109375 | val_loss : 1897.6790771484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1511 | train_loss : 1547.036865234375 | val_loss : 845.80029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1512 | train_loss : 1747.5128173828125 | val_loss : 2553.784423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1513 | train_loss : 2073.2333984375 | val_loss : 830.87158203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1514 | train_loss : 1490.8319091796875 | val_loss : 1935.4593505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1515 | train_loss : 1353.6126708984375 | val_loss : 1016.892822265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1516 | train_loss : 1848.2496337890625 | val_loss : 1813.129638671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1517 | train_loss : 1529.8785400390625 | val_loss : 931.1859130859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1518 | train_loss : 1605.8309326171875 | val_loss : 2308.82275390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1519 | train_loss : 1611.626220703125 | val_loss : 1295.38818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1520 | train_loss : 1756.2750244140625 | val_loss : 1529.856201171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1521 | train_loss : 1008.3060913085938 | val_loss : 776.0237426757812 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1522 | train_loss : 1225.011962890625 | val_loss : 2052.770263671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1523 | train_loss : 1544.1025390625 | val_loss : 668.5399780273438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1524 | train_loss : 1179.2772216796875 | val_loss : 2082.7294921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1525 | train_loss : 1868.6605224609375 | val_loss : 216.58811950683594 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1526 | train_loss : 878.296142578125 | val_loss : 2007.4144287109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1527 | train_loss : 1415.7052001953125 | val_loss : 552.3378295898438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1528 | train_loss : 1285.6192626953125 | val_loss : 2224.15625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1529 | train_loss : 1850.86669921875 | val_loss : 298.2862548828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1530 | train_loss : 914.640625 | val_loss : 1727.8668212890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1531 | train_loss : 1491.719970703125 | val_loss : 657.8375244140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1532 | train_loss : 1181.7442626953125 | val_loss : 1886.217529296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1533 | train_loss : 1722.803466796875 | val_loss : 254.8046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1534 | train_loss : 803.5977172851562 | val_loss : 1344.3865966796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1535 | train_loss : 1278.824951171875 | val_loss : 822.9346923828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1536 | train_loss : 1176.3564453125 | val_loss : 2158.149658203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1537 | train_loss : 1954.7242431640625 | val_loss : 678.4099731445312 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1538 | train_loss : 981.9107666015625 | val_loss : 1514.5384521484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1539 | train_loss : 1271.548583984375 | val_loss : 603.2909545898438 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1540 | train_loss : 1094.5966796875 | val_loss : 1617.5206298828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1541 | train_loss : 1466.8380126953125 | val_loss : 882.4343872070312 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1542 | train_loss : 1265.1680908203125 | val_loss : 2314.812744140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1543 | train_loss : 2056.37841796875 | val_loss : 345.6346740722656 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1544 | train_loss : 850.8556518554688 | val_loss : 1611.553466796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1545 | train_loss : 1049.4794921875 | val_loss : 843.1543579101562 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1546 | train_loss : 1097.90283203125 | val_loss : 2269.77490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1547 | train_loss : 1616.735107421875 | val_loss : 1171.979736328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1548 | train_loss : 1568.25634765625 | val_loss : 1465.6934814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1549 | train_loss : 1169.8526611328125 | val_loss : 331.6728210449219 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1550 | train_loss : 914.001708984375 | val_loss : 2382.00439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1551 | train_loss : 1858.8157958984375 | val_loss : 1221.5196533203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1552 | train_loss : 1670.09033203125 | val_loss : 1391.9384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1553 | train_loss : 1176.0498046875 | val_loss : 515.6900024414062 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1554 | train_loss : 891.2747802734375 | val_loss : 1730.3768310546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1555 | train_loss : 1278.1243896484375 | val_loss : 889.8362426757812 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1556 | train_loss : 1436.7353515625 | val_loss : 1213.68212890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1557 | train_loss : 1055.7620849609375 | val_loss : 377.1653137207031 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1558 | train_loss : 914.867431640625 | val_loss : 2002.534423828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1559 | train_loss : 1626.4527587890625 | val_loss : 917.9137573242188 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1560 | train_loss : 1595.2247314453125 | val_loss : 1527.9959716796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1561 | train_loss : 1390.833740234375 | val_loss : 397.900634765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1562 | train_loss : 1136.91943359375 | val_loss : 1712.5322265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1563 | train_loss : 1468.377197265625 | val_loss : 904.3431396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1564 | train_loss : 1550.60400390625 | val_loss : 1370.6837158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1565 | train_loss : 1010.7195434570312 | val_loss : 478.3856201171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1566 | train_loss : 1400.2584228515625 | val_loss : 2496.50341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1567 | train_loss : 1755.8291015625 | val_loss : 877.4534301757812 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1568 | train_loss : 1359.720947265625 | val_loss : 1286.002197265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1569 | train_loss : 971.6824340820312 | val_loss : 404.1918640136719 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1570 | train_loss : 1022.0693969726562 | val_loss : 2272.42529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1571 | train_loss : 1686.3377685546875 | val_loss : 889.217529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1572 | train_loss : 1611.2109375 | val_loss : 1188.77587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1573 | train_loss : 927.4500732421875 | val_loss : 563.389404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1574 | train_loss : 1050.8106689453125 | val_loss : 2015.8687744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1575 | train_loss : 1470.86376953125 | val_loss : 1125.0909423828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1576 | train_loss : 1696.45068359375 | val_loss : 1272.25244140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1577 | train_loss : 922.140380859375 | val_loss : 343.6128234863281 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1578 | train_loss : 956.7705688476562 | val_loss : 2690.370849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1579 | train_loss : 1809.2091064453125 | val_loss : 588.694091796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1580 | train_loss : 1098.89501953125 | val_loss : 1986.2099609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1581 | train_loss : 1352.7203369140625 | val_loss : 1273.473388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1582 | train_loss : 1499.9462890625 | val_loss : 1082.88720703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1583 | train_loss : 811.6398315429688 | val_loss : 214.21937561035156 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1584 | train_loss : 726.4081420898438 | val_loss : 1143.46337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1585 | train_loss : 822.2374267578125 | val_loss : 850.0856323242188 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1586 | train_loss : 1196.0133056640625 | val_loss : 1857.2490234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1587 | train_loss : 1597.67529296875 | val_loss : 267.919677734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1588 | train_loss : 848.1317749023438 | val_loss : 1126.830322265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1589 | train_loss : 733.0724487304688 | val_loss : 297.9856262207031 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1590 | train_loss : 918.5438842773438 | val_loss : 1408.38623046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1591 | train_loss : 1293.792236328125 | val_loss : 626.4784545898438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1592 | train_loss : 1273.708251953125 | val_loss : 1852.65380859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1593 | train_loss : 1641.5562744140625 | val_loss : 176.14866638183594 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1594 | train_loss : 1218.317626953125 | val_loss : 1822.706298828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1595 | train_loss : 1545.552978515625 | val_loss : 359.8793640136719 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1596 | train_loss : 1316.8514404296875 | val_loss : 2022.4962158203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1597 | train_loss : 1721.0255126953125 | val_loss : 120.0687484741211 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1598 | train_loss : 944.1830444335938 | val_loss : 1441.4637451171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1599 | train_loss : 1201.59619140625 | val_loss : 420.6059265136719 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 1600 | train_loss : 999.93212890625 | val_loss : 1485.9403076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 1 | epoch : 1 | train_loss : 1160334.125 | val_loss : 912473.75 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 2 | train_loss : 849904.75 | val_loss : 500095.8125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 3 | train_loss : 514906.3125 | val_loss : 379770.6875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 4 | train_loss : 557109.75 | val_loss : 476547.53125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 5 | train_loss : 588603.9375 | val_loss : 469341.25 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 6 | train_loss : 441973.28125 | val_loss : 540282.5 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 7 | train_loss : 451270.71875 | val_loss : 673348.5 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 8 | train_loss : 674561.9375 | val_loss : 834238.8125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 9 | train_loss : 787555.5 | val_loss : 367154.09375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 10 | train_loss : 309125.25 | val_loss : 330651.96875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 11 | train_loss : 320511.125 | val_loss : 181351.640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 12 | train_loss : 183001.4375 | val_loss : 75783.15625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 13 | train_loss : 124809.1015625 | val_loss : 115666.6484375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 14 | train_loss : 147332.828125 | val_loss : 120991.8515625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 15 | train_loss : 159788.125 | val_loss : 104200.9375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 16 | train_loss : 194255.6875 | val_loss : 114455.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 17 | train_loss : 183609.59375 | val_loss : 206358.1875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 18 | train_loss : 262201.09375 | val_loss : 120678.328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 19 | train_loss : 149471.234375 | val_loss : 103762.2421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 20 | train_loss : 117660.59375 | val_loss : 126822.421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 21 | train_loss : 106444.0234375 | val_loss : 122301.78125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 22 | train_loss : 137693.3125 | val_loss : 112337.1171875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 23 | train_loss : 148482.75 | val_loss : 111164.8203125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 24 | train_loss : 193479.484375 | val_loss : 70145.7109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 25 | train_loss : 141604.90625 | val_loss : 156719.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 26 | train_loss : 142030.34375 | val_loss : 212648.984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 27 | train_loss : 168051.421875 | val_loss : 147468.890625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 28 | train_loss : 191092.515625 | val_loss : 154652.09375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 29 | train_loss : 186202.234375 | val_loss : 66733.0 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 30 | train_loss : 130636.8671875 | val_loss : 221993.125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 31 | train_loss : 142885.6875 | val_loss : 221109.15625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 32 | train_loss : 154761.65625 | val_loss : 155319.921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 33 | train_loss : 122359.203125 | val_loss : 224774.3125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 34 | train_loss : 138812.90625 | val_loss : 213991.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 35 | train_loss : 186660.90625 | val_loss : 144413.375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 36 | train_loss : 159707.859375 | val_loss : 182399.921875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 37 | train_loss : 212295.578125 | val_loss : 126100.7890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 38 | train_loss : 147381.546875 | val_loss : 120764.9609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 39 | train_loss : 105594.1796875 | val_loss : 175946.265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 40 | train_loss : 132094.46875 | val_loss : 203209.140625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 41 | train_loss : 186280.40625 | val_loss : 161949.640625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 42 | train_loss : 176319.90625 | val_loss : 197724.59375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 43 | train_loss : 195420.921875 | val_loss : 90989.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 44 | train_loss : 115957.5 | val_loss : 84426.6796875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 45 | train_loss : 110103.7734375 | val_loss : 102485.78125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 46 | train_loss : 114145.046875 | val_loss : 158203.890625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 47 | train_loss : 164869.0625 | val_loss : 118943.40625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 48 | train_loss : 137354.953125 | val_loss : 86243.640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 49 | train_loss : 132986.0625 | val_loss : 235877.265625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 50 | train_loss : 167285.046875 | val_loss : 161800.109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 51 | train_loss : 171697.625 | val_loss : 133332.953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 52 | train_loss : 136418.953125 | val_loss : 96100.6796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 53 | train_loss : 113774.921875 | val_loss : 94394.7109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 54 | train_loss : 80939.703125 | val_loss : 23740.203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 55 | train_loss : 62707.62109375 | val_loss : 150311.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 56 | train_loss : 104885.7421875 | val_loss : 75098.6875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 57 | train_loss : 93138.1875 | val_loss : 117712.2265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 58 | train_loss : 114923.75 | val_loss : 103564.2421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 59 | train_loss : 98351.25 | val_loss : 74247.7265625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 60 | train_loss : 111331.671875 | val_loss : 175789.359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 61 | train_loss : 105038.6875 | val_loss : 131959.40625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 62 | train_loss : 115112.8984375 | val_loss : 129145.296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 63 | train_loss : 113209.7421875 | val_loss : 170311.078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 64 | train_loss : 127567.0390625 | val_loss : 103580.0390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 65 | train_loss : 113935.8671875 | val_loss : 51964.7734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 66 | train_loss : 93235.7109375 | val_loss : 97081.4609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 67 | train_loss : 92891.5703125 | val_loss : 45744.96875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 68 | train_loss : 111127.890625 | val_loss : 105268.9765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 69 | train_loss : 99722.578125 | val_loss : 134204.984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 70 | train_loss : 119598.3671875 | val_loss : 112107.34375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 71 | train_loss : 105949.7109375 | val_loss : 92503.3125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 72 | train_loss : 69699.8515625 | val_loss : 40998.578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 73 | train_loss : 81265.375 | val_loss : 63272.171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 74 | train_loss : 74136.4765625 | val_loss : 134639.359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 75 | train_loss : 98212.1328125 | val_loss : 120397.3984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 76 | train_loss : 96301.34375 | val_loss : 146982.15625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 77 | train_loss : 143462.234375 | val_loss : 108466.921875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 78 | train_loss : 88166.828125 | val_loss : 77572.9453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 79 | train_loss : 81080.4140625 | val_loss : 39271.26953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 80 | train_loss : 82134.171875 | val_loss : 88201.7734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 81 | train_loss : 86045.3828125 | val_loss : 92958.1171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 82 | train_loss : 91620.0 | val_loss : 47681.48046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 83 | train_loss : 78180.4921875 | val_loss : 99968.9765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 84 | train_loss : 101911.71875 | val_loss : 75697.6796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 85 | train_loss : 67864.921875 | val_loss : 101832.6015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 86 | train_loss : 93733.7734375 | val_loss : 107182.078125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 87 | train_loss : 91347.609375 | val_loss : 103656.2421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 88 | train_loss : 107872.7890625 | val_loss : 35422.11328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 89 | train_loss : 102951.921875 | val_loss : 86694.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 90 | train_loss : 86674.8671875 | val_loss : 127360.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 91 | train_loss : 102443.53125 | val_loss : 104512.3984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 92 | train_loss : 82073.15625 | val_loss : 32454.390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 93 | train_loss : 60980.88671875 | val_loss : 73647.1953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 94 | train_loss : 91833.203125 | val_loss : 33570.45703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 95 | train_loss : 72951.6328125 | val_loss : 41453.7890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 96 | train_loss : 42870.78125 | val_loss : 33831.46875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 97 | train_loss : 65042.91015625 | val_loss : 81823.34375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 98 | train_loss : 88879.6171875 | val_loss : 95324.078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 99 | train_loss : 81942.8125 | val_loss : 64512.74609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 100 | train_loss : 61087.3203125 | val_loss : 24428.845703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 101 | train_loss : 51001.26171875 | val_loss : 34335.63671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 102 | train_loss : 70906.375 | val_loss : 93177.9609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 103 | train_loss : 81809.109375 | val_loss : 82936.109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 104 | train_loss : 75598.546875 | val_loss : 82398.8203125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 105 | train_loss : 49312.94140625 | val_loss : 54994.73828125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 106 | train_loss : 78492.421875 | val_loss : 49828.0234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 107 | train_loss : 78802.2265625 | val_loss : 48474.25 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 108 | train_loss : 83600.828125 | val_loss : 65818.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 109 | train_loss : 54655.84375 | val_loss : 44058.5 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 110 | train_loss : 72602.5078125 | val_loss : 150885.875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 111 | train_loss : 89468.75 | val_loss : 82215.3671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 112 | train_loss : 79337.8671875 | val_loss : 127471.40625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 113 | train_loss : 101066.53125 | val_loss : 58014.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 114 | train_loss : 63147.62109375 | val_loss : 77429.3671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 115 | train_loss : 59248.203125 | val_loss : 22435.1484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 116 | train_loss : 56819.703125 | val_loss : 42318.08984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 117 | train_loss : 77746.2109375 | val_loss : 39633.4453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 118 | train_loss : 57649.9609375 | val_loss : 56399.6484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 119 | train_loss : 58346.0 | val_loss : 34370.45703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 120 | train_loss : 49842.734375 | val_loss : 125430.15625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 121 | train_loss : 62345.01953125 | val_loss : 125492.53125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 122 | train_loss : 80049.1640625 | val_loss : 120716.15625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 123 | train_loss : 86847.2890625 | val_loss : 127650.1875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 124 | train_loss : 109157.46875 | val_loss : 109820.59375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 125 | train_loss : 66420.859375 | val_loss : 85790.6484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 126 | train_loss : 74724.875 | val_loss : 80396.796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 127 | train_loss : 81763.796875 | val_loss : 55529.48046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 128 | train_loss : 89022.5 | val_loss : 38132.7109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 129 | train_loss : 53285.9296875 | val_loss : 52743.3203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 130 | train_loss : 64749.48828125 | val_loss : 34257.625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 131 | train_loss : 89762.1796875 | val_loss : 86141.390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 132 | train_loss : 66921.71875 | val_loss : 78664.2421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 133 | train_loss : 59999.36328125 | val_loss : 47989.62109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 134 | train_loss : 43125.14453125 | val_loss : 41710.66015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 135 | train_loss : 44227.5859375 | val_loss : 21497.10546875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 136 | train_loss : 59763.94140625 | val_loss : 77305.0390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 137 | train_loss : 70444.328125 | val_loss : 46971.8984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 138 | train_loss : 55935.30859375 | val_loss : 61291.9609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 139 | train_loss : 58441.13671875 | val_loss : 27036.80078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 140 | train_loss : 61795.3203125 | val_loss : 88188.3515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 141 | train_loss : 93077.1875 | val_loss : 125108.7734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 142 | train_loss : 115475.9296875 | val_loss : 96999.546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 143 | train_loss : 84265.078125 | val_loss : 78712.1875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 144 | train_loss : 82765.2421875 | val_loss : 58414.90625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 145 | train_loss : 100642.421875 | val_loss : 47545.8515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 146 | train_loss : 70872.28125 | val_loss : 43697.69140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 147 | train_loss : 54479.82421875 | val_loss : 18617.119140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 148 | train_loss : 44785.8984375 | val_loss : 74105.84375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 149 | train_loss : 70837.7421875 | val_loss : 57865.23046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 150 | train_loss : 46465.33984375 | val_loss : 50574.16015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 151 | train_loss : 54996.48046875 | val_loss : 65892.6875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 152 | train_loss : 62440.23046875 | val_loss : 22402.255859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 153 | train_loss : 63585.5 | val_loss : 41746.71484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 154 | train_loss : 49397.28125 | val_loss : 41376.76171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 155 | train_loss : 60122.19140625 | val_loss : 62219.12109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 156 | train_loss : 56915.85546875 | val_loss : 42805.55078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 157 | train_loss : 63519.140625 | val_loss : 32696.443359375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 158 | train_loss : 39351.109375 | val_loss : 45429.8203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 159 | train_loss : 54660.58984375 | val_loss : 29668.033203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 160 | train_loss : 43823.171875 | val_loss : 104748.7890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 161 | train_loss : 51872.09375 | val_loss : 61626.51171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 162 | train_loss : 53081.8515625 | val_loss : 61565.44140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 163 | train_loss : 54030.03125 | val_loss : 53631.01953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 164 | train_loss : 45098.25390625 | val_loss : 46533.3515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 165 | train_loss : 37822.8203125 | val_loss : 20616.0546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 166 | train_loss : 54355.15625 | val_loss : 49871.26171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 167 | train_loss : 42710.6015625 | val_loss : 36177.37890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 168 | train_loss : 45995.453125 | val_loss : 69275.0234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 169 | train_loss : 58687.0703125 | val_loss : 25893.904296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 170 | train_loss : 68486.359375 | val_loss : 108640.109375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 171 | train_loss : 62099.88671875 | val_loss : 101073.25 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 172 | train_loss : 74396.3984375 | val_loss : 109900.1171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 173 | train_loss : 64821.7265625 | val_loss : 72167.0 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 174 | train_loss : 40846.07421875 | val_loss : 90231.890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 175 | train_loss : 65491.953125 | val_loss : 64454.046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 176 | train_loss : 69784.2109375 | val_loss : 68384.484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 177 | train_loss : 52475.4140625 | val_loss : 32567.17578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 178 | train_loss : 47538.09375 | val_loss : 49353.2265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 179 | train_loss : 63144.55078125 | val_loss : 71019.6875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 180 | train_loss : 72989.21875 | val_loss : 52633.48828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 181 | train_loss : 52242.2265625 | val_loss : 34488.42578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 182 | train_loss : 37707.19921875 | val_loss : 46747.19140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 183 | train_loss : 45604.82421875 | val_loss : 61450.18359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 184 | train_loss : 46325.3984375 | val_loss : 69033.84375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 185 | train_loss : 46533.515625 | val_loss : 60871.74609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 186 | train_loss : 50950.515625 | val_loss : 55019.30078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 187 | train_loss : 60590.62890625 | val_loss : 49471.921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 188 | train_loss : 46629.73828125 | val_loss : 40047.66015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 189 | train_loss : 78765.7734375 | val_loss : 22318.880859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 190 | train_loss : 27385.943359375 | val_loss : 38450.15234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 191 | train_loss : 38521.56640625 | val_loss : 31323.6953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 192 | train_loss : 26580.109375 | val_loss : 74931.671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 193 | train_loss : 46633.5703125 | val_loss : 52309.734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 194 | train_loss : 44310.83984375 | val_loss : 65959.3671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 195 | train_loss : 57733.7265625 | val_loss : 51745.62109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 196 | train_loss : 33438.62890625 | val_loss : 7433.6474609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 197 | train_loss : 34600.75 | val_loss : 46629.015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 198 | train_loss : 29081.4375 | val_loss : 34437.046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 199 | train_loss : 50036.796875 | val_loss : 45115.25 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 200 | train_loss : 55547.359375 | val_loss : 30914.90234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 201 | train_loss : 48005.2890625 | val_loss : 74881.171875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 202 | train_loss : 56503.10546875 | val_loss : 74490.3125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 203 | train_loss : 67550.3828125 | val_loss : 48096.55859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 204 | train_loss : 69398.7421875 | val_loss : 36742.91796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 205 | train_loss : 41253.390625 | val_loss : 55935.9140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 206 | train_loss : 51233.68359375 | val_loss : 30595.068359375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 207 | train_loss : 60061.48828125 | val_loss : 13109.4970703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 208 | train_loss : 48598.234375 | val_loss : 31443.724609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 209 | train_loss : 47440.96875 | val_loss : 14752.4775390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 210 | train_loss : 32060.783203125 | val_loss : 25132.625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 211 | train_loss : 28709.92578125 | val_loss : 33772.015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 212 | train_loss : 35093.01953125 | val_loss : 25724.443359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 213 | train_loss : 24955.4296875 | val_loss : 8301.97265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 214 | train_loss : 22671.359375 | val_loss : 30977.365234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 215 | train_loss : 24808.470703125 | val_loss : 59799.83984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 216 | train_loss : 42728.21875 | val_loss : 16453.5078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 217 | train_loss : 46779.11328125 | val_loss : 16238.427734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 218 | train_loss : 31477.60546875 | val_loss : 44231.83984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 219 | train_loss : 32996.0234375 | val_loss : 52091.44140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 220 | train_loss : 36462.33984375 | val_loss : 43280.19140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 221 | train_loss : 41137.625 | val_loss : 24107.330078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 222 | train_loss : 33307.80859375 | val_loss : 31007.11328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 223 | train_loss : 47644.16015625 | val_loss : 32774.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 224 | train_loss : 33724.875 | val_loss : 53696.69921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 225 | train_loss : 38538.7890625 | val_loss : 51876.19921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 226 | train_loss : 44676.0546875 | val_loss : 26328.86328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 227 | train_loss : 49017.1953125 | val_loss : 32139.42578125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 228 | train_loss : 35764.375 | val_loss : 53203.015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 229 | train_loss : 39826.5546875 | val_loss : 50120.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 230 | train_loss : 45053.671875 | val_loss : 12165.2548828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 231 | train_loss : 36066.5703125 | val_loss : 31730.630859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 232 | train_loss : 25663.15234375 | val_loss : 18692.287109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 233 | train_loss : 34062.6328125 | val_loss : 68109.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 234 | train_loss : 38407.171875 | val_loss : 33324.484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 235 | train_loss : 45315.05078125 | val_loss : 40048.87109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 236 | train_loss : 53355.62109375 | val_loss : 18959.859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 237 | train_loss : 32972.80078125 | val_loss : 65201.26953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 238 | train_loss : 41340.93359375 | val_loss : 12300.09765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 239 | train_loss : 42652.84375 | val_loss : 16489.82421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 240 | train_loss : 32076.6640625 | val_loss : 22146.158203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 241 | train_loss : 22305.35546875 | val_loss : 40674.59765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 242 | train_loss : 32093.015625 | val_loss : 23800.837890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 243 | train_loss : 43211.46484375 | val_loss : 12172.5849609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 244 | train_loss : 39832.7109375 | val_loss : 36574.3359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 245 | train_loss : 29777.029296875 | val_loss : 34337.0859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 246 | train_loss : 33518.62109375 | val_loss : 21242.16015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 247 | train_loss : 29029.921875 | val_loss : 43595.46875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 248 | train_loss : 33721.015625 | val_loss : 8941.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 249 | train_loss : 27412.29296875 | val_loss : 23341.0859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 250 | train_loss : 26941.35546875 | val_loss : 25018.650390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 251 | train_loss : 27020.357421875 | val_loss : 25678.05078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 252 | train_loss : 28705.59765625 | val_loss : 15600.8154296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 253 | train_loss : 25832.9296875 | val_loss : 34415.3203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 254 | train_loss : 27389.765625 | val_loss : 12071.9345703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 255 | train_loss : 30545.501953125 | val_loss : 56247.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 256 | train_loss : 28439.0 | val_loss : 40730.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 257 | train_loss : 40850.953125 | val_loss : 28350.98046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 258 | train_loss : 27769.783203125 | val_loss : 34885.234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 259 | train_loss : 42632.86328125 | val_loss : 70635.609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 260 | train_loss : 52384.734375 | val_loss : 13829.642578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 261 | train_loss : 42356.42578125 | val_loss : 49266.62890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 262 | train_loss : 31783.875 | val_loss : 35239.19140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 263 | train_loss : 31054.357421875 | val_loss : 61960.55859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 264 | train_loss : 37973.2265625 | val_loss : 14701.7451171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 265 | train_loss : 21669.470703125 | val_loss : 31451.07421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 266 | train_loss : 31922.830078125 | val_loss : 10410.1826171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 267 | train_loss : 42222.73828125 | val_loss : 50904.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 268 | train_loss : 36043.2265625 | val_loss : 41155.1953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 269 | train_loss : 35079.546875 | val_loss : 51945.5703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 270 | train_loss : 32501.4453125 | val_loss : 17228.21484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 271 | train_loss : 31308.724609375 | val_loss : 25060.66015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 272 | train_loss : 28445.7734375 | val_loss : 35046.12890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 273 | train_loss : 24140.205078125 | val_loss : 37630.41015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 274 | train_loss : 30147.203125 | val_loss : 29433.26171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 275 | train_loss : 42338.89453125 | val_loss : 42130.0234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 276 | train_loss : 36941.15625 | val_loss : 18924.724609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 277 | train_loss : 41761.515625 | val_loss : 58323.19140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 278 | train_loss : 33592.296875 | val_loss : 42254.90625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 279 | train_loss : 32360.740234375 | val_loss : 26960.119140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 280 | train_loss : 20426.1640625 | val_loss : 25058.662109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 281 | train_loss : 27499.80078125 | val_loss : 29130.435546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 282 | train_loss : 26792.88671875 | val_loss : 45572.62109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 283 | train_loss : 32119.064453125 | val_loss : 36281.54296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 284 | train_loss : 34693.68359375 | val_loss : 9186.482421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 285 | train_loss : 19728.837890625 | val_loss : 19966.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 286 | train_loss : 20329.6015625 | val_loss : 37600.60546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 287 | train_loss : 30295.955078125 | val_loss : 38890.703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 288 | train_loss : 30621.373046875 | val_loss : 36425.67578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 289 | train_loss : 36586.19921875 | val_loss : 62734.4296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 290 | train_loss : 44015.93359375 | val_loss : 12457.384765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 291 | train_loss : 39689.02734375 | val_loss : 28669.517578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 292 | train_loss : 25476.662109375 | val_loss : 22085.275390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 293 | train_loss : 18513.724609375 | val_loss : 30955.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 294 | train_loss : 19724.068359375 | val_loss : 5596.052734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 295 | train_loss : 21124.1171875 | val_loss : 44515.9140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 296 | train_loss : 24851.35546875 | val_loss : 28747.5546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 297 | train_loss : 28554.7890625 | val_loss : 42102.83984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 298 | train_loss : 28979.921875 | val_loss : 6275.84521484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 299 | train_loss : 18305.40625 | val_loss : 59195.6640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 300 | train_loss : 29698.6171875 | val_loss : 29283.7890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 301 | train_loss : 34188.40625 | val_loss : 21221.755859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 302 | train_loss : 20401.671875 | val_loss : 27483.8515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 303 | train_loss : 25979.26953125 | val_loss : 51305.671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 304 | train_loss : 36318.99609375 | val_loss : 13739.5302734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 305 | train_loss : 37575.7109375 | val_loss : 45912.078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 306 | train_loss : 28797.80078125 | val_loss : 42116.2265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 307 | train_loss : 36860.13671875 | val_loss : 66866.34375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 308 | train_loss : 44276.140625 | val_loss : 17216.408203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 309 | train_loss : 26078.255859375 | val_loss : 24132.427734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 310 | train_loss : 21768.5546875 | val_loss : 43924.55859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 311 | train_loss : 30492.837890625 | val_loss : 38199.23828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 312 | train_loss : 36343.38671875 | val_loss : 10073.16015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 313 | train_loss : 22552.775390625 | val_loss : 27515.255859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 314 | train_loss : 26163.95703125 | val_loss : 29238.080078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 315 | train_loss : 27659.099609375 | val_loss : 19653.830078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 316 | train_loss : 29686.744140625 | val_loss : 25183.494140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 317 | train_loss : 31719.6015625 | val_loss : 38081.36328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 318 | train_loss : 30934.10546875 | val_loss : 62417.18359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 319 | train_loss : 121279.90625 | val_loss : 53242.15625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 320 | train_loss : 62661.89453125 | val_loss : 29903.435546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 321 | train_loss : 39217.7109375 | val_loss : 97129.109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 322 | train_loss : 99769.2890625 | val_loss : 14922.080078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 323 | train_loss : 44414.6015625 | val_loss : 30542.8828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 324 | train_loss : 27960.296875 | val_loss : 23232.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 325 | train_loss : 23352.29296875 | val_loss : 49235.87890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 326 | train_loss : 29912.4609375 | val_loss : 39720.7734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 327 | train_loss : 33201.68359375 | val_loss : 24908.669921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 328 | train_loss : 36239.65625 | val_loss : 23194.099609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 329 | train_loss : 24094.53515625 | val_loss : 28722.51953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 330 | train_loss : 27737.529296875 | val_loss : 19149.9453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 331 | train_loss : 29776.224609375 | val_loss : 21569.384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 332 | train_loss : 22660.66015625 | val_loss : 35898.1015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 333 | train_loss : 23579.255859375 | val_loss : 17827.263671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 334 | train_loss : 19646.669921875 | val_loss : 19183.830078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 335 | train_loss : 26013.056640625 | val_loss : 21164.380859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 336 | train_loss : 21675.810546875 | val_loss : 24898.072265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 337 | train_loss : 13765.990234375 | val_loss : 5448.63232421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 338 | train_loss : 15539.974609375 | val_loss : 20013.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 339 | train_loss : 12190.5458984375 | val_loss : 7455.9501953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 340 | train_loss : 17697.609375 | val_loss : 32782.34375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 341 | train_loss : 18574.0078125 | val_loss : 4722.544921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 342 | train_loss : 16799.751953125 | val_loss : 37380.94140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 343 | train_loss : 19378.404296875 | val_loss : 20085.3515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 344 | train_loss : 27067.345703125 | val_loss : 20272.884765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 345 | train_loss : 18214.912109375 | val_loss : 25592.783203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 346 | train_loss : 23095.52734375 | val_loss : 14426.5087890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 347 | train_loss : 22258.349609375 | val_loss : 9743.3740234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 348 | train_loss : 18360.91015625 | val_loss : 16035.384765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 349 | train_loss : 13366.611328125 | val_loss : 37222.27734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 350 | train_loss : 26046.001953125 | val_loss : 30470.279296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 351 | train_loss : 27517.357421875 | val_loss : 25775.67578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 352 | train_loss : 31540.115234375 | val_loss : 31635.33984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 353 | train_loss : 25528.51171875 | val_loss : 49484.3046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 354 | train_loss : 33225.50390625 | val_loss : 34391.69921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 355 | train_loss : 32292.822265625 | val_loss : 16740.857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 356 | train_loss : 28078.873046875 | val_loss : 19872.33984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 357 | train_loss : 23044.994140625 | val_loss : 17719.990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 358 | train_loss : 14071.013671875 | val_loss : 3564.097412109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 359 | train_loss : 18900.869140625 | val_loss : 26650.712890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 360 | train_loss : 17155.8046875 | val_loss : 16844.52734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 361 | train_loss : 15066.8935546875 | val_loss : 18983.14453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 362 | train_loss : 17135.7734375 | val_loss : 15875.212890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 363 | train_loss : 17819.392578125 | val_loss : 12428.61328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 364 | train_loss : 15198.8212890625 | val_loss : 29181.158203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 365 | train_loss : 18052.6484375 | val_loss : 27705.63671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 366 | train_loss : 19479.7890625 | val_loss : 26428.25 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 367 | train_loss : 26814.1171875 | val_loss : 24624.720703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 368 | train_loss : 19175.162109375 | val_loss : 17547.09765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 369 | train_loss : 15894.3984375 | val_loss : 15492.388671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 370 | train_loss : 17060.271484375 | val_loss : 16212.3037109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 371 | train_loss : 19674.189453125 | val_loss : 30896.0703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 372 | train_loss : 22537.759765625 | val_loss : 9579.0703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 373 | train_loss : 28038.072265625 | val_loss : 40065.23828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 374 | train_loss : 27842.9375 | val_loss : 32410.845703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 375 | train_loss : 26255.935546875 | val_loss : 24461.0390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 376 | train_loss : 14441.0498046875 | val_loss : 2982.4736328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 377 | train_loss : 18447.5703125 | val_loss : 26444.955078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 378 | train_loss : 16015.9453125 | val_loss : 24662.505859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 379 | train_loss : 20210.435546875 | val_loss : 14110.67578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 380 | train_loss : 10450.5673828125 | val_loss : 20956.328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 381 | train_loss : 17945.912109375 | val_loss : 16190.7890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 382 | train_loss : 18607.43359375 | val_loss : 4000.416259765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 383 | train_loss : 12690.056640625 | val_loss : 20574.458984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 384 | train_loss : 13067.544921875 | val_loss : 6669.70263671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 385 | train_loss : 14751.919921875 | val_loss : 32309.732421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 386 | train_loss : 15619.0224609375 | val_loss : 17952.087890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 387 | train_loss : 20932.587890625 | val_loss : 32327.140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 388 | train_loss : 25011.6328125 | val_loss : 22960.80078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 389 | train_loss : 25106.76953125 | val_loss : 16879.03125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 390 | train_loss : 29476.32421875 | val_loss : 30187.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 391 | train_loss : 24154.150390625 | val_loss : 30098.509765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 392 | train_loss : 15226.9921875 | val_loss : 22387.51953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 393 | train_loss : 22258.185546875 | val_loss : 26650.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 394 | train_loss : 26141.6875 | val_loss : 14445.9716796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 395 | train_loss : 21472.9921875 | val_loss : 18979.701171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 396 | train_loss : 11968.6552734375 | val_loss : 4582.74609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 397 | train_loss : 19372.6484375 | val_loss : 29708.9296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 398 | train_loss : 18875.41015625 | val_loss : 26836.626953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 399 | train_loss : 22434.4921875 | val_loss : 17612.087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 400 | train_loss : 10985.318359375 | val_loss : 6478.28271484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 401 | train_loss : 16614.615234375 | val_loss : 26679.568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 402 | train_loss : 13699.7001953125 | val_loss : 21470.564453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 403 | train_loss : 19114.421875 | val_loss : 16489.380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 404 | train_loss : 12589.9638671875 | val_loss : 30196.619140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 405 | train_loss : 21474.3515625 | val_loss : 23045.625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 406 | train_loss : 19657.828125 | val_loss : 15226.865234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 407 | train_loss : 18966.033203125 | val_loss : 29116.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 408 | train_loss : 19277.64453125 | val_loss : 7804.06005859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 409 | train_loss : 24619.8828125 | val_loss : 28064.61328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 410 | train_loss : 17193.77734375 | val_loss : 14787.865234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 411 | train_loss : 13031.357421875 | val_loss : 14567.1162109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 412 | train_loss : 10736.7822265625 | val_loss : 11986.806640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 413 | train_loss : 12953.4384765625 | val_loss : 23225.35546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 414 | train_loss : 24660.61328125 | val_loss : 14247.8173828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 415 | train_loss : 15953.39453125 | val_loss : 25442.17578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 416 | train_loss : 17055.953125 | val_loss : 6845.013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 417 | train_loss : 11791.125 | val_loss : 33802.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 418 | train_loss : 14821.9873046875 | val_loss : 12968.1513671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 419 | train_loss : 15214.5849609375 | val_loss : 15060.88671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 420 | train_loss : 8592.9453125 | val_loss : 2563.19384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 421 | train_loss : 11799.669921875 | val_loss : 22013.765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 422 | train_loss : 10302.87109375 | val_loss : 8850.0791015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 423 | train_loss : 13987.146484375 | val_loss : 22061.990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 424 | train_loss : 14763.0908203125 | val_loss : 8361.8427734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 425 | train_loss : 17669.75 | val_loss : 45201.41015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 426 | train_loss : 21028.892578125 | val_loss : 25483.287109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 427 | train_loss : 20717.9609375 | val_loss : 38043.390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 428 | train_loss : 21091.73828125 | val_loss : 25118.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 429 | train_loss : 20539.52734375 | val_loss : 14115.361328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 430 | train_loss : 18880.609375 | val_loss : 15065.212890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 431 | train_loss : 23827.908203125 | val_loss : 28937.828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 432 | train_loss : 17916.873046875 | val_loss : 9143.927734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 433 | train_loss : 14522.0576171875 | val_loss : 11858.71875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 434 | train_loss : 11622.8671875 | val_loss : 20129.11328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 435 | train_loss : 12929.919921875 | val_loss : 25560.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 436 | train_loss : 16915.744140625 | val_loss : 15974.7783203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 437 | train_loss : 16467.974609375 | val_loss : 18787.720703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 438 | train_loss : 21180.70703125 | val_loss : 21974.890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 439 | train_loss : 15049.5595703125 | val_loss : 33645.578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 440 | train_loss : 19031.875 | val_loss : 9237.1796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 441 | train_loss : 14738.87890625 | val_loss : 25978.7109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 442 | train_loss : 18908.34375 | val_loss : 16004.1064453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 443 | train_loss : 15615.865234375 | val_loss : 13518.822265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 444 | train_loss : 21955.35546875 | val_loss : 24617.494140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 445 | train_loss : 19844.6640625 | val_loss : 36059.7109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 446 | train_loss : 19022.392578125 | val_loss : 15370.5 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 447 | train_loss : 14680.8974609375 | val_loss : 18212.0546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 448 | train_loss : 15468.9833984375 | val_loss : 15501.6923828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 449 | train_loss : 12519.9609375 | val_loss : 15347.1826171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 450 | train_loss : 14955.8310546875 | val_loss : 12209.1533203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 451 | train_loss : 12567.08984375 | val_loss : 16191.6611328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 452 | train_loss : 13134.572265625 | val_loss : 16969.681640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 453 | train_loss : 11257.6083984375 | val_loss : 11151.8291015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 454 | train_loss : 13079.9521484375 | val_loss : 7498.09130859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 455 | train_loss : 12376.3125 | val_loss : 28074.974609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 456 | train_loss : 15037.8583984375 | val_loss : 2959.989990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 457 | train_loss : 10689.431640625 | val_loss : 12271.0341796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 458 | train_loss : 6687.30126953125 | val_loss : 8036.521484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 459 | train_loss : 10106.03515625 | val_loss : 16361.2783203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 460 | train_loss : 17709.607421875 | val_loss : 24528.998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 461 | train_loss : 13599.25 | val_loss : 25034.404296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 462 | train_loss : 12050.54296875 | val_loss : 16983.05078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 463 | train_loss : 14604.8349609375 | val_loss : 14881.1298828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 464 | train_loss : 15316.8486328125 | val_loss : 21667.447265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 465 | train_loss : 20819.279296875 | val_loss : 29108.9765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 466 | train_loss : 20622.888671875 | val_loss : 9818.38671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 467 | train_loss : 22786.2578125 | val_loss : 28146.216796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 468 | train_loss : 16947.359375 | val_loss : 26946.908203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 469 | train_loss : 21513.6484375 | val_loss : 17493.6640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 470 | train_loss : 9553.56640625 | val_loss : 3067.81494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 471 | train_loss : 13178.568359375 | val_loss : 23651.47265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 472 | train_loss : 11012.1201171875 | val_loss : 8064.552734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 473 | train_loss : 8292.3720703125 | val_loss : 16525.833984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 474 | train_loss : 14388.8564453125 | val_loss : 20194.57421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 475 | train_loss : 12520.0078125 | val_loss : 16630.265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 476 | train_loss : 13801.1875 | val_loss : 3227.4638671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 477 | train_loss : 9427.658203125 | val_loss : 32216.9453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 478 | train_loss : 15440.3759765625 | val_loss : 17279.677734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 479 | train_loss : 25911.0 | val_loss : 31939.83984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 480 | train_loss : 31672.990234375 | val_loss : 21100.626953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 481 | train_loss : 22473.392578125 | val_loss : 10291.322265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 482 | train_loss : 26583.296875 | val_loss : 38736.7109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 483 | train_loss : 27805.53515625 | val_loss : 37362.62890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 484 | train_loss : 23780.359375 | val_loss : 37271.109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 485 | train_loss : 19557.859375 | val_loss : 11738.6875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 486 | train_loss : 14745.1162109375 | val_loss : 6570.02734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 487 | train_loss : 9795.8388671875 | val_loss : 18218.015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 488 | train_loss : 11672.173828125 | val_loss : 9588.1865234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 489 | train_loss : 10467.4287109375 | val_loss : 17366.431640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 490 | train_loss : 12385.9248046875 | val_loss : 4828.1962890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 491 | train_loss : 15182.1337890625 | val_loss : 21820.07421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 492 | train_loss : 15108.04296875 | val_loss : 16857.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 493 | train_loss : 14963.537109375 | val_loss : 16258.931640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 494 | train_loss : 13178.2099609375 | val_loss : 25714.357421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 495 | train_loss : 17059.755859375 | val_loss : 20323.216796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 496 | train_loss : 14911.162109375 | val_loss : 11761.068359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 497 | train_loss : 11824.63671875 | val_loss : 16742.177734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 498 | train_loss : 11233.3974609375 | val_loss : 13576.5908203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 499 | train_loss : 12990.73046875 | val_loss : 10792.86328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 500 | train_loss : 14322.7578125 | val_loss : 7484.72119140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 501 | train_loss : 11562.51953125 | val_loss : 18093.888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 502 | train_loss : 12183.580078125 | val_loss : 3868.53125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 503 | train_loss : 9906.642578125 | val_loss : 28832.97265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 504 | train_loss : 12560.455078125 | val_loss : 11147.8662109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 505 | train_loss : 13567.92578125 | val_loss : 13550.1201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 506 | train_loss : 8259.978515625 | val_loss : 9619.8115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 507 | train_loss : 9784.0458984375 | val_loss : 15905.9248046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 508 | train_loss : 11981.2470703125 | val_loss : 14644.5859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 509 | train_loss : 11169.7421875 | val_loss : 13644.69140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 510 | train_loss : 11557.0458984375 | val_loss : 1814.969970703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 511 | train_loss : 7851.02685546875 | val_loss : 26899.294921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 512 | train_loss : 12098.7421875 | val_loss : 8055.09765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 513 | train_loss : 12552.705078125 | val_loss : 14570.4345703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 514 | train_loss : 11719.9375 | val_loss : 19369.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 515 | train_loss : 13373.767578125 | val_loss : 16410.880859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 516 | train_loss : 13865.02734375 | val_loss : 5594.759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 517 | train_loss : 12531.12109375 | val_loss : 20816.751953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 518 | train_loss : 11066.5048828125 | val_loss : 2580.12744140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 519 | train_loss : 12536.025390625 | val_loss : 21118.85546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 520 | train_loss : 11553.302734375 | val_loss : 22310.6015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 521 | train_loss : 17672.2421875 | val_loss : 14362.3203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 522 | train_loss : 14757.447265625 | val_loss : 17273.919921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 523 | train_loss : 12058.4248046875 | val_loss : 11410.2841796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 524 | train_loss : 11051.205078125 | val_loss : 2948.919921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 525 | train_loss : 7643.701171875 | val_loss : 23394.587890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 526 | train_loss : 9974.7978515625 | val_loss : 19177.904296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 527 | train_loss : 12936.3037109375 | val_loss : 18426.009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 528 | train_loss : 13263.41796875 | val_loss : 10916.306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 529 | train_loss : 8486.40234375 | val_loss : 23852.330078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 530 | train_loss : 14813.55859375 | val_loss : 21088.48046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 531 | train_loss : 17075.748046875 | val_loss : 7833.94873046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 532 | train_loss : 12769.919921875 | val_loss : 15144.2822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 533 | train_loss : 9559.94140625 | val_loss : 2114.1611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 534 | train_loss : 11093.5947265625 | val_loss : 20660.306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 535 | train_loss : 8837.451171875 | val_loss : 15321.236328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 536 | train_loss : 11952.2509765625 | val_loss : 14524.1884765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 537 | train_loss : 9364.0595703125 | val_loss : 18181.98046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 538 | train_loss : 14539.66796875 | val_loss : 14007.615234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 539 | train_loss : 12323.744140625 | val_loss : 4332.13623046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 540 | train_loss : 9190.412109375 | val_loss : 24634.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 541 | train_loss : 11429.58984375 | val_loss : 9725.8427734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 542 | train_loss : 12475.7451171875 | val_loss : 19190.5234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 543 | train_loss : 13588.912109375 | val_loss : 19804.900390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 544 | train_loss : 16444.98046875 | val_loss : 10795.64453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 545 | train_loss : 13022.837890625 | val_loss : 10774.736328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 546 | train_loss : 12734.8740234375 | val_loss : 20802.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 547 | train_loss : 13485.9404296875 | val_loss : 5676.642578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 548 | train_loss : 10738.8427734375 | val_loss : 31417.259765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 549 | train_loss : 14275.041015625 | val_loss : 11381.40234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 550 | train_loss : 13755.955078125 | val_loss : 10701.669921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 551 | train_loss : 6456.8857421875 | val_loss : 17699.66015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 552 | train_loss : 12281.5947265625 | val_loss : 14709.513671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 553 | train_loss : 10354.17578125 | val_loss : 3387.0087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 554 | train_loss : 9845.05078125 | val_loss : 21790.60546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 555 | train_loss : 11413.7958984375 | val_loss : 3043.902587890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 556 | train_loss : 9932.82421875 | val_loss : 19182.25390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 557 | train_loss : 12655.1650390625 | val_loss : 14647.853515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 558 | train_loss : 15181.1416015625 | val_loss : 14853.552734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 559 | train_loss : 18365.4765625 | val_loss : 20634.1640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 560 | train_loss : 11116.916015625 | val_loss : 19899.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 561 | train_loss : 11979.6689453125 | val_loss : 16100.0849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 562 | train_loss : 11545.3798828125 | val_loss : 10022.2197265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 563 | train_loss : 8625.529296875 | val_loss : 13965.4052734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 564 | train_loss : 10879.9150390625 | val_loss : 14611.38671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 565 | train_loss : 15615.9990234375 | val_loss : 7494.99365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 566 | train_loss : 12408.6220703125 | val_loss : 20665.689453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 567 | train_loss : 10929.1396484375 | val_loss : 2799.657470703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 568 | train_loss : 13920.5927734375 | val_loss : 15943.49609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 569 | train_loss : 10469.7294921875 | val_loss : 6088.72607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 570 | train_loss : 8788.7802734375 | val_loss : 12933.068359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 571 | train_loss : 13299.8720703125 | val_loss : 13676.6220703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 572 | train_loss : 9690.30078125 | val_loss : 25952.82421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 573 | train_loss : 13873.80859375 | val_loss : 2277.217529296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 574 | train_loss : 8571.58984375 | val_loss : 11486.6162109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 575 | train_loss : 5566.3935546875 | val_loss : 1434.956298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 576 | train_loss : 8724.416015625 | val_loss : 21049.626953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 577 | train_loss : 9520.2314453125 | val_loss : 7474.513671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 578 | train_loss : 9883.7666015625 | val_loss : 15524.4853515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 579 | train_loss : 11190.3662109375 | val_loss : 2616.340087890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 580 | train_loss : 5672.537109375 | val_loss : 14246.1416015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 581 | train_loss : 6554.73876953125 | val_loss : 6009.78369140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 582 | train_loss : 8184.43603515625 | val_loss : 11998.9833984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 583 | train_loss : 12720.634765625 | val_loss : 19435.404296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 584 | train_loss : 12467.6083984375 | val_loss : 28346.07421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 585 | train_loss : 12911.244140625 | val_loss : 9196.6025390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 586 | train_loss : 11244.4853515625 | val_loss : 11570.1171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 587 | train_loss : 7816.12255859375 | val_loss : 7616.076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 588 | train_loss : 8046.27734375 | val_loss : 15274.3564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 589 | train_loss : 10615.177734375 | val_loss : 16223.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 590 | train_loss : 10918.7001953125 | val_loss : 15337.869140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 591 | train_loss : 12770.1845703125 | val_loss : 1253.2562255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 592 | train_loss : 9584.669921875 | val_loss : 20920.98046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 593 | train_loss : 8549.8720703125 | val_loss : 11426.205078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 594 | train_loss : 9930.1259765625 | val_loss : 18454.841796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 595 | train_loss : 10092.0068359375 | val_loss : 1488.563720703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 596 | train_loss : 11421.259765625 | val_loss : 20123.701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 597 | train_loss : 9288.3427734375 | val_loss : 18815.55078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 598 | train_loss : 13185.5322265625 | val_loss : 11266.35546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 599 | train_loss : 9031.0634765625 | val_loss : 5756.46630859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 600 | train_loss : 6752.94677734375 | val_loss : 14052.8095703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 601 | train_loss : 10518.3447265625 | val_loss : 16518.66015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 602 | train_loss : 12424.1474609375 | val_loss : 13737.009765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 603 | train_loss : 12066.271484375 | val_loss : 6298.39990234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 604 | train_loss : 9815.3115234375 | val_loss : 22820.970703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 605 | train_loss : 12064.4462890625 | val_loss : 5587.07373046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 606 | train_loss : 21664.251953125 | val_loss : 15775.94140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 607 | train_loss : 8640.8203125 | val_loss : 9855.169921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 608 | train_loss : 11771.5947265625 | val_loss : 12730.634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 609 | train_loss : 13469.08984375 | val_loss : 19079.26171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 610 | train_loss : 11329.8466796875 | val_loss : 23781.2421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 611 | train_loss : 10796.4541015625 | val_loss : 9944.673828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 612 | train_loss : 10855.03125 | val_loss : 17914.8984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 613 | train_loss : 12290.728515625 | val_loss : 2999.070068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 614 | train_loss : 9151.515625 | val_loss : 26688.515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 615 | train_loss : 10408.9853515625 | val_loss : 11355.986328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 616 | train_loss : 9734.3515625 | val_loss : 13747.880859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 617 | train_loss : 6227.0087890625 | val_loss : 3092.824951171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 618 | train_loss : 8331.5205078125 | val_loss : 16650.9375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 619 | train_loss : 7586.41015625 | val_loss : 8495.5185546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 620 | train_loss : 8988.037109375 | val_loss : 11367.849609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 621 | train_loss : 8704.0927734375 | val_loss : 19557.591796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 622 | train_loss : 11956.9990234375 | val_loss : 17618.85546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 623 | train_loss : 11243.8779296875 | val_loss : 4510.8310546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 624 | train_loss : 5464.28515625 | val_loss : 9612.76953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 625 | train_loss : 8770.3642578125 | val_loss : 10095.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 626 | train_loss : 9076.3447265625 | val_loss : 11040.7265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 627 | train_loss : 7042.03125 | val_loss : 16205.443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 628 | train_loss : 10578.03515625 | val_loss : 53403.68359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 629 | train_loss : 61133.26953125 | val_loss : 32016.16015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 630 | train_loss : 36029.30078125 | val_loss : 23108.9609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 631 | train_loss : 28480.494140625 | val_loss : 11204.9072265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 632 | train_loss : 11427.447265625 | val_loss : 6945.51123046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 633 | train_loss : 5614.97265625 | val_loss : 7029.142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 634 | train_loss : 6443.47314453125 | val_loss : 6540.9912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 635 | train_loss : 9086.505859375 | val_loss : 19548.298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 636 | train_loss : 9230.5927734375 | val_loss : 20981.04296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 637 | train_loss : 9731.3408203125 | val_loss : 8544.6103515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 638 | train_loss : 7002.87060546875 | val_loss : 14658.4560546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 639 | train_loss : 9435.94921875 | val_loss : 2758.137451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 640 | train_loss : 7203.9619140625 | val_loss : 21473.744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 641 | train_loss : 8348.1240234375 | val_loss : 9870.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 642 | train_loss : 9686.640625 | val_loss : 15699.228515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 643 | train_loss : 9040.861328125 | val_loss : 3811.90380859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 644 | train_loss : 7240.72119140625 | val_loss : 22132.294921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 645 | train_loss : 9341.83203125 | val_loss : 7264.28515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 646 | train_loss : 11116.5625 | val_loss : 13292.4697265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 647 | train_loss : 9831.78125 | val_loss : 13490.7861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 648 | train_loss : 9558.2421875 | val_loss : 13140.7265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 649 | train_loss : 11258.1474609375 | val_loss : 2928.73876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 650 | train_loss : 9695.7509765625 | val_loss : 18099.658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 651 | train_loss : 7306.205078125 | val_loss : 5583.50244140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 652 | train_loss : 9005.490234375 | val_loss : 15759.228515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 653 | train_loss : 13954.4677734375 | val_loss : 14925.4462890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 654 | train_loss : 12620.45703125 | val_loss : 13098.3134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 655 | train_loss : 13360.08203125 | val_loss : 3403.6298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 656 | train_loss : 8218.869140625 | val_loss : 13811.0703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 657 | train_loss : 7813.60107421875 | val_loss : 1917.8074951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 658 | train_loss : 7451.5185546875 | val_loss : 22948.21484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 659 | train_loss : 8536.9453125 | val_loss : 8624.55078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 660 | train_loss : 7692.39306640625 | val_loss : 17777.880859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 661 | train_loss : 10212.24609375 | val_loss : 2056.02490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 662 | train_loss : 9232.224609375 | val_loss : 18265.3984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 663 | train_loss : 7536.85888671875 | val_loss : 9864.318359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 664 | train_loss : 8409.7763671875 | val_loss : 9703.6650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 665 | train_loss : 7233.4658203125 | val_loss : 14682.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 666 | train_loss : 9628.4248046875 | val_loss : 12284.201171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 667 | train_loss : 8106.947265625 | val_loss : 5979.5849609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 668 | train_loss : 7140.36865234375 | val_loss : 8615.4365234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 669 | train_loss : 9026.46484375 | val_loss : 95546.9375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 670 | train_loss : 76203.2890625 | val_loss : 19891.462890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 671 | train_loss : 28578.45703125 | val_loss : 3306.31494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 672 | train_loss : 15639.5947265625 | val_loss : 6918.99609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 673 | train_loss : 14762.0947265625 | val_loss : 11163.4033203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 674 | train_loss : 15640.7490234375 | val_loss : 17225.92578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 675 | train_loss : 12235.2900390625 | val_loss : 7200.08984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 676 | train_loss : 11376.0791015625 | val_loss : 9228.076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 677 | train_loss : 8194.904296875 | val_loss : 13859.052734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 678 | train_loss : 8127.5048828125 | val_loss : 15416.677734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 679 | train_loss : 7951.06396484375 | val_loss : 6796.962890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 680 | train_loss : 8380.525390625 | val_loss : 11299.52734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 681 | train_loss : 10826.9921875 | val_loss : 6681.5537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 682 | train_loss : 7484.30859375 | val_loss : 11428.4365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 683 | train_loss : 5701.0849609375 | val_loss : 11696.7470703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 684 | train_loss : 25059.337890625 | val_loss : 28808.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 685 | train_loss : 13437.2451171875 | val_loss : 23058.892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 686 | train_loss : 15669.017578125 | val_loss : 15813.388671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 687 | train_loss : 9992.236328125 | val_loss : 6156.2763671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 688 | train_loss : 8641.771484375 | val_loss : 11288.0458984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 689 | train_loss : 7519.857421875 | val_loss : 18184.8359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 690 | train_loss : 10227.15234375 | val_loss : 16545.3046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 691 | train_loss : 11054.6328125 | val_loss : 4452.65869140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 692 | train_loss : 6698.365234375 | val_loss : 15114.12890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 693 | train_loss : 6537.4873046875 | val_loss : 2681.22998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 694 | train_loss : 8134.85205078125 | val_loss : 16336.0625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 695 | train_loss : 6463.5048828125 | val_loss : 4880.03271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 696 | train_loss : 5898.208984375 | val_loss : 11896.947265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 697 | train_loss : 7787.86328125 | val_loss : 2602.8037109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 698 | train_loss : 7793.2607421875 | val_loss : 22237.16796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 699 | train_loss : 13234.650390625 | val_loss : 6283.9814453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 700 | train_loss : 7414.37451171875 | val_loss : 9452.119140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 701 | train_loss : 6529.73583984375 | val_loss : 4468.89990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 702 | train_loss : 7986.8388671875 | val_loss : 14960.5 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 703 | train_loss : 6627.009765625 | val_loss : 7801.90625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 704 | train_loss : 6364.6123046875 | val_loss : 2681.947509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 705 | train_loss : 4851.30078125 | val_loss : 7234.98486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 706 | train_loss : 4818.16943359375 | val_loss : 8643.5888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 707 | train_loss : 7059.05615234375 | val_loss : 10320.2197265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 708 | train_loss : 10742.83984375 | val_loss : 12818.9140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 709 | train_loss : 9334.619140625 | val_loss : 20624.94921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 710 | train_loss : 10510.5322265625 | val_loss : 3272.2236328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 711 | train_loss : 6023.02880859375 | val_loss : 10445.81640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 712 | train_loss : 6532.11376953125 | val_loss : 2512.824951171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 713 | train_loss : 9491.744140625 | val_loss : 18221.734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 714 | train_loss : 7812.32177734375 | val_loss : 9774.3408203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 715 | train_loss : 8906.8134765625 | val_loss : 8891.0810546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 716 | train_loss : 7127.19189453125 | val_loss : 11903.6025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 717 | train_loss : 7561.25048828125 | val_loss : 14226.0595703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 718 | train_loss : 7173.8125 | val_loss : 5693.95361328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 719 | train_loss : 8643.6572265625 | val_loss : 7436.22998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 720 | train_loss : 9575.4501953125 | val_loss : 9538.169921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 721 | train_loss : 7664.19384765625 | val_loss : 13802.787109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 722 | train_loss : 6572.78369140625 | val_loss : 2163.757568359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 723 | train_loss : 8100.77978515625 | val_loss : 17614.734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 724 | train_loss : 7012.29638671875 | val_loss : 4327.35986328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 725 | train_loss : 7130.919921875 | val_loss : 7791.95751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 726 | train_loss : 5734.927734375 | val_loss : 17544.02734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 727 | train_loss : 9849.689453125 | val_loss : 16502.8671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 728 | train_loss : 10843.8935546875 | val_loss : 4649.77001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 729 | train_loss : 6921.1279296875 | val_loss : 9255.0126953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 730 | train_loss : 6224.12353515625 | val_loss : 15600.013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 731 | train_loss : 8468.4296875 | val_loss : 16058.619140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 732 | train_loss : 8918.71875 | val_loss : 4956.302734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 733 | train_loss : 6676.73486328125 | val_loss : 7743.5400390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 734 | train_loss : 6850.01611328125 | val_loss : 9650.3818359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 735 | train_loss : 7128.42822265625 | val_loss : 12861.169921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 736 | train_loss : 8221.208984375 | val_loss : 9024.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 737 | train_loss : 9945.7001953125 | val_loss : 11875.66796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 738 | train_loss : 10541.197265625 | val_loss : 14145.9150390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 739 | train_loss : 8863.9140625 | val_loss : 13865.6884765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 740 | train_loss : 7691.58935546875 | val_loss : 9368.9248046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 741 | train_loss : 8303.056640625 | val_loss : 11825.3759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 742 | train_loss : 10206.91796875 | val_loss : 12659.271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 743 | train_loss : 8322.5927734375 | val_loss : 11378.0625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 744 | train_loss : 6136.14794921875 | val_loss : 6601.201171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 745 | train_loss : 5657.14501953125 | val_loss : 7720.23876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 746 | train_loss : 8446.1591796875 | val_loss : 6973.24755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 747 | train_loss : 5846.5537109375 | val_loss : 15103.1083984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 748 | train_loss : 8206.6513671875 | val_loss : 1025.197509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 749 | train_loss : 7173.0341796875 | val_loss : 11318.12109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 750 | train_loss : 4540.45068359375 | val_loss : 2957.91259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 751 | train_loss : 4483.48486328125 | val_loss : 12158.662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 752 | train_loss : 7867.412109375 | val_loss : 9945.2880859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 753 | train_loss : 7896.826171875 | val_loss : 9191.6435546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 754 | train_loss : 7028.9580078125 | val_loss : 7566.75390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 755 | train_loss : 7114.53076171875 | val_loss : 7722.87890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 756 | train_loss : 7366.95263671875 | val_loss : 11982.080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 757 | train_loss : 8570.251953125 | val_loss : 11257.1123046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 758 | train_loss : 6840.376953125 | val_loss : 2557.4208984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 759 | train_loss : 5263.77001953125 | val_loss : 7825.10498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 760 | train_loss : 6051.2236328125 | val_loss : 10109.0771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 761 | train_loss : 6036.6669921875 | val_loss : 12445.705078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 762 | train_loss : 6443.5986328125 | val_loss : 5162.47998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 763 | train_loss : 7852.47998046875 | val_loss : 8921.6552734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 764 | train_loss : 9389.7138671875 | val_loss : 9823.02734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 765 | train_loss : 6609.755859375 | val_loss : 17246.08203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 766 | train_loss : 8232.7783203125 | val_loss : 575.4149780273438 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 767 | train_loss : 5782.90771484375 | val_loss : 14695.318359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 768 | train_loss : 5848.71142578125 | val_loss : 2249.933837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 769 | train_loss : 5276.72265625 | val_loss : 9324.3916015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 770 | train_loss : 5423.0498046875 | val_loss : 1303.9024658203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 771 | train_loss : 3166.908203125 | val_loss : 12093.1689453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 772 | train_loss : 5175.64697265625 | val_loss : 1772.501220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 773 | train_loss : 6266.55419921875 | val_loss : 7621.98486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 774 | train_loss : 4886.40771484375 | val_loss : 2801.9375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 775 | train_loss : 4300.8623046875 | val_loss : 6834.0048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 776 | train_loss : 5054.47705078125 | val_loss : 11239.615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 777 | train_loss : 7936.43603515625 | val_loss : 10759.6376953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 778 | train_loss : 6460.474609375 | val_loss : 6668.06982421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 779 | train_loss : 8364.380859375 | val_loss : 9482.541015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 780 | train_loss : 9481.84765625 | val_loss : 12322.9951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 781 | train_loss : 7612.220703125 | val_loss : 17169.19921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 782 | train_loss : 7014.55517578125 | val_loss : 2789.95751953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 783 | train_loss : 6203.61767578125 | val_loss : 14339.048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 784 | train_loss : 7977.70166015625 | val_loss : 2393.517578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 785 | train_loss : 7559.4345703125 | val_loss : 17982.52734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 786 | train_loss : 6347.529296875 | val_loss : 5471.9560546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 787 | train_loss : 6209.908203125 | val_loss : 8963.193359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 788 | train_loss : 4790.84326171875 | val_loss : 993.5237426757812 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 789 | train_loss : 4867.3193359375 | val_loss : 12730.39453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 790 | train_loss : 5047.11328125 | val_loss : 3222.648681640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 791 | train_loss : 5473.873046875 | val_loss : 9808.7578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 792 | train_loss : 6855.43017578125 | val_loss : 1547.63623046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 793 | train_loss : 3651.7119140625 | val_loss : 10920.2939453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 794 | train_loss : 4992.03076171875 | val_loss : 2820.51123046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 795 | train_loss : 7507.34228515625 | val_loss : 19274.85546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 796 | train_loss : 13295.3115234375 | val_loss : 5701.12939453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 797 | train_loss : 7009.50048828125 | val_loss : 7271.2001953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 798 | train_loss : 5277.560546875 | val_loss : 3750.262451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 799 | train_loss : 4785.4248046875 | val_loss : 16063.69921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 800 | train_loss : 7385.1513671875 | val_loss : 6272.62353515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 801 | train_loss : 5699.4638671875 | val_loss : 5326.86376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 802 | train_loss : 4095.606201171875 | val_loss : 3164.639892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 803 | train_loss : 4431.3642578125 | val_loss : 12432.34765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 804 | train_loss : 5867.94677734375 | val_loss : 5698.31982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 805 | train_loss : 4758.77294921875 | val_loss : 10460.494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 806 | train_loss : 8737.7802734375 | val_loss : 5156.50244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 807 | train_loss : 9539.9091796875 | val_loss : 12479.7841796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 808 | train_loss : 6506.29248046875 | val_loss : 9068.87109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 809 | train_loss : 5854.72998046875 | val_loss : 3974.603759765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 810 | train_loss : 4890.71484375 | val_loss : 3867.96630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 811 | train_loss : 3941.583984375 | val_loss : 4966.12646484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 812 | train_loss : 4200.6533203125 | val_loss : 10588.2451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 813 | train_loss : 5556.65380859375 | val_loss : 4374.6826171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 814 | train_loss : 4912.9306640625 | val_loss : 3727.027587890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 815 | train_loss : 4161.7705078125 | val_loss : 8860.0322265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 816 | train_loss : 4711.841796875 | val_loss : 1608.1099853515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 817 | train_loss : 4633.63134765625 | val_loss : 14734.259765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 818 | train_loss : 6346.3876953125 | val_loss : 2545.195068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 819 | train_loss : 3776.110595703125 | val_loss : 8969.1865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 820 | train_loss : 6721.033203125 | val_loss : 2741.8662109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 821 | train_loss : 4503.93994140625 | val_loss : 15648.3349609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 822 | train_loss : 7498.9482421875 | val_loss : 1320.98876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 823 | train_loss : 5495.294921875 | val_loss : 15459.5966796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 824 | train_loss : 7081.91796875 | val_loss : 3228.255615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 825 | train_loss : 6042.50927734375 | val_loss : 12873.8837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 826 | train_loss : 6880.36376953125 | val_loss : 3136.22509765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 827 | train_loss : 8428.0576171875 | val_loss : 15695.5478515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 828 | train_loss : 11500.0810546875 | val_loss : 16045.74609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 829 | train_loss : 15107.9150390625 | val_loss : 17121.443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 830 | train_loss : 14608.7275390625 | val_loss : 6679.5341796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 831 | train_loss : 7900.55615234375 | val_loss : 8387.11328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 832 | train_loss : 4179.45703125 | val_loss : 2264.98193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 833 | train_loss : 4471.3623046875 | val_loss : 8540.65234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 834 | train_loss : 4289.171875 | val_loss : 8192.6904296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 835 | train_loss : 7061.27685546875 | val_loss : 8941.6328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 836 | train_loss : 7517.7939453125 | val_loss : 3353.5244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 837 | train_loss : 6087.18017578125 | val_loss : 7415.57861328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 838 | train_loss : 4794.62939453125 | val_loss : 3371.563720703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 839 | train_loss : 5177.04248046875 | val_loss : 11519.818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 840 | train_loss : 5240.63037109375 | val_loss : 1798.677490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 841 | train_loss : 6291.72998046875 | val_loss : 13142.08203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 842 | train_loss : 5485.69921875 | val_loss : 3903.9755859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 843 | train_loss : 5971.29638671875 | val_loss : 9224.48046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 844 | train_loss : 7023.2587890625 | val_loss : 15067.0400390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 845 | train_loss : 9137.6708984375 | val_loss : 13892.017578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 846 | train_loss : 5639.30322265625 | val_loss : 8656.3154296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 847 | train_loss : 5939.06298828125 | val_loss : 10108.9072265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 848 | train_loss : 7338.015625 | val_loss : 3787.621826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 849 | train_loss : 7156.23583984375 | val_loss : 6563.43359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 850 | train_loss : 3191.570068359375 | val_loss : 1138.166259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 851 | train_loss : 4143.53271484375 | val_loss : 13263.9248046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 852 | train_loss : 5482.62451171875 | val_loss : 2209.23876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 853 | train_loss : 8031.044921875 | val_loss : 8688.2294921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 854 | train_loss : 4019.887451171875 | val_loss : 1102.2724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 855 | train_loss : 4390.4130859375 | val_loss : 16374.6962890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 856 | train_loss : 6769.640625 | val_loss : 1557.4993896484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 857 | train_loss : 4989.44873046875 | val_loss : 9057.6123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 858 | train_loss : 4419.3974609375 | val_loss : 5968.57763671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 859 | train_loss : 5988.62255859375 | val_loss : 7272.87744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 860 | train_loss : 4793.11572265625 | val_loss : 9897.67578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 861 | train_loss : 6787.40869140625 | val_loss : 7810.1875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 862 | train_loss : 5236.60205078125 | val_loss : 7674.65478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 863 | train_loss : 6418.64697265625 | val_loss : 9263.9326171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 864 | train_loss : 6211.04833984375 | val_loss : 7575.759765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 865 | train_loss : 5585.75146484375 | val_loss : 9292.64453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 866 | train_loss : 6225.6650390625 | val_loss : 6737.9306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 867 | train_loss : 6230.46630859375 | val_loss : 10299.7158203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 868 | train_loss : 5829.037109375 | val_loss : 10046.5185546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 869 | train_loss : 7510.10009765625 | val_loss : 9411.677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 870 | train_loss : 7893.8564453125 | val_loss : 866.0499877929688 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 871 | train_loss : 4989.6435546875 | val_loss : 16720.814453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 872 | train_loss : 6614.900390625 | val_loss : 4695.009765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 873 | train_loss : 5831.12353515625 | val_loss : 10369.828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 874 | train_loss : 6029.04296875 | val_loss : 1652.447509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 875 | train_loss : 5037.849609375 | val_loss : 11869.0810546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 876 | train_loss : 5281.771484375 | val_loss : 832.66748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 877 | train_loss : 5747.66748046875 | val_loss : 9384.57421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 878 | train_loss : 3518.62255859375 | val_loss : 1017.8462524414062 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 879 | train_loss : 3545.510009765625 | val_loss : 16048.349609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 880 | train_loss : 5993.21435546875 | val_loss : 3032.2119140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 881 | train_loss : 5288.8974609375 | val_loss : 9284.119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 882 | train_loss : 5502.41943359375 | val_loss : 5792.92919921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 883 | train_loss : 5608.228515625 | val_loss : 6884.02490234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 884 | train_loss : 3994.576904296875 | val_loss : 10395.8935546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 885 | train_loss : 6064.2763671875 | val_loss : 9498.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 886 | train_loss : 5467.6513671875 | val_loss : 2122.341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 887 | train_loss : 4866.30419921875 | val_loss : 8879.990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 888 | train_loss : 4603.90478515625 | val_loss : 6277.6162109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 889 | train_loss : 5957.17919921875 | val_loss : 7430.568359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 890 | train_loss : 6755.74169921875 | val_loss : 7331.77197265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 891 | train_loss : 5889.70263671875 | val_loss : 14584.0615234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 892 | train_loss : 7242.2724609375 | val_loss : 990.2324829101562 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 893 | train_loss : 6623.1298828125 | val_loss : 12057.4365234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 894 | train_loss : 4681.27734375 | val_loss : 2133.74560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 895 | train_loss : 3266.476318359375 | val_loss : 8074.39111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 896 | train_loss : 4642.6787109375 | val_loss : 9739.7490234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 897 | train_loss : 6887.3125 | val_loss : 8639.9814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 898 | train_loss : 5308.09375 | val_loss : 5851.810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 899 | train_loss : 5240.072265625 | val_loss : 6493.6826171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 900 | train_loss : 3636.00439453125 | val_loss : 7930.34814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 901 | train_loss : 4856.705078125 | val_loss : 8015.3935546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 902 | train_loss : 4879.53369140625 | val_loss : 4086.31689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 903 | train_loss : 3931.428466796875 | val_loss : 8742.09765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 904 | train_loss : 7059.86181640625 | val_loss : 8543.70703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 905 | train_loss : 7120.21484375 | val_loss : 10069.630859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 906 | train_loss : 5429.12353515625 | val_loss : 2681.86181640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 907 | train_loss : 6077.04541015625 | val_loss : 13393.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 908 | train_loss : 5905.94873046875 | val_loss : 1906.18310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 909 | train_loss : 4284.1865234375 | val_loss : 8657.4853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 910 | train_loss : 4967.00390625 | val_loss : 4416.44921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 911 | train_loss : 3513.87060546875 | val_loss : 7203.708984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 912 | train_loss : 5321.51953125 | val_loss : 7229.14208984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 913 | train_loss : 5078.61279296875 | val_loss : 8773.328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 914 | train_loss : 3978.144287109375 | val_loss : 3744.029296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 915 | train_loss : 4787.23828125 | val_loss : 6978.384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 916 | train_loss : 5994.91357421875 | val_loss : 4968.15478515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 917 | train_loss : 3892.7265625 | val_loss : 7598.80859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 918 | train_loss : 4033.647705078125 | val_loss : 7367.70703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 919 | train_loss : 6559.56982421875 | val_loss : 6877.61865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 920 | train_loss : 5968.435546875 | val_loss : 1701.8062744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 921 | train_loss : 2675.74755859375 | val_loss : 7055.759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 922 | train_loss : 4364.4560546875 | val_loss : 13744.0927734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 923 | train_loss : 7332.8662109375 | val_loss : 13750.1220703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 924 | train_loss : 6755.3955078125 | val_loss : 5842.95556640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 925 | train_loss : 4907.23193359375 | val_loss : 10172.4033203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 926 | train_loss : 7576.4716796875 | val_loss : 7266.75830078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 927 | train_loss : 6495.04052734375 | val_loss : 10086.0498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 928 | train_loss : 5346.91357421875 | val_loss : 1296.6324462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 929 | train_loss : 4152.93896484375 | val_loss : 13267.7177734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 930 | train_loss : 4737.2978515625 | val_loss : 4869.37548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 931 | train_loss : 4747.54296875 | val_loss : 10467.0439453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 932 | train_loss : 5757.30859375 | val_loss : 1524.623779296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 933 | train_loss : 5248.18896484375 | val_loss : 13769.693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 934 | train_loss : 4917.45361328125 | val_loss : 4405.109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 935 | train_loss : 3359.001220703125 | val_loss : 7095.720703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 936 | train_loss : 3681.256591796875 | val_loss : 1714.407470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 937 | train_loss : 4460.36083984375 | val_loss : 14733.1171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 938 | train_loss : 5514.27197265625 | val_loss : 3845.476806640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 939 | train_loss : 6145.14892578125 | val_loss : 9557.2470703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 940 | train_loss : 6634.4375 | val_loss : 1622.916259765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 941 | train_loss : 5059.36767578125 | val_loss : 13100.611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 942 | train_loss : 6257.41357421875 | val_loss : 1400.018798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 943 | train_loss : 6614.4375 | val_loss : 9728.7265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 944 | train_loss : 4133.5859375 | val_loss : 2554.293701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 945 | train_loss : 3886.1123046875 | val_loss : 7153.224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 946 | train_loss : 4067.49365234375 | val_loss : 7306.115234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 947 | train_loss : 5965.6318359375 | val_loss : 7851.73583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 948 | train_loss : 4782.90234375 | val_loss : 4665.638671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 949 | train_loss : 5296.857421875 | val_loss : 4919.62255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 950 | train_loss : 4484.4091796875 | val_loss : 5521.8623046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 951 | train_loss : 3793.783447265625 | val_loss : 7449.5048828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 952 | train_loss : 3703.653076171875 | val_loss : 6219.81884765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 953 | train_loss : 5813.72021484375 | val_loss : 5498.1962890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 954 | train_loss : 4228.568359375 | val_loss : 5349.47802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 955 | train_loss : 3501.695556640625 | val_loss : 6962.11376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 956 | train_loss : 3796.068359375 | val_loss : 8157.291015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 957 | train_loss : 5347.18017578125 | val_loss : 10137.73828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 958 | train_loss : 5195.49951171875 | val_loss : 6908.615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 959 | train_loss : 7196.8486328125 | val_loss : 6794.3798828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 960 | train_loss : 5375.6923828125 | val_loss : 8663.0927734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 961 | train_loss : 5411.58984375 | val_loss : 11317.2783203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 962 | train_loss : 5095.3408203125 | val_loss : 2373.5419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 963 | train_loss : 4863.99169921875 | val_loss : 9554.7060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 964 | train_loss : 8541.8046875 | val_loss : 10460.3857421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 965 | train_loss : 6802.44384765625 | val_loss : 10544.66015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 966 | train_loss : 7324.94140625 | val_loss : 3416.53125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 967 | train_loss : 4510.85986328125 | val_loss : 8021.6806640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 968 | train_loss : 3466.970703125 | val_loss : 3037.673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 969 | train_loss : 3659.90185546875 | val_loss : 8283.33984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 970 | train_loss : 4082.67431640625 | val_loss : 2249.7099609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 971 | train_loss : 3569.5400390625 | val_loss : 7383.064453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 972 | train_loss : 3344.34912109375 | val_loss : 2077.760009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 973 | train_loss : 3196.225341796875 | val_loss : 8040.75390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 974 | train_loss : 3352.949462890625 | val_loss : 3071.760009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 975 | train_loss : 3757.39697265625 | val_loss : 7263.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 976 | train_loss : 3482.74462890625 | val_loss : 3063.40625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 977 | train_loss : 3853.88037109375 | val_loss : 10956.763671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 978 | train_loss : 6296.96435546875 | val_loss : 4818.69384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 979 | train_loss : 4703.34375 | val_loss : 7094.69482421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 980 | train_loss : 4563.0048828125 | val_loss : 3971.18505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 981 | train_loss : 4610.798828125 | val_loss : 9191.6708984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 982 | train_loss : 4218.787109375 | val_loss : 5138.44189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 983 | train_loss : 3348.42626953125 | val_loss : 4555.42138671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 984 | train_loss : 3609.44873046875 | val_loss : 5485.5576171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 985 | train_loss : 4748.6484375 | val_loss : 4933.71044921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 986 | train_loss : 4489.19140625 | val_loss : 6111.10546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 987 | train_loss : 3191.594482421875 | val_loss : 4065.351806640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 988 | train_loss : 3679.234619140625 | val_loss : 8981.037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 989 | train_loss : 4387.13232421875 | val_loss : 8720.904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 990 | train_loss : 6753.8369140625 | val_loss : 7125.9755859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 991 | train_loss : 3722.643798828125 | val_loss : 3165.33447265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 992 | train_loss : 4235.677734375 | val_loss : 10066.6494140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 993 | train_loss : 5702.2607421875 | val_loss : 2040.3031005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 994 | train_loss : 5144.61865234375 | val_loss : 6060.111328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 995 | train_loss : 2450.137451171875 | val_loss : 1187.80810546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 996 | train_loss : 3929.5693359375 | val_loss : 6443.13330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 997 | train_loss : 2743.35400390625 | val_loss : 792.126220703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 998 | train_loss : 2851.4921875 | val_loss : 12545.7099609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 999 | train_loss : 4321.4814453125 | val_loss : 1362.1636962890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1000 | train_loss : 4023.253662109375 | val_loss : 6589.638671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1001 | train_loss : 3079.9794921875 | val_loss : 1866.7437744140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1002 | train_loss : 3447.766357421875 | val_loss : 6434.49267578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1003 | train_loss : 4166.19921875 | val_loss : 9012.2880859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1004 | train_loss : 5999.9150390625 | val_loss : 7051.31689453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1005 | train_loss : 4014.799072265625 | val_loss : 2320.153076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1006 | train_loss : 3262.85498046875 | val_loss : 7606.365234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1007 | train_loss : 5107.74560546875 | val_loss : 6385.74560546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1008 | train_loss : 5894.5966796875 | val_loss : 5512.40234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1009 | train_loss : 2771.170654296875 | val_loss : 1595.53564453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1010 | train_loss : 2964.2138671875 | val_loss : 8367.0771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1011 | train_loss : 4115.8720703125 | val_loss : 6741.98046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1012 | train_loss : 5687.15185546875 | val_loss : 6244.251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1013 | train_loss : 3552.155517578125 | val_loss : 3906.29443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1014 | train_loss : 3994.0439453125 | val_loss : 7212.79541015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1015 | train_loss : 5799.619140625 | val_loss : 5631.521484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1016 | train_loss : 5463.46875 | val_loss : 6660.140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1017 | train_loss : 3604.422119140625 | val_loss : 1230.1175537109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1018 | train_loss : 4831.595703125 | val_loss : 9919.45703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1019 | train_loss : 4402.20703125 | val_loss : 1134.12744140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1020 | train_loss : 4508.93896484375 | val_loss : 10138.1806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1021 | train_loss : 5181.55078125 | val_loss : 84.44750213623047 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1022 | train_loss : 4582.7373046875 | val_loss : 11037.6103515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1023 | train_loss : 4166.72998046875 | val_loss : 1361.0662841796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1024 | train_loss : 4563.21533203125 | val_loss : 8798.1298828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1025 | train_loss : 4746.16552734375 | val_loss : 6950.65478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1026 | train_loss : 5708.740234375 | val_loss : 5948.44580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1027 | train_loss : 3995.481201171875 | val_loss : 2461.512451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1028 | train_loss : 3753.48779296875 | val_loss : 4751.99755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1029 | train_loss : 2549.35009765625 | val_loss : 2762.005615234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1030 | train_loss : 2811.83447265625 | val_loss : 5691.912109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1031 | train_loss : 2316.279296875 | val_loss : 2086.328857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1032 | train_loss : 2928.824951171875 | val_loss : 8017.78564453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1033 | train_loss : 4288.99609375 | val_loss : 7255.7626953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1034 | train_loss : 5821.21484375 | val_loss : 5958.783203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1035 | train_loss : 3541.314453125 | val_loss : 3543.5732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1036 | train_loss : 3751.120849609375 | val_loss : 7993.92236328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1037 | train_loss : 5126.18603515625 | val_loss : 7342.70068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1038 | train_loss : 5903.36083984375 | val_loss : 6906.45751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1039 | train_loss : 3252.90087890625 | val_loss : 1931.4737548828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1040 | train_loss : 3598.3759765625 | val_loss : 7998.1142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1041 | train_loss : 3276.1337890625 | val_loss : 1994.6025390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1042 | train_loss : 3890.99853515625 | val_loss : 8565.4189453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1043 | train_loss : 7479.37939453125 | val_loss : 8906.8232421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1044 | train_loss : 6024.43603515625 | val_loss : 9525.4375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1045 | train_loss : 8296.5380859375 | val_loss : 1569.3631591796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1046 | train_loss : 4783.947265625 | val_loss : 12124.4052734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1047 | train_loss : 4805.42919921875 | val_loss : 2473.138671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1048 | train_loss : 2837.181640625 | val_loss : 38697.67578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1049 | train_loss : 36319.828125 | val_loss : 5028.185546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1050 | train_loss : 13811.111328125 | val_loss : 11754.8115234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1051 | train_loss : 5859.8251953125 | val_loss : 3101.61572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1052 | train_loss : 2747.2177734375 | val_loss : 6200.751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1053 | train_loss : 3875.00439453125 | val_loss : 6060.14697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1054 | train_loss : 4844.8349609375 | val_loss : 6873.32421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1055 | train_loss : 3575.77685546875 | val_loss : 4295.208984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1056 | train_loss : 4370.7763671875 | val_loss : 5523.17041015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1057 | train_loss : 5455.1591796875 | val_loss : 6075.4404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1058 | train_loss : 4059.95947265625 | val_loss : 8101.18115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1059 | train_loss : 3993.021240234375 | val_loss : 1399.5380859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1060 | train_loss : 3823.86083984375 | val_loss : 8962.9287109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1061 | train_loss : 4231.783203125 | val_loss : 868.2412719726562 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1062 | train_loss : 4588.4384765625 | val_loss : 8366.263671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1063 | train_loss : 3194.596923828125 | val_loss : 1640.6444091796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1064 | train_loss : 2548.5751953125 | val_loss : 7862.47509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1065 | train_loss : 3286.7314453125 | val_loss : 2268.183837890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1066 | train_loss : 4746.50146484375 | val_loss : 12367.365234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1067 | train_loss : 4984.22802734375 | val_loss : 1975.4412841796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1068 | train_loss : 3771.601318359375 | val_loss : 7987.29248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1069 | train_loss : 3400.13818359375 | val_loss : 1430.096923828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1070 | train_loss : 3751.55615234375 | val_loss : 5804.4560546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1071 | train_loss : 3172.875 | val_loss : 5128.2783203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1072 | train_loss : 4527.7861328125 | val_loss : 6365.00390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1073 | train_loss : 3109.477294921875 | val_loss : 2522.3193359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1074 | train_loss : 2928.78125 | val_loss : 7024.18505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1075 | train_loss : 4087.02685546875 | val_loss : 7404.89794921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1076 | train_loss : 5157.79443359375 | val_loss : 6738.251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1077 | train_loss : 3781.913818359375 | val_loss : 1415.8419189453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1078 | train_loss : 2930.809326171875 | val_loss : 9346.408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1079 | train_loss : 4169.73486328125 | val_loss : 4071.885009765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1080 | train_loss : 4867.44580078125 | val_loss : 5418.45361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1081 | train_loss : 5271.912109375 | val_loss : 4988.0029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1082 | train_loss : 3861.338134765625 | val_loss : 8832.6220703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1083 | train_loss : 3441.29931640625 | val_loss : 587.4450073242188 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1084 | train_loss : 4073.487548828125 | val_loss : 10036.3896484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1085 | train_loss : 3734.324462890625 | val_loss : 1045.701904296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1086 | train_loss : 2847.258056640625 | val_loss : 8907.1865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1087 | train_loss : 3253.58349609375 | val_loss : 867.8331298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1088 | train_loss : 4284.7451171875 | val_loss : 10111.4404296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1089 | train_loss : 3620.64697265625 | val_loss : 1473.09814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1090 | train_loss : 2741.1982421875 | val_loss : 7223.392578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1091 | train_loss : 3024.061279296875 | val_loss : 2056.5400390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1092 | train_loss : 3724.633544921875 | val_loss : 12841.64453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1093 | train_loss : 4792.2841796875 | val_loss : 2318.117431640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1094 | train_loss : 3562.699462890625 | val_loss : 8177.23388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1095 | train_loss : 4153.84228515625 | val_loss : 4032.3974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1096 | train_loss : 4482.76025390625 | val_loss : 5449.37451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1097 | train_loss : 2539.98681640625 | val_loss : 3242.900634765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1098 | train_loss : 3319.316162109375 | val_loss : 6231.3251953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1099 | train_loss : 3888.587158203125 | val_loss : 7174.5654296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1100 | train_loss : 5007.65380859375 | val_loss : 7642.5361328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1101 | train_loss : 4055.250732421875 | val_loss : 3966.375732421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1102 | train_loss : 4225.86083984375 | val_loss : 7379.92431640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1103 | train_loss : 5576.7275390625 | val_loss : 6198.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1104 | train_loss : 4191.9111328125 | val_loss : 8703.43359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1105 | train_loss : 3879.65966796875 | val_loss : 1862.5474853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1106 | train_loss : 4126.78515625 | val_loss : 6643.10888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1107 | train_loss : 4196.67431640625 | val_loss : 8692.109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1108 | train_loss : 4834.6787109375 | val_loss : 8483.2607421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1109 | train_loss : 5079.23388671875 | val_loss : 2656.820556640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1110 | train_loss : 5413.05859375 | val_loss : 9153.380859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1111 | train_loss : 3923.953857421875 | val_loss : 1686.6356201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1112 | train_loss : 3691.6357421875 | val_loss : 6682.02490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1113 | train_loss : 2849.036865234375 | val_loss : 1616.688720703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1114 | train_loss : 3182.925048828125 | val_loss : 6321.6220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1115 | train_loss : 2690.171630859375 | val_loss : 1001.235595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1116 | train_loss : 3468.652587890625 | val_loss : 8363.5224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1117 | train_loss : 3033.83447265625 | val_loss : 670.9255981445312 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1118 | train_loss : 4214.06201171875 | val_loss : 10354.97265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1119 | train_loss : 3751.984375 | val_loss : 1772.71875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1120 | train_loss : 3857.730224609375 | val_loss : 10961.05078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1121 | train_loss : 4659.55810546875 | val_loss : 1875.3575439453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1122 | train_loss : 4586.4580078125 | val_loss : 11271.9697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1123 | train_loss : 4762.236328125 | val_loss : 2132.9375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1124 | train_loss : 4360.98828125 | val_loss : 10767.3896484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1125 | train_loss : 4607.86572265625 | val_loss : 1062.5362548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1126 | train_loss : 4573.0439453125 | val_loss : 10951.5029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1127 | train_loss : 4269.134765625 | val_loss : 1474.0550537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1128 | train_loss : 3472.516845703125 | val_loss : 26857.373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1129 | train_loss : 14063.8447265625 | val_loss : 3529.8076171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1130 | train_loss : 10688.6865234375 | val_loss : 2929.94384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1131 | train_loss : 2660.651611328125 | val_loss : 5755.04638671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1132 | train_loss : 4143.43896484375 | val_loss : 5786.4931640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1133 | train_loss : 4087.1845703125 | val_loss : 2371.991943359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1134 | train_loss : 2693.453857421875 | val_loss : 5462.09423828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1135 | train_loss : 3647.635009765625 | val_loss : 5913.5283203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1136 | train_loss : 3471.998779296875 | val_loss : 5958.12890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1137 | train_loss : 3066.92626953125 | val_loss : 3424.811279296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1138 | train_loss : 2916.621337890625 | val_loss : 5723.0908203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1139 | train_loss : 4818.29443359375 | val_loss : 4980.4443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1140 | train_loss : 3315.166259765625 | val_loss : 6885.72998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1141 | train_loss : 2945.68994140625 | val_loss : 1916.7506103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1142 | train_loss : 2643.38916015625 | val_loss : 6484.17822265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1143 | train_loss : 3755.87353515625 | val_loss : 8257.90234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1144 | train_loss : 4677.9853515625 | val_loss : 8632.9921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1145 | train_loss : 4629.42138671875 | val_loss : 2634.679443359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1146 | train_loss : 3709.071533203125 | val_loss : 4556.02978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1147 | train_loss : 3083.19384765625 | val_loss : 3093.983154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1148 | train_loss : 2217.861328125 | val_loss : 5594.421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1149 | train_loss : 3960.01318359375 | val_loss : 5333.73046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1150 | train_loss : 3369.047119140625 | val_loss : 7894.2783203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1151 | train_loss : 3384.96875 | val_loss : 2975.05322265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1152 | train_loss : 3096.8486328125 | val_loss : 6534.326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1153 | train_loss : 4175.28369140625 | val_loss : 7324.416015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1154 | train_loss : 4168.8544921875 | val_loss : 8120.60888671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1155 | train_loss : 3529.866943359375 | val_loss : 1738.5843505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1156 | train_loss : 2735.9580078125 | val_loss : 5450.224609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1157 | train_loss : 2794.062744140625 | val_loss : 5205.26953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1158 | train_loss : 3188.24462890625 | val_loss : 5973.30419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1159 | train_loss : 3216.390869140625 | val_loss : 4257.48291015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1160 | train_loss : 3416.3349609375 | val_loss : 6442.28564453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1161 | train_loss : 3463.8671875 | val_loss : 5854.619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1162 | train_loss : 4193.09423828125 | val_loss : 6293.75390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1163 | train_loss : 2971.239990234375 | val_loss : 4120.33935546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1164 | train_loss : 3306.168701171875 | val_loss : 5830.783203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1165 | train_loss : 4358.703125 | val_loss : 5832.98193359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1166 | train_loss : 3526.087158203125 | val_loss : 7465.5087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1167 | train_loss : 3120.787841796875 | val_loss : 1241.311279296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1168 | train_loss : 2492.596435546875 | val_loss : 7122.0693359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1169 | train_loss : 4176.80517578125 | val_loss : 540.546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1170 | train_loss : 2785.8056640625 | val_loss : 8547.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1171 | train_loss : 4077.563232421875 | val_loss : 2307.516357421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1172 | train_loss : 2689.199951171875 | val_loss : 5380.53857421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1173 | train_loss : 2129.43310546875 | val_loss : 594.7762451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1174 | train_loss : 2977.4013671875 | val_loss : 6490.10302734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1175 | train_loss : 2544.81494140625 | val_loss : 2231.51806640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1176 | train_loss : 2030.119384765625 | val_loss : 7836.87109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1177 | train_loss : 3458.5654296875 | val_loss : 4272.04931640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1178 | train_loss : 3618.06591796875 | val_loss : 9282.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1179 | train_loss : 5358.3681640625 | val_loss : 4068.070556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1180 | train_loss : 3440.068115234375 | val_loss : 8112.40673828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1181 | train_loss : 3802.809326171875 | val_loss : 2906.195068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1182 | train_loss : 2718.8359375 | val_loss : 6998.5439453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1183 | train_loss : 3456.556640625 | val_loss : 2659.0087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1184 | train_loss : 3357.52978515625 | val_loss : 7701.06689453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1185 | train_loss : 3340.0888671875 | val_loss : 2349.208740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1186 | train_loss : 2317.68212890625 | val_loss : 6443.3310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1187 | train_loss : 3220.55029296875 | val_loss : 2487.826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1188 | train_loss : 4288.55078125 | val_loss : 7824.00390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1189 | train_loss : 3090.558349609375 | val_loss : 2900.364990234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1190 | train_loss : 2091.578857421875 | val_loss : 4195.5576171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1191 | train_loss : 2340.94873046875 | val_loss : 2601.091796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1192 | train_loss : 3112.01025390625 | val_loss : 7874.05419921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1193 | train_loss : 3689.375244140625 | val_loss : 4447.759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1194 | train_loss : 2225.5791015625 | val_loss : 1194.0074462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1195 | train_loss : 2172.2177734375 | val_loss : 8026.31005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1196 | train_loss : 3057.67333984375 | val_loss : 418.4731140136719 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1197 | train_loss : 3475.01904296875 | val_loss : 7290.9658203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1198 | train_loss : 2576.066650390625 | val_loss : 112.38999938964844 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1199 | train_loss : 3577.58251953125 | val_loss : 10140.103515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1200 | train_loss : 3376.384033203125 | val_loss : 914.70751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1201 | train_loss : 3436.957275390625 | val_loss : 6386.60498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1202 | train_loss : 2555.001220703125 | val_loss : 772.25439453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1203 | train_loss : 3519.9130859375 | val_loss : 10863.107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1204 | train_loss : 3747.0732421875 | val_loss : 940.2550048828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1205 | train_loss : 3965.69189453125 | val_loss : 7765.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1206 | train_loss : 2892.62353515625 | val_loss : 769.766845703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1207 | train_loss : 4036.3388671875 | val_loss : 8377.451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1208 | train_loss : 3112.9775390625 | val_loss : 385.4856262207031 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1209 | train_loss : 2378.186767578125 | val_loss : 10047.66796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1210 | train_loss : 3515.36181640625 | val_loss : 611.6024780273438 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1211 | train_loss : 3644.635009765625 | val_loss : 8632.212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1212 | train_loss : 3472.398681640625 | val_loss : 930.3356323242188 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1213 | train_loss : 2169.409912109375 | val_loss : 9520.732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1214 | train_loss : 3914.65869140625 | val_loss : 1839.6981201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1215 | train_loss : 2635.927490234375 | val_loss : 6917.66357421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1216 | train_loss : 3055.049072265625 | val_loss : 2806.360595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1217 | train_loss : 3152.432861328125 | val_loss : 7070.01513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1218 | train_loss : 3368.98193359375 | val_loss : 2946.54248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1219 | train_loss : 2444.289794921875 | val_loss : 6082.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1220 | train_loss : 2962.289306640625 | val_loss : 1500.670654296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1221 | train_loss : 2463.37158203125 | val_loss : 7641.69677734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1222 | train_loss : 3382.375 | val_loss : 3044.43505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1223 | train_loss : 2471.16162109375 | val_loss : 5850.076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1224 | train_loss : 2729.897216796875 | val_loss : 1383.092529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1225 | train_loss : 2679.7900390625 | val_loss : 7448.32861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1226 | train_loss : 3189.90087890625 | val_loss : 3789.036865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1227 | train_loss : 2597.775390625 | val_loss : 4099.60986328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1228 | train_loss : 2847.46240234375 | val_loss : 3506.811279296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1229 | train_loss : 3478.522216796875 | val_loss : 9551.49609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1230 | train_loss : 3905.966796875 | val_loss : 2803.849365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1231 | train_loss : 2074.5 | val_loss : 5151.4345703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1232 | train_loss : 2790.12744140625 | val_loss : 677.2562255859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1233 | train_loss : 2975.511474609375 | val_loss : 6848.201171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1234 | train_loss : 2177.679931640625 | val_loss : 40.32624816894531 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1235 | train_loss : 3819.956298828125 | val_loss : 8646.8642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1236 | train_loss : 2697.386962890625 | val_loss : 799.014404296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1237 | train_loss : 2376.6806640625 | val_loss : 7905.71728515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1238 | train_loss : 3053.760009765625 | val_loss : 1347.4906005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1239 | train_loss : 5145.77685546875 | val_loss : 4902.0576171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1240 | train_loss : 2827.38818359375 | val_loss : 1468.8363037109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1241 | train_loss : 3739.5205078125 | val_loss : 8383.9375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1242 | train_loss : 3425.642578125 | val_loss : 370.0318603515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1243 | train_loss : 2996.144287109375 | val_loss : 9461.4716796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1244 | train_loss : 3315.62158203125 | val_loss : 408.2281188964844 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1245 | train_loss : 3123.72509765625 | val_loss : 6144.06396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1246 | train_loss : 2225.324462890625 | val_loss : 285.4150085449219 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1247 | train_loss : 3139.9443359375 | val_loss : 8606.9521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1248 | train_loss : 2902.80908203125 | val_loss : 811.9606323242188 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1249 | train_loss : 3175.226806640625 | val_loss : 9379.8359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1250 | train_loss : 3491.494140625 | val_loss : 382.0425109863281 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1251 | train_loss : 3776.686767578125 | val_loss : 8150.33544921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1252 | train_loss : 2913.1171875 | val_loss : 448.70001220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1253 | train_loss : 3323.91259765625 | val_loss : 9961.2373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1254 | train_loss : 3626.652587890625 | val_loss : 1441.0875244140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1255 | train_loss : 3621.877197265625 | val_loss : 10733.9921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1256 | train_loss : 4401.5439453125 | val_loss : 1628.8187255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1257 | train_loss : 4781.576171875 | val_loss : 8963.6953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1258 | train_loss : 3779.82470703125 | val_loss : 1627.012451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1259 | train_loss : 2307.2236328125 | val_loss : 7585.08056640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1260 | train_loss : 2882.3125 | val_loss : 1234.13818359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1261 | train_loss : 3106.775634765625 | val_loss : 10065.244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1262 | train_loss : 3588.268798828125 | val_loss : 1576.471923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1263 | train_loss : 3807.90478515625 | val_loss : 4630.1005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1264 | train_loss : 2091.05615234375 | val_loss : 1039.1456298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1265 | train_loss : 2441.332763671875 | val_loss : 10497.54296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1266 | train_loss : 3513.538330078125 | val_loss : 732.05810546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1267 | train_loss : 3497.195068359375 | val_loss : 5813.654296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1268 | train_loss : 2121.693359375 | val_loss : 512.5831298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1269 | train_loss : 2207.580078125 | val_loss : 9902.6689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1270 | train_loss : 3282.531494140625 | val_loss : 770.869384765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1271 | train_loss : 3405.28564453125 | val_loss : 6128.826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1272 | train_loss : 2310.6484375 | val_loss : 695.958740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1273 | train_loss : 2856.52197265625 | val_loss : 7005.90869140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1274 | train_loss : 2499.85791015625 | val_loss : 732.4918823242188 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1275 | train_loss : 2907.20947265625 | val_loss : 9324.06640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1276 | train_loss : 3185.98583984375 | val_loss : 799.2949829101562 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1277 | train_loss : 2586.3388671875 | val_loss : 6082.0439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1278 | train_loss : 2652.941162109375 | val_loss : 5502.181640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1279 | train_loss : 4649.8427734375 | val_loss : 5530.099609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1280 | train_loss : 2257.822509765625 | val_loss : 999.9081420898438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1281 | train_loss : 1862.83447265625 | val_loss : 7334.4755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1282 | train_loss : 2877.943115234375 | val_loss : 1165.81689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1283 | train_loss : 2675.230712890625 | val_loss : 9054.603515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1284 | train_loss : 3414.6533203125 | val_loss : 797.1162719726562 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1285 | train_loss : 4396.5791015625 | val_loss : 4819.5556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1286 | train_loss : 1799.275634765625 | val_loss : 1026.5380859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1287 | train_loss : 2532.300048828125 | val_loss : 7844.84423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1288 | train_loss : 3019.2412109375 | val_loss : 319.0787353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1289 | train_loss : 3407.642578125 | val_loss : 7084.6806640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1290 | train_loss : 2287.6591796875 | val_loss : 430.9443664550781 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1291 | train_loss : 2373.701904296875 | val_loss : 8393.0380859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1292 | train_loss : 2598.64599609375 | val_loss : 502.21563720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1293 | train_loss : 2821.20849609375 | val_loss : 9417.421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1294 | train_loss : 3235.5869140625 | val_loss : 714.5956420898438 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1295 | train_loss : 3059.79833984375 | val_loss : 7170.31494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1296 | train_loss : 2664.414306640625 | val_loss : 743.5518798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1297 | train_loss : 2720.931640625 | val_loss : 8126.82177734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1298 | train_loss : 2843.369384765625 | val_loss : 1067.00244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1299 | train_loss : 2160.7275390625 | val_loss : 7983.052734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1300 | train_loss : 2732.061279296875 | val_loss : 255.14125061035156 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1301 | train_loss : 3209.951904296875 | val_loss : 9703.95703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1302 | train_loss : 3469.991455078125 | val_loss : 2068.534912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1303 | train_loss : 2609.224609375 | val_loss : 6843.52294921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1304 | train_loss : 3606.5498046875 | val_loss : 1382.862548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1305 | train_loss : 3887.9326171875 | val_loss : 8692.7998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1306 | train_loss : 3255.111572265625 | val_loss : 619.4912719726562 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1307 | train_loss : 3114.218017578125 | val_loss : 6256.72998046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1308 | train_loss : 2247.887451171875 | val_loss : 151.9268798828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1309 | train_loss : 2849.95849609375 | val_loss : 9130.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1310 | train_loss : 2864.961181640625 | val_loss : 751.516845703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1311 | train_loss : 2827.463134765625 | val_loss : 6996.69921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1312 | train_loss : 2393.1220703125 | val_loss : 635.0599975585938 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1313 | train_loss : 2524.23974609375 | val_loss : 8908.96484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1314 | train_loss : 3030.4736328125 | val_loss : 1139.4837646484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1315 | train_loss : 2182.63134765625 | val_loss : 7695.771484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1316 | train_loss : 2883.244140625 | val_loss : 70.08875274658203 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1317 | train_loss : 3038.7392578125 | val_loss : 7610.9169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1318 | train_loss : 2457.763916015625 | val_loss : 954.431884765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1319 | train_loss : 2504.601318359375 | val_loss : 7989.591796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1320 | train_loss : 3047.6943359375 | val_loss : 1022.34375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1321 | train_loss : 4206.22900390625 | val_loss : 5462.1845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1322 | train_loss : 2139.13037109375 | val_loss : 409.864990234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1323 | train_loss : 1937.829833984375 | val_loss : 8013.23876953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1324 | train_loss : 2708.341796875 | val_loss : 641.1875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1325 | train_loss : 1807.1993408203125 | val_loss : 6689.10546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1326 | train_loss : 2222.31884765625 | val_loss : 760.4974975585938 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1327 | train_loss : 3069.592529296875 | val_loss : 8625.2294921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1328 | train_loss : 3059.43896484375 | val_loss : 884.7787475585938 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1329 | train_loss : 1542.9859619140625 | val_loss : 5251.0380859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1330 | train_loss : 1807.96923828125 | val_loss : 1124.984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1331 | train_loss : 1692.9547119140625 | val_loss : 5582.77294921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1332 | train_loss : 2597.285400390625 | val_loss : 5651.431640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1333 | train_loss : 3910.88623046875 | val_loss : 4699.66064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1334 | train_loss : 2102.398193359375 | val_loss : 2444.461181640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1335 | train_loss : 2091.0390625 | val_loss : 59484.64453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1336 | train_loss : 65620.7578125 | val_loss : 15034.73046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1337 | train_loss : 16921.453125 | val_loss : 8708.9248046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1338 | train_loss : 11264.5634765625 | val_loss : 4489.87744140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1339 | train_loss : 11877.603515625 | val_loss : 6054.27001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1340 | train_loss : 7209.38134765625 | val_loss : 6640.00146484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1341 | train_loss : 4271.5185546875 | val_loss : 2603.260986328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1342 | train_loss : 2867.474365234375 | val_loss : 6417.09619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1343 | train_loss : 4201.98291015625 | val_loss : 5251.68505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1344 | train_loss : 3824.782470703125 | val_loss : 6665.91455078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1345 | train_loss : 2731.796142578125 | val_loss : 843.4593505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1346 | train_loss : 2416.6552734375 | val_loss : 6137.30615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1347 | train_loss : 3152.816650390625 | val_loss : 5885.04638671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1348 | train_loss : 4043.044921875 | val_loss : 5947.1455078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1349 | train_loss : 2572.9208984375 | val_loss : 1521.6993408203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1350 | train_loss : 1965.2744140625 | val_loss : 5503.328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1351 | train_loss : 2745.978515625 | val_loss : 2901.7978515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1352 | train_loss : 2570.72900390625 | val_loss : 5767.99560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1353 | train_loss : 3736.869140625 | val_loss : 3137.563232421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1354 | train_loss : 3420.4111328125 | val_loss : 3945.064453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1355 | train_loss : 1979.31298828125 | val_loss : 4273.5400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1356 | train_loss : 2739.7470703125 | val_loss : 5416.56005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1357 | train_loss : 2711.131591796875 | val_loss : 4465.6123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1358 | train_loss : 3165.408203125 | val_loss : 5185.3544921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1359 | train_loss : 2797.74755859375 | val_loss : 4444.29296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1360 | train_loss : 2915.725341796875 | val_loss : 6929.79541015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1361 | train_loss : 3379.934326171875 | val_loss : 3987.387451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1362 | train_loss : 3649.492431640625 | val_loss : 4983.923828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1363 | train_loss : 2868.642822265625 | val_loss : 4128.30029296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1364 | train_loss : 2536.644287109375 | val_loss : 5436.333984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1365 | train_loss : 2742.0810546875 | val_loss : 3207.72119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1366 | train_loss : 2593.3408203125 | val_loss : 6035.15234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1367 | train_loss : 3339.789794921875 | val_loss : 4602.7841796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1368 | train_loss : 3937.09130859375 | val_loss : 5189.80322265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1369 | train_loss : 2572.359619140625 | val_loss : 3828.693115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1370 | train_loss : 3294.94189453125 | val_loss : 6599.072265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1371 | train_loss : 3769.70068359375 | val_loss : 4332.04541015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1372 | train_loss : 3256.80712890625 | val_loss : 4326.72412109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1373 | train_loss : 2956.42626953125 | val_loss : 2241.8818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1374 | train_loss : 1737.1131591796875 | val_loss : 3452.36376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1375 | train_loss : 2502.623046875 | val_loss : 3996.738525390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1376 | train_loss : 2712.011474609375 | val_loss : 4728.16748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1377 | train_loss : 2058.067626953125 | val_loss : 2366.3662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1378 | train_loss : 2055.359130859375 | val_loss : 4971.36083984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1379 | train_loss : 3007.10400390625 | val_loss : 4867.33544921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1380 | train_loss : 3082.768798828125 | val_loss : 7087.328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1381 | train_loss : 2586.254150390625 | val_loss : 599.6603393554688 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1382 | train_loss : 1787.3284912109375 | val_loss : 6535.01123046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1383 | train_loss : 2069.193603515625 | val_loss : 375.10186767578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1384 | train_loss : 2481.289306640625 | val_loss : 6852.38916015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1385 | train_loss : 2375.943603515625 | val_loss : 545.7999877929688 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1386 | train_loss : 1594.9129638671875 | val_loss : 5369.4150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1387 | train_loss : 1819.0684814453125 | val_loss : 793.9281005859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1388 | train_loss : 1791.48681640625 | val_loss : 7354.166015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1389 | train_loss : 2601.581298828125 | val_loss : 777.1912231445312 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1390 | train_loss : 1560.9803466796875 | val_loss : 6392.0400390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1391 | train_loss : 2236.686279296875 | val_loss : 536.10498046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1392 | train_loss : 2509.1435546875 | val_loss : 8057.6982421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1393 | train_loss : 2555.4296875 | val_loss : 316.9437561035156 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1394 | train_loss : 2030.809814453125 | val_loss : 6160.25439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1395 | train_loss : 1887.221923828125 | val_loss : 363.6625061035156 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1396 | train_loss : 2455.800048828125 | val_loss : 8023.4248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1397 | train_loss : 2653.273193359375 | val_loss : 1094.169677734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1398 | train_loss : 1724.2734375 | val_loss : 4251.35205078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1399 | train_loss : 1495.0865478515625 | val_loss : 643.9443969726562 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1400 | train_loss : 1865.8470458984375 | val_loss : 5783.69384765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1401 | train_loss : 1942.4927978515625 | val_loss : 1173.88623046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1402 | train_loss : 2465.553955078125 | val_loss : 4101.73828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1403 | train_loss : 2333.591064453125 | val_loss : 5541.3486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1404 | train_loss : 3205.47900390625 | val_loss : 6155.310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1405 | train_loss : 2187.5341796875 | val_loss : 534.6165771484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1406 | train_loss : 1860.9296875 | val_loss : 5715.34423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1407 | train_loss : 2026.205322265625 | val_loss : 302.41876220703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1408 | train_loss : 2516.9990234375 | val_loss : 7905.89453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1409 | train_loss : 2729.85595703125 | val_loss : 479.6256103515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1410 | train_loss : 1822.6014404296875 | val_loss : 3513.48095703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1411 | train_loss : 1381.790283203125 | val_loss : 1163.9683837890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1412 | train_loss : 1395.212158203125 | val_loss : 4704.984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1413 | train_loss : 2232.68798828125 | val_loss : 5359.59326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1414 | train_loss : 3330.164306640625 | val_loss : 6978.88427734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1415 | train_loss : 2630.46435546875 | val_loss : 472.0731201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1416 | train_loss : 2202.170166015625 | val_loss : 4399.009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1417 | train_loss : 1640.2572021484375 | val_loss : 1128.764404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1418 | train_loss : 1459.20361328125 | val_loss : 5425.0908203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1419 | train_loss : 2491.787841796875 | val_loss : 4726.88671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1420 | train_loss : 3596.6962890625 | val_loss : 5018.11767578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1421 | train_loss : 2047.3232421875 | val_loss : 1213.9912109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1422 | train_loss : 1566.8382568359375 | val_loss : 4047.383056640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1423 | train_loss : 2011.341552734375 | val_loss : 4561.39892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1424 | train_loss : 2673.1162109375 | val_loss : 6609.05078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1425 | train_loss : 2649.715087890625 | val_loss : 2218.4990234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1426 | train_loss : 3148.354736328125 | val_loss : 3456.945556640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1427 | train_loss : 3056.382568359375 | val_loss : 3724.989990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1428 | train_loss : 2378.51806640625 | val_loss : 4432.7939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1429 | train_loss : 2136.01708984375 | val_loss : 2726.797119140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1430 | train_loss : 2472.098388671875 | val_loss : 5894.224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1431 | train_loss : 3112.9755859375 | val_loss : 3734.66064453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1432 | train_loss : 3233.455078125 | val_loss : 5029.53564453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1433 | train_loss : 1913.8511962890625 | val_loss : 2616.357177734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1434 | train_loss : 2492.5517578125 | val_loss : 5001.357421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1435 | train_loss : 2848.775634765625 | val_loss : 3779.421142578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1436 | train_loss : 2698.77880859375 | val_loss : 6079.8720703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1437 | train_loss : 2872.21875 | val_loss : 3254.454345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1438 | train_loss : 3293.556884765625 | val_loss : 4597.27294921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1439 | train_loss : 2257.626708984375 | val_loss : 3355.95556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1440 | train_loss : 2073.656494140625 | val_loss : 5148.06640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1441 | train_loss : 2362.458984375 | val_loss : 2944.1953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1442 | train_loss : 2451.06591796875 | val_loss : 3667.0869140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1443 | train_loss : 1915.0775146484375 | val_loss : 3096.963134765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1444 | train_loss : 2098.371826171875 | val_loss : 4743.8720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1445 | train_loss : 2519.017578125 | val_loss : 2944.080322265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1446 | train_loss : 2505.8056640625 | val_loss : 5114.251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1447 | train_loss : 2445.4365234375 | val_loss : 3685.835205078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1448 | train_loss : 3006.175048828125 | val_loss : 4469.79833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1449 | train_loss : 2110.757080078125 | val_loss : 3602.48193359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1450 | train_loss : 2124.679443359375 | val_loss : 3933.577392578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1451 | train_loss : 1867.5028076171875 | val_loss : 3861.241943359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1452 | train_loss : 2424.958984375 | val_loss : 5133.63818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1453 | train_loss : 2359.4482421875 | val_loss : 3286.389892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1454 | train_loss : 2399.8701171875 | val_loss : 6502.314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1455 | train_loss : 2892.0791015625 | val_loss : 3684.76708984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1456 | train_loss : 3352.617431640625 | val_loss : 4309.5263671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1457 | train_loss : 1908.6424560546875 | val_loss : 2663.508056640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1458 | train_loss : 2165.501708984375 | val_loss : 5216.2294921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1459 | train_loss : 2696.8349609375 | val_loss : 2821.67431640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1460 | train_loss : 2322.650146484375 | val_loss : 3905.639892578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1461 | train_loss : 1316.2265625 | val_loss : 1026.388427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1462 | train_loss : 1609.8323974609375 | val_loss : 4652.19677734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1463 | train_loss : 2036.119873046875 | val_loss : 4616.55126953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1464 | train_loss : 2756.534423828125 | val_loss : 5846.751953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1465 | train_loss : 1986.825439453125 | val_loss : 792.439697265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1466 | train_loss : 1782.235595703125 | val_loss : 4880.5263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1467 | train_loss : 1576.854736328125 | val_loss : 515.453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1468 | train_loss : 1410.8056640625 | val_loss : 4166.3134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1469 | train_loss : 1300.050537109375 | val_loss : 642.4656372070312 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1470 | train_loss : 1661.9290771484375 | val_loss : 7801.2607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1471 | train_loss : 2446.927734375 | val_loss : 309.04278564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1472 | train_loss : 1983.2896728515625 | val_loss : 7241.42578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1473 | train_loss : 2282.12158203125 | val_loss : 505.7706298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1474 | train_loss : 2929.421875 | val_loss : 6568.24853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1475 | train_loss : 2133.112548828125 | val_loss : 768.3118896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1476 | train_loss : 1528.3599853515625 | val_loss : 4343.74951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1477 | train_loss : 1480.85302734375 | val_loss : 543.6369018554688 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1478 | train_loss : 2239.397216796875 | val_loss : 6794.54248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1479 | train_loss : 2119.853515625 | val_loss : 616.1956176757812 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1480 | train_loss : 1492.7662353515625 | val_loss : 6499.9775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1481 | train_loss : 2006.1090087890625 | val_loss : 417.44500732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1482 | train_loss : 2582.54833984375 | val_loss : 8630.703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1483 | train_loss : 2791.8974609375 | val_loss : 821.2281494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1484 | train_loss : 2956.202392578125 | val_loss : 5817.70751953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1485 | train_loss : 2166.560302734375 | val_loss : 865.228759765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1486 | train_loss : 2582.79833984375 | val_loss : 6535.56982421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1487 | train_loss : 2383.658447265625 | val_loss : 1196.704345703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1488 | train_loss : 1756.014892578125 | val_loss : 6434.74169921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1489 | train_loss : 2222.900390625 | val_loss : 815.7081298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1490 | train_loss : 2602.946533203125 | val_loss : 8277.7275390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1491 | train_loss : 2818.9599609375 | val_loss : 1031.8900146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1492 | train_loss : 3029.923095703125 | val_loss : 7623.5419921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1493 | train_loss : 2837.475830078125 | val_loss : 882.5018920898438 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1494 | train_loss : 2561.358154296875 | val_loss : 7035.015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1495 | train_loss : 2490.044921875 | val_loss : 1037.8612060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1496 | train_loss : 2422.400146484375 | val_loss : 7186.67138671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1497 | train_loss : 2510.562744140625 | val_loss : 541.8150024414062 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1498 | train_loss : 1916.809326171875 | val_loss : 5460.6220703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1499 | train_loss : 1821.561279296875 | val_loss : 819.635009765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1500 | train_loss : 1876.94482421875 | val_loss : 59844.8203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1501 | train_loss : 36129.671875 | val_loss : 250042.90625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1502 | train_loss : 486972.40625 | val_loss : 43497.1484375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1503 | train_loss : 51658.1015625 | val_loss : 20062.873046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1504 | train_loss : 23079.89453125 | val_loss : 13995.517578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1505 | train_loss : 15041.4599609375 | val_loss : 13577.0908203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1506 | train_loss : 13288.3779296875 | val_loss : 2874.477294921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1507 | train_loss : 7078.69677734375 | val_loss : 6720.27392578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1508 | train_loss : 6044.17138671875 | val_loss : 3202.03466796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1509 | train_loss : 5362.0693359375 | val_loss : 4167.830078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1510 | train_loss : 3282.494384765625 | val_loss : 4415.697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1511 | train_loss : 3138.433837890625 | val_loss : 4644.3330078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1512 | train_loss : 2771.755615234375 | val_loss : 2719.70166015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1513 | train_loss : 2916.9736328125 | val_loss : 4029.355712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1514 | train_loss : 3193.577880859375 | val_loss : 3475.59912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1515 | train_loss : 2766.59228515625 | val_loss : 4177.38330078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1516 | train_loss : 2408.99755859375 | val_loss : 3381.559326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1517 | train_loss : 2937.32470703125 | val_loss : 4231.87548828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1518 | train_loss : 2815.891357421875 | val_loss : 2263.732421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1519 | train_loss : 2167.855224609375 | val_loss : 4463.39306640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1520 | train_loss : 2611.93408203125 | val_loss : 1819.5927734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1521 | train_loss : 2651.362548828125 | val_loss : 5364.806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1522 | train_loss : 2994.365234375 | val_loss : 3118.327392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1523 | train_loss : 4490.744140625 | val_loss : 5386.4130859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1524 | train_loss : 2529.227294921875 | val_loss : 2046.1368408203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1525 | train_loss : 2760.11962890625 | val_loss : 4032.530029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1526 | train_loss : 2540.015869140625 | val_loss : 2338.178955078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1527 | train_loss : 2125.253173828125 | val_loss : 3832.625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1528 | train_loss : 2084.420166015625 | val_loss : 2277.603515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1529 | train_loss : 1977.602294921875 | val_loss : 4855.27978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1530 | train_loss : 2433.549560546875 | val_loss : 2564.0390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1531 | train_loss : 2763.376220703125 | val_loss : 3624.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1532 | train_loss : 2044.13671875 | val_loss : 2334.85302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1533 | train_loss : 1785.8638916015625 | val_loss : 3381.27685546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1534 | train_loss : 1830.44921875 | val_loss : 2280.240234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1535 | train_loss : 1897.5301513671875 | val_loss : 3468.791259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1536 | train_loss : 1833.22021484375 | val_loss : 3025.9580078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1537 | train_loss : 2089.78662109375 | val_loss : 3620.221923828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1538 | train_loss : 1666.2728271484375 | val_loss : 1753.84814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1539 | train_loss : 1523.782470703125 | val_loss : 3597.01806640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1540 | train_loss : 1569.9381103515625 | val_loss : 2825.1904296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1541 | train_loss : 1783.3974609375 | val_loss : 3240.92529296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1542 | train_loss : 1418.55029296875 | val_loss : 2228.8583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1543 | train_loss : 3073.16650390625 | val_loss : 3374.10302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1544 | train_loss : 1751.9541015625 | val_loss : 4263.33642578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1545 | train_loss : 2635.193115234375 | val_loss : 5137.30810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1546 | train_loss : 1788.9886474609375 | val_loss : 744.264404296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1547 | train_loss : 1409.7840576171875 | val_loss : 4683.82373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1548 | train_loss : 1906.6484375 | val_loss : 2491.0859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1549 | train_loss : 2591.1181640625 | val_loss : 3577.395263671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1550 | train_loss : 1602.0863037109375 | val_loss : 1804.00537109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1551 | train_loss : 1672.154541015625 | val_loss : 3930.48193359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1552 | train_loss : 1873.3824462890625 | val_loss : 2360.958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1553 | train_loss : 2138.437255859375 | val_loss : 3670.600341796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1554 | train_loss : 1879.3226318359375 | val_loss : 1567.6175537109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1555 | train_loss : 1403.5308837890625 | val_loss : 4367.98291015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1556 | train_loss : 1917.6800537109375 | val_loss : 2670.23974609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1557 | train_loss : 2420.810546875 | val_loss : 4641.021484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1558 | train_loss : 3425.530029296875 | val_loss : 2745.35302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1559 | train_loss : 2312.939453125 | val_loss : 3602.037109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1560 | train_loss : 1961.7596435546875 | val_loss : 2335.373779296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1561 | train_loss : 1542.262451171875 | val_loss : 2832.4951171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1562 | train_loss : 1979.0528564453125 | val_loss : 2636.7939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1563 | train_loss : 1742.2425537109375 | val_loss : 2545.82568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1564 | train_loss : 1634.1781005859375 | val_loss : 2463.283447265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1565 | train_loss : 1694.353271484375 | val_loss : 2846.676025390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1566 | train_loss : 2050.788818359375 | val_loss : 2389.541015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1567 | train_loss : 1378.2840576171875 | val_loss : 1642.8477783203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1568 | train_loss : 1266.7845458984375 | val_loss : 2273.5771484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1569 | train_loss : 1354.6285400390625 | val_loss : 2105.341796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1570 | train_loss : 1522.7264404296875 | val_loss : 1953.4833984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1571 | train_loss : 1217.7427978515625 | val_loss : 3273.89501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1572 | train_loss : 1563.76123046875 | val_loss : 1807.62841796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1573 | train_loss : 1984.1148681640625 | val_loss : 3851.828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1574 | train_loss : 1990.39453125 | val_loss : 2670.71728515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1575 | train_loss : 2159.5595703125 | val_loss : 4244.17822265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1576 | train_loss : 1839.8447265625 | val_loss : 2545.578857421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1577 | train_loss : 2456.337890625 | val_loss : 3374.382568359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1578 | train_loss : 1482.4002685546875 | val_loss : 2410.319580078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1579 | train_loss : 1889.28173828125 | val_loss : 4555.9736328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1580 | train_loss : 1934.771728515625 | val_loss : 2521.089599609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1581 | train_loss : 3216.46337890625 | val_loss : 3582.025634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1582 | train_loss : 1756.38623046875 | val_loss : 2257.241455078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1583 | train_loss : 1714.653564453125 | val_loss : 3925.838134765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1584 | train_loss : 1757.0606689453125 | val_loss : 2050.04931640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1585 | train_loss : 2103.8134765625 | val_loss : 4195.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1586 | train_loss : 1654.814697265625 | val_loss : 2337.728759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1587 | train_loss : 2216.6650390625 | val_loss : 4226.724609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1588 | train_loss : 1765.021240234375 | val_loss : 2227.750732421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1589 | train_loss : 1976.0028076171875 | val_loss : 3866.675537109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1590 | train_loss : 1759.2197265625 | val_loss : 2293.883056640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1591 | train_loss : 1888.576416015625 | val_loss : 4064.460693359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1592 | train_loss : 1728.504638671875 | val_loss : 2011.3565673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1593 | train_loss : 2128.258056640625 | val_loss : 4302.958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1594 | train_loss : 1674.5836181640625 | val_loss : 1686.2694091796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1595 | train_loss : 1950.2225341796875 | val_loss : 4661.22998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1596 | train_loss : 1886.793701171875 | val_loss : 2293.10791015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1597 | train_loss : 2273.358154296875 | val_loss : 4192.6123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1598 | train_loss : 1448.6053466796875 | val_loss : 1192.88037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1599 | train_loss : 1938.692626953125 | val_loss : 4179.35986328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 1600 | train_loss : 1510.83837890625 | val_loss : 2261.4248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 2 | epoch : 1 | train_loss : 1039213.625 | val_loss : 1065591.5 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 2 | train_loss : 1174560.5 | val_loss : 1038738.25 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 3 | train_loss : 1138237.75 | val_loss : 1113679.875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 4 | train_loss : 1067220.875 | val_loss : 1135641.5 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 5 | train_loss : 1068694.75 | val_loss : 401829.75 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 6 | train_loss : 395465.03125 | val_loss : 331552.09375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 7 | train_loss : 347111.03125 | val_loss : 495362.625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 8 | train_loss : 527122.25 | val_loss : 719935.8125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 9 | train_loss : 631797.4375 | val_loss : 385537.84375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 10 | train_loss : 402869.28125 | val_loss : 489755.5625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 11 | train_loss : 457935.6875 | val_loss : 554169.0625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 12 | train_loss : 517682.09375 | val_loss : 563319.1875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 13 | train_loss : 591951.625 | val_loss : 372571.4375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 14 | train_loss : 411491.3125 | val_loss : 466607.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 15 | train_loss : 411244.6875 | val_loss : 344656.15625 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 16 | train_loss : 317303.46875 | val_loss : 375456.75 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 17 | train_loss : 328320.875 | val_loss : 286781.90625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 18 | train_loss : 355649.8125 | val_loss : 157043.5 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 19 | train_loss : 226494.0625 | val_loss : 213989.40625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 20 | train_loss : 285407.90625 | val_loss : 185207.296875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 21 | train_loss : 336937.84375 | val_loss : 368143.375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 22 | train_loss : 419489.1875 | val_loss : 426841.53125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 23 | train_loss : 487221.375 | val_loss : 276634.625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 24 | train_loss : 326218.0625 | val_loss : 342148.96875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 25 | train_loss : 335789.125 | val_loss : 295803.125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 26 | train_loss : 321939.0625 | val_loss : 164612.484375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 27 | train_loss : 206745.265625 | val_loss : 212248.203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 28 | train_loss : 235749.15625 | val_loss : 270082.6875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 29 | train_loss : 240654.234375 | val_loss : 245438.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 30 | train_loss : 231538.859375 | val_loss : 156324.765625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 31 | train_loss : 188681.265625 | val_loss : 173446.125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 32 | train_loss : 160399.203125 | val_loss : 125448.4375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 33 | train_loss : 134032.109375 | val_loss : 133737.640625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 34 | train_loss : 149366.390625 | val_loss : 227555.265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 35 | train_loss : 178149.515625 | val_loss : 230850.921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 36 | train_loss : 220368.578125 | val_loss : 190454.90625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 37 | train_loss : 181299.125 | val_loss : 188965.421875 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 38 | train_loss : 245127.765625 | val_loss : 153833.578125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 39 | train_loss : 154674.65625 | val_loss : 190935.5625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 40 | train_loss : 155419.46875 | val_loss : 172919.640625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 41 | train_loss : 170557.203125 | val_loss : 209706.78125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 42 | train_loss : 196208.375 | val_loss : 149710.078125 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 43 | train_loss : 213333.578125 | val_loss : 126066.5390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 44 | train_loss : 172714.546875 | val_loss : 187545.046875 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 45 | train_loss : 184185.078125 | val_loss : 190551.953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 46 | train_loss : 143377.625 | val_loss : 216179.765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 47 | train_loss : 185090.5625 | val_loss : 193799.265625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 48 | train_loss : 192226.5625 | val_loss : 303663.1875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 49 | train_loss : 243812.875 | val_loss : 100219.5625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 50 | train_loss : 114432.3984375 | val_loss : 136366.65625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 51 | train_loss : 148300.359375 | val_loss : 153280.78125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 52 | train_loss : 168388.09375 | val_loss : 190018.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 53 | train_loss : 174166.1875 | val_loss : 189471.40625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 54 | train_loss : 176288.203125 | val_loss : 154331.703125 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 55 | train_loss : 163206.0625 | val_loss : 158622.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 56 | train_loss : 153414.84375 | val_loss : 161472.421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 57 | train_loss : 165820.5625 | val_loss : 132873.421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 58 | train_loss : 164190.15625 | val_loss : 107624.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 59 | train_loss : 132021.9375 | val_loss : 185230.71875 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 60 | train_loss : 196789.8125 | val_loss : 275486.46875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 61 | train_loss : 225118.046875 | val_loss : 251896.140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 62 | train_loss : 213728.359375 | val_loss : 140425.484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 63 | train_loss : 182188.65625 | val_loss : 113665.5390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 64 | train_loss : 146016.09375 | val_loss : 178650.59375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 65 | train_loss : 161208.453125 | val_loss : 177072.40625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 66 | train_loss : 156485.84375 | val_loss : 117041.9609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 67 | train_loss : 126777.78125 | val_loss : 204501.015625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 68 | train_loss : 187799.6875 | val_loss : 226442.4375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 69 | train_loss : 185008.71875 | val_loss : 139352.4375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 70 | train_loss : 97208.359375 | val_loss : 118607.5 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 71 | train_loss : 114930.4921875 | val_loss : 227542.6875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 72 | train_loss : 181268.734375 | val_loss : 138953.5625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 73 | train_loss : 102526.7265625 | val_loss : 98938.2109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 74 | train_loss : 135633.875 | val_loss : 66109.2265625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 75 | train_loss : 109565.4921875 | val_loss : 164382.65625 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 76 | train_loss : 186809.703125 | val_loss : 219771.078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 77 | train_loss : 195424.71875 | val_loss : 202178.546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 78 | train_loss : 167520.84375 | val_loss : 229342.40625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 79 | train_loss : 202327.734375 | val_loss : 101895.578125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 80 | train_loss : 133205.484375 | val_loss : 149136.484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 81 | train_loss : 129799.1171875 | val_loss : 170727.84375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 82 | train_loss : 129025.953125 | val_loss : 95728.7578125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 83 | train_loss : 134401.515625 | val_loss : 128564.8203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 84 | train_loss : 128960.3671875 | val_loss : 103381.359375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 85 | train_loss : 116372.0625 | val_loss : 98330.09375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 86 | train_loss : 123502.1328125 | val_loss : 182465.421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 87 | train_loss : 145507.578125 | val_loss : 166220.859375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 88 | train_loss : 114159.1015625 | val_loss : 225547.125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 89 | train_loss : 170145.859375 | val_loss : 146791.34375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 90 | train_loss : 116488.6328125 | val_loss : 168656.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 91 | train_loss : 162813.3125 | val_loss : 223993.203125 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 92 | train_loss : 226261.1875 | val_loss : 222539.4375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 93 | train_loss : 213231.0625 | val_loss : 200971.765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 94 | train_loss : 202446.796875 | val_loss : 126912.1875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 95 | train_loss : 115820.328125 | val_loss : 99009.390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 96 | train_loss : 111530.7421875 | val_loss : 128451.1796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 97 | train_loss : 134855.890625 | val_loss : 180331.40625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 98 | train_loss : 150983.609375 | val_loss : 168221.078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 99 | train_loss : 161701.59375 | val_loss : 154092.015625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 100 | train_loss : 143453.140625 | val_loss : 193538.046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 101 | train_loss : 150434.0625 | val_loss : 160279.3125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 102 | train_loss : 171264.734375 | val_loss : 96438.5625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 103 | train_loss : 102427.2890625 | val_loss : 78571.453125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 104 | train_loss : 82176.1015625 | val_loss : 124758.1171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 105 | train_loss : 116467.953125 | val_loss : 130978.53125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 106 | train_loss : 139752.28125 | val_loss : 146327.0 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 107 | train_loss : 155097.546875 | val_loss : 113363.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 108 | train_loss : 124776.59375 | val_loss : 112224.296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 109 | train_loss : 122318.640625 | val_loss : 206570.078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 110 | train_loss : 152240.65625 | val_loss : 66627.34375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 111 | train_loss : 85845.2109375 | val_loss : 41417.03515625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 112 | train_loss : 68142.2578125 | val_loss : 109353.8828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 113 | train_loss : 79534.4296875 | val_loss : 98836.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 114 | train_loss : 101156.34375 | val_loss : 93599.0 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 115 | train_loss : 93381.75 | val_loss : 97163.140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 116 | train_loss : 102748.171875 | val_loss : 120767.3828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 117 | train_loss : 87875.03125 | val_loss : 46923.3515625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 118 | train_loss : 64212.05078125 | val_loss : 49154.0859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 119 | train_loss : 60738.390625 | val_loss : 97305.640625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 120 | train_loss : 89470.6796875 | val_loss : 143420.546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 121 | train_loss : 104819.2734375 | val_loss : 119815.8203125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 122 | train_loss : 133961.828125 | val_loss : 65235.8515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 123 | train_loss : 95676.671875 | val_loss : 108110.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 124 | train_loss : 115617.546875 | val_loss : 117619.9921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 125 | train_loss : 99829.46875 | val_loss : 79645.1171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 126 | train_loss : 69261.40625 | val_loss : 86492.2421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 127 | train_loss : 96631.671875 | val_loss : 34207.62890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 128 | train_loss : 40088.390625 | val_loss : 83682.765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 129 | train_loss : 81736.59375 | val_loss : 109884.359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 130 | train_loss : 84087.9921875 | val_loss : 129223.0390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 131 | train_loss : 106566.25 | val_loss : 49465.81640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 132 | train_loss : 48415.4296875 | val_loss : 64491.37890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 133 | train_loss : 69845.8125 | val_loss : 104144.84375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 134 | train_loss : 81840.0625 | val_loss : 73815.828125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 135 | train_loss : 74431.1328125 | val_loss : 115431.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 136 | train_loss : 97550.7421875 | val_loss : 106162.7109375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 137 | train_loss : 102809.859375 | val_loss : 81215.2421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 138 | train_loss : 89850.4375 | val_loss : 84462.453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 139 | train_loss : 95988.4609375 | val_loss : 131502.65625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 140 | train_loss : 132388.40625 | val_loss : 92574.5703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 141 | train_loss : 67451.1875 | val_loss : 101933.53125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 142 | train_loss : 98693.0625 | val_loss : 132380.734375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 143 | train_loss : 122257.03125 | val_loss : 160919.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 144 | train_loss : 146419.59375 | val_loss : 117557.609375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 145 | train_loss : 119982.5625 | val_loss : 95463.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 146 | train_loss : 92594.5234375 | val_loss : 141151.5625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 147 | train_loss : 134847.796875 | val_loss : 106146.2109375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 148 | train_loss : 96768.90625 | val_loss : 86837.7421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 149 | train_loss : 80658.5234375 | val_loss : 106045.546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 150 | train_loss : 121041.7421875 | val_loss : 121884.34375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 151 | train_loss : 95220.2109375 | val_loss : 133301.59375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 152 | train_loss : 132188.671875 | val_loss : 68283.453125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 153 | train_loss : 82779.8515625 | val_loss : 53667.35546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 154 | train_loss : 42044.10546875 | val_loss : 74375.2421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 155 | train_loss : 57183.8984375 | val_loss : 52457.73828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 156 | train_loss : 71912.53125 | val_loss : 125911.546875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 157 | train_loss : 113626.5234375 | val_loss : 121546.6171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 158 | train_loss : 116931.09375 | val_loss : 116488.296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 159 | train_loss : 95084.4765625 | val_loss : 58505.87890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 160 | train_loss : 65560.65625 | val_loss : 50557.58984375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 161 | train_loss : 43953.03125 | val_loss : 89486.4921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 162 | train_loss : 86823.3203125 | val_loss : 135393.9375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 163 | train_loss : 109466.203125 | val_loss : 120488.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 164 | train_loss : 99466.15625 | val_loss : 100386.2578125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 165 | train_loss : 117247.3203125 | val_loss : 64742.734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 166 | train_loss : 58744.44140625 | val_loss : 56301.63671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 167 | train_loss : 63316.42578125 | val_loss : 87213.109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 168 | train_loss : 74892.1484375 | val_loss : 138247.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 169 | train_loss : 97979.5625 | val_loss : 53682.68359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 170 | train_loss : 66125.2109375 | val_loss : 65909.3984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 171 | train_loss : 72519.765625 | val_loss : 100274.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 172 | train_loss : 80531.6328125 | val_loss : 89560.171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 173 | train_loss : 60165.0 | val_loss : 67866.2734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 174 | train_loss : 83082.828125 | val_loss : 74756.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 175 | train_loss : 65957.515625 | val_loss : 64187.62109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 176 | train_loss : 62059.94921875 | val_loss : 74926.3984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 177 | train_loss : 53974.3046875 | val_loss : 84694.2109375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 178 | train_loss : 97181.0234375 | val_loss : 76579.0078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 179 | train_loss : 73148.015625 | val_loss : 75010.4765625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 180 | train_loss : 72472.8671875 | val_loss : 113536.25 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 181 | train_loss : 114445.8984375 | val_loss : 108209.2265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 182 | train_loss : 91786.9765625 | val_loss : 109808.796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 183 | train_loss : 88420.2890625 | val_loss : 95132.796875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 184 | train_loss : 101095.2109375 | val_loss : 76571.34375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 185 | train_loss : 83687.53125 | val_loss : 73878.8046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 186 | train_loss : 54024.40625 | val_loss : 52381.8515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 187 | train_loss : 75720.7265625 | val_loss : 92601.0 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 188 | train_loss : 79234.78125 | val_loss : 88958.2421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 189 | train_loss : 79153.8984375 | val_loss : 86458.703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 190 | train_loss : 86052.390625 | val_loss : 95964.703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 191 | train_loss : 65414.0 | val_loss : 94131.1171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 192 | train_loss : 77095.3984375 | val_loss : 45126.91015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 193 | train_loss : 49646.9140625 | val_loss : 73463.5625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 194 | train_loss : 69321.53125 | val_loss : 97968.4921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 195 | train_loss : 75197.171875 | val_loss : 77765.546875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 196 | train_loss : 61273.453125 | val_loss : 56258.03125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 197 | train_loss : 50770.48828125 | val_loss : 52347.68359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 198 | train_loss : 55406.21484375 | val_loss : 102899.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 199 | train_loss : 77714.046875 | val_loss : 102837.9609375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 200 | train_loss : 84476.7265625 | val_loss : 41801.58984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 201 | train_loss : 43185.5 | val_loss : 70500.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 202 | train_loss : 54033.8046875 | val_loss : 74826.8828125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 203 | train_loss : 77838.890625 | val_loss : 55025.5703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 204 | train_loss : 60096.53125 | val_loss : 77892.3046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 205 | train_loss : 93503.0 | val_loss : 125086.9296875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 206 | train_loss : 129054.609375 | val_loss : 109235.9296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 207 | train_loss : 84017.890625 | val_loss : 75978.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 208 | train_loss : 85682.59375 | val_loss : 50809.9296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 209 | train_loss : 45620.11328125 | val_loss : 68040.1484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 210 | train_loss : 61101.7109375 | val_loss : 110602.59375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 211 | train_loss : 76535.46875 | val_loss : 86911.296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 212 | train_loss : 67782.453125 | val_loss : 57211.4296875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 213 | train_loss : 70641.96875 | val_loss : 76439.8984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 214 | train_loss : 73208.0625 | val_loss : 34609.01171875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 215 | train_loss : 32709.720703125 | val_loss : 58193.7265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 216 | train_loss : 48755.6796875 | val_loss : 62077.6640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 217 | train_loss : 56919.171875 | val_loss : 76575.3984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 218 | train_loss : 75693.2734375 | val_loss : 113954.1328125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 219 | train_loss : 91099.78125 | val_loss : 66792.859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 220 | train_loss : 49605.93359375 | val_loss : 62047.19140625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 221 | train_loss : 76759.234375 | val_loss : 53734.3515625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 222 | train_loss : 52861.5703125 | val_loss : 64452.18359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 223 | train_loss : 52960.796875 | val_loss : 74941.5390625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 224 | train_loss : 67669.328125 | val_loss : 48764.09375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 225 | train_loss : 37146.82421875 | val_loss : 41503.9296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 226 | train_loss : 39976.6640625 | val_loss : 45040.05859375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 227 | train_loss : 42011.66015625 | val_loss : 63610.32421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 228 | train_loss : 54430.9296875 | val_loss : 60069.6484375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 229 | train_loss : 46288.5859375 | val_loss : 79989.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 230 | train_loss : 73888.984375 | val_loss : 87442.703125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 231 | train_loss : 80115.875 | val_loss : 78956.8828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 232 | train_loss : 81380.1875 | val_loss : 81037.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 233 | train_loss : 80346.1953125 | val_loss : 61497.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 234 | train_loss : 70998.21875 | val_loss : 91207.5625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 235 | train_loss : 75885.2734375 | val_loss : 57557.33984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 236 | train_loss : 54230.92578125 | val_loss : 50838.96484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 237 | train_loss : 61281.12890625 | val_loss : 68856.515625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 238 | train_loss : 55607.25 | val_loss : 98038.09375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 239 | train_loss : 75403.0078125 | val_loss : 52519.5234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 240 | train_loss : 62459.6953125 | val_loss : 67636.59375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 241 | train_loss : 75217.296875 | val_loss : 46836.0546875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 242 | train_loss : 47725.203125 | val_loss : 66570.59375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 243 | train_loss : 49972.46484375 | val_loss : 42740.63671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 244 | train_loss : 37594.5546875 | val_loss : 71102.5390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 245 | train_loss : 51336.015625 | val_loss : 54114.19140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 246 | train_loss : 63287.57421875 | val_loss : 70921.2265625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 247 | train_loss : 59095.14453125 | val_loss : 57500.80078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 248 | train_loss : 48893.3203125 | val_loss : 59183.91015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 249 | train_loss : 42013.19921875 | val_loss : 64785.38671875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 250 | train_loss : 47055.91015625 | val_loss : 42374.1953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 251 | train_loss : 35038.75390625 | val_loss : 39302.87109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 252 | train_loss : 41437.40625 | val_loss : 56353.41015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 253 | train_loss : 57019.55859375 | val_loss : 94482.1796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 254 | train_loss : 65248.59375 | val_loss : 60611.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 255 | train_loss : 48697.828125 | val_loss : 54858.9453125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 256 | train_loss : 65502.59375 | val_loss : 46206.33984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 257 | train_loss : 36214.51171875 | val_loss : 40481.89453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 258 | train_loss : 36307.69140625 | val_loss : 94932.96875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 259 | train_loss : 99973.046875 | val_loss : 75854.6484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 260 | train_loss : 72509.4453125 | val_loss : 66291.671875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 261 | train_loss : 69670.8671875 | val_loss : 30675.1640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 262 | train_loss : 42565.58984375 | val_loss : 71991.2421875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 263 | train_loss : 47218.015625 | val_loss : 56030.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 264 | train_loss : 34773.78125 | val_loss : 27431.072265625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 265 | train_loss : 35733.046875 | val_loss : 53542.0703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 266 | train_loss : 58633.0 | val_loss : 81847.7421875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 267 | train_loss : 61511.15625 | val_loss : 62225.56640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 268 | train_loss : 56128.37890625 | val_loss : 83955.7421875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 269 | train_loss : 76473.8515625 | val_loss : 54182.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 270 | train_loss : 47419.36328125 | val_loss : 34250.8671875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 271 | train_loss : 28713.380859375 | val_loss : 63817.55078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 272 | train_loss : 53519.3515625 | val_loss : 39231.68359375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 273 | train_loss : 48425.64453125 | val_loss : 45559.3984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 274 | train_loss : 35684.21484375 | val_loss : 36749.171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 275 | train_loss : 23271.376953125 | val_loss : 40565.203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 276 | train_loss : 36748.87890625 | val_loss : 23145.431640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 277 | train_loss : 21848.955078125 | val_loss : 39783.12890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 278 | train_loss : 32954.80078125 | val_loss : 40743.609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 279 | train_loss : 32615.154296875 | val_loss : 52932.9453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 280 | train_loss : 40052.31640625 | val_loss : 43156.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 281 | train_loss : 37189.390625 | val_loss : 32763.23046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 282 | train_loss : 25662.619140625 | val_loss : 37434.00390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 283 | train_loss : 34177.390625 | val_loss : 59061.125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 284 | train_loss : 38296.09375 | val_loss : 32027.8203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 285 | train_loss : 24986.400390625 | val_loss : 32592.869140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 286 | train_loss : 27905.92578125 | val_loss : 41740.57421875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 287 | train_loss : 40304.85546875 | val_loss : 70156.1171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 288 | train_loss : 51340.8984375 | val_loss : 60526.25 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 289 | train_loss : 65075.375 | val_loss : 52442.06640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 290 | train_loss : 48742.9453125 | val_loss : 40565.59375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 291 | train_loss : 50904.875 | val_loss : 66957.2421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 292 | train_loss : 59971.07421875 | val_loss : 60045.796875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 293 | train_loss : 51551.1953125 | val_loss : 81057.140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 294 | train_loss : 68089.484375 | val_loss : 35203.41015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 295 | train_loss : 33930.7265625 | val_loss : 46178.05078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 296 | train_loss : 46630.06640625 | val_loss : 71169.4921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 297 | train_loss : 53078.1015625 | val_loss : 63105.53125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 298 | train_loss : 40203.16015625 | val_loss : 34060.12109375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 299 | train_loss : 37820.2578125 | val_loss : 36506.671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 300 | train_loss : 36687.109375 | val_loss : 39556.2109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 301 | train_loss : 26448.662109375 | val_loss : 30043.046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 302 | train_loss : 33210.88671875 | val_loss : 45819.6015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 303 | train_loss : 44805.921875 | val_loss : 74381.6171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 304 | train_loss : 64143.87109375 | val_loss : 60118.99609375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 305 | train_loss : 43405.55859375 | val_loss : 50159.3359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 306 | train_loss : 43728.36328125 | val_loss : 52966.296875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 307 | train_loss : 38723.34765625 | val_loss : 14492.8701171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 308 | train_loss : 15161.3779296875 | val_loss : 56627.34375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 309 | train_loss : 47660.1953125 | val_loss : 49444.765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 310 | train_loss : 39539.55859375 | val_loss : 58353.07421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 311 | train_loss : 42768.51171875 | val_loss : 20731.119140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 312 | train_loss : 20647.265625 | val_loss : 43684.671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 313 | train_loss : 27807.578125 | val_loss : 32530.306640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 314 | train_loss : 26444.501953125 | val_loss : 53419.59375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 315 | train_loss : 40375.58203125 | val_loss : 37155.2421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 316 | train_loss : 30142.681640625 | val_loss : 63698.6953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 317 | train_loss : 41997.75390625 | val_loss : 27283.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 318 | train_loss : 38441.640625 | val_loss : 31829.46484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 319 | train_loss : 25065.47265625 | val_loss : 45013.4609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 320 | train_loss : 43168.91015625 | val_loss : 51137.23046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 321 | train_loss : 32424.796875 | val_loss : 33099.26171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 322 | train_loss : 31504.845703125 | val_loss : 44638.4609375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 323 | train_loss : 27127.078125 | val_loss : 35160.73828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 324 | train_loss : 30669.431640625 | val_loss : 60294.73828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 325 | train_loss : 53299.35546875 | val_loss : 38858.515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 326 | train_loss : 30962.158203125 | val_loss : 40017.50390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 327 | train_loss : 30010.064453125 | val_loss : 31113.240234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 328 | train_loss : 43705.51171875 | val_loss : 55482.41015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 329 | train_loss : 64792.74609375 | val_loss : 40769.2109375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 330 | train_loss : 34624.44921875 | val_loss : 52964.28515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 331 | train_loss : 48406.37109375 | val_loss : 41957.32421875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 332 | train_loss : 33781.96875 | val_loss : 74831.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 333 | train_loss : 58311.11328125 | val_loss : 35836.984375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 334 | train_loss : 52923.078125 | val_loss : 40510.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 335 | train_loss : 45645.69921875 | val_loss : 55619.98828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 336 | train_loss : 40853.37890625 | val_loss : 36559.0390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 337 | train_loss : 30044.9140625 | val_loss : 49906.453125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 338 | train_loss : 50876.640625 | val_loss : 26434.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 339 | train_loss : 20700.88671875 | val_loss : 42347.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 340 | train_loss : 41472.48828125 | val_loss : 26683.36328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 341 | train_loss : 22437.76953125 | val_loss : 56988.953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 342 | train_loss : 45804.734375 | val_loss : 51154.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 343 | train_loss : 35703.17578125 | val_loss : 32308.615234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 344 | train_loss : 24219.998046875 | val_loss : 14467.3974609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 345 | train_loss : 28498.720703125 | val_loss : 22889.703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 346 | train_loss : 17516.65234375 | val_loss : 32815.203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 347 | train_loss : 32100.671875 | val_loss : 54933.58984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 348 | train_loss : 36749.26171875 | val_loss : 36269.2109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 349 | train_loss : 31262.5859375 | val_loss : 38528.53515625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 350 | train_loss : 47963.5859375 | val_loss : 47608.37890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 351 | train_loss : 39925.90234375 | val_loss : 22029.2578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 352 | train_loss : 21185.1484375 | val_loss : 22050.966796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 353 | train_loss : 17139.080078125 | val_loss : 31049.552734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 354 | train_loss : 24434.337890625 | val_loss : 72338.2578125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 355 | train_loss : 63485.66015625 | val_loss : 17685.453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 356 | train_loss : 17027.521484375 | val_loss : 32356.2109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 357 | train_loss : 28873.4453125 | val_loss : 53503.61328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 358 | train_loss : 40308.5546875 | val_loss : 46506.171875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 359 | train_loss : 29171.9375 | val_loss : 31837.455078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 360 | train_loss : 28349.9296875 | val_loss : 25543.3359375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 361 | train_loss : 32156.849609375 | val_loss : 33520.984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 362 | train_loss : 28910.0703125 | val_loss : 48771.88671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 363 | train_loss : 30826.4375 | val_loss : 20625.216796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 364 | train_loss : 20349.931640625 | val_loss : 44646.6796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 365 | train_loss : 29616.7421875 | val_loss : 29866.296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 366 | train_loss : 32864.4765625 | val_loss : 29824.90234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 367 | train_loss : 26432.328125 | val_loss : 30602.38671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 368 | train_loss : 20727.29296875 | val_loss : 27394.365234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 369 | train_loss : 27989.83203125 | val_loss : 54607.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 370 | train_loss : 36662.00390625 | val_loss : 35762.4140625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 371 | train_loss : 44443.98046875 | val_loss : 46246.48828125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 372 | train_loss : 49628.0859375 | val_loss : 54172.80859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 373 | train_loss : 49007.33984375 | val_loss : 56664.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 374 | train_loss : 45836.859375 | val_loss : 51297.125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 375 | train_loss : 49752.05078125 | val_loss : 56357.3984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 376 | train_loss : 52952.1953125 | val_loss : 38814.234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 377 | train_loss : 35987.9140625 | val_loss : 38494.77734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 378 | train_loss : 32785.1796875 | val_loss : 45044.80859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 379 | train_loss : 37161.62109375 | val_loss : 61428.328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 380 | train_loss : 53222.671875 | val_loss : 41682.328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 381 | train_loss : 30408.0625 | val_loss : 30578.6640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 382 | train_loss : 28204.099609375 | val_loss : 27665.560546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 383 | train_loss : 24261.765625 | val_loss : 22482.1484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 384 | train_loss : 19611.2109375 | val_loss : 45898.06640625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 385 | train_loss : 37949.13671875 | val_loss : 61297.91015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 386 | train_loss : 42137.203125 | val_loss : 27238.314453125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 387 | train_loss : 39360.37890625 | val_loss : 14738.025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 388 | train_loss : 21119.33203125 | val_loss : 36979.81640625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 389 | train_loss : 40802.31640625 | val_loss : 58552.5 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 390 | train_loss : 41580.16796875 | val_loss : 26384.32421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 391 | train_loss : 16785.421875 | val_loss : 31180.32421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 392 | train_loss : 23381.865234375 | val_loss : 38041.6796875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 393 | train_loss : 35131.515625 | val_loss : 45229.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 394 | train_loss : 31746.193359375 | val_loss : 25324.96484375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 395 | train_loss : 34210.4765625 | val_loss : 84451.3515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 396 | train_loss : 79659.7578125 | val_loss : 78327.3671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 397 | train_loss : 65158.703125 | val_loss : 61517.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 398 | train_loss : 68903.3984375 | val_loss : 55917.01953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 399 | train_loss : 51088.78125 | val_loss : 61348.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 400 | train_loss : 49650.28515625 | val_loss : 29634.060546875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 401 | train_loss : 30428.498046875 | val_loss : 74362.5234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 402 | train_loss : 46179.5703125 | val_loss : 25623.205078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 403 | train_loss : 27368.0390625 | val_loss : 32415.34765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 404 | train_loss : 32334.685546875 | val_loss : 26893.3359375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 405 | train_loss : 22523.828125 | val_loss : 43039.55078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 406 | train_loss : 27901.044921875 | val_loss : 24081.767578125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 407 | train_loss : 36130.46484375 | val_loss : 35475.27734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 408 | train_loss : 36131.63671875 | val_loss : 26961.2109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 409 | train_loss : 24918.716796875 | val_loss : 34919.8671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 410 | train_loss : 26385.037109375 | val_loss : 44301.62109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 411 | train_loss : 50737.11328125 | val_loss : 48695.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 412 | train_loss : 44139.18359375 | val_loss : 25961.283203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 413 | train_loss : 24974.54296875 | val_loss : 26924.580078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 414 | train_loss : 20727.8515625 | val_loss : 15631.58984375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 415 | train_loss : 14534.4404296875 | val_loss : 30870.205078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 416 | train_loss : 29927.48046875 | val_loss : 33742.265625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 417 | train_loss : 31929.5 | val_loss : 50448.828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 418 | train_loss : 35262.6484375 | val_loss : 30780.712890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 419 | train_loss : 24996.841796875 | val_loss : 40156.2890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 420 | train_loss : 31858.7421875 | val_loss : 29104.4296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 421 | train_loss : 23603.244140625 | val_loss : 33178.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 422 | train_loss : 24457.64453125 | val_loss : 24846.970703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 423 | train_loss : 27804.8984375 | val_loss : 46083.3515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 424 | train_loss : 39691.94140625 | val_loss : 43246.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 425 | train_loss : 31595.515625 | val_loss : 26462.875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 426 | train_loss : 18534.0546875 | val_loss : 26099.55078125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 427 | train_loss : 22168.7734375 | val_loss : 35651.19921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 428 | train_loss : 31243.1171875 | val_loss : 86409.296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 429 | train_loss : 70835.296875 | val_loss : 60257.5 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 430 | train_loss : 46272.16015625 | val_loss : 24490.244140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 431 | train_loss : 18761.685546875 | val_loss : 18898.91015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 432 | train_loss : 22650.3125 | val_loss : 29819.23046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 433 | train_loss : 20328.087890625 | val_loss : 32545.150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 434 | train_loss : 23658.125 | val_loss : 43469.0390625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 435 | train_loss : 44017.3359375 | val_loss : 31850.392578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 436 | train_loss : 22618.96484375 | val_loss : 117746.046875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 437 | train_loss : 96540.1328125 | val_loss : 54385.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 438 | train_loss : 45375.078125 | val_loss : 49407.9609375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 439 | train_loss : 49572.578125 | val_loss : 35703.93359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 440 | train_loss : 29771.349609375 | val_loss : 25277.732421875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 441 | train_loss : 25365.908203125 | val_loss : 40285.41015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 442 | train_loss : 31552.990234375 | val_loss : 28226.119140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 443 | train_loss : 21846.85546875 | val_loss : 36914.4375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 444 | train_loss : 26723.615234375 | val_loss : 30662.302734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 445 | train_loss : 21314.7265625 | val_loss : 23310.8046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 446 | train_loss : 18249.8671875 | val_loss : 22773.470703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 447 | train_loss : 19506.33203125 | val_loss : 37342.828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 448 | train_loss : 31060.0859375 | val_loss : 27242.6484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 449 | train_loss : 23682.265625 | val_loss : 37944.375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 450 | train_loss : 24651.859375 | val_loss : 24086.91015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 451 | train_loss : 23666.07421875 | val_loss : 31902.724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 452 | train_loss : 24702.54296875 | val_loss : 28421.10546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 453 | train_loss : 21707.732421875 | val_loss : 32082.52734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 454 | train_loss : 31629.9609375 | val_loss : 32034.619140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 455 | train_loss : 31226.974609375 | val_loss : 41599.140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 456 | train_loss : 29799.052734375 | val_loss : 33651.86328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 457 | train_loss : 33687.421875 | val_loss : 46613.19140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 458 | train_loss : 35994.19140625 | val_loss : 28773.78515625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 459 | train_loss : 22871.544921875 | val_loss : 31390.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 460 | train_loss : 24888.19921875 | val_loss : 22966.5078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 461 | train_loss : 26530.0234375 | val_loss : 41806.609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 462 | train_loss : 35963.8125 | val_loss : 32368.19921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 463 | train_loss : 22837.302734375 | val_loss : 23117.9921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 464 | train_loss : 13593.7763671875 | val_loss : 18247.556640625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 465 | train_loss : 21861.9609375 | val_loss : 27199.759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 466 | train_loss : 20028.212890625 | val_loss : 23328.22265625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 467 | train_loss : 21148.005859375 | val_loss : 33113.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 468 | train_loss : 25133.275390625 | val_loss : 15862.1298828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 469 | train_loss : 26070.900390625 | val_loss : 30518.025390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 470 | train_loss : 28898.6640625 | val_loss : 18035.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 471 | train_loss : 16233.611328125 | val_loss : 29174.1640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 472 | train_loss : 16317.5029296875 | val_loss : 23306.15234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 473 | train_loss : 19333.810546875 | val_loss : 37083.625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 474 | train_loss : 30104.544921875 | val_loss : 33837.32421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 475 | train_loss : 24639.876953125 | val_loss : 34974.390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 476 | train_loss : 24199.091796875 | val_loss : 17993.65234375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 477 | train_loss : 23989.3984375 | val_loss : 30396.109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 478 | train_loss : 20287.123046875 | val_loss : 21824.88671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 479 | train_loss : 19640.390625 | val_loss : 29927.220703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 480 | train_loss : 23912.2265625 | val_loss : 24982.634765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 481 | train_loss : 19024.953125 | val_loss : 22378.51171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 482 | train_loss : 25750.46484375 | val_loss : 25779.060546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 483 | train_loss : 29045.025390625 | val_loss : 35745.703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 484 | train_loss : 24955.51953125 | val_loss : 24634.60546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 485 | train_loss : 26772.390625 | val_loss : 39080.890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 486 | train_loss : 26734.328125 | val_loss : 29046.373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 487 | train_loss : 25906.251953125 | val_loss : 24695.841796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 488 | train_loss : 27633.76171875 | val_loss : 41202.48828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 489 | train_loss : 40214.24609375 | val_loss : 50004.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 490 | train_loss : 38536.046875 | val_loss : 27486.94921875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 491 | train_loss : 20382.26171875 | val_loss : 36676.7109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 492 | train_loss : 31842.9609375 | val_loss : 25678.095703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 493 | train_loss : 24510.69921875 | val_loss : 34450.28125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 494 | train_loss : 26673.23046875 | val_loss : 24283.822265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 495 | train_loss : 17487.14453125 | val_loss : 25570.427734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 496 | train_loss : 22349.482421875 | val_loss : 30018.4921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 497 | train_loss : 22921.4765625 | val_loss : 26077.716796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 498 | train_loss : 17459.884765625 | val_loss : 19111.16796875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 499 | train_loss : 22687.42578125 | val_loss : 31855.556640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 500 | train_loss : 27729.390625 | val_loss : 28135.10546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 501 | train_loss : 20879.376953125 | val_loss : 26767.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 502 | train_loss : 16074.806640625 | val_loss : 20076.3515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 503 | train_loss : 22575.875 | val_loss : 36575.09375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 504 | train_loss : 32261.26953125 | val_loss : 29246.705078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 505 | train_loss : 20295.943359375 | val_loss : 26365.494140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 506 | train_loss : 16950.408203125 | val_loss : 15199.3974609375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 507 | train_loss : 17868.1875 | val_loss : 30862.501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 508 | train_loss : 19650.7421875 | val_loss : 24144.064453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 509 | train_loss : 24907.953125 | val_loss : 60864.4296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 510 | train_loss : 54999.33984375 | val_loss : 34932.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 511 | train_loss : 24568.0078125 | val_loss : 26515.57421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 512 | train_loss : 17243.0390625 | val_loss : 16206.0849609375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 513 | train_loss : 15898.3349609375 | val_loss : 30352.966796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 514 | train_loss : 20945.482421875 | val_loss : 19796.66015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 515 | train_loss : 24383.591796875 | val_loss : 36499.2109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 516 | train_loss : 33666.87890625 | val_loss : 30355.529296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 517 | train_loss : 21059.640625 | val_loss : 27893.759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 518 | train_loss : 18546.623046875 | val_loss : 15769.4951171875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 519 | train_loss : 16997.58203125 | val_loss : 29378.287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 520 | train_loss : 20138.734375 | val_loss : 23336.056640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 521 | train_loss : 26324.7109375 | val_loss : 30074.20703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 522 | train_loss : 28443.625 | val_loss : 27056.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 523 | train_loss : 18855.890625 | val_loss : 26605.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 524 | train_loss : 14476.78515625 | val_loss : 14466.5595703125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 525 | train_loss : 14562.50390625 | val_loss : 27338.27734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 526 | train_loss : 20734.6875 | val_loss : 17073.162109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 527 | train_loss : 16378.5009765625 | val_loss : 24730.5859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 528 | train_loss : 19741.986328125 | val_loss : 19776.734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 529 | train_loss : 19498.515625 | val_loss : 33682.48828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 530 | train_loss : 22286.185546875 | val_loss : 15043.60546875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 531 | train_loss : 19642.07421875 | val_loss : 29744.384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 532 | train_loss : 25368.72265625 | val_loss : 22458.431640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 533 | train_loss : 17247.865234375 | val_loss : 31311.73828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 534 | train_loss : 25037.2734375 | val_loss : 21032.6328125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 535 | train_loss : 17093.12109375 | val_loss : 29215.705078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 536 | train_loss : 22877.080078125 | val_loss : 16218.4697265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 537 | train_loss : 16628.560546875 | val_loss : 31255.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 538 | train_loss : 26124.802734375 | val_loss : 27465.296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 539 | train_loss : 19469.02734375 | val_loss : 26563.966796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 540 | train_loss : 20314.875 | val_loss : 17294.53515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 541 | train_loss : 19956.0546875 | val_loss : 31133.1015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 542 | train_loss : 24844.060546875 | val_loss : 22200.30078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 543 | train_loss : 15539.48828125 | val_loss : 25326.57421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 544 | train_loss : 19704.4453125 | val_loss : 309549.59375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 545 | train_loss : 317027.03125 | val_loss : 74305.3125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 546 | train_loss : 60983.50390625 | val_loss : 72366.078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 547 | train_loss : 62463.2265625 | val_loss : 43865.01171875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 548 | train_loss : 42571.421875 | val_loss : 24625.140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 549 | train_loss : 30633.724609375 | val_loss : 14996.294921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 550 | train_loss : 17716.375 | val_loss : 27285.142578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 551 | train_loss : 24482.552734375 | val_loss : 19153.705078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 552 | train_loss : 14459.6845703125 | val_loss : 18276.634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 553 | train_loss : 13615.974609375 | val_loss : 18797.94921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 554 | train_loss : 16812.552734375 | val_loss : 32620.01953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 555 | train_loss : 23509.185546875 | val_loss : 21189.640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 556 | train_loss : 14087.6171875 | val_loss : 25463.658203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 557 | train_loss : 19932.259765625 | val_loss : 31641.091796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 558 | train_loss : 28472.375 | val_loss : 38414.1875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 559 | train_loss : 26667.48046875 | val_loss : 17128.28125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 560 | train_loss : 11045.89453125 | val_loss : 18817.0390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 561 | train_loss : 10346.0498046875 | val_loss : 19177.60546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 562 | train_loss : 15380.91796875 | val_loss : 32247.67578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 563 | train_loss : 24158.689453125 | val_loss : 23358.794921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 564 | train_loss : 15025.13671875 | val_loss : 17318.3828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 565 | train_loss : 11888.52734375 | val_loss : 17423.9609375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 566 | train_loss : 17363.599609375 | val_loss : 33251.6015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 567 | train_loss : 19939.5078125 | val_loss : 12473.4208984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 568 | train_loss : 12779.8203125 | val_loss : 31048.8984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 569 | train_loss : 25257.216796875 | val_loss : 24945.419921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 570 | train_loss : 17210.15234375 | val_loss : 19346.537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 571 | train_loss : 12889.1748046875 | val_loss : 20266.853515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 572 | train_loss : 20249.693359375 | val_loss : 22259.9765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 573 | train_loss : 17692.658203125 | val_loss : 24889.98046875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 574 | train_loss : 21337.125 | val_loss : 28292.091796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 575 | train_loss : 22684.125 | val_loss : 21402.470703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 576 | train_loss : 22763.53515625 | val_loss : 39051.375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 577 | train_loss : 31666.265625 | val_loss : 24360.869140625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 578 | train_loss : 15873.224609375 | val_loss : 21689.369140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 579 | train_loss : 17835.505859375 | val_loss : 20752.45703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 580 | train_loss : 19350.927734375 | val_loss : 32155.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 581 | train_loss : 23167.46484375 | val_loss : 18067.837890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 582 | train_loss : 12022.26953125 | val_loss : 18624.552734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 583 | train_loss : 12755.8408203125 | val_loss : 14182.431640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 584 | train_loss : 13859.3974609375 | val_loss : 71397.90625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 585 | train_loss : 56217.3515625 | val_loss : 19633.65625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 586 | train_loss : 19343.822265625 | val_loss : 20865.943359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 587 | train_loss : 14398.9873046875 | val_loss : 30995.328125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 588 | train_loss : 31542.412109375 | val_loss : 41900.0234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 589 | train_loss : 33909.64453125 | val_loss : 22626.8828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 590 | train_loss : 16471.703125 | val_loss : 21893.345703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 591 | train_loss : 14228.0 | val_loss : 17637.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 592 | train_loss : 16719.466796875 | val_loss : 14152.009765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 593 | train_loss : 16967.400390625 | val_loss : 14990.9951171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 594 | train_loss : 13174.8154296875 | val_loss : 25240.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 595 | train_loss : 18531.658203125 | val_loss : 23420.755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 596 | train_loss : 16267.880859375 | val_loss : 16258.08984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 597 | train_loss : 14117.6572265625 | val_loss : 24748.01171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 598 | train_loss : 13873.193359375 | val_loss : 9505.8916015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 599 | train_loss : 10063.4736328125 | val_loss : 20613.115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 600 | train_loss : 14403.736328125 | val_loss : 14578.5771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 601 | train_loss : 10937.392578125 | val_loss : 18755.662109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 602 | train_loss : 13695.0458984375 | val_loss : 22373.1875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 603 | train_loss : 18404.849609375 | val_loss : 33500.73046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 604 | train_loss : 22033.626953125 | val_loss : 18423.177734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 605 | train_loss : 16891.29296875 | val_loss : 12880.4599609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 606 | train_loss : 8373.5341796875 | val_loss : 14320.75390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 607 | train_loss : 10323.392578125 | val_loss : 18906.095703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 608 | train_loss : 13272.0849609375 | val_loss : 18480.439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 609 | train_loss : 16774.4921875 | val_loss : 31845.48046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 610 | train_loss : 18841.615234375 | val_loss : 12065.4775390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 611 | train_loss : 11749.3583984375 | val_loss : 23295.439453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 612 | train_loss : 14917.5625 | val_loss : 13241.5927734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 613 | train_loss : 9639.0908203125 | val_loss : 17733.216796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 614 | train_loss : 14338.7666015625 | val_loss : 10803.8125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 615 | train_loss : 11215.35546875 | val_loss : 23986.466796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 616 | train_loss : 16003.7333984375 | val_loss : 15110.8291015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 617 | train_loss : 12035.5458984375 | val_loss : 20613.7265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 618 | train_loss : 15352.0 | val_loss : 22837.392578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 619 | train_loss : 19475.0390625 | val_loss : 30581.267578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 620 | train_loss : 17502.3125 | val_loss : 12246.0400390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 621 | train_loss : 12620.005859375 | val_loss : 20562.650390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 622 | train_loss : 14171.1240234375 | val_loss : 12161.2275390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 623 | train_loss : 10847.103515625 | val_loss : 22892.330078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 624 | train_loss : 12526.7724609375 | val_loss : 16345.6796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 625 | train_loss : 12988.48046875 | val_loss : 29732.001953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 626 | train_loss : 24532.017578125 | val_loss : 27141.8984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 627 | train_loss : 20303.248046875 | val_loss : 19675.17578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 628 | train_loss : 13301.638671875 | val_loss : 13910.9541015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 629 | train_loss : 11480.7099609375 | val_loss : 21148.533203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 630 | train_loss : 12393.7451171875 | val_loss : 12805.7099609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 631 | train_loss : 10141.6611328125 | val_loss : 23981.77734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 632 | train_loss : 18621.20703125 | val_loss : 15142.0234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 633 | train_loss : 13353.29296875 | val_loss : 24838.064453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 634 | train_loss : 17213.052734375 | val_loss : 10663.537109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 635 | train_loss : 10716.6748046875 | val_loss : 20756.775390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 636 | train_loss : 13604.8525390625 | val_loss : 9318.443359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 637 | train_loss : 7999.21240234375 | val_loss : 17508.00390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 638 | train_loss : 13315.46484375 | val_loss : 10935.97265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 639 | train_loss : 10828.681640625 | val_loss : 26808.5390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 640 | train_loss : 15841.9658203125 | val_loss : 15628.0546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 641 | train_loss : 13230.962890625 | val_loss : 28171.9453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 642 | train_loss : 26133.248046875 | val_loss : 23171.2109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 643 | train_loss : 17127.05859375 | val_loss : 14723.5498046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 644 | train_loss : 11850.7822265625 | val_loss : 18144.216796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 645 | train_loss : 14150.3076171875 | val_loss : 28671.060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 646 | train_loss : 17074.703125 | val_loss : 7915.3974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 647 | train_loss : 8100.40625 | val_loss : 15518.1826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 648 | train_loss : 12503.8154296875 | val_loss : 17749.58203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 649 | train_loss : 10833.4638671875 | val_loss : 11513.9716796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 650 | train_loss : 12128.9052734375 | val_loss : 20694.294921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 651 | train_loss : 12131.8173828125 | val_loss : 10263.009765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 652 | train_loss : 9529.6787109375 | val_loss : 18939.5546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 653 | train_loss : 12542.1201171875 | val_loss : 13133.6171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 654 | train_loss : 14750.5078125 | val_loss : 18972.919921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 655 | train_loss : 11894.26171875 | val_loss : 17273.7421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 656 | train_loss : 15418.7001953125 | val_loss : 27179.3046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 657 | train_loss : 23670.869140625 | val_loss : 21101.1796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 658 | train_loss : 15203.7275390625 | val_loss : 25388.29296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 659 | train_loss : 15948.193359375 | val_loss : 30258.4609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 660 | train_loss : 29037.650390625 | val_loss : 48935.96484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 661 | train_loss : 32306.23828125 | val_loss : 15750.3671875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 662 | train_loss : 17136.294921875 | val_loss : 24159.6953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 663 | train_loss : 20673.236328125 | val_loss : 34689.8515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 664 | train_loss : 22742.546875 | val_loss : 13610.5947265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 665 | train_loss : 11110.513671875 | val_loss : 6766.2099609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 666 | train_loss : 6139.36767578125 | val_loss : 20541.048828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 667 | train_loss : 14369.39453125 | val_loss : 15176.21875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 668 | train_loss : 10311.0654296875 | val_loss : 20965.046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 669 | train_loss : 13710.1025390625 | val_loss : 13388.7314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 670 | train_loss : 11988.919921875 | val_loss : 27854.9765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 671 | train_loss : 18437.890625 | val_loss : 12319.8388671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 672 | train_loss : 8734.2041015625 | val_loss : 16193.75 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 673 | train_loss : 11224.322265625 | val_loss : 12526.75 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 674 | train_loss : 11873.7646484375 | val_loss : 26078.345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 675 | train_loss : 17035.373046875 | val_loss : 9445.0048828125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 676 | train_loss : 9989.34375 | val_loss : 21728.1171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 677 | train_loss : 17061.2265625 | val_loss : 13731.9814453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 678 | train_loss : 15450.357421875 | val_loss : 25602.9765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 679 | train_loss : 16818.51171875 | val_loss : 7592.4111328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 680 | train_loss : 8615.96484375 | val_loss : 17516.306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 681 | train_loss : 13233.2021484375 | val_loss : 16837.373046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 682 | train_loss : 13309.4736328125 | val_loss : 27916.109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 683 | train_loss : 20584.015625 | val_loss : 9532.95703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 684 | train_loss : 9521.0703125 | val_loss : 22536.80078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 685 | train_loss : 16998.671875 | val_loss : 19943.470703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 686 | train_loss : 14553.830078125 | val_loss : 25583.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 687 | train_loss : 17757.326171875 | val_loss : 8055.74609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 688 | train_loss : 6809.90234375 | val_loss : 15099.3564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 689 | train_loss : 13728.3203125 | val_loss : 24854.009765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 690 | train_loss : 17736.693359375 | val_loss : 23695.408203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 691 | train_loss : 15948.0927734375 | val_loss : 11175.5849609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 692 | train_loss : 11965.330078125 | val_loss : 16208.0498046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 693 | train_loss : 10809.4951171875 | val_loss : 16134.837890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 694 | train_loss : 9646.7587890625 | val_loss : 11198.8349609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 695 | train_loss : 11475.650390625 | val_loss : 22953.919921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 696 | train_loss : 12410.2470703125 | val_loss : 7201.94482421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 697 | train_loss : 5314.56640625 | val_loss : 16376.447265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 698 | train_loss : 9783.8095703125 | val_loss : 16148.6064453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 699 | train_loss : 13217.388671875 | val_loss : 24961.720703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 700 | train_loss : 18343.8515625 | val_loss : 20168.98046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 701 | train_loss : 18269.666015625 | val_loss : 30955.158203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 702 | train_loss : 31646.078125 | val_loss : 6209.18505859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 703 | train_loss : 13885.927734375 | val_loss : 21295.83203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 704 | train_loss : 16551.970703125 | val_loss : 19841.3984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 705 | train_loss : 13897.9814453125 | val_loss : 20032.39453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 706 | train_loss : 15901.8046875 | val_loss : 17196.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 707 | train_loss : 12871.6611328125 | val_loss : 19739.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 708 | train_loss : 12075.30859375 | val_loss : 9352.03515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 709 | train_loss : 7074.244140625 | val_loss : 16384.091796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 710 | train_loss : 12790.193359375 | val_loss : 16819.060546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 711 | train_loss : 10071.7529296875 | val_loss : 20251.373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 712 | train_loss : 13532.64453125 | val_loss : 11785.755859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 713 | train_loss : 6137.19873046875 | val_loss : 12896.771484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 714 | train_loss : 9381.6875 | val_loss : 20133.556640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 715 | train_loss : 17884.529296875 | val_loss : 31562.27734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 716 | train_loss : 18395.853515625 | val_loss : 7930.78271484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 717 | train_loss : 6468.24755859375 | val_loss : 13237.552734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 718 | train_loss : 10310.3134765625 | val_loss : 19573.48046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 719 | train_loss : 11737.8720703125 | val_loss : 10377.919921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 720 | train_loss : 8560.51953125 | val_loss : 21559.25 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 721 | train_loss : 16297.8876953125 | val_loss : 16458.63671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 722 | train_loss : 11847.25390625 | val_loss : 19685.84765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 723 | train_loss : 13678.7412109375 | val_loss : 13403.9150390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 724 | train_loss : 15282.775390625 | val_loss : 21054.185546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 725 | train_loss : 13081.40234375 | val_loss : 9362.927734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 726 | train_loss : 9501.951171875 | val_loss : 22271.046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 727 | train_loss : 13897.7822265625 | val_loss : 9861.0947265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 728 | train_loss : 9671.9716796875 | val_loss : 11843.3701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 729 | train_loss : 8950.5849609375 | val_loss : 13145.875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 730 | train_loss : 9866.1328125 | val_loss : 20200.84765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 731 | train_loss : 17103.23828125 | val_loss : 23471.91796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 732 | train_loss : 16438.783203125 | val_loss : 13965.8037109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 733 | train_loss : 10283.26171875 | val_loss : 39629.2109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 734 | train_loss : 37721.38671875 | val_loss : 35060.77734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 735 | train_loss : 27799.5859375 | val_loss : 28594.537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 736 | train_loss : 21813.953125 | val_loss : 22680.3671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 737 | train_loss : 17179.6953125 | val_loss : 11050.19140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 738 | train_loss : 9809.986328125 | val_loss : 8776.72265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 739 | train_loss : 9544.576171875 | val_loss : 9995.68359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 740 | train_loss : 8941.8671875 | val_loss : 18186.310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 741 | train_loss : 15037.1650390625 | val_loss : 26714.453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 742 | train_loss : 16054.73046875 | val_loss : 6159.4150390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 743 | train_loss : 6756.328125 | val_loss : 14560.1689453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 744 | train_loss : 10731.7978515625 | val_loss : 11647.6162109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 745 | train_loss : 7159.56103515625 | val_loss : 13742.9716796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 746 | train_loss : 8652.1416015625 | val_loss : 13504.1640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 747 | train_loss : 10937.7060546875 | val_loss : 19094.751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 748 | train_loss : 12173.169921875 | val_loss : 7570.99267578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 749 | train_loss : 5587.173828125 | val_loss : 14621.107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 750 | train_loss : 9609.109375 | val_loss : 8865.5224609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 751 | train_loss : 9266.7021484375 | val_loss : 18085.748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 752 | train_loss : 11744.6015625 | val_loss : 8450.0078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 753 | train_loss : 5569.19921875 | val_loss : 16549.47265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 754 | train_loss : 11210.6904296875 | val_loss : 12442.142578125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 755 | train_loss : 12241.072265625 | val_loss : 18038.576171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 756 | train_loss : 10551.212890625 | val_loss : 8848.9609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 757 | train_loss : 8780.0810546875 | val_loss : 20946.927734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 758 | train_loss : 15095.91796875 | val_loss : 12408.548828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 759 | train_loss : 7887.13232421875 | val_loss : 12037.3974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 760 | train_loss : 9971.8349609375 | val_loss : 19383.20703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 761 | train_loss : 16231.5703125 | val_loss : 27772.98046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 762 | train_loss : 15233.2470703125 | val_loss : 6369.71240234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 763 | train_loss : 4298.501953125 | val_loss : 10346.5849609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 764 | train_loss : 8906.228515625 | val_loss : 20828.689453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 765 | train_loss : 12146.2978515625 | val_loss : 6452.77490234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 766 | train_loss : 4981.6845703125 | val_loss : 17545.025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 767 | train_loss : 10840.2099609375 | val_loss : 7846.49267578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 768 | train_loss : 7946.07373046875 | val_loss : 18941.4140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 769 | train_loss : 10017.37890625 | val_loss : 11841.6611328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 770 | train_loss : 10287.72265625 | val_loss : 22716.9609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 771 | train_loss : 18057.12109375 | val_loss : 22631.869140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 772 | train_loss : 15650.46484375 | val_loss : 17973.2109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 773 | train_loss : 10438.673828125 | val_loss : 6535.080078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 774 | train_loss : 6908.64111328125 | val_loss : 14282.62890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 775 | train_loss : 10669.19921875 | val_loss : 12916.1689453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 776 | train_loss : 11332.05078125 | val_loss : 18572.697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 777 | train_loss : 13007.900390625 | val_loss : 10484.71484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 778 | train_loss : 12232.54296875 | val_loss : 22333.828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 779 | train_loss : 17886.876953125 | val_loss : 13051.57421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 780 | train_loss : 7815.8779296875 | val_loss : 17784.3125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 781 | train_loss : 12039.9404296875 | val_loss : 6948.65380859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 782 | train_loss : 4904.8076171875 | val_loss : 14751.6064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 783 | train_loss : 10572.9638671875 | val_loss : 14832.7802734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 784 | train_loss : 11428.9033203125 | val_loss : 19786.650390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 785 | train_loss : 11480.7197265625 | val_loss : 7147.8212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 786 | train_loss : 6528.001953125 | val_loss : 16393.154296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 787 | train_loss : 10307.87109375 | val_loss : 9057.9658203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 788 | train_loss : 6790.77294921875 | val_loss : 13829.865234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 789 | train_loss : 7689.73486328125 | val_loss : 9387.525390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 790 | train_loss : 8393.244140625 | val_loss : 16524.23828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 791 | train_loss : 8866.7177734375 | val_loss : 6993.865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 792 | train_loss : 5930.53759765625 | val_loss : 17712.509765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 793 | train_loss : 10696.5458984375 | val_loss : 9687.9912109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 794 | train_loss : 7492.10498046875 | val_loss : 17257.599609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 795 | train_loss : 10182.6826171875 | val_loss : 8206.0908203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 796 | train_loss : 5813.21923828125 | val_loss : 16856.576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 797 | train_loss : 9817.16796875 | val_loss : 6892.78125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 798 | train_loss : 5310.36669921875 | val_loss : 13677.10546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 799 | train_loss : 9646.291015625 | val_loss : 14203.7939453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 800 | train_loss : 9994.4287109375 | val_loss : 20616.275390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 801 | train_loss : 13878.0322265625 | val_loss : 16280.4814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 802 | train_loss : 13251.8095703125 | val_loss : 21388.84765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 803 | train_loss : 13746.3486328125 | val_loss : 12527.701171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 804 | train_loss : 12270.9697265625 | val_loss : 20381.466796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 805 | train_loss : 12037.5234375 | val_loss : 6676.28857421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 806 | train_loss : 4692.86572265625 | val_loss : 13529.0029296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 807 | train_loss : 8997.3662109375 | val_loss : 32897.4921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 808 | train_loss : 29618.48046875 | val_loss : 34001.82421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 809 | train_loss : 25216.310546875 | val_loss : 14311.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 810 | train_loss : 9892.8310546875 | val_loss : 9212.96484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 811 | train_loss : 11023.630859375 | val_loss : 24299.95703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 812 | train_loss : 17528.130859375 | val_loss : 14093.90625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 813 | train_loss : 8408.2314453125 | val_loss : 9449.2822265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 814 | train_loss : 8477.3896484375 | val_loss : 14209.4091796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 815 | train_loss : 12494.0263671875 | val_loss : 20729.234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 816 | train_loss : 12656.41796875 | val_loss : 7117.46484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 817 | train_loss : 3944.039794921875 | val_loss : 10134.66015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 818 | train_loss : 6604.45751953125 | val_loss : 12163.8251953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 819 | train_loss : 11037.849609375 | val_loss : 19338.35546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 820 | train_loss : 10775.47265625 | val_loss : 9656.6650390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 821 | train_loss : 7298.05419921875 | val_loss : 15777.603515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 822 | train_loss : 12445.5576171875 | val_loss : 13827.712890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 823 | train_loss : 8725.3515625 | val_loss : 17244.56640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 824 | train_loss : 10344.7314453125 | val_loss : 7489.583984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 825 | train_loss : 5826.06982421875 | val_loss : 13614.4384765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 826 | train_loss : 7298.4111328125 | val_loss : 8219.03125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 827 | train_loss : 7382.421875 | val_loss : 16878.29296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 828 | train_loss : 8849.5224609375 | val_loss : 6611.21728515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 829 | train_loss : 5777.13818359375 | val_loss : 13177.1591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 830 | train_loss : 8654.1083984375 | val_loss : 8479.71875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 831 | train_loss : 6441.23681640625 | val_loss : 12967.076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 832 | train_loss : 7047.03564453125 | val_loss : 8406.8310546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 833 | train_loss : 7248.28076171875 | val_loss : 15384.5283203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 834 | train_loss : 9112.7666015625 | val_loss : 7608.23388671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 835 | train_loss : 5426.1474609375 | val_loss : 14761.48046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 836 | train_loss : 9627.3642578125 | val_loss : 9411.8984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 837 | train_loss : 9019.708984375 | val_loss : 14157.3837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 838 | train_loss : 7613.857421875 | val_loss : 7234.986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 839 | train_loss : 6765.08984375 | val_loss : 17345.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 840 | train_loss : 9942.47265625 | val_loss : 10878.21484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 841 | train_loss : 9720.2939453125 | val_loss : 131201.96875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 842 | train_loss : 152916.765625 | val_loss : 47181.46484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 843 | train_loss : 38882.328125 | val_loss : 27676.087890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 844 | train_loss : 26125.193359375 | val_loss : 13065.431640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 845 | train_loss : 13270.228515625 | val_loss : 17943.126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 846 | train_loss : 15385.224609375 | val_loss : 24871.400390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 847 | train_loss : 15168.375 | val_loss : 7168.7763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 848 | train_loss : 7400.7275390625 | val_loss : 14918.8359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 849 | train_loss : 10131.931640625 | val_loss : 7912.46728515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 850 | train_loss : 7283.19189453125 | val_loss : 14896.4521484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 851 | train_loss : 7590.7001953125 | val_loss : 6834.80517578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 852 | train_loss : 5815.5751953125 | val_loss : 14146.6904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 853 | train_loss : 8399.2822265625 | val_loss : 8720.447265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 854 | train_loss : 7785.45947265625 | val_loss : 14318.544921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 855 | train_loss : 6785.27294921875 | val_loss : 12045.9814453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 856 | train_loss : 9240.240234375 | val_loss : 20322.841796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 857 | train_loss : 16471.701171875 | val_loss : 16496.255859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 858 | train_loss : 11083.642578125 | val_loss : 18134.80078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 859 | train_loss : 13513.8271484375 | val_loss : 14139.013671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 860 | train_loss : 11662.4150390625 | val_loss : 19484.12109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 861 | train_loss : 12613.9462890625 | val_loss : 10466.5234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 862 | train_loss : 9714.537109375 | val_loss : 15266.572265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 863 | train_loss : 10008.4921875 | val_loss : 7838.34765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 864 | train_loss : 6931.591796875 | val_loss : 13865.830078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 865 | train_loss : 9570.44921875 | val_loss : 8615.7666015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 866 | train_loss : 8381.1962890625 | val_loss : 16346.5283203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 867 | train_loss : 7791.09619140625 | val_loss : 10757.212890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 868 | train_loss : 8595.41796875 | val_loss : 20149.828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 869 | train_loss : 16320.162109375 | val_loss : 14951.9287109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 870 | train_loss : 9882.302734375 | val_loss : 12616.076171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 871 | train_loss : 8573.447265625 | val_loss : 15506.04296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 872 | train_loss : 12550.19140625 | val_loss : 22072.185546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 873 | train_loss : 12450.857421875 | val_loss : 5315.79736328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 874 | train_loss : 4435.02197265625 | val_loss : 9201.2666015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 875 | train_loss : 6603.4423828125 | val_loss : 7086.44140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 876 | train_loss : 5152.90771484375 | val_loss : 7907.3876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 877 | train_loss : 4176.0419921875 | val_loss : 5506.2060546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 878 | train_loss : 5366.51611328125 | val_loss : 11603.0615234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 879 | train_loss : 6851.44482421875 | val_loss : 9724.8896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 880 | train_loss : 6953.228515625 | val_loss : 14780.6162109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 881 | train_loss : 8334.8701171875 | val_loss : 5028.076171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 882 | train_loss : 4994.94140625 | val_loss : 10583.9716796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 883 | train_loss : 5858.39453125 | val_loss : 9706.8388671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 884 | train_loss : 6874.021484375 | val_loss : 16295.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 885 | train_loss : 8364.25 | val_loss : 4434.68115234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 886 | train_loss : 3382.699462890625 | val_loss : 9148.1923828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 887 | train_loss : 6755.666015625 | val_loss : 12236.1162109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 888 | train_loss : 6992.18994140625 | val_loss : 8026.53271484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 889 | train_loss : 6291.70703125 | val_loss : 15037.009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 890 | train_loss : 8682.36328125 | val_loss : 6530.01611328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 891 | train_loss : 5614.2939453125 | val_loss : 10856.865234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 892 | train_loss : 5582.62890625 | val_loss : 6979.97119140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 893 | train_loss : 6336.33642578125 | val_loss : 18827.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 894 | train_loss : 10686.7099609375 | val_loss : 5028.68896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 895 | train_loss : 3764.577392578125 | val_loss : 6592.22021484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 896 | train_loss : 3667.347412109375 | val_loss : 5369.1025390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 897 | train_loss : 5181.28515625 | val_loss : 10013.787109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 898 | train_loss : 5371.9580078125 | val_loss : 4776.40869140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 899 | train_loss : 4349.96923828125 | val_loss : 11789.7138671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 900 | train_loss : 7106.259765625 | val_loss : 9926.712890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 901 | train_loss : 7223.28125 | val_loss : 13389.982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 902 | train_loss : 7914.77392578125 | val_loss : 8817.0146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 903 | train_loss : 5343.63671875 | val_loss : 13932.4990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 904 | train_loss : 9572.3427734375 | val_loss : 10368.5673828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 905 | train_loss : 6353.61328125 | val_loss : 12047.3974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 906 | train_loss : 7801.283203125 | val_loss : 13874.302734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 907 | train_loss : 10295.462890625 | val_loss : 16124.3212890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 908 | train_loss : 9129.78125 | val_loss : 5853.40771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 909 | train_loss : 4933.39990234375 | val_loss : 13978.8359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 910 | train_loss : 7806.6376953125 | val_loss : 7388.5185546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 911 | train_loss : 5743.568359375 | val_loss : 14979.74609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 912 | train_loss : 8239.6943359375 | val_loss : 6921.302734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 913 | train_loss : 5515.30615234375 | val_loss : 13291.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 914 | train_loss : 7861.6630859375 | val_loss : 6314.08251953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 915 | train_loss : 5137.04638671875 | val_loss : 12140.599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 916 | train_loss : 6468.90234375 | val_loss : 7238.82861328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 917 | train_loss : 5913.34423828125 | val_loss : 12772.5458984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 918 | train_loss : 6581.04296875 | val_loss : 166181.890625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 919 | train_loss : 167070.15625 | val_loss : 41162.92578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 920 | train_loss : 42035.07421875 | val_loss : 33007.62109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 921 | train_loss : 41122.05859375 | val_loss : 43947.75 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 922 | train_loss : 36207.546875 | val_loss : 18753.521484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 923 | train_loss : 17404.29296875 | val_loss : 18779.73828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 924 | train_loss : 13535.9716796875 | val_loss : 13459.5224609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 925 | train_loss : 12113.3583984375 | val_loss : 13862.9423828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 926 | train_loss : 10129.8583984375 | val_loss : 12228.6953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 927 | train_loss : 11472.607421875 | val_loss : 19002.193359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 928 | train_loss : 15510.6884765625 | val_loss : 20627.677734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 929 | train_loss : 15094.4658203125 | val_loss : 10660.212890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 930 | train_loss : 6694.9013671875 | val_loss : 7417.34521484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 931 | train_loss : 5656.43994140625 | val_loss : 8613.69140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 932 | train_loss : 9625.5234375 | val_loss : 9624.3408203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 933 | train_loss : 7790.53173828125 | val_loss : 9768.23046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 934 | train_loss : 8572.6171875 | val_loss : 17447.01953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 935 | train_loss : 15425.8447265625 | val_loss : 24491.78515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 936 | train_loss : 15186.85546875 | val_loss : 7862.18896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 937 | train_loss : 6424.67626953125 | val_loss : 6637.53369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 938 | train_loss : 7255.0185546875 | val_loss : 14907.1787109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 939 | train_loss : 10312.55859375 | val_loss : 13579.69140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 940 | train_loss : 8400.87109375 | val_loss : 15839.7939453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 941 | train_loss : 10057.60546875 | val_loss : 11528.572265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 942 | train_loss : 7927.25244140625 | val_loss : 10103.21484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 943 | train_loss : 5860.240234375 | val_loss : 7428.6162109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 944 | train_loss : 4883.2431640625 | val_loss : 11666.9326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 945 | train_loss : 6853.22314453125 | val_loss : 9950.416015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 946 | train_loss : 7564.69873046875 | val_loss : 16101.37890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 947 | train_loss : 9226.251953125 | val_loss : 6457.7900390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 948 | train_loss : 4069.421875 | val_loss : 10400.5078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 949 | train_loss : 6239.24365234375 | val_loss : 7977.10888671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 950 | train_loss : 6637.9873046875 | val_loss : 13114.4248046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 951 | train_loss : 8939.3427734375 | val_loss : 10380.9521484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 952 | train_loss : 6349.6318359375 | val_loss : 10747.53125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 953 | train_loss : 6873.7529296875 | val_loss : 10049.8037109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 954 | train_loss : 6514.5576171875 | val_loss : 13399.10546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 955 | train_loss : 9497.0048828125 | val_loss : 10218.5166015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 956 | train_loss : 6177.52001953125 | val_loss : 10505.5751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 957 | train_loss : 7257.23876953125 | val_loss : 12074.0400390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 958 | train_loss : 8572.5078125 | val_loss : 13870.1279296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 959 | train_loss : 8208.4267578125 | val_loss : 5286.767578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 960 | train_loss : 3666.560546875 | val_loss : 11923.544921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 961 | train_loss : 6261.71923828125 | val_loss : 5913.517578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 962 | train_loss : 5200.2392578125 | val_loss : 11866.7060546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 963 | train_loss : 6337.12548828125 | val_loss : 5528.048828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 964 | train_loss : 4671.330078125 | val_loss : 11614.509765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 965 | train_loss : 6939.44384765625 | val_loss : 7509.77880859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 966 | train_loss : 5473.0595703125 | val_loss : 9712.6962890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 967 | train_loss : 5117.0205078125 | val_loss : 5746.20361328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 968 | train_loss : 4212.25146484375 | val_loss : 14727.3701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 969 | train_loss : 10387.5791015625 | val_loss : 7978.10986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 970 | train_loss : 4153.21826171875 | val_loss : 10943.7822265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 971 | train_loss : 7850.01513671875 | val_loss : 13872.205078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 972 | train_loss : 10685.3876953125 | val_loss : 18150.15234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 973 | train_loss : 11520.9296875 | val_loss : 5662.29638671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 974 | train_loss : 2389.609619140625 | val_loss : 5849.5400390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 975 | train_loss : 4710.35693359375 | val_loss : 8462.0126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 976 | train_loss : 5015.92578125 | val_loss : 6444.06640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 977 | train_loss : 5583.69873046875 | val_loss : 16932.56640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 978 | train_loss : 9223.2001953125 | val_loss : 5498.60009765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 979 | train_loss : 3928.291015625 | val_loss : 9406.611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 980 | train_loss : 7033.94140625 | val_loss : 20429.154296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 981 | train_loss : 12358.09765625 | val_loss : 7501.71142578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 982 | train_loss : 3889.521240234375 | val_loss : 4409.83740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 983 | train_loss : 3714.339599609375 | val_loss : 9128.607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 984 | train_loss : 4808.1611328125 | val_loss : 9186.255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 985 | train_loss : 6587.98876953125 | val_loss : 21262.21484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 986 | train_loss : 14451.826171875 | val_loss : 8886.8974609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 987 | train_loss : 5022.6591796875 | val_loss : 4856.2275390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 988 | train_loss : 4931.80029296875 | val_loss : 12163.5849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 989 | train_loss : 7051.14990234375 | val_loss : 5943.228515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 990 | train_loss : 5110.10791015625 | val_loss : 11032.4345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 991 | train_loss : 7288.45458984375 | val_loss : 6650.39013671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 992 | train_loss : 4497.84423828125 | val_loss : 10341.7041015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 993 | train_loss : 6262.17138671875 | val_loss : 4476.62744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 994 | train_loss : 2764.1806640625 | val_loss : 10609.3984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 995 | train_loss : 7934.861328125 | val_loss : 11678.361328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 996 | train_loss : 8079.4033203125 | val_loss : 14913.693359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 997 | train_loss : 9653.01171875 | val_loss : 9503.03125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 998 | train_loss : 6463.517578125 | val_loss : 7616.900390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 999 | train_loss : 4899.435546875 | val_loss : 5785.71728515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1000 | train_loss : 4785.83984375 | val_loss : 12058.1748046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1001 | train_loss : 10951.1728515625 | val_loss : 12895.4912109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1002 | train_loss : 9407.5947265625 | val_loss : 11518.4052734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1003 | train_loss : 9480.662109375 | val_loss : 11160.77734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1004 | train_loss : 8817.0810546875 | val_loss : 10818.505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1005 | train_loss : 9102.94140625 | val_loss : 17817.654296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1006 | train_loss : 10425.92578125 | val_loss : 6464.70263671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1007 | train_loss : 4248.41064453125 | val_loss : 6026.388671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1008 | train_loss : 5461.2705078125 | val_loss : 7875.25146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1009 | train_loss : 5316.541015625 | val_loss : 5696.3701171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1010 | train_loss : 4656.87353515625 | val_loss : 9119.787109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1011 | train_loss : 6733.130859375 | val_loss : 14967.0458984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1012 | train_loss : 10691.9208984375 | val_loss : 9008.9189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1013 | train_loss : 5922.6669921875 | val_loss : 11279.740234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1014 | train_loss : 7269.33544921875 | val_loss : 9086.0546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1015 | train_loss : 7399.78857421875 | val_loss : 13438.4248046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1016 | train_loss : 7965.18017578125 | val_loss : 6929.947265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1017 | train_loss : 4238.56689453125 | val_loss : 11472.3154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1018 | train_loss : 7367.25927734375 | val_loss : 10647.21484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1019 | train_loss : 8639.7626953125 | val_loss : 12320.7841796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1020 | train_loss : 7062.40185546875 | val_loss : 5840.34765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1021 | train_loss : 4651.80810546875 | val_loss : 8956.0185546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1022 | train_loss : 5463.837890625 | val_loss : 5177.02880859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1023 | train_loss : 3794.494384765625 | val_loss : 10980.736328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1024 | train_loss : 6808.24951171875 | val_loss : 5806.4501953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1025 | train_loss : 4212.337890625 | val_loss : 9169.583984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1026 | train_loss : 5198.83203125 | val_loss : 6794.35107421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1027 | train_loss : 5346.703125 | val_loss : 12758.326171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1028 | train_loss : 7433.41943359375 | val_loss : 5643.00732421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1029 | train_loss : 3867.04345703125 | val_loss : 9350.794921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1030 | train_loss : 5934.65185546875 | val_loss : 7248.5810546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1031 | train_loss : 5882.298828125 | val_loss : 14728.6171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1032 | train_loss : 7823.31396484375 | val_loss : 5349.24853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1033 | train_loss : 3863.029296875 | val_loss : 7202.2939453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1034 | train_loss : 4534.72119140625 | val_loss : 6360.2060546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1035 | train_loss : 6084.10009765625 | val_loss : 8910.8740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1036 | train_loss : 4598.73876953125 | val_loss : 5418.6923828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1037 | train_loss : 3968.26318359375 | val_loss : 8580.3916015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1038 | train_loss : 5714.3876953125 | val_loss : 8376.068359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1039 | train_loss : 7209.38671875 | val_loss : 8054.06982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1040 | train_loss : 4323.10205078125 | val_loss : 5724.62109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1041 | train_loss : 4471.60205078125 | val_loss : 9268.4208984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1042 | train_loss : 6238.00146484375 | val_loss : 7572.615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1043 | train_loss : 5336.9345703125 | val_loss : 5277.9951171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1044 | train_loss : 2661.002197265625 | val_loss : 5275.072265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1045 | train_loss : 3140.597412109375 | val_loss : 6566.072265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1046 | train_loss : 4560.673828125 | val_loss : 7813.96728515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1047 | train_loss : 5327.341796875 | val_loss : 7651.77001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1048 | train_loss : 4367.45361328125 | val_loss : 6325.0537109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1049 | train_loss : 4735.60888671875 | val_loss : 8123.861328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1050 | train_loss : 5633.14111328125 | val_loss : 5804.24609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1051 | train_loss : 4055.940673828125 | val_loss : 4480.97021484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1052 | train_loss : 2724.821533203125 | val_loss : 8835.31640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1053 | train_loss : 5799.2275390625 | val_loss : 8940.4296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1054 | train_loss : 6395.11865234375 | val_loss : 6409.37744140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1055 | train_loss : 3854.934326171875 | val_loss : 5481.03857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1056 | train_loss : 3497.772705078125 | val_loss : 6491.59130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1057 | train_loss : 4878.193359375 | val_loss : 8033.85107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1058 | train_loss : 5213.37353515625 | val_loss : 8166.197265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1059 | train_loss : 5354.048828125 | val_loss : 9804.4111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1060 | train_loss : 5913.72119140625 | val_loss : 10202.458984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1061 | train_loss : 9346.3134765625 | val_loss : 11724.1015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1062 | train_loss : 7875.568359375 | val_loss : 8618.603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1063 | train_loss : 7120.849609375 | val_loss : 8024.3486328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1064 | train_loss : 5490.138671875 | val_loss : 10442.8828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1065 | train_loss : 7858.794921875 | val_loss : 36854.11328125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1066 | train_loss : 40018.5859375 | val_loss : 22074.6875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1067 | train_loss : 22808.9453125 | val_loss : 34147.38671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1068 | train_loss : 28399.376953125 | val_loss : 12265.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1069 | train_loss : 12863.1591796875 | val_loss : 8319.173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1070 | train_loss : 8752.8896484375 | val_loss : 8994.0673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1071 | train_loss : 8918.822265625 | val_loss : 11759.900390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1072 | train_loss : 9626.53515625 | val_loss : 14317.7685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1073 | train_loss : 9430.615234375 | val_loss : 7486.77392578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1074 | train_loss : 4960.748046875 | val_loss : 7214.07373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1075 | train_loss : 4522.5068359375 | val_loss : 8438.6904296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1076 | train_loss : 5700.07177734375 | val_loss : 12599.1171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1077 | train_loss : 7773.9501953125 | val_loss : 8347.005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1078 | train_loss : 6168.28125 | val_loss : 12426.375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1079 | train_loss : 6800.4130859375 | val_loss : 6474.3798828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1080 | train_loss : 4634.32080078125 | val_loss : 11192.0927734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1081 | train_loss : 7838.84130859375 | val_loss : 8962.0576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1082 | train_loss : 5673.69482421875 | val_loss : 8769.1376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1083 | train_loss : 5776.64501953125 | val_loss : 9427.7509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1084 | train_loss : 6777.84521484375 | val_loss : 12128.2412109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1085 | train_loss : 7587.8935546875 | val_loss : 5503.15478515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1086 | train_loss : 3558.11865234375 | val_loss : 10272.9697265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1087 | train_loss : 6904.8125 | val_loss : 8203.5908203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1088 | train_loss : 6245.19921875 | val_loss : 11556.76171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1089 | train_loss : 6691.5 | val_loss : 5279.7763671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1090 | train_loss : 3230.385986328125 | val_loss : 9676.3564453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1091 | train_loss : 6261.37109375 | val_loss : 7382.24609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1092 | train_loss : 5567.87109375 | val_loss : 11446.57421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1093 | train_loss : 7475.8173828125 | val_loss : 6518.97998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1094 | train_loss : 3852.515625 | val_loss : 9327.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1095 | train_loss : 6230.98876953125 | val_loss : 8337.11328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1096 | train_loss : 5600.46728515625 | val_loss : 10350.474609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1097 | train_loss : 6647.39111328125 | val_loss : 6162.55859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1098 | train_loss : 3395.965576171875 | val_loss : 12061.0087890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1099 | train_loss : 7662.1337890625 | val_loss : 7548.02734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1100 | train_loss : 5543.45166015625 | val_loss : 9990.7587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1101 | train_loss : 6121.86865234375 | val_loss : 6898.25390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1102 | train_loss : 4549.46240234375 | val_loss : 10602.0439453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1103 | train_loss : 7359.716796875 | val_loss : 6879.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1104 | train_loss : 3388.2275390625 | val_loss : 9556.4296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1105 | train_loss : 5635.9423828125 | val_loss : 8130.1181640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1106 | train_loss : 5479.13623046875 | val_loss : 14264.8203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1107 | train_loss : 8747.76171875 | val_loss : 4351.4560546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1108 | train_loss : 2062.808349609375 | val_loss : 3824.331298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1109 | train_loss : 2572.585205078125 | val_loss : 8064.85986328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1110 | train_loss : 5402.3251953125 | val_loss : 16999.751953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1111 | train_loss : 10380.640625 | val_loss : 6959.205078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1112 | train_loss : 3331.491943359375 | val_loss : 3046.451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1113 | train_loss : 2050.598876953125 | val_loss : 9190.013671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1114 | train_loss : 4679.5185546875 | val_loss : 7309.33740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1115 | train_loss : 5136.39697265625 | val_loss : 14884.802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1116 | train_loss : 7350.45703125 | val_loss : 3879.177490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1117 | train_loss : 2082.449951171875 | val_loss : 6878.9912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1118 | train_loss : 4796.041015625 | val_loss : 12241.9736328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1119 | train_loss : 7285.74365234375 | val_loss : 6698.52392578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1120 | train_loss : 3733.951904296875 | val_loss : 7122.0126953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1121 | train_loss : 4402.3935546875 | val_loss : 9255.716796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1122 | train_loss : 6580.05517578125 | val_loss : 15342.6884765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1123 | train_loss : 9185.9658203125 | val_loss : 5019.56494140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1124 | train_loss : 2165.354736328125 | val_loss : 2416.52880859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1125 | train_loss : 2250.732421875 | val_loss : 5183.87744140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1126 | train_loss : 3442.130615234375 | val_loss : 3961.455078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1127 | train_loss : 2991.26123046875 | val_loss : 7058.2412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1128 | train_loss : 3361.97998046875 | val_loss : 7111.9951171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1129 | train_loss : 5207.25244140625 | val_loss : 13429.4609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1130 | train_loss : 7316.65478515625 | val_loss : 4526.8349609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1131 | train_loss : 2907.031005859375 | val_loss : 7312.58642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1132 | train_loss : 4526.85986328125 | val_loss : 12880.6083984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1133 | train_loss : 8350.876953125 | val_loss : 6845.1875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1134 | train_loss : 3431.0947265625 | val_loss : 10823.587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1135 | train_loss : 6786.63427734375 | val_loss : 8078.91015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1136 | train_loss : 5209.763671875 | val_loss : 10397.0751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1137 | train_loss : 6080.52294921875 | val_loss : 5388.01611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1138 | train_loss : 2848.2421875 | val_loss : 11224.763671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1139 | train_loss : 7400.4267578125 | val_loss : 7683.1787109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1140 | train_loss : 4462.8408203125 | val_loss : 9342.9501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1141 | train_loss : 5516.42041015625 | val_loss : 7135.2138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1142 | train_loss : 4994.95751953125 | val_loss : 13546.478515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1143 | train_loss : 8224.5009765625 | val_loss : 5422.93505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1144 | train_loss : 2635.491455078125 | val_loss : 5946.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1145 | train_loss : 4070.737548828125 | val_loss : 10088.55859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1146 | train_loss : 8021.365234375 | val_loss : 14252.1240234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1147 | train_loss : 8426.787109375 | val_loss : 4928.8349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1148 | train_loss : 3010.193115234375 | val_loss : 3279.862548828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1149 | train_loss : 2543.7275390625 | val_loss : 7356.486328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1150 | train_loss : 5976.615234375 | val_loss : 15438.7802734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1151 | train_loss : 10129.6083984375 | val_loss : 7470.15478515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1152 | train_loss : 4411.06640625 | val_loss : 4621.48388671875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1153 | train_loss : 4477.54638671875 | val_loss : 8906.4970703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1154 | train_loss : 6388.970703125 | val_loss : 14286.98046875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1155 | train_loss : 11004.369140625 | val_loss : 13757.6259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1156 | train_loss : 11149.8408203125 | val_loss : 15443.1123046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1157 | train_loss : 12583.3125 | val_loss : 8251.6025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1158 | train_loss : 4929.07568359375 | val_loss : 13195.708984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1159 | train_loss : 8435.66796875 | val_loss : 9157.8876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1160 | train_loss : 6854.37548828125 | val_loss : 13035.7412109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1161 | train_loss : 8094.77978515625 | val_loss : 9076.7265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1162 | train_loss : 5514.5126953125 | val_loss : 12380.021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1163 | train_loss : 6546.021484375 | val_loss : 6526.53125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1164 | train_loss : 4077.61572265625 | val_loss : 12298.4921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1165 | train_loss : 7299.40234375 | val_loss : 6385.1689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1166 | train_loss : 3699.900634765625 | val_loss : 10560.6220703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1167 | train_loss : 6295.705078125 | val_loss : 6268.71142578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1168 | train_loss : 4523.81396484375 | val_loss : 10281.1611328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1169 | train_loss : 6294.87451171875 | val_loss : 6111.91357421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1170 | train_loss : 3419.5 | val_loss : 9351.6416015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1171 | train_loss : 5523.47119140625 | val_loss : 8257.75390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1172 | train_loss : 5614.38232421875 | val_loss : 10330.0546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1173 | train_loss : 5724.3701171875 | val_loss : 5609.291015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1174 | train_loss : 3364.1240234375 | val_loss : 10194.5810546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1175 | train_loss : 6518.87646484375 | val_loss : 7561.9462890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1176 | train_loss : 4573.669921875 | val_loss : 9576.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1177 | train_loss : 5581.9970703125 | val_loss : 7311.10498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1178 | train_loss : 4827.0126953125 | val_loss : 10606.4189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1179 | train_loss : 6191.2900390625 | val_loss : 6550.958984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1180 | train_loss : 3429.218017578125 | val_loss : 9006.0673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1181 | train_loss : 5491.04833984375 | val_loss : 8540.2373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1182 | train_loss : 5571.337890625 | val_loss : 12233.2041015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1183 | train_loss : 7626.3837890625 | val_loss : 6134.41259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1184 | train_loss : 2524.3671875 | val_loss : 4859.44873046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1185 | train_loss : 2560.042724609375 | val_loss : 8127.541015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1186 | train_loss : 5351.8076171875 | val_loss : 13171.630859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1187 | train_loss : 7255.20751953125 | val_loss : 5903.31396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1188 | train_loss : 2710.562744140625 | val_loss : 9329.85546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1189 | train_loss : 6624.54052734375 | val_loss : 8603.3310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1190 | train_loss : 6013.669921875 | val_loss : 9529.5615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1191 | train_loss : 5731.2060546875 | val_loss : 5956.14111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1192 | train_loss : 2932.8583984375 | val_loss : 9667.2998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1193 | train_loss : 5943.77001953125 | val_loss : 6351.92138671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1194 | train_loss : 3539.021240234375 | val_loss : 9874.4375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1195 | train_loss : 6000.68115234375 | val_loss : 6652.4150390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1196 | train_loss : 3680.233154296875 | val_loss : 8112.2236328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1197 | train_loss : 5532.51123046875 | val_loss : 7269.37646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1198 | train_loss : 4458.46728515625 | val_loss : 8975.9365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1199 | train_loss : 5730.623046875 | val_loss : 6124.55517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1200 | train_loss : 3395.356201171875 | val_loss : 7764.4599609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1201 | train_loss : 4978.81689453125 | val_loss : 6979.28125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1202 | train_loss : 4007.481201171875 | val_loss : 8937.94140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1203 | train_loss : 5940.19384765625 | val_loss : 6748.74267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1204 | train_loss : 4073.987548828125 | val_loss : 7261.73388671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1205 | train_loss : 4488.05908203125 | val_loss : 6432.00146484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1206 | train_loss : 3899.722412109375 | val_loss : 9132.25390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1207 | train_loss : 6221.861328125 | val_loss : 6366.25390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1208 | train_loss : 3315.189697265625 | val_loss : 6949.107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1209 | train_loss : 4551.802734375 | val_loss : 6071.51513671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1210 | train_loss : 3916.6474609375 | val_loss : 9499.62890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1211 | train_loss : 5471.68896484375 | val_loss : 6066.14501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1212 | train_loss : 3521.189697265625 | val_loss : 7225.79736328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1213 | train_loss : 4689.57666015625 | val_loss : 6055.16015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1214 | train_loss : 3638.12255859375 | val_loss : 8888.0146484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1215 | train_loss : 5781.0888671875 | val_loss : 5774.021484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1216 | train_loss : 3203.3486328125 | val_loss : 6561.689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1217 | train_loss : 4365.80615234375 | val_loss : 6970.90869140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1218 | train_loss : 3908.4501953125 | val_loss : 10524.2841796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1219 | train_loss : 6063.9912109375 | val_loss : 5341.81103515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1220 | train_loss : 3274.79541015625 | val_loss : 6070.912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1221 | train_loss : 3693.388671875 | val_loss : 7633.2763671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1222 | train_loss : 5604.17431640625 | val_loss : 12408.4658203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1223 | train_loss : 7075.0712890625 | val_loss : 5489.68505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1224 | train_loss : 2743.767578125 | val_loss : 5551.8251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1225 | train_loss : 3554.077880859375 | val_loss : 9018.2646484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1226 | train_loss : 7401.88134765625 | val_loss : 11746.4287109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1227 | train_loss : 6578.755859375 | val_loss : 5042.3974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1228 | train_loss : 2619.0576171875 | val_loss : 6096.10009765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1229 | train_loss : 3634.603515625 | val_loss : 7430.62353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1230 | train_loss : 4610.3037109375 | val_loss : 12142.8935546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1231 | train_loss : 6505.974609375 | val_loss : 5057.5400390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1232 | train_loss : 2507.426025390625 | val_loss : 4015.077392578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1233 | train_loss : 2278.214111328125 | val_loss : 5306.27978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1234 | train_loss : 3341.991943359375 | val_loss : 9271.9541015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1235 | train_loss : 5245.0625 | val_loss : 6760.96240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1236 | train_loss : 3856.833984375 | val_loss : 8779.6484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1237 | train_loss : 5013.83544921875 | val_loss : 4962.50732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1238 | train_loss : 3016.469970703125 | val_loss : 11138.947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1239 | train_loss : 7366.724609375 | val_loss : 8913.1904296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1240 | train_loss : 5246.26953125 | val_loss : 7441.41015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1241 | train_loss : 3587.007080078125 | val_loss : 4425.79248046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1242 | train_loss : 2657.155517578125 | val_loss : 7847.802734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1243 | train_loss : 5180.7431640625 | val_loss : 6256.09765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1244 | train_loss : 3837.483154296875 | val_loss : 7329.87939453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1245 | train_loss : 4531.744140625 | val_loss : 5889.26513671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1246 | train_loss : 3894.5224609375 | val_loss : 7768.609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1247 | train_loss : 5320.685546875 | val_loss : 6246.05517578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1248 | train_loss : 4459.33203125 | val_loss : 11138.865234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1249 | train_loss : 6832.00390625 | val_loss : 5642.46484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1250 | train_loss : 4362.85546875 | val_loss : 8069.302734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1251 | train_loss : 4101.96240234375 | val_loss : 6480.576171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1252 | train_loss : 3794.279296875 | val_loss : 11953.0537109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1253 | train_loss : 6760.09765625 | val_loss : 4656.3349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1254 | train_loss : 1978.451904296875 | val_loss : 5078.66357421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1255 | train_loss : 2301.007080078125 | val_loss : 6903.94873046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1256 | train_loss : 4304.08251953125 | val_loss : 11883.73046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1257 | train_loss : 6779.15869140625 | val_loss : 5304.6376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1258 | train_loss : 2029.9666748046875 | val_loss : 5512.712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1259 | train_loss : 2766.996826171875 | val_loss : 8130.19873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1260 | train_loss : 4875.53955078125 | val_loss : 11450.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1261 | train_loss : 6380.80126953125 | val_loss : 5353.21142578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1262 | train_loss : 2243.046142578125 | val_loss : 5580.09765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1263 | train_loss : 2744.391357421875 | val_loss : 6531.5712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1264 | train_loss : 3824.556884765625 | val_loss : 9513.435546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1265 | train_loss : 5434.994140625 | val_loss : 7037.892578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1266 | train_loss : 3311.781982421875 | val_loss : 8518.0654296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1267 | train_loss : 4419.46533203125 | val_loss : 6451.92431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1268 | train_loss : 3663.827880859375 | val_loss : 9318.5556640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1269 | train_loss : 5232.76171875 | val_loss : 6669.5537109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1270 | train_loss : 3301.2900390625 | val_loss : 7210.1142578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1271 | train_loss : 3653.8076171875 | val_loss : 7247.71484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1272 | train_loss : 4641.18701171875 | val_loss : 11334.2001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1273 | train_loss : 6321.85546875 | val_loss : 4115.87109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1274 | train_loss : 1639.057861328125 | val_loss : 5219.12060546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1275 | train_loss : 2394.2998046875 | val_loss : 29510.720703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1276 | train_loss : 27183.744140625 | val_loss : 29177.9609375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1277 | train_loss : 19190.12890625 | val_loss : 23505.98828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1278 | train_loss : 24435.640625 | val_loss : 6540.30322265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1279 | train_loss : 4372.85693359375 | val_loss : 5417.9423828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1280 | train_loss : 3675.533203125 | val_loss : 4312.03759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1281 | train_loss : 2210.546142578125 | val_loss : 4159.4189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1282 | train_loss : 2206.716796875 | val_loss : 4730.7060546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1283 | train_loss : 3272.22900390625 | val_loss : 7281.61376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1284 | train_loss : 3541.996337890625 | val_loss : 4934.7060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1285 | train_loss : 3027.90185546875 | val_loss : 7731.18115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1286 | train_loss : 3982.91064453125 | val_loss : 6978.45361328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1287 | train_loss : 4684.2724609375 | val_loss : 8667.0146484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1288 | train_loss : 4432.568359375 | val_loss : 6383.55419921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1289 | train_loss : 3995.1259765625 | val_loss : 9753.0322265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1290 | train_loss : 5231.11865234375 | val_loss : 5988.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1291 | train_loss : 3535.28564453125 | val_loss : 8137.314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1292 | train_loss : 3874.2412109375 | val_loss : 6692.236328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1293 | train_loss : 3941.0615234375 | val_loss : 10707.7421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1294 | train_loss : 5651.3525390625 | val_loss : 4905.70458984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1295 | train_loss : 2880.491943359375 | val_loss : 5801.59423828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1296 | train_loss : 2600.301025390625 | val_loss : 4979.77978515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1297 | train_loss : 3055.168701171875 | val_loss : 6642.76123046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1298 | train_loss : 3128.012451171875 | val_loss : 6614.08984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1299 | train_loss : 4205.45703125 | val_loss : 8995.056640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1300 | train_loss : 4816.7080078125 | val_loss : 6812.146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1301 | train_loss : 4521.69384765625 | val_loss : 7036.65869140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1302 | train_loss : 3906.10693359375 | val_loss : 8035.05615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1303 | train_loss : 5661.91259765625 | val_loss : 12023.490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1304 | train_loss : 6645.1533203125 | val_loss : 5993.4111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1305 | train_loss : 3568.304931640625 | val_loss : 4564.35009765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1306 | train_loss : 2751.6669921875 | val_loss : 6245.84765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1307 | train_loss : 3484.249755859375 | val_loss : 7534.8232421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1308 | train_loss : 4025.685546875 | val_loss : 11030.6845703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1309 | train_loss : 6420.64306640625 | val_loss : 5697.279296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1310 | train_loss : 2105.533203125 | val_loss : 3884.42431640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1311 | train_loss : 2156.4619140625 | val_loss : 5839.7568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1312 | train_loss : 3818.636962890625 | val_loss : 10405.3232421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1313 | train_loss : 6103.634765625 | val_loss : 5190.42822265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1314 | train_loss : 1891.001708984375 | val_loss : 4957.3818359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1315 | train_loss : 2651.58447265625 | val_loss : 6996.0830078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1316 | train_loss : 4011.343505859375 | val_loss : 10552.115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1317 | train_loss : 5877.35498046875 | val_loss : 5455.98046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1318 | train_loss : 2052.11474609375 | val_loss : 4471.7900390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1319 | train_loss : 2595.58837890625 | val_loss : 6394.4462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1320 | train_loss : 3725.77001953125 | val_loss : 7520.11376953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1321 | train_loss : 4379.01416015625 | val_loss : 7130.5087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1322 | train_loss : 3319.20654296875 | val_loss : 9713.8046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1323 | train_loss : 5307.85986328125 | val_loss : 4927.61328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1324 | train_loss : 2438.7392578125 | val_loss : 5864.4287109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1325 | train_loss : 3360.990966796875 | val_loss : 6985.47119140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1326 | train_loss : 3750.69189453125 | val_loss : 9165.5537109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1327 | train_loss : 5243.2900390625 | val_loss : 4859.92822265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1328 | train_loss : 2277.38818359375 | val_loss : 6789.3486328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1329 | train_loss : 3886.0625 | val_loss : 6387.99853515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1330 | train_loss : 3285.865234375 | val_loss : 8112.8017578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1331 | train_loss : 4474.7646484375 | val_loss : 5554.57373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1332 | train_loss : 2901.526611328125 | val_loss : 7748.32763671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1333 | train_loss : 4135.0361328125 | val_loss : 6160.69873046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1334 | train_loss : 3099.462890625 | val_loss : 7492.1005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1335 | train_loss : 4108.11865234375 | val_loss : 6134.939453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1336 | train_loss : 2848.141845703125 | val_loss : 8240.7919921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1337 | train_loss : 4806.81298828125 | val_loss : 5384.0751953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1338 | train_loss : 2623.44970703125 | val_loss : 6256.46826171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1339 | train_loss : 3670.59521484375 | val_loss : 5854.34130859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1340 | train_loss : 4159.87548828125 | val_loss : 9417.5634765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1341 | train_loss : 5438.0400390625 | val_loss : 4676.990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1342 | train_loss : 2129.93212890625 | val_loss : 4604.4423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1343 | train_loss : 2715.130859375 | val_loss : 5930.947265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1344 | train_loss : 3276.9443359375 | val_loss : 7917.92578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1345 | train_loss : 4736.3154296875 | val_loss : 6286.74560546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1346 | train_loss : 2741.510986328125 | val_loss : 6855.958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1347 | train_loss : 3670.17822265625 | val_loss : 5478.888671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1348 | train_loss : 3078.03564453125 | val_loss : 7272.6279296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1349 | train_loss : 3836.410888671875 | val_loss : 6345.09228515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1350 | train_loss : 3165.86962890625 | val_loss : 8398.943359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1351 | train_loss : 4459.49609375 | val_loss : 4442.40478515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1352 | train_loss : 2141.5419921875 | val_loss : 6366.376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1353 | train_loss : 3492.74560546875 | val_loss : 5993.92626953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1354 | train_loss : 3057.572509765625 | val_loss : 437410.4375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1355 | train_loss : 416516.96875 | val_loss : 42183.12890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1356 | train_loss : 34264.59375 | val_loss : 37154.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1357 | train_loss : 53732.3359375 | val_loss : 31913.490234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1358 | train_loss : 35215.83984375 | val_loss : 18244.134765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1359 | train_loss : 17308.73046875 | val_loss : 5732.8349609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1360 | train_loss : 5494.4287109375 | val_loss : 8761.9541015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1361 | train_loss : 5780.6591796875 | val_loss : 5417.42236328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1362 | train_loss : 5131.6923828125 | val_loss : 9332.337890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1363 | train_loss : 5755.498046875 | val_loss : 7356.14111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1364 | train_loss : 5891.3486328125 | val_loss : 9888.8115234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1365 | train_loss : 6020.22607421875 | val_loss : 5914.119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1366 | train_loss : 4315.87841796875 | val_loss : 6678.06396484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1367 | train_loss : 3406.901611328125 | val_loss : 6295.3173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1368 | train_loss : 4174.623046875 | val_loss : 8211.0009765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1369 | train_loss : 3933.730712890625 | val_loss : 5187.95361328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1370 | train_loss : 3116.49072265625 | val_loss : 8396.080078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1371 | train_loss : 3416.607421875 | val_loss : 4504.294921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1372 | train_loss : 2619.04443359375 | val_loss : 9224.8134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1373 | train_loss : 3727.679443359375 | val_loss : 4588.7998046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1374 | train_loss : 2416.446044921875 | val_loss : 6063.95361328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1375 | train_loss : 2640.849365234375 | val_loss : 5087.10986328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1376 | train_loss : 2808.323486328125 | val_loss : 6747.537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1377 | train_loss : 2925.234375 | val_loss : 3843.685546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1378 | train_loss : 2032.6148681640625 | val_loss : 5818.259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1379 | train_loss : 2499.322265625 | val_loss : 4632.28759765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1380 | train_loss : 2545.087890625 | val_loss : 6109.7685546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1381 | train_loss : 2669.10595703125 | val_loss : 4964.58251953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1382 | train_loss : 2736.33251953125 | val_loss : 5797.30078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1383 | train_loss : 2385.2392578125 | val_loss : 4021.6025390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1384 | train_loss : 2226.9287109375 | val_loss : 5486.193359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1385 | train_loss : 2647.92333984375 | val_loss : 4749.75732421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1386 | train_loss : 2579.576171875 | val_loss : 5651.87451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1387 | train_loss : 2226.388671875 | val_loss : 3968.304931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1388 | train_loss : 2372.8515625 | val_loss : 5639.23876953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1389 | train_loss : 2591.1171875 | val_loss : 4021.29052734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1390 | train_loss : 2566.629638671875 | val_loss : 6647.412109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1391 | train_loss : 2670.275634765625 | val_loss : 5968.78857421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1392 | train_loss : 3222.95947265625 | val_loss : 7821.62548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1393 | train_loss : 3068.87255859375 | val_loss : 4531.37060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1394 | train_loss : 2254.977783203125 | val_loss : 6396.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1395 | train_loss : 2836.31689453125 | val_loss : 4121.04638671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1396 | train_loss : 2969.787109375 | val_loss : 6408.51953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1397 | train_loss : 2694.0361328125 | val_loss : 3291.6162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1398 | train_loss : 2359.09521484375 | val_loss : 5717.55615234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1399 | train_loss : 2755.251220703125 | val_loss : 4190.3037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1400 | train_loss : 2646.64208984375 | val_loss : 6037.37890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1401 | train_loss : 2468.933349609375 | val_loss : 3390.923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1402 | train_loss : 2186.59912109375 | val_loss : 5493.58935546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1403 | train_loss : 2775.703857421875 | val_loss : 5213.48876953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1404 | train_loss : 2708.50146484375 | val_loss : 6243.89501953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1405 | train_loss : 2677.830078125 | val_loss : 4531.96435546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1406 | train_loss : 2562.422119140625 | val_loss : 5965.984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1407 | train_loss : 2968.544921875 | val_loss : 5807.77001953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1408 | train_loss : 3275.981201171875 | val_loss : 6301.5498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1409 | train_loss : 2685.4970703125 | val_loss : 4867.5224609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1410 | train_loss : 2407.218017578125 | val_loss : 6459.56884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1411 | train_loss : 3038.860595703125 | val_loss : 3487.597412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1412 | train_loss : 2263.02392578125 | val_loss : 5076.40673828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1413 | train_loss : 1952.4693603515625 | val_loss : 3748.97314453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1414 | train_loss : 2136.511962890625 | val_loss : 5721.00439453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1415 | train_loss : 2711.1640625 | val_loss : 5242.85205078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1416 | train_loss : 3330.335205078125 | val_loss : 6758.845703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1417 | train_loss : 2683.3662109375 | val_loss : 3574.581298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1418 | train_loss : 2872.04443359375 | val_loss : 8059.8388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1419 | train_loss : 3845.148193359375 | val_loss : 3604.387451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1420 | train_loss : 2315.886474609375 | val_loss : 4406.9482421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1421 | train_loss : 1475.0223388671875 | val_loss : 3346.52880859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1422 | train_loss : 1914.0257568359375 | val_loss : 5199.6474609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1423 | train_loss : 2127.900390625 | val_loss : 4083.52490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1424 | train_loss : 2360.6953125 | val_loss : 6455.60009765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1425 | train_loss : 2543.26904296875 | val_loss : 4924.634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1426 | train_loss : 2530.455078125 | val_loss : 6341.607421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1427 | train_loss : 2705.543212890625 | val_loss : 4951.83984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1428 | train_loss : 2739.031982421875 | val_loss : 6457.98291015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1429 | train_loss : 2765.702880859375 | val_loss : 3606.451171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1430 | train_loss : 2035.438720703125 | val_loss : 4795.046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1431 | train_loss : 2189.45458984375 | val_loss : 4854.40576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1432 | train_loss : 2615.36376953125 | val_loss : 6141.27978515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1433 | train_loss : 2580.19384765625 | val_loss : 4520.603515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1434 | train_loss : 2061.04345703125 | val_loss : 5181.42138671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1435 | train_loss : 2602.8271484375 | val_loss : 4770.275390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1436 | train_loss : 2266.251708984375 | val_loss : 5420.43310546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1437 | train_loss : 2142.9306640625 | val_loss : 4367.48583984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1438 | train_loss : 2212.561279296875 | val_loss : 7149.302734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1439 | train_loss : 3471.20751953125 | val_loss : 4041.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1440 | train_loss : 2005.5340576171875 | val_loss : 4859.06201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1441 | train_loss : 1658.2662353515625 | val_loss : 3540.065673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1442 | train_loss : 1942.1522216796875 | val_loss : 4779.76806640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1443 | train_loss : 2147.05615234375 | val_loss : 4845.26416015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1444 | train_loss : 2476.598388671875 | val_loss : 4846.42919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1445 | train_loss : 1843.6365966796875 | val_loss : 4725.453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1446 | train_loss : 3272.331298828125 | val_loss : 5443.0849609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1447 | train_loss : 2922.991943359375 | val_loss : 4840.8564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1448 | train_loss : 2371.1845703125 | val_loss : 3841.260009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1449 | train_loss : 1465.3935546875 | val_loss : 4596.43310546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1450 | train_loss : 2050.367431640625 | val_loss : 3722.911865234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1451 | train_loss : 2174.512451171875 | val_loss : 6117.484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1452 | train_loss : 2892.365966796875 | val_loss : 5794.763671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1453 | train_loss : 3365.593017578125 | val_loss : 8853.0546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1454 | train_loss : 4836.30126953125 | val_loss : 3378.715576171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1455 | train_loss : 2206.2158203125 | val_loss : 4175.2841796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1456 | train_loss : 1830.38037109375 | val_loss : 4278.5751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1457 | train_loss : 2312.8115234375 | val_loss : 8418.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1458 | train_loss : 4810.55859375 | val_loss : 3336.6669921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1459 | train_loss : 1490.4267578125 | val_loss : 3415.566162109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1460 | train_loss : 1771.4072265625 | val_loss : 5013.62646484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1461 | train_loss : 3125.788818359375 | val_loss : 8072.0625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1462 | train_loss : 4824.185546875 | val_loss : 5795.07568359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1463 | train_loss : 3642.890625 | val_loss : 7344.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1464 | train_loss : 4064.789306640625 | val_loss : 4612.9267578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1465 | train_loss : 2991.80322265625 | val_loss : 6661.8466796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1466 | train_loss : 3479.188720703125 | val_loss : 5296.18701171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1467 | train_loss : 3041.5703125 | val_loss : 7315.0498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1468 | train_loss : 3593.3505859375 | val_loss : 4195.96728515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1469 | train_loss : 2475.2236328125 | val_loss : 7055.12353515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1470 | train_loss : 3334.10009765625 | val_loss : 4218.25732421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1471 | train_loss : 2345.93115234375 | val_loss : 6966.5048828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1472 | train_loss : 3333.037109375 | val_loss : 4380.24951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1473 | train_loss : 1876.2427978515625 | val_loss : 6809.10107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1474 | train_loss : 3186.074951171875 | val_loss : 4346.0751953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1475 | train_loss : 2475.63720703125 | val_loss : 7485.205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1476 | train_loss : 3573.423095703125 | val_loss : 4255.0419921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1477 | train_loss : 2111.019287109375 | val_loss : 6547.23486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1478 | train_loss : 3128.962890625 | val_loss : 4011.175048828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1479 | train_loss : 2397.455810546875 | val_loss : 6920.732421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1480 | train_loss : 3394.3955078125 | val_loss : 4243.0107421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1481 | train_loss : 1962.8477783203125 | val_loss : 6775.79736328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1482 | train_loss : 3372.9033203125 | val_loss : 3625.140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1483 | train_loss : 1987.093017578125 | val_loss : 6721.62890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1484 | train_loss : 3497.26025390625 | val_loss : 4297.2080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1485 | train_loss : 2102.52783203125 | val_loss : 6123.87890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1486 | train_loss : 3176.830078125 | val_loss : 4608.611328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1487 | train_loss : 2242.80712890625 | val_loss : 6496.74267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1488 | train_loss : 3351.701904296875 | val_loss : 3706.1455078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1489 | train_loss : 1843.00439453125 | val_loss : 6589.53076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1490 | train_loss : 3275.087890625 | val_loss : 4111.12451171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1491 | train_loss : 1763.962646484375 | val_loss : 5542.2060546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1492 | train_loss : 2785.434326171875 | val_loss : 4552.1357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1493 | train_loss : 2508.646484375 | val_loss : 7585.10546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1494 | train_loss : 3859.5810546875 | val_loss : 3371.44189453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1495 | train_loss : 1254.404541015625 | val_loss : 4351.1123046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1496 | train_loss : 2028.64599609375 | val_loss : 4705.27734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1497 | train_loss : 2675.0 | val_loss : 9067.6025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1498 | train_loss : 4932.39013671875 | val_loss : 3785.644287109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1499 | train_loss : 1111.885498046875 | val_loss : 2607.16748046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1500 | train_loss : 1048.5570068359375 | val_loss : 3022.25634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1501 | train_loss : 1047.9229736328125 | val_loss : 3629.896240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1502 | train_loss : 1565.76123046875 | val_loss : 3187.656982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1503 | train_loss : 1527.093017578125 | val_loss : 3467.757568359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1504 | train_loss : 1615.134521484375 | val_loss : 3375.469970703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1505 | train_loss : 1167.2974853515625 | val_loss : 3439.71630859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1506 | train_loss : 1620.7880859375 | val_loss : 3328.66748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1507 | train_loss : 1729.1087646484375 | val_loss : 4024.793701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1508 | train_loss : 1972.3414306640625 | val_loss : 4224.23193359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1509 | train_loss : 1925.4102783203125 | val_loss : 6990.044921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1510 | train_loss : 3865.825927734375 | val_loss : 5391.12353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1511 | train_loss : 2945.116943359375 | val_loss : 6948.45068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1512 | train_loss : 3647.3984375 | val_loss : 4024.04052734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1513 | train_loss : 2187.619384765625 | val_loss : 6922.0205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1514 | train_loss : 3576.82666015625 | val_loss : 3124.744384765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1515 | train_loss : 2112.050048828125 | val_loss : 6095.8369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1516 | train_loss : 3176.240966796875 | val_loss : 3020.81494140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1517 | train_loss : 2175.92236328125 | val_loss : 6210.8662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1518 | train_loss : 3176.88818359375 | val_loss : 4375.66357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1519 | train_loss : 2657.238037109375 | val_loss : 7048.23388671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1520 | train_loss : 3335.720703125 | val_loss : 3942.222412109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1521 | train_loss : 1653.9493408203125 | val_loss : 5700.24560546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1522 | train_loss : 2932.386962890625 | val_loss : 3182.861328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1523 | train_loss : 1931.3946533203125 | val_loss : 6169.17333984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1524 | train_loss : 3139.685546875 | val_loss : 3483.226318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1525 | train_loss : 2131.271484375 | val_loss : 4964.05126953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1526 | train_loss : 2527.898193359375 | val_loss : 3458.269287109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1527 | train_loss : 2240.66162109375 | val_loss : 6351.39501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1528 | train_loss : 3381.97998046875 | val_loss : 3205.433837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1529 | train_loss : 1741.8818359375 | val_loss : 5772.5712890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1530 | train_loss : 2967.25927734375 | val_loss : 3137.982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1531 | train_loss : 2230.6357421875 | val_loss : 5527.0224609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1532 | train_loss : 2799.781982421875 | val_loss : 3305.69189453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1533 | train_loss : 1926.6322021484375 | val_loss : 6188.8349609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1534 | train_loss : 3348.923828125 | val_loss : 2811.281982421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1535 | train_loss : 1620.9468994140625 | val_loss : 4652.50244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1536 | train_loss : 2469.0224609375 | val_loss : 3468.3701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1537 | train_loss : 2917.918701171875 | val_loss : 8424.94140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1538 | train_loss : 4737.1845703125 | val_loss : 3062.9619140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1539 | train_loss : 1138.717529296875 | val_loss : 2311.38427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1540 | train_loss : 1086.828857421875 | val_loss : 2266.433837890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1541 | train_loss : 1138.8463134765625 | val_loss : 2675.580078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1542 | train_loss : 1678.288330078125 | val_loss : 3706.382568359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1543 | train_loss : 2574.410888671875 | val_loss : 5638.13427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1544 | train_loss : 3504.2421875 | val_loss : 4864.70556640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1545 | train_loss : 3410.672119140625 | val_loss : 6811.09765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1546 | train_loss : 4288.4150390625 | val_loss : 3238.0 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1547 | train_loss : 2318.06884765625 | val_loss : 5221.18017578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1548 | train_loss : 3177.83740234375 | val_loss : 6638.837890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1549 | train_loss : 7229.18798828125 | val_loss : 31480.294921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1550 | train_loss : 27098.400390625 | val_loss : 19216.740234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1551 | train_loss : 15355.4091796875 | val_loss : 6121.33935546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1552 | train_loss : 11890.3984375 | val_loss : 4777.33984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1553 | train_loss : 5375.623046875 | val_loss : 5933.9091796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1554 | train_loss : 3983.2421875 | val_loss : 6226.86572265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1555 | train_loss : 4780.37744140625 | val_loss : 7648.9560546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1556 | train_loss : 5703.23681640625 | val_loss : 8173.623046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1557 | train_loss : 6445.3857421875 | val_loss : 6719.62255859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1558 | train_loss : 4629.92626953125 | val_loss : 4853.21142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1559 | train_loss : 3280.39990234375 | val_loss : 6116.8466796875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1560 | train_loss : 4102.291015625 | val_loss : 5209.73291015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1561 | train_loss : 2712.09619140625 | val_loss : 5616.18115234375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1562 | train_loss : 3079.435546875 | val_loss : 4429.7451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1563 | train_loss : 2845.294677734375 | val_loss : 6370.07421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1564 | train_loss : 3060.231201171875 | val_loss : 4689.56689453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1565 | train_loss : 2541.9345703125 | val_loss : 6258.46630859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1566 | train_loss : 3030.880615234375 | val_loss : 6945.48388671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1567 | train_loss : 4986.9873046875 | val_loss : 11003.130859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1568 | train_loss : 5667.75 | val_loss : 5397.94921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1569 | train_loss : 2692.653076171875 | val_loss : 5843.8857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1570 | train_loss : 3298.91259765625 | val_loss : 5664.36572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1571 | train_loss : 2734.581298828125 | val_loss : 8341.005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1572 | train_loss : 5265.53076171875 | val_loss : 11835.0166015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1573 | train_loss : 8506.85546875 | val_loss : 7180.1806640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1574 | train_loss : 3828.28125 | val_loss : 3593.45556640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1575 | train_loss : 2785.979736328125 | val_loss : 6467.2607421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1576 | train_loss : 3713.84130859375 | val_loss : 6661.44482421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1577 | train_loss : 6260.841796875 | val_loss : 8043.3154296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1578 | train_loss : 4640.35205078125 | val_loss : 5902.32763671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1579 | train_loss : 4429.1015625 | val_loss : 8266.3623046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1580 | train_loss : 4835.75390625 | val_loss : 6490.7138671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1581 | train_loss : 4071.79052734375 | val_loss : 6015.4951171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1582 | train_loss : 2933.531982421875 | val_loss : 5560.89306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1583 | train_loss : 3668.027587890625 | val_loss : 5721.80078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1584 | train_loss : 2980.546875 | val_loss : 5050.71630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1585 | train_loss : 2884.763427734375 | val_loss : 4703.14990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1586 | train_loss : 1634.8699951171875 | val_loss : 3751.9638671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1587 | train_loss : 1651.533447265625 | val_loss : 3921.656982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1588 | train_loss : 1515.125732421875 | val_loss : 4953.662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1589 | train_loss : 2078.013427734375 | val_loss : 4684.05322265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1590 | train_loss : 2502.51611328125 | val_loss : 6568.67431640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1591 | train_loss : 3076.668701171875 | val_loss : 6715.48046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1592 | train_loss : 5013.466796875 | val_loss : 7097.12451171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1593 | train_loss : 4349.31005859375 | val_loss : 3664.554443359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1594 | train_loss : 1769.5328369140625 | val_loss : 4313.21484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1595 | train_loss : 1835.219970703125 | val_loss : 3935.97998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1596 | train_loss : 1988.0634765625 | val_loss : 6630.47607421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1597 | train_loss : 3310.392578125 | val_loss : 3805.79248046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1598 | train_loss : 1429.6724853515625 | val_loss : 3854.574951171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1599 | train_loss : 1786.12939453125 | val_loss : 4226.90625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 1600 | train_loss : 2430.099365234375 | val_loss : 7893.22314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 3 | epoch : 1 | train_loss : 805974.75 | val_loss : 639569.3125 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 2 | train_loss : 680773.375 | val_loss : 453347.84375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 3 | train_loss : 402400.15625 | val_loss : 714279.6875 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 4 | train_loss : 483074.1875 | val_loss : 388768.6875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 5 | train_loss : 349697.15625 | val_loss : 262305.625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 6 | train_loss : 237835.296875 | val_loss : 475131.375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 7 | train_loss : 354552.6875 | val_loss : 485027.625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 8 | train_loss : 387973.875 | val_loss : 137148.53125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 9 | train_loss : 162053.546875 | val_loss : 205186.296875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 10 | train_loss : 190479.859375 | val_loss : 414853.8125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 11 | train_loss : 225320.8125 | val_loss : 243863.265625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 12 | train_loss : 219600.421875 | val_loss : 312727.46875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 13 | train_loss : 314506.8125 | val_loss : 443950.625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 14 | train_loss : 389831.8125 | val_loss : 493471.90625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 15 | train_loss : 435629.84375 | val_loss : 346420.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 16 | train_loss : 368145.75 | val_loss : 302948.28125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 17 | train_loss : 216186.703125 | val_loss : 119707.5 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 18 | train_loss : 152937.703125 | val_loss : 154262.5 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 19 | train_loss : 163049.6875 | val_loss : 154889.421875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 20 | train_loss : 214615.734375 | val_loss : 205809.859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 21 | train_loss : 181224.859375 | val_loss : 284193.15625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 22 | train_loss : 209298.484375 | val_loss : 184370.984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 23 | train_loss : 262949.53125 | val_loss : 218294.015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 24 | train_loss : 210702.765625 | val_loss : 127966.15625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 25 | train_loss : 143203.734375 | val_loss : 238660.796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 26 | train_loss : 210988.65625 | val_loss : 214308.0 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 27 | train_loss : 210346.28125 | val_loss : 78422.6875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 28 | train_loss : 135129.984375 | val_loss : 140209.875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 29 | train_loss : 138070.6875 | val_loss : 135983.3125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 30 | train_loss : 128332.5390625 | val_loss : 180899.078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 31 | train_loss : 144743.890625 | val_loss : 217970.859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 32 | train_loss : 183582.921875 | val_loss : 192231.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 33 | train_loss : 193181.140625 | val_loss : 191758.21875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 34 | train_loss : 246066.546875 | val_loss : 145076.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 35 | train_loss : 135383.890625 | val_loss : 320726.6875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 36 | train_loss : 173430.640625 | val_loss : 305655.15625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 37 | train_loss : 184961.375 | val_loss : 108174.5 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 38 | train_loss : 136140.375 | val_loss : 132087.71875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 39 | train_loss : 179526.375 | val_loss : 221659.703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 40 | train_loss : 203657.203125 | val_loss : 135216.265625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 41 | train_loss : 138013.265625 | val_loss : 175247.28125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 42 | train_loss : 102526.6015625 | val_loss : 177582.4375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 43 | train_loss : 157376.5625 | val_loss : 273518.90625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 44 | train_loss : 166698.1875 | val_loss : 203868.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 45 | train_loss : 191827.703125 | val_loss : 147488.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 46 | train_loss : 135732.515625 | val_loss : 71667.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 47 | train_loss : 108742.0 | val_loss : 163756.296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 48 | train_loss : 107285.2109375 | val_loss : 167438.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 49 | train_loss : 154360.21875 | val_loss : 158481.140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 50 | train_loss : 179437.34375 | val_loss : 144392.421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 51 | train_loss : 166231.265625 | val_loss : 174729.203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 52 | train_loss : 139370.125 | val_loss : 122830.5 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 53 | train_loss : 155156.8125 | val_loss : 194751.65625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 54 | train_loss : 122039.1171875 | val_loss : 101937.7265625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 55 | train_loss : 106493.0703125 | val_loss : 96258.7421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 56 | train_loss : 132199.203125 | val_loss : 93751.53125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 57 | train_loss : 126107.2578125 | val_loss : 175100.234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 58 | train_loss : 107777.578125 | val_loss : 127172.9921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 59 | train_loss : 105735.609375 | val_loss : 34014.4140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 60 | train_loss : 80333.8984375 | val_loss : 161661.4375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 61 | train_loss : 106907.6015625 | val_loss : 118980.84375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 62 | train_loss : 109199.34375 | val_loss : 184873.125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 63 | train_loss : 142994.453125 | val_loss : 222717.640625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 64 | train_loss : 141091.6875 | val_loss : 148196.015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 65 | train_loss : 154804.09375 | val_loss : 157717.546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 66 | train_loss : 175957.640625 | val_loss : 90516.2578125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 67 | train_loss : 80377.21875 | val_loss : 186555.484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 68 | train_loss : 127466.46875 | val_loss : 88848.6796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 69 | train_loss : 125886.0625 | val_loss : 88029.1015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 70 | train_loss : 103269.0 | val_loss : 203533.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 71 | train_loss : 119107.84375 | val_loss : 139298.84375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 72 | train_loss : 114605.3125 | val_loss : 289994.375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 73 | train_loss : 178431.1875 | val_loss : 123528.7734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 74 | train_loss : 91189.5 | val_loss : 100669.7578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 75 | train_loss : 111675.2421875 | val_loss : 102299.7109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 76 | train_loss : 106648.953125 | val_loss : 78248.8984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 77 | train_loss : 167501.53125 | val_loss : 44796.89453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 78 | train_loss : 66591.296875 | val_loss : 80930.2734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 79 | train_loss : 63342.8046875 | val_loss : 57931.85546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 80 | train_loss : 60481.64453125 | val_loss : 54692.8984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 81 | train_loss : 64654.42578125 | val_loss : 82588.046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 82 | train_loss : 74798.0625 | val_loss : 165381.328125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 83 | train_loss : 94741.0390625 | val_loss : 145321.125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 84 | train_loss : 145441.765625 | val_loss : 105427.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 85 | train_loss : 91954.53125 | val_loss : 268488.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 86 | train_loss : 155907.90625 | val_loss : 196078.0625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 87 | train_loss : 149359.46875 | val_loss : 66630.78125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 88 | train_loss : 103926.40625 | val_loss : 97522.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 89 | train_loss : 92429.3515625 | val_loss : 102647.671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 90 | train_loss : 83539.9375 | val_loss : 149599.8125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 91 | train_loss : 104524.1015625 | val_loss : 71098.2265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 92 | train_loss : 73137.5625 | val_loss : 62680.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 93 | train_loss : 67997.0234375 | val_loss : 141542.0 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 94 | train_loss : 97489.671875 | val_loss : 80349.703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 95 | train_loss : 74188.828125 | val_loss : 59022.3203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 96 | train_loss : 46460.73828125 | val_loss : 61978.55859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 97 | train_loss : 84623.2734375 | val_loss : 154259.703125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 98 | train_loss : 120511.59375 | val_loss : 88764.0 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 99 | train_loss : 147112.015625 | val_loss : 136767.140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 100 | train_loss : 129685.03125 | val_loss : 74558.7265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 101 | train_loss : 69075.9140625 | val_loss : 214253.515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 102 | train_loss : 111937.109375 | val_loss : 120324.7421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 103 | train_loss : 99731.703125 | val_loss : 34228.48828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 104 | train_loss : 73710.0625 | val_loss : 75651.3515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 105 | train_loss : 65120.42578125 | val_loss : 65257.828125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 106 | train_loss : 61240.76171875 | val_loss : 85390.3203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 107 | train_loss : 75509.6328125 | val_loss : 35601.31640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 108 | train_loss : 64550.19140625 | val_loss : 26504.4453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 109 | train_loss : 59650.359375 | val_loss : 93652.8515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 110 | train_loss : 74055.9609375 | val_loss : 60628.078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 111 | train_loss : 60141.51171875 | val_loss : 124606.2578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 112 | train_loss : 68186.5625 | val_loss : 56912.80078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 113 | train_loss : 76797.8984375 | val_loss : 60319.55859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 114 | train_loss : 69274.7421875 | val_loss : 102903.46875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 115 | train_loss : 73097.296875 | val_loss : 74522.4765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 116 | train_loss : 91736.859375 | val_loss : 149023.234375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 117 | train_loss : 70596.6171875 | val_loss : 77831.6640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 118 | train_loss : 71813.8203125 | val_loss : 77579.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 119 | train_loss : 95045.03125 | val_loss : 114604.328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 120 | train_loss : 62122.80859375 | val_loss : 56415.1796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 121 | train_loss : 67207.0 | val_loss : 150338.390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 122 | train_loss : 87971.421875 | val_loss : 62340.859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 123 | train_loss : 77874.359375 | val_loss : 82415.3359375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 124 | train_loss : 110512.953125 | val_loss : 181255.484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 125 | train_loss : 114642.828125 | val_loss : 69603.9375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 126 | train_loss : 77502.9375 | val_loss : 182664.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 127 | train_loss : 116242.203125 | val_loss : 54772.2265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 128 | train_loss : 50838.76953125 | val_loss : 112335.953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 129 | train_loss : 92616.359375 | val_loss : 82933.96875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 130 | train_loss : 115478.9375 | val_loss : 122970.0234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 131 | train_loss : 73967.1484375 | val_loss : 84616.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 132 | train_loss : 68250.5 | val_loss : 74128.453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 133 | train_loss : 66467.3203125 | val_loss : 39033.34765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 134 | train_loss : 63444.421875 | val_loss : 62890.43359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 135 | train_loss : 34841.4375 | val_loss : 22975.5859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 136 | train_loss : 35059.80859375 | val_loss : 98230.921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 137 | train_loss : 68855.7421875 | val_loss : 71571.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 138 | train_loss : 91277.7109375 | val_loss : 97244.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 139 | train_loss : 67872.53125 | val_loss : 51737.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 140 | train_loss : 63771.15625 | val_loss : 127630.9296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 141 | train_loss : 89087.7578125 | val_loss : 50569.8984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 142 | train_loss : 45083.63671875 | val_loss : 49604.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 143 | train_loss : 63303.16015625 | val_loss : 72356.3828125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 144 | train_loss : 65297.73828125 | val_loss : 26230.0859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 145 | train_loss : 32492.078125 | val_loss : 40066.390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 146 | train_loss : 50149.30859375 | val_loss : 85064.390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 147 | train_loss : 54054.671875 | val_loss : 39586.23828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 148 | train_loss : 43313.8046875 | val_loss : 43143.91015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 149 | train_loss : 65186.921875 | val_loss : 87550.8203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 150 | train_loss : 62081.21875 | val_loss : 44468.2109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 151 | train_loss : 55120.07421875 | val_loss : 80068.3515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 152 | train_loss : 41730.42578125 | val_loss : 63220.359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 153 | train_loss : 67509.7421875 | val_loss : 93822.953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 154 | train_loss : 62822.71875 | val_loss : 77024.46875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 155 | train_loss : 55498.5859375 | val_loss : 74824.2265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 156 | train_loss : 50480.40625 | val_loss : 46377.05859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 157 | train_loss : 65088.01953125 | val_loss : 49009.03515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 158 | train_loss : 27707.34765625 | val_loss : 39896.640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 159 | train_loss : 57514.1796875 | val_loss : 50403.85546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 160 | train_loss : 42046.46484375 | val_loss : 58793.10546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 161 | train_loss : 54951.18359375 | val_loss : 41475.05859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 162 | train_loss : 54062.359375 | val_loss : 34724.57421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 163 | train_loss : 52249.62109375 | val_loss : 110608.3203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 164 | train_loss : 63428.25390625 | val_loss : 52898.69140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 165 | train_loss : 66397.2421875 | val_loss : 62047.2265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 166 | train_loss : 60305.015625 | val_loss : 62898.03515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 167 | train_loss : 48354.94921875 | val_loss : 33723.05078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 168 | train_loss : 41131.69140625 | val_loss : 45530.765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 169 | train_loss : 44847.390625 | val_loss : 30434.142578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 170 | train_loss : 47750.46875 | val_loss : 76736.7578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 171 | train_loss : 36181.96875 | val_loss : 78624.2734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 172 | train_loss : 66432.7265625 | val_loss : 116264.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 173 | train_loss : 55849.17578125 | val_loss : 49882.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 174 | train_loss : 31306.078125 | val_loss : 20123.123046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 175 | train_loss : 34368.3515625 | val_loss : 70281.828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 176 | train_loss : 48749.38671875 | val_loss : 78794.4140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 177 | train_loss : 61638.6015625 | val_loss : 54672.76171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 178 | train_loss : 37791.23828125 | val_loss : 32931.484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 179 | train_loss : 34734.9453125 | val_loss : 56021.37890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 180 | train_loss : 45176.9140625 | val_loss : 98070.6015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 181 | train_loss : 64951.609375 | val_loss : 67444.7734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 182 | train_loss : 49600.51953125 | val_loss : 48641.43359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 183 | train_loss : 44848.23828125 | val_loss : 58046.12890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 184 | train_loss : 32500.63671875 | val_loss : 31542.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 185 | train_loss : 40814.01953125 | val_loss : 64225.98828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 186 | train_loss : 46346.48046875 | val_loss : 60109.7890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 187 | train_loss : 67976.96875 | val_loss : 100451.921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 188 | train_loss : 61410.2734375 | val_loss : 27802.447265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 189 | train_loss : 39976.82421875 | val_loss : 49376.98828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 190 | train_loss : 48694.8984375 | val_loss : 78412.6328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 191 | train_loss : 51168.55859375 | val_loss : 65058.640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 192 | train_loss : 52022.48046875 | val_loss : 124068.859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 193 | train_loss : 56411.98046875 | val_loss : 151253.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 194 | train_loss : 72948.109375 | val_loss : 80425.078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 195 | train_loss : 63981.58984375 | val_loss : 126636.59375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 196 | train_loss : 64857.765625 | val_loss : 62749.64453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 197 | train_loss : 50155.88671875 | val_loss : 79300.3125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 198 | train_loss : 59814.046875 | val_loss : 30102.23046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 199 | train_loss : 60911.87109375 | val_loss : 114640.5 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 200 | train_loss : 77595.09375 | val_loss : 78478.2421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 201 | train_loss : 65078.61328125 | val_loss : 91617.421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 202 | train_loss : 46643.890625 | val_loss : 55513.78125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 203 | train_loss : 50289.0234375 | val_loss : 81039.328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 204 | train_loss : 62499.43359375 | val_loss : 78794.328125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 205 | train_loss : 69508.296875 | val_loss : 108161.90625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 206 | train_loss : 74748.3125 | val_loss : 76918.6484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 207 | train_loss : 93523.7265625 | val_loss : 88088.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 208 | train_loss : 55020.64453125 | val_loss : 59719.203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 209 | train_loss : 54114.24609375 | val_loss : 63246.0703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 210 | train_loss : 50901.03125 | val_loss : 16461.7734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 211 | train_loss : 31186.001953125 | val_loss : 62463.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 212 | train_loss : 47497.46875 | val_loss : 25991.783203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 213 | train_loss : 31127.087890625 | val_loss : 32903.53515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 214 | train_loss : 29020.419921875 | val_loss : 82108.8828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 215 | train_loss : 38687.4765625 | val_loss : 40003.625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 216 | train_loss : 52678.890625 | val_loss : 65382.71484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 217 | train_loss : 43807.33984375 | val_loss : 28485.78515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 218 | train_loss : 48030.5234375 | val_loss : 95423.8671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 219 | train_loss : 58305.609375 | val_loss : 39494.70703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 220 | train_loss : 55443.5 | val_loss : 46586.44140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 221 | train_loss : 42443.203125 | val_loss : 39595.2890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 222 | train_loss : 39190.78125 | val_loss : 30901.203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 223 | train_loss : 44537.046875 | val_loss : 49806.421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 224 | train_loss : 24628.544921875 | val_loss : 35240.05859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 225 | train_loss : 36731.484375 | val_loss : 97876.0 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 226 | train_loss : 52733.10546875 | val_loss : 38185.921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 227 | train_loss : 52629.984375 | val_loss : 41840.79296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 228 | train_loss : 24057.05078125 | val_loss : 28155.36328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 229 | train_loss : 35142.953125 | val_loss : 68269.75 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 230 | train_loss : 47017.83984375 | val_loss : 14481.8203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 231 | train_loss : 28297.744140625 | val_loss : 25311.11328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 232 | train_loss : 34349.51953125 | val_loss : 49265.421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 233 | train_loss : 33940.50390625 | val_loss : 47088.90625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 234 | train_loss : 36467.24609375 | val_loss : 20987.349609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 235 | train_loss : 27407.0234375 | val_loss : 22572.6328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 236 | train_loss : 37158.671875 | val_loss : 64765.8203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 237 | train_loss : 34889.29296875 | val_loss : 57313.015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 238 | train_loss : 58818.62109375 | val_loss : 78328.8203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 239 | train_loss : 38116.765625 | val_loss : 36212.48828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 240 | train_loss : 31521.740234375 | val_loss : 64848.05078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 241 | train_loss : 49447.01171875 | val_loss : 26479.669921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 242 | train_loss : 47156.55078125 | val_loss : 19903.435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 243 | train_loss : 19218.115234375 | val_loss : 29469.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 244 | train_loss : 27692.546875 | val_loss : 26712.919921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 245 | train_loss : 26994.884765625 | val_loss : 46480.18359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 246 | train_loss : 32886.55078125 | val_loss : 23905.990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 247 | train_loss : 26046.91796875 | val_loss : 66033.5 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 248 | train_loss : 34286.4921875 | val_loss : 38376.2890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 249 | train_loss : 40307.12109375 | val_loss : 66224.8671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 250 | train_loss : 44719.015625 | val_loss : 44008.66015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 251 | train_loss : 75898.6015625 | val_loss : 117861.9765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 252 | train_loss : 81091.546875 | val_loss : 95397.3203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 253 | train_loss : 51009.23828125 | val_loss : 36280.1796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 254 | train_loss : 31631.671875 | val_loss : 55859.37890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 255 | train_loss : 32772.1796875 | val_loss : 33505.24609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 256 | train_loss : 35412.27734375 | val_loss : 43904.5390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 257 | train_loss : 23539.732421875 | val_loss : 12006.3251953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 258 | train_loss : 27001.6640625 | val_loss : 70551.8125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 259 | train_loss : 47734.43359375 | val_loss : 30158.703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 260 | train_loss : 49648.18359375 | val_loss : 51839.69921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 261 | train_loss : 33974.5390625 | val_loss : 30501.775390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 262 | train_loss : 45135.53125 | val_loss : 79876.2265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 263 | train_loss : 45443.90625 | val_loss : 22991.2265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 264 | train_loss : 37952.1171875 | val_loss : 39054.16015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 265 | train_loss : 41725.53125 | val_loss : 52715.75 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 266 | train_loss : 37940.62890625 | val_loss : 20628.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 267 | train_loss : 31736.974609375 | val_loss : 68844.2734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 268 | train_loss : 37108.91796875 | val_loss : 34142.7109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 269 | train_loss : 37631.9921875 | val_loss : 81030.0703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 270 | train_loss : 39243.4609375 | val_loss : 63324.92578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 271 | train_loss : 44585.8515625 | val_loss : 84853.296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 272 | train_loss : 40731.421875 | val_loss : 45503.4140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 273 | train_loss : 45789.32421875 | val_loss : 79405.421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 274 | train_loss : 46659.24609375 | val_loss : 27330.009765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 275 | train_loss : 37161.234375 | val_loss : 26568.419921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 276 | train_loss : 22009.51171875 | val_loss : 31001.349609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 277 | train_loss : 25764.546875 | val_loss : 17517.8359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 278 | train_loss : 18979.1484375 | val_loss : 19624.341796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 279 | train_loss : 33253.40625 | val_loss : 56581.03125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 280 | train_loss : 32986.16015625 | val_loss : 25528.876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 281 | train_loss : 32937.1953125 | val_loss : 126274.1171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 282 | train_loss : 98020.046875 | val_loss : 40881.95703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 283 | train_loss : 50550.140625 | val_loss : 23644.1796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 284 | train_loss : 25450.34765625 | val_loss : 52293.93359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 285 | train_loss : 32737.755859375 | val_loss : 25212.744140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 286 | train_loss : 38475.28125 | val_loss : 59221.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 287 | train_loss : 34608.1640625 | val_loss : 14000.2802734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 288 | train_loss : 28481.998046875 | val_loss : 60616.3515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 289 | train_loss : 41534.0546875 | val_loss : 33100.80859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 290 | train_loss : 46946.3515625 | val_loss : 73801.0546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 291 | train_loss : 47487.66015625 | val_loss : 24002.408203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 292 | train_loss : 25449.51953125 | val_loss : 25718.404296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 293 | train_loss : 22462.66015625 | val_loss : 9201.9521484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 294 | train_loss : 33011.65625 | val_loss : 42823.0390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 295 | train_loss : 22608.919921875 | val_loss : 15122.5947265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 296 | train_loss : 18099.962890625 | val_loss : 13681.6748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 297 | train_loss : 27827.517578125 | val_loss : 37251.63671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 298 | train_loss : 19475.484375 | val_loss : 30838.033203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 299 | train_loss : 21787.935546875 | val_loss : 55402.390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 300 | train_loss : 43768.14453125 | val_loss : 36866.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 301 | train_loss : 33269.90234375 | val_loss : 15928.1845703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 302 | train_loss : 42545.21875 | val_loss : 56447.375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 303 | train_loss : 30429.10546875 | val_loss : 42722.25 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 304 | train_loss : 31540.080078125 | val_loss : 36830.4609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 305 | train_loss : 22978.4921875 | val_loss : 23217.91796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 306 | train_loss : 32022.94921875 | val_loss : 53705.98046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 307 | train_loss : 23020.6015625 | val_loss : 28514.099609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 308 | train_loss : 32899.79296875 | val_loss : 57829.55859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 309 | train_loss : 33557.890625 | val_loss : 28347.36328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 310 | train_loss : 35202.765625 | val_loss : 78876.75 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 311 | train_loss : 35973.69921875 | val_loss : 37849.55859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 312 | train_loss : 30446.064453125 | val_loss : 17343.2734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 313 | train_loss : 25377.84765625 | val_loss : 42469.76953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 314 | train_loss : 26756.140625 | val_loss : 32103.078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 315 | train_loss : 22135.341796875 | val_loss : 70541.8125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 316 | train_loss : 30865.134765625 | val_loss : 27371.015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 317 | train_loss : 20898.484375 | val_loss : 18431.0546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 318 | train_loss : 23543.953125 | val_loss : 71271.9453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 319 | train_loss : 36888.55078125 | val_loss : 37500.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 320 | train_loss : 38776.61328125 | val_loss : 57116.23828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 321 | train_loss : 35590.35546875 | val_loss : 33178.1640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 322 | train_loss : 37189.84375 | val_loss : 19758.35546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 323 | train_loss : 17720.25 | val_loss : 76006.53125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 324 | train_loss : 38342.421875 | val_loss : 49292.28125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 325 | train_loss : 47134.3984375 | val_loss : 59770.703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 326 | train_loss : 30667.72265625 | val_loss : 40544.8984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 327 | train_loss : 39195.859375 | val_loss : 69537.203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 328 | train_loss : 41593.84375 | val_loss : 17289.2890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 329 | train_loss : 41069.1640625 | val_loss : 32690.8125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 330 | train_loss : 30579.244140625 | val_loss : 28967.73046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 331 | train_loss : 25362.57421875 | val_loss : 116140.296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 332 | train_loss : 84264.96875 | val_loss : 32913.18359375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 333 | train_loss : 35928.47265625 | val_loss : 14660.7470703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 334 | train_loss : 26076.38671875 | val_loss : 35435.140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 335 | train_loss : 23993.400390625 | val_loss : 14683.4453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 336 | train_loss : 19292.75390625 | val_loss : 39742.80859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 337 | train_loss : 22171.7890625 | val_loss : 24941.908203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 338 | train_loss : 38147.40625 | val_loss : 49449.734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 339 | train_loss : 26274.125 | val_loss : 30069.234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 340 | train_loss : 31005.48046875 | val_loss : 64731.8203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 341 | train_loss : 33200.93359375 | val_loss : 20416.623046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 342 | train_loss : 28517.48046875 | val_loss : 18806.837890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 343 | train_loss : 23593.919921875 | val_loss : 42816.7265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 344 | train_loss : 23778.1796875 | val_loss : 20471.642578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 345 | train_loss : 22520.244140625 | val_loss : 45075.51953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 346 | train_loss : 27116.79296875 | val_loss : 23922.232421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 347 | train_loss : 21667.935546875 | val_loss : 27970.390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 348 | train_loss : 16981.302734375 | val_loss : 26189.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 349 | train_loss : 21859.11328125 | val_loss : 17436.47265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 350 | train_loss : 25578.087890625 | val_loss : 13224.7373046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 351 | train_loss : 11962.791015625 | val_loss : 16203.037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 352 | train_loss : 13080.4521484375 | val_loss : 23670.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 353 | train_loss : 23417.341796875 | val_loss : 8540.14453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 354 | train_loss : 24579.431640625 | val_loss : 20362.986328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 355 | train_loss : 12341.3779296875 | val_loss : 13530.607421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 356 | train_loss : 16371.3046875 | val_loss : 53624.25390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 357 | train_loss : 31891.544921875 | val_loss : 18407.482421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 358 | train_loss : 31507.16015625 | val_loss : 24273.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 359 | train_loss : 14341.0478515625 | val_loss : 26763.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 360 | train_loss : 21609.703125 | val_loss : 21938.53515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 361 | train_loss : 27825.669921875 | val_loss : 11388.4658203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 362 | train_loss : 13659.66015625 | val_loss : 43028.140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 363 | train_loss : 22898.86328125 | val_loss : 19049.634765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 364 | train_loss : 20135.546875 | val_loss : 29882.078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 365 | train_loss : 18667.39453125 | val_loss : 15385.775390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 366 | train_loss : 22957.533203125 | val_loss : 13204.46875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 367 | train_loss : 12352.2451171875 | val_loss : 10074.7041015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 368 | train_loss : 23625.8984375 | val_loss : 33233.48828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 369 | train_loss : 18309.783203125 | val_loss : 29028.857421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 370 | train_loss : 36305.94140625 | val_loss : 27893.279296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 371 | train_loss : 26535.5546875 | val_loss : 51128.74609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 372 | train_loss : 32939.97265625 | val_loss : 22189.9296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 373 | train_loss : 19905.7421875 | val_loss : 31150.064453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 374 | train_loss : 13680.9423828125 | val_loss : 12276.798828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 375 | train_loss : 17262.5078125 | val_loss : 45187.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 376 | train_loss : 24206.58203125 | val_loss : 16361.791015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 377 | train_loss : 22111.59765625 | val_loss : 18013.2734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 378 | train_loss : 19005.82421875 | val_loss : 20164.85546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 379 | train_loss : 24882.1640625 | val_loss : 15820.5146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 380 | train_loss : 10973.802734375 | val_loss : 18105.41796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 381 | train_loss : 15329.2197265625 | val_loss : 17478.693359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 382 | train_loss : 18002.017578125 | val_loss : 21379.970703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 383 | train_loss : 22985.6015625 | val_loss : 18117.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 384 | train_loss : 18362.76171875 | val_loss : 27961.341796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 385 | train_loss : 24064.76953125 | val_loss : 24981.26953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 386 | train_loss : 13233.7890625 | val_loss : 10847.611328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 387 | train_loss : 20014.359375 | val_loss : 42541.69921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 388 | train_loss : 27773.869140625 | val_loss : 14057.322265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 389 | train_loss : 27984.900390625 | val_loss : 36464.6484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 390 | train_loss : 29409.48046875 | val_loss : 44955.24609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 391 | train_loss : 28273.73046875 | val_loss : 37006.734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 392 | train_loss : 30496.88671875 | val_loss : 18727.2109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 393 | train_loss : 20503.109375 | val_loss : 150858.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 394 | train_loss : 91732.0078125 | val_loss : 29185.998046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 395 | train_loss : 36328.23828125 | val_loss : 32999.1484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 396 | train_loss : 21165.849609375 | val_loss : 22380.28515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 397 | train_loss : 20788.712890625 | val_loss : 45674.359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 398 | train_loss : 26198.072265625 | val_loss : 9710.8203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 399 | train_loss : 17104.77734375 | val_loss : 44507.56640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 400 | train_loss : 30201.552734375 | val_loss : 26152.7890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 401 | train_loss : 36182.62890625 | val_loss : 47674.76171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 402 | train_loss : 26463.140625 | val_loss : 7883.1474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 403 | train_loss : 13321.125 | val_loss : 20765.4296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 404 | train_loss : 19686.3984375 | val_loss : 16645.6640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 405 | train_loss : 12781.900390625 | val_loss : 7796.73388671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 406 | train_loss : 18798.85546875 | val_loss : 32264.904296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 407 | train_loss : 17455.099609375 | val_loss : 14335.73046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 408 | train_loss : 20724.76953125 | val_loss : 40586.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 409 | train_loss : 19830.552734375 | val_loss : 17695.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 410 | train_loss : 30816.130859375 | val_loss : 44733.94140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 411 | train_loss : 20140.04296875 | val_loss : 28411.3984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 412 | train_loss : 22329.240234375 | val_loss : 53781.55859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 413 | train_loss : 29859.248046875 | val_loss : 16474.966796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 414 | train_loss : 27653.455078125 | val_loss : 14946.21875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 415 | train_loss : 11362.73828125 | val_loss : 26252.654296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 416 | train_loss : 15827.29296875 | val_loss : 15588.8740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 417 | train_loss : 17376.693359375 | val_loss : 38159.62109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 418 | train_loss : 23017.931640625 | val_loss : 16656.0859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 419 | train_loss : 16505.869140625 | val_loss : 40678.265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 420 | train_loss : 21243.8046875 | val_loss : 21823.470703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 421 | train_loss : 21825.775390625 | val_loss : 22235.91015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 422 | train_loss : 18986.8671875 | val_loss : 11121.1279296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 423 | train_loss : 12367.8408203125 | val_loss : 40147.89453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 424 | train_loss : 19444.794921875 | val_loss : 11417.259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 425 | train_loss : 10395.943359375 | val_loss : 15183.826171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 426 | train_loss : 9859.443359375 | val_loss : 9018.6904296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 427 | train_loss : 16080.728515625 | val_loss : 39276.0859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 428 | train_loss : 24123.216796875 | val_loss : 23511.10546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 429 | train_loss : 18583.884765625 | val_loss : 10174.5400390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 430 | train_loss : 17861.859375 | val_loss : 27619.119140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 431 | train_loss : 14107.6484375 | val_loss : 11310.6279296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 432 | train_loss : 18627.05078125 | val_loss : 38405.953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 433 | train_loss : 22736.1015625 | val_loss : 20033.8203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 434 | train_loss : 12869.0224609375 | val_loss : 10003.7021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 435 | train_loss : 18792.998046875 | val_loss : 14850.0576171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 436 | train_loss : 20195.685546875 | val_loss : 17807.544921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 437 | train_loss : 12579.6337890625 | val_loss : 9842.1337890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 438 | train_loss : 16043.9404296875 | val_loss : 20377.341796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 439 | train_loss : 16870.423828125 | val_loss : 11753.482421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 440 | train_loss : 18786.564453125 | val_loss : 8682.0126953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 441 | train_loss : 8443.6826171875 | val_loss : 34655.24609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 442 | train_loss : 18159.373046875 | val_loss : 17972.490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 443 | train_loss : 16985.830078125 | val_loss : 12428.3427734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 444 | train_loss : 15804.6552734375 | val_loss : 8932.4375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 445 | train_loss : 13807.388671875 | val_loss : 23385.029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 446 | train_loss : 12149.115234375 | val_loss : 22146.39453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 447 | train_loss : 15393.541015625 | val_loss : 12630.12890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 448 | train_loss : 16040.1962890625 | val_loss : 12495.201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 449 | train_loss : 13998.83984375 | val_loss : 29754.0546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 450 | train_loss : 19453.21484375 | val_loss : 10733.7978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 451 | train_loss : 11179.2978515625 | val_loss : 27466.0390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 452 | train_loss : 14405.923828125 | val_loss : 11519.0908203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 453 | train_loss : 16458.1875 | val_loss : 38312.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 454 | train_loss : 22171.328125 | val_loss : 23659.759765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 455 | train_loss : 18145.8046875 | val_loss : 11803.2685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 456 | train_loss : 13799.2900390625 | val_loss : 31277.322265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 457 | train_loss : 21912.939453125 | val_loss : 14511.5048828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 458 | train_loss : 29685.9921875 | val_loss : 44024.453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 459 | train_loss : 20797.744140625 | val_loss : 34164.3203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 460 | train_loss : 28577.009765625 | val_loss : 26479.125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 461 | train_loss : 24668.818359375 | val_loss : 16475.626953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 462 | train_loss : 11576.7197265625 | val_loss : 16151.7060546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 463 | train_loss : 17090.810546875 | val_loss : 26852.89453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 464 | train_loss : 15045.125 | val_loss : 11142.57421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 465 | train_loss : 9549.3349609375 | val_loss : 16699.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 466 | train_loss : 10530.236328125 | val_loss : 16380.7158203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 467 | train_loss : 13594.1787109375 | val_loss : 10223.900390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 468 | train_loss : 14048.4873046875 | val_loss : 11782.3759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 469 | train_loss : 16319.9833984375 | val_loss : 8430.103515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 470 | train_loss : 6868.02490234375 | val_loss : 15141.8154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 471 | train_loss : 8861.681640625 | val_loss : 8534.2978515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 472 | train_loss : 9296.30078125 | val_loss : 6631.24853515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 473 | train_loss : 13818.9765625 | val_loss : 17127.626953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 474 | train_loss : 8687.5263671875 | val_loss : 10576.818359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 475 | train_loss : 22908.369140625 | val_loss : 27944.92578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 476 | train_loss : 13637.087890625 | val_loss : 13495.2041015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 477 | train_loss : 17206.1328125 | val_loss : 12713.4228515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 478 | train_loss : 8650.267578125 | val_loss : 8445.5673828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 479 | train_loss : 21483.8046875 | val_loss : 31783.8203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 480 | train_loss : 14770.60546875 | val_loss : 13615.708984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 481 | train_loss : 15991.1884765625 | val_loss : 25120.392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 482 | train_loss : 17968.4453125 | val_loss : 156193.640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 483 | train_loss : 296428.1875 | val_loss : 32495.5703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 484 | train_loss : 25317.5859375 | val_loss : 100491.0390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 485 | train_loss : 58646.3359375 | val_loss : 53911.015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 486 | train_loss : 39252.70703125 | val_loss : 15246.4404296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 487 | train_loss : 29102.65234375 | val_loss : 18918.83203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 488 | train_loss : 16676.755859375 | val_loss : 20435.462890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 489 | train_loss : 13041.482421875 | val_loss : 10278.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 490 | train_loss : 16272.0478515625 | val_loss : 37430.12109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 491 | train_loss : 20717.462890625 | val_loss : 10766.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 492 | train_loss : 20401.94921875 | val_loss : 19397.453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 493 | train_loss : 10277.4150390625 | val_loss : 9906.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 494 | train_loss : 11422.4296875 | val_loss : 16658.994140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 495 | train_loss : 16304.740234375 | val_loss : 17881.70703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 496 | train_loss : 22648.125 | val_loss : 9249.708984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 497 | train_loss : 5950.94873046875 | val_loss : 11507.7861328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 498 | train_loss : 10146.962890625 | val_loss : 9702.802734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 499 | train_loss : 14556.6650390625 | val_loss : 21301.3046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 500 | train_loss : 19885.294921875 | val_loss : 14480.57421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 501 | train_loss : 6804.6298828125 | val_loss : 8023.978515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 502 | train_loss : 11301.642578125 | val_loss : 35487.48828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 503 | train_loss : 21777.322265625 | val_loss : 13582.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 504 | train_loss : 24415.873046875 | val_loss : 12516.7158203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 505 | train_loss : 13583.1484375 | val_loss : 38017.37109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 506 | train_loss : 22382.640625 | val_loss : 23165.9140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 507 | train_loss : 27163.974609375 | val_loss : 18533.025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 508 | train_loss : 9677.6611328125 | val_loss : 8743.7451171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 509 | train_loss : 11277.763671875 | val_loss : 35974.0859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 510 | train_loss : 20244.01171875 | val_loss : 12983.2548828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 511 | train_loss : 19931.650390625 | val_loss : 28640.345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 512 | train_loss : 15978.4013671875 | val_loss : 8151.22998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 513 | train_loss : 19216.857421875 | val_loss : 34186.17578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 514 | train_loss : 16462.8359375 | val_loss : 14055.1572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 515 | train_loss : 14131.3408203125 | val_loss : 13553.3564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 516 | train_loss : 12461.2109375 | val_loss : 12704.61328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 517 | train_loss : 12984.8759765625 | val_loss : 10865.9677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 518 | train_loss : 11518.15625 | val_loss : 12787.67578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 519 | train_loss : 12655.52734375 | val_loss : 25464.4296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 520 | train_loss : 15251.6572265625 | val_loss : 8101.30859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 521 | train_loss : 16744.064453125 | val_loss : 27701.41015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 522 | train_loss : 13757.4541015625 | val_loss : 7915.4189453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 523 | train_loss : 13382.23046875 | val_loss : 11712.806640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 524 | train_loss : 17339.951171875 | val_loss : 29184.404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 525 | train_loss : 20854.9765625 | val_loss : 11960.4736328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 526 | train_loss : 8202.4150390625 | val_loss : 23193.845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 527 | train_loss : 9097.7373046875 | val_loss : 7825.85498046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 528 | train_loss : 15052.755859375 | val_loss : 38053.0859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 529 | train_loss : 19491.26953125 | val_loss : 24092.794921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 530 | train_loss : 27514.375 | val_loss : 21933.16015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 531 | train_loss : 13033.90234375 | val_loss : 9816.767578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 532 | train_loss : 16906.64453125 | val_loss : 33520.6015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 533 | train_loss : 18479.9609375 | val_loss : 8931.9765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 534 | train_loss : 19500.26953125 | val_loss : 14440.833984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 535 | train_loss : 8837.6455078125 | val_loss : 8441.34375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 536 | train_loss : 11497.6171875 | val_loss : 12118.0927734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 537 | train_loss : 13986.10546875 | val_loss : 4823.00634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 538 | train_loss : 20038.9296875 | val_loss : 18898.87109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 539 | train_loss : 10654.62890625 | val_loss : 10329.1376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 540 | train_loss : 10662.037109375 | val_loss : 8698.369140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 541 | train_loss : 13057.4111328125 | val_loss : 30242.244140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 542 | train_loss : 15438.419921875 | val_loss : 14468.767578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 543 | train_loss : 14417.15234375 | val_loss : 18249.849609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 544 | train_loss : 14939.94921875 | val_loss : 6507.17236328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 545 | train_loss : 21059.998046875 | val_loss : 28324.7421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 546 | train_loss : 12205.9013671875 | val_loss : 11449.98046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 547 | train_loss : 10626.5615234375 | val_loss : 5419.8974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 548 | train_loss : 9428.3408203125 | val_loss : 29972.890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 549 | train_loss : 16334.80859375 | val_loss : 14906.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 550 | train_loss : 17980.8515625 | val_loss : 29743.404296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 551 | train_loss : 14680.2158203125 | val_loss : 9306.27734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 552 | train_loss : 13244.8828125 | val_loss : 33114.37109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 553 | train_loss : 17272.646484375 | val_loss : 10865.5478515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 554 | train_loss : 14535.6796875 | val_loss : 11373.7626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 555 | train_loss : 6193.8310546875 | val_loss : 13940.833984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 556 | train_loss : 10468.9658203125 | val_loss : 6657.0087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 557 | train_loss : 12018.1015625 | val_loss : 11538.5341796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 558 | train_loss : 14567.2158203125 | val_loss : 8559.787109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 559 | train_loss : 5793.29248046875 | val_loss : 16062.5771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 560 | train_loss : 10364.8896484375 | val_loss : 6762.294921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 561 | train_loss : 10325.3388671875 | val_loss : 6623.90771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 562 | train_loss : 13253.7001953125 | val_loss : 6045.31884765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 563 | train_loss : 6114.24560546875 | val_loss : 9736.0185546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 564 | train_loss : 5934.5869140625 | val_loss : 7689.31640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 565 | train_loss : 4793.91064453125 | val_loss : 11318.009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 566 | train_loss : 10101.626953125 | val_loss : 6086.263671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 567 | train_loss : 9022.357421875 | val_loss : 12549.8046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 568 | train_loss : 14988.4375 | val_loss : 8134.052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 569 | train_loss : 7508.1318359375 | val_loss : 13648.23046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 570 | train_loss : 12245.7138671875 | val_loss : 5354.7236328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 571 | train_loss : 7110.8623046875 | val_loss : 6879.00244140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 572 | train_loss : 7531.02490234375 | val_loss : 10877.9716796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 573 | train_loss : 13147.16796875 | val_loss : 13599.31640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 574 | train_loss : 18092.84375 | val_loss : 4714.8486328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 575 | train_loss : 3940.4921875 | val_loss : 9590.51171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 576 | train_loss : 5508.35546875 | val_loss : 4182.392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 577 | train_loss : 6811.458984375 | val_loss : 7363.04248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 578 | train_loss : 8399.0361328125 | val_loss : 8328.33984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 579 | train_loss : 7451.021484375 | val_loss : 10692.86328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 580 | train_loss : 12960.8095703125 | val_loss : 6900.38134765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 581 | train_loss : 5460.259765625 | val_loss : 12799.4052734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 582 | train_loss : 9803.44921875 | val_loss : 5533.990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 583 | train_loss : 9988.5634765625 | val_loss : 10769.5537109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 584 | train_loss : 14366.2333984375 | val_loss : 4150.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 585 | train_loss : 4281.44482421875 | val_loss : 15368.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 586 | train_loss : 9268.55859375 | val_loss : 9915.15625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 587 | train_loss : 18030.185546875 | val_loss : 8531.66015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 588 | train_loss : 8586.857421875 | val_loss : 20765.154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 589 | train_loss : 11607.197265625 | val_loss : 11478.6259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 590 | train_loss : 10855.15625 | val_loss : 6065.513671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 591 | train_loss : 13915.87890625 | val_loss : 20204.818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 592 | train_loss : 10330.06640625 | val_loss : 9238.0654296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 593 | train_loss : 10336.5986328125 | val_loss : 15279.9501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 594 | train_loss : 13148.2587890625 | val_loss : 7232.20361328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 595 | train_loss : 16718.1953125 | val_loss : 25335.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 596 | train_loss : 9253.041015625 | val_loss : 7757.1025390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 597 | train_loss : 5970.337890625 | val_loss : 7390.3798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 598 | train_loss : 8686.150390625 | val_loss : 23744.068359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 599 | train_loss : 14274.5751953125 | val_loss : 13809.541015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 600 | train_loss : 17954.26953125 | val_loss : 9756.1513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 601 | train_loss : 6157.0 | val_loss : 4077.8388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 602 | train_loss : 6460.69189453125 | val_loss : 11037.7998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 603 | train_loss : 6834.35009765625 | val_loss : 9126.861328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 604 | train_loss : 13861.79296875 | val_loss : 21790.427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 605 | train_loss : 11275.6796875 | val_loss : 10693.357421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 606 | train_loss : 12840.73828125 | val_loss : 7459.1123046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 607 | train_loss : 8089.1201171875 | val_loss : 8467.23828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 608 | train_loss : 14114.5400390625 | val_loss : 10782.044921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 609 | train_loss : 9102.662109375 | val_loss : 9299.5458984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 610 | train_loss : 10514.9599609375 | val_loss : 16602.8828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 611 | train_loss : 10868.2509765625 | val_loss : 7724.64990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 612 | train_loss : 12406.0771484375 | val_loss : 9002.5078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 613 | train_loss : 8792.63671875 | val_loss : 19988.345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 614 | train_loss : 12622.5654296875 | val_loss : 12210.130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 615 | train_loss : 9581.54296875 | val_loss : 13884.5263671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 616 | train_loss : 14477.0751953125 | val_loss : 16999.443359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 617 | train_loss : 9710.2626953125 | val_loss : 7160.91259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 618 | train_loss : 10590.076171875 | val_loss : 11841.5703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 619 | train_loss : 10468.3134765625 | val_loss : 6068.7412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 620 | train_loss : 15663.236328125 | val_loss : 36224.78125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 621 | train_loss : 23225.64453125 | val_loss : 23588.4375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 622 | train_loss : 29061.05078125 | val_loss : 8463.2275390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 623 | train_loss : 15640.99609375 | val_loss : 30306.609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 624 | train_loss : 14856.2900390625 | val_loss : 12791.84765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 625 | train_loss : 14794.5810546875 | val_loss : 18326.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 626 | train_loss : 11092.7578125 | val_loss : 8952.66796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 627 | train_loss : 14681.43359375 | val_loss : 23851.810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 628 | train_loss : 10524.525390625 | val_loss : 6682.853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 629 | train_loss : 7714.4892578125 | val_loss : 25488.66796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 630 | train_loss : 15168.5361328125 | val_loss : 5968.5576171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 631 | train_loss : 15189.6611328125 | val_loss : 20898.96875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 632 | train_loss : 8608.642578125 | val_loss : 6824.22265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 633 | train_loss : 6704.88330078125 | val_loss : 26466.14453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 634 | train_loss : 10331.912109375 | val_loss : 6733.74365234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 635 | train_loss : 5949.763671875 | val_loss : 11882.875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 636 | train_loss : 6672.50634765625 | val_loss : 6962.9248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 637 | train_loss : 10605.62890625 | val_loss : 7917.548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 638 | train_loss : 6275.1513671875 | val_loss : 6293.03857421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 639 | train_loss : 9756.318359375 | val_loss : 15616.8525390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 640 | train_loss : 8259.2509765625 | val_loss : 7011.9501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 641 | train_loss : 10010.0478515625 | val_loss : 9241.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 642 | train_loss : 9449.62890625 | val_loss : 10651.6259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 643 | train_loss : 10801.6533203125 | val_loss : 9781.7978515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 644 | train_loss : 10701.611328125 | val_loss : 6399.68896484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 645 | train_loss : 9772.798828125 | val_loss : 15978.4052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 646 | train_loss : 9562.5126953125 | val_loss : 6613.4560546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 647 | train_loss : 13325.1416015625 | val_loss : 12186.083984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 648 | train_loss : 6404.0185546875 | val_loss : 6442.99609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 649 | train_loss : 7668.875 | val_loss : 20561.564453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 650 | train_loss : 10665.22265625 | val_loss : 6723.822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 651 | train_loss : 12624.150390625 | val_loss : 20812.962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 652 | train_loss : 7522.2998046875 | val_loss : 7046.13623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 653 | train_loss : 10566.7451171875 | val_loss : 23126.650390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 654 | train_loss : 9392.8662109375 | val_loss : 9586.4384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 655 | train_loss : 11302.75390625 | val_loss : 17462.794921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 656 | train_loss : 9330.8662109375 | val_loss : 14443.4609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 657 | train_loss : 13833.5966796875 | val_loss : 8058.2939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 658 | train_loss : 7953.0595703125 | val_loss : 15755.8720703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 659 | train_loss : 11789.1748046875 | val_loss : 7367.986328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 660 | train_loss : 5556.6220703125 | val_loss : 7515.63232421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 661 | train_loss : 8448.0341796875 | val_loss : 9520.1953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 662 | train_loss : 7589.29931640625 | val_loss : 6926.1298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 663 | train_loss : 9679.01953125 | val_loss : 18445.728515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 664 | train_loss : 9231.1328125 | val_loss : 6979.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 665 | train_loss : 15698.869140625 | val_loss : 17995.439453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 666 | train_loss : 7275.623046875 | val_loss : 9264.0908203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 667 | train_loss : 9112.1962890625 | val_loss : 7387.625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 668 | train_loss : 6621.0263671875 | val_loss : 17010.5703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 669 | train_loss : 8507.3603515625 | val_loss : 8971.51953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 670 | train_loss : 7723.60302734375 | val_loss : 7159.28759765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 671 | train_loss : 13444.8291015625 | val_loss : 14284.5859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 672 | train_loss : 6477.26953125 | val_loss : 8937.412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 673 | train_loss : 8925.328125 | val_loss : 12254.677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 674 | train_loss : 8358.3896484375 | val_loss : 5801.74609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 675 | train_loss : 10490.349609375 | val_loss : 11875.474609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 676 | train_loss : 6397.99169921875 | val_loss : 5447.59130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 677 | train_loss : 7786.126953125 | val_loss : 11701.33984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 678 | train_loss : 7014.10107421875 | val_loss : 11002.41796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 679 | train_loss : 10740.021484375 | val_loss : 5517.392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 680 | train_loss : 4753.30126953125 | val_loss : 11249.947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 681 | train_loss : 10280.1787109375 | val_loss : 5821.71484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 682 | train_loss : 5966.92919921875 | val_loss : 7016.509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 683 | train_loss : 9142.896484375 | val_loss : 6395.73388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 684 | train_loss : 7394.76611328125 | val_loss : 12248.8203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 685 | train_loss : 9622.3701171875 | val_loss : 7249.68896484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 686 | train_loss : 5192.43994140625 | val_loss : 6350.0263671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 687 | train_loss : 11904.9296875 | val_loss : 15423.76171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 688 | train_loss : 6092.66357421875 | val_loss : 5786.18017578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 689 | train_loss : 7284.4658203125 | val_loss : 23547.08984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 690 | train_loss : 12312.16796875 | val_loss : 11755.7353515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 691 | train_loss : 16152.5361328125 | val_loss : 10017.9375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 692 | train_loss : 6098.6513671875 | val_loss : 17805.755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 693 | train_loss : 24341.3515625 | val_loss : 23912.125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 694 | train_loss : 28353.52734375 | val_loss : 175799.078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 695 | train_loss : 111172.4921875 | val_loss : 12200.6640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 696 | train_loss : 10095.2666015625 | val_loss : 17345.384765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 697 | train_loss : 9376.3388671875 | val_loss : 15252.5849609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 698 | train_loss : 8969.9072265625 | val_loss : 7232.732421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 699 | train_loss : 8914.55078125 | val_loss : 9890.49609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 700 | train_loss : 13117.2626953125 | val_loss : 10280.92578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 701 | train_loss : 6487.44873046875 | val_loss : 24871.3359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 702 | train_loss : 13364.42578125 | val_loss : 13683.2373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 703 | train_loss : 16478.64453125 | val_loss : 10550.041015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 704 | train_loss : 5134.93408203125 | val_loss : 5752.81640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 705 | train_loss : 5952.4130859375 | val_loss : 7210.40478515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 706 | train_loss : 6013.0537109375 | val_loss : 4840.388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 707 | train_loss : 11943.01953125 | val_loss : 15660.1298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 708 | train_loss : 6656.25146484375 | val_loss : 6250.79736328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 709 | train_loss : 5147.92822265625 | val_loss : 6776.134765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 710 | train_loss : 5808.21923828125 | val_loss : 12358.994140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 711 | train_loss : 9650.43359375 | val_loss : 6256.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 712 | train_loss : 6856.47802734375 | val_loss : 5117.3876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 713 | train_loss : 7619.052734375 | val_loss : 7345.19384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 714 | train_loss : 7744.03369140625 | val_loss : 6409.93115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 715 | train_loss : 9520.154296875 | val_loss : 5991.97998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 716 | train_loss : 6546.64697265625 | val_loss : 4629.59765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 717 | train_loss : 10453.8271484375 | val_loss : 5907.60107421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 718 | train_loss : 5036.09765625 | val_loss : 5406.64501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 719 | train_loss : 9685.44140625 | val_loss : 7881.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 720 | train_loss : 5722.1474609375 | val_loss : 4524.2314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 721 | train_loss : 8414.8388671875 | val_loss : 11437.166015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 722 | train_loss : 7255.57568359375 | val_loss : 4524.75927734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 723 | train_loss : 7029.66357421875 | val_loss : 8770.513671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 724 | train_loss : 7556.3876953125 | val_loss : 6955.3701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 725 | train_loss : 11491.794921875 | val_loss : 7147.013671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 726 | train_loss : 6946.6767578125 | val_loss : 39747.296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 727 | train_loss : 27011.73046875 | val_loss : 13820.712890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 728 | train_loss : 16190.0341796875 | val_loss : 6700.85498046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 729 | train_loss : 7346.69384765625 | val_loss : 18983.353515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 730 | train_loss : 7929.3642578125 | val_loss : 4596.01513671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 731 | train_loss : 5756.1787109375 | val_loss : 8106.31884765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 732 | train_loss : 10358.81640625 | val_loss : 4428.15869140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 733 | train_loss : 12706.44921875 | val_loss : 8277.4599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 734 | train_loss : 4314.7568359375 | val_loss : 4289.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 735 | train_loss : 3931.073486328125 | val_loss : 29476.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 736 | train_loss : 12098.857421875 | val_loss : 9914.7490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 737 | train_loss : 11519.73046875 | val_loss : 16545.2421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 738 | train_loss : 12830.197265625 | val_loss : 7752.81640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 739 | train_loss : 10183.9619140625 | val_loss : 6573.77392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 740 | train_loss : 5281.16357421875 | val_loss : 12963.9677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 741 | train_loss : 6182.8173828125 | val_loss : 9530.38671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 742 | train_loss : 7672.90771484375 | val_loss : 9605.9541015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 743 | train_loss : 8742.8994140625 | val_loss : 6309.94384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 744 | train_loss : 5566.11376953125 | val_loss : 14028.4375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 745 | train_loss : 7172.34521484375 | val_loss : 7299.31884765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 746 | train_loss : 5775.69873046875 | val_loss : 7318.822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 747 | train_loss : 6111.32958984375 | val_loss : 9841.1591796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 748 | train_loss : 6499.75732421875 | val_loss : 10734.4091796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 749 | train_loss : 8260.0654296875 | val_loss : 6228.99609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 750 | train_loss : 7944.25390625 | val_loss : 12566.009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 751 | train_loss : 7387.11572265625 | val_loss : 6001.55615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 752 | train_loss : 5039.9638671875 | val_loss : 5286.43603515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 753 | train_loss : 5772.25 | val_loss : 19344.763671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 754 | train_loss : 10414.2177734375 | val_loss : 7318.0712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 755 | train_loss : 11725.1953125 | val_loss : 11228.134765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 756 | train_loss : 8520.6064453125 | val_loss : 7122.18994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 757 | train_loss : 8768.958984375 | val_loss : 7616.7099609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 758 | train_loss : 7479.58251953125 | val_loss : 9867.3564453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 759 | train_loss : 8807.6630859375 | val_loss : 5042.6962890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 760 | train_loss : 4956.34521484375 | val_loss : 9848.9462890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 761 | train_loss : 8167.70751953125 | val_loss : 6508.919921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 762 | train_loss : 6584.68505859375 | val_loss : 5847.013671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 763 | train_loss : 10355.6826171875 | val_loss : 7309.701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 764 | train_loss : 4757.458984375 | val_loss : 4180.83251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 765 | train_loss : 7068.6962890625 | val_loss : 10338.4541015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 766 | train_loss : 7926.53076171875 | val_loss : 5051.5712890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 767 | train_loss : 10875.8125 | val_loss : 6704.22607421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 768 | train_loss : 4224.4462890625 | val_loss : 5257.9814453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 769 | train_loss : 6410.8076171875 | val_loss : 8536.103515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 770 | train_loss : 6116.90771484375 | val_loss : 3738.657470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 771 | train_loss : 6995.0576171875 | val_loss : 10312.9501953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 772 | train_loss : 6052.138671875 | val_loss : 5324.30615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 773 | train_loss : 9523.056640625 | val_loss : 8385.0537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 774 | train_loss : 5377.2138671875 | val_loss : 5529.40625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 775 | train_loss : 9371.2080078125 | val_loss : 10430.2109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 776 | train_loss : 7564.5595703125 | val_loss : 5485.57763671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 777 | train_loss : 9717.701171875 | val_loss : 7501.4111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 778 | train_loss : 4099.53515625 | val_loss : 8327.66796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 779 | train_loss : 8660.7568359375 | val_loss : 4165.15869140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 780 | train_loss : 6858.447265625 | val_loss : 9417.84765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 781 | train_loss : 9707.26953125 | val_loss : 3349.072509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 782 | train_loss : 3219.017578125 | val_loss : 5681.14990234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 783 | train_loss : 7672.78125 | val_loss : 4669.240234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 784 | train_loss : 6203.14111328125 | val_loss : 8161.07373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 785 | train_loss : 8199.1611328125 | val_loss : 5698.09619140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 786 | train_loss : 4569.22705078125 | val_loss : 7241.291015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 787 | train_loss : 9120.5263671875 | val_loss : 6398.8525390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 788 | train_loss : 5035.64208984375 | val_loss : 11631.9775390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 789 | train_loss : 9520.8310546875 | val_loss : 5155.21142578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 790 | train_loss : 4849.66796875 | val_loss : 4458.517578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 791 | train_loss : 9029.92578125 | val_loss : 4814.39111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 792 | train_loss : 3998.716796875 | val_loss : 3438.267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 793 | train_loss : 4915.7724609375 | val_loss : 17867.845703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 794 | train_loss : 11694.9296875 | val_loss : 5896.44873046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 795 | train_loss : 13374.0302734375 | val_loss : 11048.9599609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 796 | train_loss : 6764.5673828125 | val_loss : 6766.9248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 797 | train_loss : 5757.8642578125 | val_loss : 5266.64501953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 798 | train_loss : 10782.8974609375 | val_loss : 20854.533203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 799 | train_loss : 11654.8974609375 | val_loss : 12274.2138671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 800 | train_loss : 12987.3447265625 | val_loss : 10567.724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 801 | train_loss : 8229.94140625 | val_loss : 5099.5400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 802 | train_loss : 9512.869140625 | val_loss : 9587.482421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 803 | train_loss : 5335.58251953125 | val_loss : 5250.4287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 804 | train_loss : 8517.505859375 | val_loss : 12378.896484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 805 | train_loss : 6914.294921875 | val_loss : 5617.42236328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 806 | train_loss : 9960.306640625 | val_loss : 7923.1787109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 807 | train_loss : 5594.99365234375 | val_loss : 5176.0888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 808 | train_loss : 10057.384765625 | val_loss : 11125.419921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 809 | train_loss : 6610.771484375 | val_loss : 5019.23876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 810 | train_loss : 7689.21875 | val_loss : 9810.33203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 811 | train_loss : 5959.830078125 | val_loss : 5197.23486328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 812 | train_loss : 10710.583984375 | val_loss : 11060.1015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 813 | train_loss : 5839.33251953125 | val_loss : 4312.56982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 814 | train_loss : 6298.185546875 | val_loss : 6285.72607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 815 | train_loss : 5481.89501953125 | val_loss : 4738.25146484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 816 | train_loss : 10791.9716796875 | val_loss : 4154.2763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 817 | train_loss : 2798.6962890625 | val_loss : 6441.142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 818 | train_loss : 4792.798828125 | val_loss : 12872.201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 819 | train_loss : 9843.0009765625 | val_loss : 6250.3076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 820 | train_loss : 12905.142578125 | val_loss : 5632.1474609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 821 | train_loss : 4689.25927734375 | val_loss : 6270.97509765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 822 | train_loss : 3926.048095703125 | val_loss : 4010.83740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 823 | train_loss : 6470.85498046875 | val_loss : 14630.4091796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 824 | train_loss : 10156.9765625 | val_loss : 6860.27001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 825 | train_loss : 13409.62890625 | val_loss : 5334.06005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 826 | train_loss : 5337.46630859375 | val_loss : 17214.97265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 827 | train_loss : 7227.36328125 | val_loss : 7281.5576171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 828 | train_loss : 5011.7001953125 | val_loss : 4244.69140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 829 | train_loss : 7079.00439453125 | val_loss : 4125.19140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 830 | train_loss : 6140.14501953125 | val_loss : 9438.59375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 831 | train_loss : 8342.7490234375 | val_loss : 4646.3701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 832 | train_loss : 3764.7568359375 | val_loss : 3372.114990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 833 | train_loss : 7791.44189453125 | val_loss : 8921.72265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 834 | train_loss : 5172.90478515625 | val_loss : 3807.333740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 835 | train_loss : 7849.810546875 | val_loss : 7442.97509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 836 | train_loss : 4653.32568359375 | val_loss : 4867.865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 837 | train_loss : 8689.48046875 | val_loss : 8747.59375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 838 | train_loss : 5187.25439453125 | val_loss : 4811.57763671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 839 | train_loss : 8270.4072265625 | val_loss : 7839.25634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 840 | train_loss : 5573.04638671875 | val_loss : 5197.24267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 841 | train_loss : 9570.9228515625 | val_loss : 7073.19384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 842 | train_loss : 4657.1572265625 | val_loss : 5644.52392578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 843 | train_loss : 8745.7958984375 | val_loss : 9539.1484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 844 | train_loss : 6362.23876953125 | val_loss : 10561.2783203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 845 | train_loss : 11933.9912109375 | val_loss : 8221.7509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 846 | train_loss : 5786.59326171875 | val_loss : 5499.8623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 847 | train_loss : 7415.7607421875 | val_loss : 6718.22119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 848 | train_loss : 6004.82373046875 | val_loss : 5061.4326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 849 | train_loss : 11230.900390625 | val_loss : 6479.142578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 850 | train_loss : 4162.67236328125 | val_loss : 6202.46240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 851 | train_loss : 7047.35009765625 | val_loss : 8590.5908203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 852 | train_loss : 7680.75830078125 | val_loss : 10669.8251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 853 | train_loss : 11291.1328125 | val_loss : 8242.3095703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 854 | train_loss : 9866.6982421875 | val_loss : 7267.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 855 | train_loss : 10444.53125 | val_loss : 14564.28515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 856 | train_loss : 11868.0673828125 | val_loss : 10564.9384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 857 | train_loss : 10319.0322265625 | val_loss : 5354.923828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 858 | train_loss : 10133.150390625 | val_loss : 7844.03271484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 859 | train_loss : 5889.85888671875 | val_loss : 3867.188720703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 860 | train_loss : 6442.79931640625 | val_loss : 12677.974609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 861 | train_loss : 7626.3623046875 | val_loss : 2673.764892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 862 | train_loss : 7407.41357421875 | val_loss : 10814.3271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 863 | train_loss : 5632.3388671875 | val_loss : 3582.032470703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 864 | train_loss : 7981.68017578125 | val_loss : 9571.5966796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 865 | train_loss : 5745.98681640625 | val_loss : 3387.862548828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 866 | train_loss : 6084.84814453125 | val_loss : 8332.5595703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 867 | train_loss : 5130.990234375 | val_loss : 7705.01611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 868 | train_loss : 7833.19677734375 | val_loss : 4431.35986328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 869 | train_loss : 6052.8408203125 | val_loss : 12450.7587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 870 | train_loss : 8589.408203125 | val_loss : 5626.5224609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 871 | train_loss : 5250.0380859375 | val_loss : 2536.521240234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 872 | train_loss : 8163.029296875 | val_loss : 7940.80517578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 873 | train_loss : 3517.398193359375 | val_loss : 3008.2099609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 874 | train_loss : 3728.19287109375 | val_loss : 12904.48046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 875 | train_loss : 5110.54345703125 | val_loss : 3545.469970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 876 | train_loss : 3642.68115234375 | val_loss : 7165.21875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 877 | train_loss : 5994.52734375 | val_loss : 5868.2412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 878 | train_loss : 7166.1337890625 | val_loss : 7725.013671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 879 | train_loss : 7219.3017578125 | val_loss : 5602.73876953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 880 | train_loss : 9505.7451171875 | val_loss : 6612.73388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 881 | train_loss : 3973.984375 | val_loss : 2139.0087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 882 | train_loss : 6227.62451171875 | val_loss : 8399.9912109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 883 | train_loss : 5861.5263671875 | val_loss : 3850.123779296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 884 | train_loss : 7796.8779296875 | val_loss : 7178.35498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 885 | train_loss : 5622.107421875 | val_loss : 4114.62255859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 886 | train_loss : 8492.4599609375 | val_loss : 7124.66943359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 887 | train_loss : 5085.771484375 | val_loss : 3027.625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 888 | train_loss : 6661.14990234375 | val_loss : 45907.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 889 | train_loss : 26586.193359375 | val_loss : 14496.2900390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 890 | train_loss : 25752.640625 | val_loss : 23119.58984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 891 | train_loss : 14154.080078125 | val_loss : 11630.5703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 892 | train_loss : 10662.67578125 | val_loss : 5007.35107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 893 | train_loss : 11878.24609375 | val_loss : 13319.2099609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 894 | train_loss : 6489.94580078125 | val_loss : 6331.9091796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 895 | train_loss : 5676.185546875 | val_loss : 7190.9951171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 896 | train_loss : 8271.865234375 | val_loss : 7589.3095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 897 | train_loss : 11199.3154296875 | val_loss : 2565.69384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 898 | train_loss : 3289.2392578125 | val_loss : 5397.4892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 899 | train_loss : 3355.75 | val_loss : 2380.76123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 900 | train_loss : 3766.89306640625 | val_loss : 5773.2880859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 901 | train_loss : 4825.82080078125 | val_loss : 2285.77880859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 902 | train_loss : 6305.8486328125 | val_loss : 5102.00927734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 903 | train_loss : 9478.568359375 | val_loss : 2427.77490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 904 | train_loss : 4344.28369140625 | val_loss : 16176.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 905 | train_loss : 10325.8330078125 | val_loss : 8700.9873046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 906 | train_loss : 9222.8408203125 | val_loss : 8964.611328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 907 | train_loss : 6308.4638671875 | val_loss : 3218.53369140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 908 | train_loss : 8030.79931640625 | val_loss : 5239.42236328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 909 | train_loss : 4393.6904296875 | val_loss : 2709.304931640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 910 | train_loss : 6252.6123046875 | val_loss : 10479.8623046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 911 | train_loss : 6286.4267578125 | val_loss : 2540.052490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 912 | train_loss : 6241.662109375 | val_loss : 6176.46484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 913 | train_loss : 5970.90380859375 | val_loss : 6188.3369140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 914 | train_loss : 9658.654296875 | val_loss : 4667.107421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 915 | train_loss : 4318.85009765625 | val_loss : 5281.02880859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 916 | train_loss : 4748.74072265625 | val_loss : 8826.556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 917 | train_loss : 8604.4873046875 | val_loss : 3366.09375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 918 | train_loss : 10075.5517578125 | val_loss : 5519.19384765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 919 | train_loss : 2972.704345703125 | val_loss : 1750.7149658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 920 | train_loss : 3037.205078125 | val_loss : 8556.4833984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 921 | train_loss : 4380.10498046875 | val_loss : 1805.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 922 | train_loss : 4738.0595703125 | val_loss : 5613.31396484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 923 | train_loss : 7796.31103515625 | val_loss : 5389.16455078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 924 | train_loss : 10266.5849609375 | val_loss : 3728.847412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 925 | train_loss : 3916.062255859375 | val_loss : 4559.322265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 926 | train_loss : 4514.18896484375 | val_loss : 7321.1025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 927 | train_loss : 6776.00146484375 | val_loss : 4389.708984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 928 | train_loss : 7716.24072265625 | val_loss : 8561.4619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 929 | train_loss : 5661.32666015625 | val_loss : 1957.7724609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 930 | train_loss : 5583.06689453125 | val_loss : 6577.2783203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 931 | train_loss : 6209.84619140625 | val_loss : 3137.19873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 932 | train_loss : 10000.994140625 | val_loss : 5405.5224609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 933 | train_loss : 2761.225830078125 | val_loss : 1381.5074462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 934 | train_loss : 2931.86572265625 | val_loss : 7469.56982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 935 | train_loss : 4051.420654296875 | val_loss : 1892.7762451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 936 | train_loss : 4875.30615234375 | val_loss : 4967.45361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 937 | train_loss : 6036.58056640625 | val_loss : 3288.344970703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 938 | train_loss : 9871.9716796875 | val_loss : 3084.683837890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 939 | train_loss : 3192.14208984375 | val_loss : 5721.302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 940 | train_loss : 3569.153076171875 | val_loss : 3524.137451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 941 | train_loss : 6629.77978515625 | val_loss : 13279.947265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 942 | train_loss : 10453.3779296875 | val_loss : 2800.314453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 943 | train_loss : 3010.186767578125 | val_loss : 2780.003662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 944 | train_loss : 4924.50048828125 | val_loss : 8350.4404296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 945 | train_loss : 6675.58447265625 | val_loss : 5314.99755859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 946 | train_loss : 9308.01953125 | val_loss : 5495.32861328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 947 | train_loss : 3501.5556640625 | val_loss : 3178.358642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 948 | train_loss : 5989.95361328125 | val_loss : 12780.8486328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 949 | train_loss : 7739.916015625 | val_loss : 4602.3564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 950 | train_loss : 10912.173828125 | val_loss : 10305.58203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 951 | train_loss : 4582.31640625 | val_loss : 2506.8525390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 952 | train_loss : 5682.884765625 | val_loss : 12291.50390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 953 | train_loss : 6519.728515625 | val_loss : 4173.69580078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 954 | train_loss : 9457.08984375 | val_loss : 6953.69384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 955 | train_loss : 4278.4931640625 | val_loss : 9699.4248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 956 | train_loss : 6327.52392578125 | val_loss : 2198.969970703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 957 | train_loss : 4039.83056640625 | val_loss : 4616.57861328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 958 | train_loss : 7353.33056640625 | val_loss : 2299.7236328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 959 | train_loss : 4648.86328125 | val_loss : 8908.5751953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 960 | train_loss : 6991.83740234375 | val_loss : 3783.610107421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 961 | train_loss : 5916.56396484375 | val_loss : 3047.146240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 962 | train_loss : 8242.986328125 | val_loss : 2505.8701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 963 | train_loss : 2451.189208984375 | val_loss : 5010.86865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 964 | train_loss : 5754.08544921875 | val_loss : 2536.586181640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 965 | train_loss : 6330.591796875 | val_loss : 6515.17919921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 966 | train_loss : 7792.85546875 | val_loss : 1918.4512939453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 967 | train_loss : 3290.564697265625 | val_loss : 6267.58740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 968 | train_loss : 7199.45751953125 | val_loss : 2096.58740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 969 | train_loss : 5178.42431640625 | val_loss : 4318.83251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 970 | train_loss : 6914.35986328125 | val_loss : 2235.330078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 971 | train_loss : 4837.67578125 | val_loss : 10802.3984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 972 | train_loss : 8369.884765625 | val_loss : 4493.2001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 973 | train_loss : 4600.76220703125 | val_loss : 2870.441162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 974 | train_loss : 7531.75390625 | val_loss : 3272.563232421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 975 | train_loss : 3265.4521484375 | val_loss : 2811.7587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 976 | train_loss : 5318.37255859375 | val_loss : 11679.72265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 977 | train_loss : 6843.03857421875 | val_loss : 3428.913818359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 978 | train_loss : 7555.23046875 | val_loss : 2670.213134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 979 | train_loss : 4418.0830078125 | val_loss : 3085.045654296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 980 | train_loss : 6324.08642578125 | val_loss : 4533.41943359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 981 | train_loss : 4472.98828125 | val_loss : 4491.34765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 982 | train_loss : 7967.28857421875 | val_loss : 6034.8564453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 983 | train_loss : 4443.78564453125 | val_loss : 4970.30517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 984 | train_loss : 5506.07666015625 | val_loss : 6211.9580078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 985 | train_loss : 6464.99609375 | val_loss : 3564.8798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 986 | train_loss : 8288.4140625 | val_loss : 6412.35693359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 987 | train_loss : 4153.51806640625 | val_loss : 2021.9962158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 988 | train_loss : 3692.007568359375 | val_loss : 6371.28369140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 989 | train_loss : 7353.62548828125 | val_loss : 2846.308837890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 990 | train_loss : 10871.201171875 | val_loss : 3996.83056640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 991 | train_loss : 2829.997802734375 | val_loss : 2906.458740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 992 | train_loss : 4329.58984375 | val_loss : 6556.24267578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 993 | train_loss : 3549.760009765625 | val_loss : 1900.6474609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 994 | train_loss : 2334.55712890625 | val_loss : 3955.094482421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 995 | train_loss : 3160.2236328125 | val_loss : 2660.655029296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 996 | train_loss : 5635.1005859375 | val_loss : 8398.2060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 997 | train_loss : 6250.43359375 | val_loss : 2766.2412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 998 | train_loss : 8274.6865234375 | val_loss : 3875.234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 999 | train_loss : 4109.791015625 | val_loss : 9842.8779296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1000 | train_loss : 8988.423828125 | val_loss : 5095.0107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1001 | train_loss : 6847.28759765625 | val_loss : 2956.1513671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1002 | train_loss : 8322.2958984375 | val_loss : 5579.99169921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1003 | train_loss : 3231.054931640625 | val_loss : 1201.2349853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1004 | train_loss : 4069.478759765625 | val_loss : 5396.98876953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1005 | train_loss : 6028.005859375 | val_loss : 2548.92822265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1006 | train_loss : 8870.9404296875 | val_loss : 4070.470703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1007 | train_loss : 2590.968505859375 | val_loss : 1006.1300048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1008 | train_loss : 2682.2099609375 | val_loss : 6133.7412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1009 | train_loss : 4114.63232421875 | val_loss : 1896.62744140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1010 | train_loss : 5875.2255859375 | val_loss : 5371.8095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1011 | train_loss : 6338.13623046875 | val_loss : 3824.5517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1012 | train_loss : 6400.96923828125 | val_loss : 3130.25439453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1013 | train_loss : 4300.9111328125 | val_loss : 3390.858642578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1014 | train_loss : 5744.75634765625 | val_loss : 7886.8701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1015 | train_loss : 5503.72607421875 | val_loss : 2387.742431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1016 | train_loss : 6119.8681640625 | val_loss : 5116.83251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1017 | train_loss : 6461.87109375 | val_loss : 3369.59375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1018 | train_loss : 6129.09326171875 | val_loss : 3548.75244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1019 | train_loss : 4341.888671875 | val_loss : 3795.57177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1020 | train_loss : 6695.74755859375 | val_loss : 8674.7001953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1021 | train_loss : 5050.6337890625 | val_loss : 5271.54248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1022 | train_loss : 5435.900390625 | val_loss : 3855.773193359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1023 | train_loss : 6249.646484375 | val_loss : 5466.8330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1024 | train_loss : 9280.162109375 | val_loss : 3363.909912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1025 | train_loss : 3270.913818359375 | val_loss : 3672.611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1026 | train_loss : 3152.219482421875 | val_loss : 6016.1025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1027 | train_loss : 4860.77734375 | val_loss : 4746.81005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1028 | train_loss : 5926.3544921875 | val_loss : 6063.1474609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1029 | train_loss : 11097.6201171875 | val_loss : 5030.279296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1030 | train_loss : 3856.762451171875 | val_loss : 8526.533203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1031 | train_loss : 5807.55615234375 | val_loss : 10451.7802734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1032 | train_loss : 10231.0458984375 | val_loss : 2603.195556640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1033 | train_loss : 8869.775390625 | val_loss : 4747.65234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1034 | train_loss : 6202.40771484375 | val_loss : 7690.9599609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1035 | train_loss : 7860.53515625 | val_loss : 2282.650634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1036 | train_loss : 5214.2763671875 | val_loss : 2900.2919921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1037 | train_loss : 6278.48388671875 | val_loss : 2524.038818359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1038 | train_loss : 4707.7705078125 | val_loss : 6024.2373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1039 | train_loss : 4421.31201171875 | val_loss : 1703.8331298828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1040 | train_loss : 4339.75 | val_loss : 4395.134765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1041 | train_loss : 7192.20556640625 | val_loss : 1742.8143310546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1042 | train_loss : 3418.845703125 | val_loss : 4919.00146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1043 | train_loss : 4012.613037109375 | val_loss : 2484.59375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1044 | train_loss : 3912.959716796875 | val_loss : 4387.18896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1045 | train_loss : 7290.0439453125 | val_loss : 4122.3017578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1046 | train_loss : 4165.43359375 | val_loss : 8943.6083984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1047 | train_loss : 5902.369140625 | val_loss : 3534.235595703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1048 | train_loss : 6482.71044921875 | val_loss : 1662.4537353515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1049 | train_loss : 6986.52392578125 | val_loss : 1669.0174560546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1050 | train_loss : 4274.1025390625 | val_loss : 6200.8681640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1051 | train_loss : 4519.15771484375 | val_loss : 3307.7451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1052 | train_loss : 5288.81884765625 | val_loss : 2221.655517578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1053 | train_loss : 7212.07958984375 | val_loss : 7879.3681640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1054 | train_loss : 4431.7197265625 | val_loss : 1829.7850341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1055 | train_loss : 3135.35595703125 | val_loss : 4809.345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1056 | train_loss : 5398.2783203125 | val_loss : 5181.83544921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1057 | train_loss : 6842.71240234375 | val_loss : 5174.8974609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1058 | train_loss : 5038.2763671875 | val_loss : 4869.43896484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1059 | train_loss : 6850.38671875 | val_loss : 5607.96923828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1060 | train_loss : 5075.0869140625 | val_loss : 3323.83447265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1061 | train_loss : 5231.75048828125 | val_loss : 5610.70751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1062 | train_loss : 5415.37646484375 | val_loss : 2271.29248046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1063 | train_loss : 5462.490234375 | val_loss : 6873.521484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1064 | train_loss : 5028.5458984375 | val_loss : 2642.91064453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1065 | train_loss : 6015.24609375 | val_loss : 4155.2236328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1066 | train_loss : 5245.67431640625 | val_loss : 2746.913818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1067 | train_loss : 6231.09423828125 | val_loss : 3652.56689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1068 | train_loss : 3775.16943359375 | val_loss : 2656.416259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1069 | train_loss : 5681.20458984375 | val_loss : 6596.29736328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1070 | train_loss : 5067.82568359375 | val_loss : 1735.6680908203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1071 | train_loss : 5385.87646484375 | val_loss : 4840.28857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1072 | train_loss : 4359.458984375 | val_loss : 1503.6005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1073 | train_loss : 5396.0986328125 | val_loss : 5051.7763671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1074 | train_loss : 4172.044921875 | val_loss : 1603.3968505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1075 | train_loss : 5096.06591796875 | val_loss : 5345.76708984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1076 | train_loss : 4381.04296875 | val_loss : 2831.05615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1077 | train_loss : 6181.90673828125 | val_loss : 7673.044921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1078 | train_loss : 6263.07568359375 | val_loss : 2988.112548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1079 | train_loss : 7141.923828125 | val_loss : 7104.5888671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1080 | train_loss : 4858.4892578125 | val_loss : 3307.1513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1081 | train_loss : 6853.0732421875 | val_loss : 4454.6279296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1082 | train_loss : 3642.515869140625 | val_loss : 1406.8106689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1083 | train_loss : 4924.6494140625 | val_loss : 6269.92578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1084 | train_loss : 5046.64306640625 | val_loss : 2977.52001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1085 | train_loss : 6487.6435546875 | val_loss : 2474.621337890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1086 | train_loss : 3156.327392578125 | val_loss : 2446.63427734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1087 | train_loss : 5534.5224609375 | val_loss : 5122.24951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1088 | train_loss : 4291.798828125 | val_loss : 4867.78076171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1089 | train_loss : 5599.345703125 | val_loss : 4072.154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1090 | train_loss : 5011.52978515625 | val_loss : 3739.748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1091 | train_loss : 5184.93896484375 | val_loss : 7704.15869140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1092 | train_loss : 5707.87353515625 | val_loss : 4166.82177734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1093 | train_loss : 5640.93017578125 | val_loss : 1991.5787353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1094 | train_loss : 4990.45947265625 | val_loss : 7184.16796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1095 | train_loss : 7261.93115234375 | val_loss : 1895.70556640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1096 | train_loss : 4797.82421875 | val_loss : 11317.2412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1097 | train_loss : 7923.9599609375 | val_loss : 2210.048095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1098 | train_loss : 3541.047119140625 | val_loss : 8217.439453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1099 | train_loss : 7278.423828125 | val_loss : 3515.038818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1100 | train_loss : 3731.6982421875 | val_loss : 5764.8056640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1101 | train_loss : 6327.96630859375 | val_loss : 2711.331298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1102 | train_loss : 3894.345703125 | val_loss : 2023.31494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1103 | train_loss : 7575.18798828125 | val_loss : 9410.322265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1104 | train_loss : 3559.86376953125 | val_loss : 1850.39306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1105 | train_loss : 2477.663330078125 | val_loss : 10248.16015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1106 | train_loss : 4451.28466796875 | val_loss : 1643.998779296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1107 | train_loss : 4564.982421875 | val_loss : 8732.9384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1108 | train_loss : 5131.85986328125 | val_loss : 1631.6368408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1109 | train_loss : 6625.00244140625 | val_loss : 11761.865234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1110 | train_loss : 5060.900390625 | val_loss : 2718.346923828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1111 | train_loss : 4282.23046875 | val_loss : 8413.48046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1112 | train_loss : 7768.91796875 | val_loss : 3056.304931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1113 | train_loss : 7943.41357421875 | val_loss : 7747.79541015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1114 | train_loss : 7703.12939453125 | val_loss : 6637.5048828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1115 | train_loss : 6024.171875 | val_loss : 4997.447265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1116 | train_loss : 4463.64794921875 | val_loss : 5835.50048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1117 | train_loss : 5877.56005859375 | val_loss : 3579.090576171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1118 | train_loss : 5184.62646484375 | val_loss : 7101.630859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1119 | train_loss : 7774.5908203125 | val_loss : 2921.454345703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1120 | train_loss : 3532.389404296875 | val_loss : 3846.23876953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1121 | train_loss : 5059.56396484375 | val_loss : 6417.220703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1122 | train_loss : 8048.38232421875 | val_loss : 6763.6982421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1123 | train_loss : 7941.77392578125 | val_loss : 6518.45556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1124 | train_loss : 5455.8701171875 | val_loss : 4625.97119140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1125 | train_loss : 7106.49267578125 | val_loss : 3594.36376953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1126 | train_loss : 3866.695556640625 | val_loss : 7579.59423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1127 | train_loss : 6177.828125 | val_loss : 3412.530029296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1128 | train_loss : 4581.12353515625 | val_loss : 1526.936279296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1129 | train_loss : 6454.96044921875 | val_loss : 4058.52197265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1130 | train_loss : 2969.050048828125 | val_loss : 5091.927734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1131 | train_loss : 3755.16259765625 | val_loss : 2257.250732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1132 | train_loss : 3041.657470703125 | val_loss : 4346.15869140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1133 | train_loss : 4448.939453125 | val_loss : 2631.64501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1134 | train_loss : 4781.9208984375 | val_loss : 4257.40185546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1135 | train_loss : 6089.62890625 | val_loss : 2566.482421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1136 | train_loss : 3966.371826171875 | val_loss : 6061.1474609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1137 | train_loss : 5763.00732421875 | val_loss : 2772.486328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1138 | train_loss : 4325.97314453125 | val_loss : 4676.828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1139 | train_loss : 5393.833984375 | val_loss : 2310.89990234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1140 | train_loss : 5100.15576171875 | val_loss : 6501.8662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1141 | train_loss : 5896.3310546875 | val_loss : 1720.2738037109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1142 | train_loss : 3620.22216796875 | val_loss : 1490.219970703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1143 | train_loss : 6451.11181640625 | val_loss : 3376.135009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1144 | train_loss : 2760.686279296875 | val_loss : 5133.64013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1145 | train_loss : 4001.265625 | val_loss : 2640.5048828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1146 | train_loss : 3824.360595703125 | val_loss : 3678.52490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1147 | train_loss : 4719.00927734375 | val_loss : 1931.0137939453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1148 | train_loss : 5052.69091796875 | val_loss : 6847.68798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1149 | train_loss : 5737.18798828125 | val_loss : 1909.5531005859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1150 | train_loss : 3633.851318359375 | val_loss : 1328.5350341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1151 | train_loss : 6406.48583984375 | val_loss : 5072.2158203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1152 | train_loss : 2754.367431640625 | val_loss : 1314.2568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1153 | train_loss : 2295.84912109375 | val_loss : 6256.5732421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1154 | train_loss : 4465.6904296875 | val_loss : 3121.732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1155 | train_loss : 4845.171875 | val_loss : 3916.619384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1156 | train_loss : 4638.181640625 | val_loss : 1859.135009765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1157 | train_loss : 5602.2119140625 | val_loss : 5295.310546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1158 | train_loss : 4199.54248046875 | val_loss : 1155.31689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1159 | train_loss : 4368.0380859375 | val_loss : 4529.63134765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1160 | train_loss : 6175.1962890625 | val_loss : 3948.561767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1161 | train_loss : 7186.568359375 | val_loss : 4577.29248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1162 | train_loss : 5377.986328125 | val_loss : 4240.9443359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1163 | train_loss : 3925.6513671875 | val_loss : 1869.5831298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1164 | train_loss : 4909.81982421875 | val_loss : 11642.6220703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1165 | train_loss : 9093.583984375 | val_loss : 1982.4300537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1166 | train_loss : 2190.908447265625 | val_loss : 6249.92431640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1167 | train_loss : 3334.9296875 | val_loss : 7616.51171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1168 | train_loss : 4963.3486328125 | val_loss : 3696.630615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1169 | train_loss : 5563.07763671875 | val_loss : 3451.24560546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1170 | train_loss : 4568.39697265625 | val_loss : 2149.0068359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1171 | train_loss : 4912.44140625 | val_loss : 3337.0400390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1172 | train_loss : 4076.716796875 | val_loss : 1447.1875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1173 | train_loss : 5956.958984375 | val_loss : 4832.65673828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1174 | train_loss : 3401.517578125 | val_loss : 1984.3399658203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1175 | train_loss : 4641.70703125 | val_loss : 3688.455078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1176 | train_loss : 4024.324951171875 | val_loss : 1305.7574462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1177 | train_loss : 5355.50390625 | val_loss : 5407.96435546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1178 | train_loss : 4103.53076171875 | val_loss : 2551.574462890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1179 | train_loss : 5126.5146484375 | val_loss : 4392.5712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1180 | train_loss : 4338.208984375 | val_loss : 1176.2275390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1181 | train_loss : 4903.8466796875 | val_loss : 5564.3857421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1182 | train_loss : 4023.689697265625 | val_loss : 1533.3699951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1183 | train_loss : 4386.5380859375 | val_loss : 5534.837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1184 | train_loss : 4794.5830078125 | val_loss : 1329.8712158203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1185 | train_loss : 5866.046875 | val_loss : 3850.923828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1186 | train_loss : 3108.6962890625 | val_loss : 966.1031494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1187 | train_loss : 5907.07373046875 | val_loss : 5917.73681640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1188 | train_loss : 3603.1328125 | val_loss : 2445.011962890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1189 | train_loss : 4457.0712890625 | val_loss : 6599.3935546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1190 | train_loss : 7787.35009765625 | val_loss : 5683.48583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1191 | train_loss : 9220.55859375 | val_loss : 5574.48046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1192 | train_loss : 3215.5576171875 | val_loss : 1910.786865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1193 | train_loss : 3580.01318359375 | val_loss : 12238.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1194 | train_loss : 7580.84130859375 | val_loss : 2335.37255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1195 | train_loss : 5698.88916015625 | val_loss : 5183.17626953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1196 | train_loss : 5749.6435546875 | val_loss : 1500.7099609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1197 | train_loss : 5964.95458984375 | val_loss : 4199.7392578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1198 | train_loss : 4024.9736328125 | val_loss : 1329.3487548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1199 | train_loss : 3608.779296875 | val_loss : 3809.032470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1200 | train_loss : 3722.810546875 | val_loss : 1029.0224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1201 | train_loss : 5734.5048828125 | val_loss : 4627.068359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1202 | train_loss : 3003.606201171875 | val_loss : 1271.60498046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1203 | train_loss : 3205.57958984375 | val_loss : 6019.32861328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1204 | train_loss : 5176.5634765625 | val_loss : 1459.2381591796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1205 | train_loss : 5133.0751953125 | val_loss : 2782.97998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1206 | train_loss : 3373.296630859375 | val_loss : 1353.0799560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1207 | train_loss : 5215.7919921875 | val_loss : 5100.26953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1208 | train_loss : 4278.39501953125 | val_loss : 1549.0137939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1209 | train_loss : 4226.6064453125 | val_loss : 3935.000732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1210 | train_loss : 5302.21875 | val_loss : 5184.48876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1211 | train_loss : 5496.5595703125 | val_loss : 1220.675048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1212 | train_loss : 3229.8173828125 | val_loss : 3301.544921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1213 | train_loss : 5072.419921875 | val_loss : 2313.54052734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1214 | train_loss : 3804.72216796875 | val_loss : 5242.43115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1215 | train_loss : 5943.24267578125 | val_loss : 3482.72119140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1216 | train_loss : 3471.798828125 | val_loss : 3591.566162109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1217 | train_loss : 5574.07373046875 | val_loss : 3982.03369140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1218 | train_loss : 3964.562744140625 | val_loss : 6416.70166015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1219 | train_loss : 6024.1904296875 | val_loss : 3240.35302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1220 | train_loss : 3444.832275390625 | val_loss : 1149.840576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1221 | train_loss : 5528.92919921875 | val_loss : 4361.06396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1222 | train_loss : 2148.643798828125 | val_loss : 1075.668701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1223 | train_loss : 4348.490234375 | val_loss : 9446.9814453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1224 | train_loss : 4608.22900390625 | val_loss : 1114.5350341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1225 | train_loss : 5481.58642578125 | val_loss : 8796.08984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1226 | train_loss : 4290.64208984375 | val_loss : 1140.5999755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1227 | train_loss : 4055.8232421875 | val_loss : 8121.017578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1228 | train_loss : 4701.83544921875 | val_loss : 1638.170654296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1229 | train_loss : 5109.39208984375 | val_loss : 4289.73046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1230 | train_loss : 5676.6376953125 | val_loss : 2631.755615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1231 | train_loss : 4723.287109375 | val_loss : 1832.6768798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1232 | train_loss : 4510.73486328125 | val_loss : 4968.77685546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1233 | train_loss : 6074.34619140625 | val_loss : 2107.503173828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1234 | train_loss : 2813.100341796875 | val_loss : 3369.7236328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1235 | train_loss : 4825.65087890625 | val_loss : 1590.028076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1236 | train_loss : 3465.608154296875 | val_loss : 3782.894287109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1237 | train_loss : 5218.857421875 | val_loss : 1570.54443359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1238 | train_loss : 2991.755859375 | val_loss : 3498.721923828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1239 | train_loss : 4635.82373046875 | val_loss : 1501.530029296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1240 | train_loss : 3482.648193359375 | val_loss : 3147.483154296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1241 | train_loss : 5741.35888671875 | val_loss : 441621.46875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1242 | train_loss : 469951.75 | val_loss : 17941.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1243 | train_loss : 24037.64453125 | val_loss : 95825.4609375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1244 | train_loss : 65824.8828125 | val_loss : 40602.1796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1245 | train_loss : 47900.203125 | val_loss : 7063.69140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1246 | train_loss : 16619.822265625 | val_loss : 13692.1640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1247 | train_loss : 14334.1708984375 | val_loss : 9191.97265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1248 | train_loss : 5726.77880859375 | val_loss : 3619.474365234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1249 | train_loss : 3315.9794921875 | val_loss : 3470.168212890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1250 | train_loss : 3345.572265625 | val_loss : 2028.572509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1251 | train_loss : 5094.69873046875 | val_loss : 6560.267578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1252 | train_loss : 3770.65869140625 | val_loss : 2455.559326171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1253 | train_loss : 3560.656005859375 | val_loss : 2826.515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1254 | train_loss : 3542.39697265625 | val_loss : 2173.273193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1255 | train_loss : 3885.425537109375 | val_loss : 4228.140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1256 | train_loss : 4620.77099609375 | val_loss : 1908.01806640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1257 | train_loss : 4035.812744140625 | val_loss : 2758.984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1258 | train_loss : 2942.23583984375 | val_loss : 1305.701904296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1259 | train_loss : 3878.8427734375 | val_loss : 5799.21484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1260 | train_loss : 3978.6806640625 | val_loss : 1543.0262451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1261 | train_loss : 3739.11572265625 | val_loss : 2962.7412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1262 | train_loss : 3509.017578125 | val_loss : 1822.5394287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1263 | train_loss : 4889.2412109375 | val_loss : 4686.40576171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1264 | train_loss : 3289.486328125 | val_loss : 1865.26318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1265 | train_loss : 3419.45556640625 | val_loss : 3490.507568359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1266 | train_loss : 3273.5517578125 | val_loss : 1715.0238037109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1267 | train_loss : 4674.57177734375 | val_loss : 5371.47802734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1268 | train_loss : 3585.237548828125 | val_loss : 1985.224365234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1269 | train_loss : 3554.796875 | val_loss : 3714.1962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1270 | train_loss : 4044.929931640625 | val_loss : 3559.80810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1271 | train_loss : 6388.6826171875 | val_loss : 4047.681884765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1272 | train_loss : 3090.9267578125 | val_loss : 3781.181884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1273 | train_loss : 2955.9638671875 | val_loss : 2456.86572265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1274 | train_loss : 3137.3505859375 | val_loss : 2711.263671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1275 | train_loss : 4721.22509765625 | val_loss : 6743.736328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1276 | train_loss : 4210.599609375 | val_loss : 3703.633056640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1277 | train_loss : 4436.82421875 | val_loss : 2999.47998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1278 | train_loss : 4124.724609375 | val_loss : 6081.5595703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1279 | train_loss : 6836.16015625 | val_loss : 3727.050537109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1280 | train_loss : 4263.53515625 | val_loss : 4135.376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1281 | train_loss : 5489.28857421875 | val_loss : 5339.060546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1282 | train_loss : 5070.76953125 | val_loss : 3920.0244140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1283 | train_loss : 2869.5205078125 | val_loss : 5116.56494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1284 | train_loss : 4080.44189453125 | val_loss : 3220.81005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1285 | train_loss : 4056.078125 | val_loss : 4993.50390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1286 | train_loss : 3699.029052734375 | val_loss : 1772.6568603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1287 | train_loss : 3599.389892578125 | val_loss : 3002.605712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1288 | train_loss : 3674.715576171875 | val_loss : 1774.03369140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1289 | train_loss : 6432.583984375 | val_loss : 5020.13818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1290 | train_loss : 2543.013916015625 | val_loss : 4935.443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1291 | train_loss : 3751.689697265625 | val_loss : 6001.98046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1292 | train_loss : 4183.0517578125 | val_loss : 3391.340087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1293 | train_loss : 4938.82177734375 | val_loss : 5682.97705078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1294 | train_loss : 4210.2421875 | val_loss : 2228.183349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1295 | train_loss : 3561.90185546875 | val_loss : 2072.610595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1296 | train_loss : 3244.133544921875 | val_loss : 2203.541259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1297 | train_loss : 5912.18505859375 | val_loss : 5432.2119140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1298 | train_loss : 2749.285888671875 | val_loss : 2756.320556640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1299 | train_loss : 1868.7041015625 | val_loss : 1821.6343994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1300 | train_loss : 1893.6248779296875 | val_loss : 2766.94384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1301 | train_loss : 2327.620849609375 | val_loss : 4619.03271484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1302 | train_loss : 2796.982421875 | val_loss : 2133.68994140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1303 | train_loss : 3271.41748046875 | val_loss : 5090.93701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1304 | train_loss : 6213.87744140625 | val_loss : 2839.304931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1305 | train_loss : 3598.223388671875 | val_loss : 3933.606201171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1306 | train_loss : 5636.40478515625 | val_loss : 4917.06982421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1307 | train_loss : 6080.1201171875 | val_loss : 5652.3818359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1308 | train_loss : 6495.41015625 | val_loss : 4070.641357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1309 | train_loss : 3229.7412109375 | val_loss : 2440.8017578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1310 | train_loss : 5315.13916015625 | val_loss : 2594.150634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1311 | train_loss : 2470.012451171875 | val_loss : 5663.583984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1312 | train_loss : 4440.37939453125 | val_loss : 3261.376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1313 | train_loss : 3757.24560546875 | val_loss : 3409.076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1314 | train_loss : 4911.18603515625 | val_loss : 6078.16796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1315 | train_loss : 5420.76123046875 | val_loss : 5378.46826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1316 | train_loss : 5340.6337890625 | val_loss : 5396.501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1317 | train_loss : 4571.5849609375 | val_loss : 2245.7255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1318 | train_loss : 4853.9033203125 | val_loss : 3054.342529296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1319 | train_loss : 2909.92822265625 | val_loss : 5500.61767578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1320 | train_loss : 3406.206298828125 | val_loss : 2418.264404296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1321 | train_loss : 2676.68115234375 | val_loss : 1843.920654296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1322 | train_loss : 3646.05712890625 | val_loss : 2378.440673828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1323 | train_loss : 2784.645263671875 | val_loss : 4006.70751953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1324 | train_loss : 5044.033203125 | val_loss : 2117.965576171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1325 | train_loss : 3160.491943359375 | val_loss : 1519.6387939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1326 | train_loss : 3074.189453125 | val_loss : 2209.890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1327 | train_loss : 2970.7294921875 | val_loss : 1531.609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1328 | train_loss : 3841.52685546875 | val_loss : 6419.68359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1329 | train_loss : 4180.919921875 | val_loss : 2556.94384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1330 | train_loss : 3593.8330078125 | val_loss : 2528.505615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1331 | train_loss : 4662.9404296875 | val_loss : 3581.141357421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1332 | train_loss : 5450.5498046875 | val_loss : 3969.47314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1333 | train_loss : 4340.27734375 | val_loss : 1638.8511962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1334 | train_loss : 3191.619384765625 | val_loss : 4727.33251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1335 | train_loss : 4207.71240234375 | val_loss : 1554.056884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1336 | train_loss : 3935.5224609375 | val_loss : 3325.6025390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1337 | train_loss : 3583.806884765625 | val_loss : 1552.7574462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1338 | train_loss : 4511.13818359375 | val_loss : 5199.5732421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1339 | train_loss : 4030.853759765625 | val_loss : 2224.72314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1340 | train_loss : 4208.29248046875 | val_loss : 2990.550048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1341 | train_loss : 3847.121826171875 | val_loss : 1876.33251953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1342 | train_loss : 4309.25244140625 | val_loss : 5380.232421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1343 | train_loss : 3924.71337890625 | val_loss : 2271.081298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1344 | train_loss : 3717.8857421875 | val_loss : 4655.39453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1345 | train_loss : 3954.563232421875 | val_loss : 1425.5506591796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1346 | train_loss : 4282.44580078125 | val_loss : 4951.263671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1347 | train_loss : 2921.087158203125 | val_loss : 1741.8299560546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1348 | train_loss : 3548.543701171875 | val_loss : 3792.597412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1349 | train_loss : 4033.58056640625 | val_loss : 1734.4468994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1350 | train_loss : 4315.81103515625 | val_loss : 3724.736328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1351 | train_loss : 2822.563232421875 | val_loss : 1669.7550048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1352 | train_loss : 3965.056884765625 | val_loss : 6120.60498046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1353 | train_loss : 4004.759765625 | val_loss : 2861.293701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1354 | train_loss : 4429.287109375 | val_loss : 10913.60546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1355 | train_loss : 9001.54296875 | val_loss : 3206.3349609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1356 | train_loss : 5300.1611328125 | val_loss : 6003.2587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1357 | train_loss : 4458.32080078125 | val_loss : 2135.70068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1358 | train_loss : 4519.70849609375 | val_loss : 4877.720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1359 | train_loss : 2857.467529296875 | val_loss : 2586.328857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1360 | train_loss : 3769.949951171875 | val_loss : 4111.7255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1361 | train_loss : 3734.256591796875 | val_loss : 2443.947509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1362 | train_loss : 4591.45166015625 | val_loss : 4279.869140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1363 | train_loss : 3751.1787109375 | val_loss : 4355.19580078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1364 | train_loss : 6384.61865234375 | val_loss : 3900.481201171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1365 | train_loss : 4443.365234375 | val_loss : 5172.79833984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1366 | train_loss : 4829.86767578125 | val_loss : 2620.921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1367 | train_loss : 3695.294921875 | val_loss : 3781.6943359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1368 | train_loss : 5823.0126953125 | val_loss : 1686.0999755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1369 | train_loss : 2355.9609375 | val_loss : 5793.66748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1370 | train_loss : 3801.673828125 | val_loss : 1342.46630859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1371 | train_loss : 3569.99658203125 | val_loss : 1960.793701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1372 | train_loss : 5502.50244140625 | val_loss : 1396.119384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1373 | train_loss : 2646.1103515625 | val_loss : 5884.44580078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1374 | train_loss : 3854.583984375 | val_loss : 2069.706298828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1375 | train_loss : 2382.64208984375 | val_loss : 1367.5987548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1376 | train_loss : 3531.2802734375 | val_loss : 4453.82568359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1377 | train_loss : 3255.655517578125 | val_loss : 2259.124267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1378 | train_loss : 3544.419677734375 | val_loss : 3285.5849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1379 | train_loss : 3643.160888671875 | val_loss : 2950.500732421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1380 | train_loss : 4626.3798828125 | val_loss : 4707.72265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1381 | train_loss : 4027.1171875 | val_loss : 2396.44873046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1382 | train_loss : 3779.97216796875 | val_loss : 4771.2763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1383 | train_loss : 3998.378173828125 | val_loss : 2372.90185546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1384 | train_loss : 3736.072509765625 | val_loss : 4041.711181640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1385 | train_loss : 4074.164306640625 | val_loss : 2509.44384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1386 | train_loss : 4190.45751953125 | val_loss : 4312.34130859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1387 | train_loss : 3214.066162109375 | val_loss : 3620.15869140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1388 | train_loss : 3884.407470703125 | val_loss : 3953.2275390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1389 | train_loss : 3992.04248046875 | val_loss : 2332.806884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1390 | train_loss : 4111.76416015625 | val_loss : 4523.9013671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1391 | train_loss : 3393.31689453125 | val_loss : 1391.9906005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1392 | train_loss : 3455.017578125 | val_loss : 3921.9375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1393 | train_loss : 3396.00439453125 | val_loss : 1272.50439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1394 | train_loss : 3597.813720703125 | val_loss : 4858.6875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1395 | train_loss : 3464.46875 | val_loss : 1602.3231201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1396 | train_loss : 3187.53125 | val_loss : 2456.1142578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1397 | train_loss : 3602.07177734375 | val_loss : 1605.48876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1398 | train_loss : 4617.91064453125 | val_loss : 3770.611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1399 | train_loss : 2293.57958984375 | val_loss : 1262.501220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1400 | train_loss : 3241.306640625 | val_loss : 5343.51611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1401 | train_loss : 3598.718994140625 | val_loss : 1400.3687744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1402 | train_loss : 3490.450927734375 | val_loss : 3129.648681640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1403 | train_loss : 3179.65283203125 | val_loss : 1512.04443359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1404 | train_loss : 4691.8017578125 | val_loss : 3137.278076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1405 | train_loss : 2558.369140625 | val_loss : 1601.3837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1406 | train_loss : 3027.63623046875 | val_loss : 3789.7275390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1407 | train_loss : 3239.320068359375 | val_loss : 1156.46875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1408 | train_loss : 3660.5869140625 | val_loss : 2841.38427734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1409 | train_loss : 2977.40380859375 | val_loss : 1556.7119140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1410 | train_loss : 4278.67822265625 | val_loss : 4304.2216796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1411 | train_loss : 3100.85302734375 | val_loss : 1807.3199462890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1412 | train_loss : 3675.005859375 | val_loss : 3938.828857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1413 | train_loss : 4602.14013671875 | val_loss : 4567.8525390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1414 | train_loss : 5296.6201171875 | val_loss : 4838.29931640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1415 | train_loss : 3967.704345703125 | val_loss : 2971.596923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1416 | train_loss : 4542.076171875 | val_loss : 5165.80810546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1417 | train_loss : 4159.36083984375 | val_loss : 2202.1162109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1418 | train_loss : 3846.373046875 | val_loss : 16018.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1419 | train_loss : 12102.8359375 | val_loss : 4856.125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1420 | train_loss : 11650.0771484375 | val_loss : 2075.654296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1421 | train_loss : 4574.38330078125 | val_loss : 9656.7392578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1422 | train_loss : 4626.88037109375 | val_loss : 4030.808837890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1423 | train_loss : 4789.17919921875 | val_loss : 2532.87255859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1424 | train_loss : 2889.066162109375 | val_loss : 3291.304443359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1425 | train_loss : 4994.49169921875 | val_loss : 3253.835693359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1426 | train_loss : 2933.445068359375 | val_loss : 4901.0185546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1427 | train_loss : 4826.619140625 | val_loss : 2554.55615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1428 | train_loss : 3634.2060546875 | val_loss : 2267.175048828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1429 | train_loss : 5540.4794921875 | val_loss : 4060.4580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1430 | train_loss : 3923.9951171875 | val_loss : 24208.4609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1431 | train_loss : 12290.5859375 | val_loss : 12128.6474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1432 | train_loss : 5908.49267578125 | val_loss : 5626.15771484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1433 | train_loss : 4194.49658203125 | val_loss : 4397.97607421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1434 | train_loss : 3749.466796875 | val_loss : 2587.640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1435 | train_loss : 4789.166015625 | val_loss : 5098.42626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1436 | train_loss : 3025.77685546875 | val_loss : 2345.060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1437 | train_loss : 3723.678955078125 | val_loss : 6495.3212890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1438 | train_loss : 4046.371337890625 | val_loss : 2245.994384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1439 | train_loss : 4176.23583984375 | val_loss : 7224.38232421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1440 | train_loss : 4454.7587890625 | val_loss : 2849.113037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1441 | train_loss : 4804.76953125 | val_loss : 6890.99072265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1442 | train_loss : 4417.22265625 | val_loss : 2122.63427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1443 | train_loss : 3390.2802734375 | val_loss : 5242.53564453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1444 | train_loss : 4018.641845703125 | val_loss : 1144.208740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1445 | train_loss : 3484.451171875 | val_loss : 2605.89697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1446 | train_loss : 2946.727294921875 | val_loss : 1930.373779296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1447 | train_loss : 4590.46875 | val_loss : 4910.66748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1448 | train_loss : 3355.034912109375 | val_loss : 1978.82568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1449 | train_loss : 2902.54150390625 | val_loss : 3557.193115234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1450 | train_loss : 3436.198486328125 | val_loss : 2633.96240234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1451 | train_loss : 4137.99365234375 | val_loss : 3836.56884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1452 | train_loss : 3367.30615234375 | val_loss : 3389.621826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1453 | train_loss : 3922.876953125 | val_loss : 4132.95068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1454 | train_loss : 3735.507568359375 | val_loss : 3035.669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1455 | train_loss : 3101.539794921875 | val_loss : 3457.253662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1456 | train_loss : 3655.88427734375 | val_loss : 2042.130615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1457 | train_loss : 3709.94677734375 | val_loss : 3124.409912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1458 | train_loss : 3172.944580078125 | val_loss : 1563.9537353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1459 | train_loss : 3347.931884765625 | val_loss : 4458.71044921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1460 | train_loss : 3618.50244140625 | val_loss : 1955.4893798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1461 | train_loss : 3367.023681640625 | val_loss : 5001.05810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1462 | train_loss : 3700.21728515625 | val_loss : 1917.8843994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1463 | train_loss : 3335.441162109375 | val_loss : 2390.06689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1464 | train_loss : 3045.996826171875 | val_loss : 2195.1142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1465 | train_loss : 3984.102783203125 | val_loss : 3097.891357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1466 | train_loss : 2587.769775390625 | val_loss : 978.05126953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1467 | train_loss : 4262.21630859375 | val_loss : 4137.05859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1468 | train_loss : 2524.9267578125 | val_loss : 1147.68310546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1469 | train_loss : 2097.968994140625 | val_loss : 2883.523681640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1470 | train_loss : 2979.98095703125 | val_loss : 1023.1793823242188 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1471 | train_loss : 4214.4794921875 | val_loss : 3759.2236328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1472 | train_loss : 2292.130615234375 | val_loss : 1265.166259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1473 | train_loss : 2045.3612060546875 | val_loss : 3487.74755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1474 | train_loss : 3139.60498046875 | val_loss : 1966.7462158203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1475 | train_loss : 3339.185546875 | val_loss : 3226.574462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1476 | train_loss : 2819.001953125 | val_loss : 1483.7550048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1477 | train_loss : 3070.792724609375 | val_loss : 4162.734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1478 | train_loss : 3298.811767578125 | val_loss : 2002.9481201171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1479 | train_loss : 3097.553955078125 | val_loss : 3117.951904296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1480 | train_loss : 3968.31396484375 | val_loss : 2360.22802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1481 | train_loss : 5524.77001953125 | val_loss : 4059.829345703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1482 | train_loss : 3495.234619140625 | val_loss : 2697.322509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1483 | train_loss : 2457.3271484375 | val_loss : 761.6331176757812 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1484 | train_loss : 2405.378662109375 | val_loss : 3962.767578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1485 | train_loss : 4607.341796875 | val_loss : 1469.0556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1486 | train_loss : 2107.45556640625 | val_loss : 3399.330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1487 | train_loss : 4164.32958984375 | val_loss : 1091.8675537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1488 | train_loss : 2949.422607421875 | val_loss : 4053.945556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1489 | train_loss : 5290.86376953125 | val_loss : 1939.583740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1490 | train_loss : 2109.725830078125 | val_loss : 1319.208740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1491 | train_loss : 3141.956298828125 | val_loss : 3632.89697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1492 | train_loss : 4076.74755859375 | val_loss : 5237.80517578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1493 | train_loss : 6187.93017578125 | val_loss : 3534.00634765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1494 | train_loss : 1916.22021484375 | val_loss : 946.7181396484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1495 | train_loss : 2300.6865234375 | val_loss : 6213.1611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1496 | train_loss : 3290.681884765625 | val_loss : 946.0406494140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1497 | train_loss : 3105.71630859375 | val_loss : 6951.66357421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1498 | train_loss : 4260.06396484375 | val_loss : 1110.614990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1499 | train_loss : 4470.52001953125 | val_loss : 4892.93603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1500 | train_loss : 2557.26025390625 | val_loss : 4770.064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1501 | train_loss : 3928.43994140625 | val_loss : 11077.048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1502 | train_loss : 8719.29296875 | val_loss : 2932.641845703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1503 | train_loss : 5784.18017578125 | val_loss : 2015.4937744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1504 | train_loss : 1844.1490478515625 | val_loss : 1805.5999755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1505 | train_loss : 3150.53271484375 | val_loss : 4320.40478515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1506 | train_loss : 3885.11376953125 | val_loss : 1025.5037841796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1507 | train_loss : 2854.8369140625 | val_loss : 4108.814453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1508 | train_loss : 3368.905029296875 | val_loss : 1067.313720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1509 | train_loss : 3158.34375 | val_loss : 2877.869384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1510 | train_loss : 3054.179443359375 | val_loss : 992.5900268554688 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1511 | train_loss : 3521.2744140625 | val_loss : 2779.93115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1512 | train_loss : 2825.921875 | val_loss : 1387.2137451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1513 | train_loss : 2905.3544921875 | val_loss : 2942.63623046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1514 | train_loss : 3179.297119140625 | val_loss : 1932.4368896484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1515 | train_loss : 2955.039306640625 | val_loss : 3163.8798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1516 | train_loss : 3397.316162109375 | val_loss : 2210.070068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1517 | train_loss : 3487.202880859375 | val_loss : 2926.664306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1518 | train_loss : 3013.279296875 | val_loss : 1656.6256103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1519 | train_loss : 2939.743408203125 | val_loss : 1816.552490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1520 | train_loss : 3041.08056640625 | val_loss : 1430.5068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1521 | train_loss : 4718.38623046875 | val_loss : 3975.0732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1522 | train_loss : 2276.867919921875 | val_loss : 1716.112548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1523 | train_loss : 2012.9144287109375 | val_loss : 1377.1212158203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1524 | train_loss : 2115.961181640625 | val_loss : 2676.22119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1525 | train_loss : 3577.42041015625 | val_loss : 1536.0550537109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1526 | train_loss : 3216.874267578125 | val_loss : 4432.67578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1527 | train_loss : 4917.85107421875 | val_loss : 5510.64697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1528 | train_loss : 4122.21875 | val_loss : 3828.81005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1529 | train_loss : 4384.84326171875 | val_loss : 3718.422607421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1530 | train_loss : 3794.77001953125 | val_loss : 1711.7481689453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1531 | train_loss : 3681.7646484375 | val_loss : 4342.86669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1532 | train_loss : 3171.21630859375 | val_loss : 2747.840576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1533 | train_loss : 4395.89306640625 | val_loss : 3387.20947265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1534 | train_loss : 3056.9013671875 | val_loss : 3833.248779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1535 | train_loss : 4469.4365234375 | val_loss : 4508.12548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1536 | train_loss : 3333.168701171875 | val_loss : 3003.405517578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1537 | train_loss : 2809.524169921875 | val_loss : 1614.2049560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1538 | train_loss : 2828.771484375 | val_loss : 1741.3106689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1539 | train_loss : 3172.251220703125 | val_loss : 3869.98681640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1540 | train_loss : 2681.8251953125 | val_loss : 1010.391845703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1541 | train_loss : 3082.011962890625 | val_loss : 2513.210693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1542 | train_loss : 3209.468994140625 | val_loss : 832.9356079101562 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1543 | train_loss : 3718.10791015625 | val_loss : 3239.99755859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1544 | train_loss : 2140.537353515625 | val_loss : 934.2531127929688 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1545 | train_loss : 2814.896240234375 | val_loss : 2846.33251953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1546 | train_loss : 2450.453857421875 | val_loss : 1192.85498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1547 | train_loss : 3494.7353515625 | val_loss : 3398.695556640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1548 | train_loss : 2564.991455078125 | val_loss : 1252.239990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1549 | train_loss : 2857.202392578125 | val_loss : 1916.349365234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1550 | train_loss : 2665.244384765625 | val_loss : 1297.911865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1551 | train_loss : 4031.162109375 | val_loss : 3832.1962890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1552 | train_loss : 2116.33740234375 | val_loss : 1487.98681640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1553 | train_loss : 2283.521484375 | val_loss : 1475.4493408203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1554 | train_loss : 2653.420654296875 | val_loss : 1812.39501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1555 | train_loss : 4856.7216796875 | val_loss : 4250.07177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1556 | train_loss : 3979.296142578125 | val_loss : 3295.063720703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1557 | train_loss : 2476.7666015625 | val_loss : 1217.0224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1558 | train_loss : 3085.0791015625 | val_loss : 5927.0517578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1559 | train_loss : 5767.98583984375 | val_loss : 1223.889404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1560 | train_loss : 1952.2152099609375 | val_loss : 5519.302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1561 | train_loss : 2734.31787109375 | val_loss : 680.592529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1562 | train_loss : 1826.2275390625 | val_loss : 3727.201171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1563 | train_loss : 3833.2724609375 | val_loss : 567.3518676757812 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1564 | train_loss : 2235.614501953125 | val_loss : 2879.73681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1565 | train_loss : 4168.55126953125 | val_loss : 793.0150146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1566 | train_loss : 2428.496826171875 | val_loss : 3611.74755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1567 | train_loss : 3778.4560546875 | val_loss : 1649.2874755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1568 | train_loss : 2686.41552734375 | val_loss : 2361.311767578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1569 | train_loss : 4289.69482421875 | val_loss : 1792.4080810546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1570 | train_loss : 2668.028076171875 | val_loss : 3092.60302734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1571 | train_loss : 3756.574951171875 | val_loss : 1442.71875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1572 | train_loss : 2000.7998046875 | val_loss : 2308.625732421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1573 | train_loss : 3653.37060546875 | val_loss : 1448.635009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1574 | train_loss : 3045.912109375 | val_loss : 2843.203857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1575 | train_loss : 3892.971923828125 | val_loss : 1391.6287841796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1576 | train_loss : 2494.943115234375 | val_loss : 4805.689453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1577 | train_loss : 4696.046875 | val_loss : 1783.177490234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1578 | train_loss : 1845.7484130859375 | val_loss : 2283.734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1579 | train_loss : 3585.257080078125 | val_loss : 2925.970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1580 | train_loss : 2456.97119140625 | val_loss : 3962.5849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1581 | train_loss : 4067.563720703125 | val_loss : 1182.6925048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1582 | train_loss : 2410.179931640625 | val_loss : 3839.5537109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1583 | train_loss : 5199.49365234375 | val_loss : 1361.84375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1584 | train_loss : 1874.41162109375 | val_loss : 3135.9580078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1585 | train_loss : 2794.929443359375 | val_loss : 2037.52685546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1586 | train_loss : 3218.50439453125 | val_loss : 3877.056884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1587 | train_loss : 5773.015625 | val_loss : 2671.77490234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1588 | train_loss : 1630.70849609375 | val_loss : 1819.1893310546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1589 | train_loss : 2369.593505859375 | val_loss : 2356.20947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1590 | train_loss : 2414.722900390625 | val_loss : 5080.34814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1591 | train_loss : 4232.96826171875 | val_loss : 4505.271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1592 | train_loss : 4591.18603515625 | val_loss : 4271.79248046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1593 | train_loss : 6938.9189453125 | val_loss : 4423.24169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1594 | train_loss : 2197.629638671875 | val_loss : 2679.331787109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1595 | train_loss : 3083.555419921875 | val_loss : 1380.8199462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1596 | train_loss : 2868.10400390625 | val_loss : 4389.45751953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1597 | train_loss : 5040.29150390625 | val_loss : 833.6937255859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1598 | train_loss : 1639.0556640625 | val_loss : 3480.668212890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1599 | train_loss : 2630.1103515625 | val_loss : 1271.4549560546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 1600 | train_loss : 2237.355224609375 | val_loss : 2952.3994140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 4 | epoch : 1 | train_loss : 1701505.0 | val_loss : 1353332.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 2 | train_loss : 1245766.125 | val_loss : 1143362.25 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 3 | train_loss : 1109403.5 | val_loss : 571592.5 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 4 | train_loss : 549227.5 | val_loss : 372079.6875 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 5 | train_loss : 422008.71875 | val_loss : 267342.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 6 | train_loss : 281683.3125 | val_loss : 348535.1875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 7 | train_loss : 354238.6875 | val_loss : 415492.8125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 8 | train_loss : 524730.1875 | val_loss : 483649.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 9 | train_loss : 642249.0625 | val_loss : 663911.375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 10 | train_loss : 759846.75 | val_loss : 863719.5 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 11 | train_loss : 815534.3125 | val_loss : 876090.0 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 12 | train_loss : 801038.3125 | val_loss : 286531.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 13 | train_loss : 262882.75 | val_loss : 166608.34375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 14 | train_loss : 197423.546875 | val_loss : 124808.8203125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 15 | train_loss : 183979.5 | val_loss : 210696.40625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 16 | train_loss : 202787.515625 | val_loss : 175262.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 17 | train_loss : 239895.90625 | val_loss : 135591.4375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 18 | train_loss : 118841.453125 | val_loss : 110155.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 19 | train_loss : 138473.5625 | val_loss : 209190.125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 20 | train_loss : 215265.59375 | val_loss : 144043.3125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 21 | train_loss : 127961.4921875 | val_loss : 198424.3125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 22 | train_loss : 145707.59375 | val_loss : 137840.375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 23 | train_loss : 161842.671875 | val_loss : 170445.203125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 24 | train_loss : 182435.59375 | val_loss : 155801.0 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 25 | train_loss : 161341.09375 | val_loss : 172322.28125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 26 | train_loss : 137172.203125 | val_loss : 160119.09375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 27 | train_loss : 159877.40625 | val_loss : 160755.34375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 28 | train_loss : 204683.640625 | val_loss : 159291.875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 29 | train_loss : 191919.40625 | val_loss : 194483.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 30 | train_loss : 243163.0625 | val_loss : 151762.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 31 | train_loss : 178850.09375 | val_loss : 136414.140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 32 | train_loss : 110733.1171875 | val_loss : 190213.65625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 33 | train_loss : 141260.53125 | val_loss : 205585.796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 34 | train_loss : 183136.375 | val_loss : 155429.21875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 35 | train_loss : 160522.234375 | val_loss : 141301.515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 36 | train_loss : 120290.7109375 | val_loss : 132557.15625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 37 | train_loss : 133376.265625 | val_loss : 96079.546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 38 | train_loss : 146960.234375 | val_loss : 120454.703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 39 | train_loss : 141149.796875 | val_loss : 110336.5390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 40 | train_loss : 144837.84375 | val_loss : 168077.734375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 41 | train_loss : 116480.90625 | val_loss : 125845.1171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 42 | train_loss : 95667.2109375 | val_loss : 88810.09375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 43 | train_loss : 110087.6328125 | val_loss : 67737.5 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 44 | train_loss : 115756.8828125 | val_loss : 105570.4375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 45 | train_loss : 146823.359375 | val_loss : 65304.83984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 46 | train_loss : 85340.703125 | val_loss : 157492.796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 47 | train_loss : 100944.296875 | val_loss : 178148.65625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 48 | train_loss : 141401.9375 | val_loss : 95146.7578125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 49 | train_loss : 143184.46875 | val_loss : 82377.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 50 | train_loss : 105886.3984375 | val_loss : 66715.2578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 51 | train_loss : 76137.5546875 | val_loss : 183677.875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 52 | train_loss : 145706.6875 | val_loss : 187761.296875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 53 | train_loss : 194395.21875 | val_loss : 100566.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 54 | train_loss : 147971.625 | val_loss : 166064.375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 55 | train_loss : 167623.890625 | val_loss : 66968.6328125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 56 | train_loss : 70201.3984375 | val_loss : 125785.84375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 57 | train_loss : 85506.0625 | val_loss : 132937.875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 58 | train_loss : 100098.6015625 | val_loss : 119181.0625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 59 | train_loss : 130412.4609375 | val_loss : 75653.203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 60 | train_loss : 78536.015625 | val_loss : 85521.6015625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 61 | train_loss : 82937.109375 | val_loss : 95930.4609375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 62 | train_loss : 116505.8984375 | val_loss : 67340.953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 63 | train_loss : 78035.4921875 | val_loss : 122618.4921875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 64 | train_loss : 126028.328125 | val_loss : 74870.4375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 65 | train_loss : 132362.515625 | val_loss : 91307.3828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 66 | train_loss : 130819.078125 | val_loss : 159105.078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 67 | train_loss : 190817.4375 | val_loss : 61499.7109375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 68 | train_loss : 42369.05078125 | val_loss : 67956.265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 69 | train_loss : 88136.3984375 | val_loss : 118050.28125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 70 | train_loss : 103521.3671875 | val_loss : 45299.0234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 71 | train_loss : 68477.953125 | val_loss : 100684.0 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 72 | train_loss : 99873.203125 | val_loss : 93179.5625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 73 | train_loss : 116096.03125 | val_loss : 163829.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 74 | train_loss : 135275.21875 | val_loss : 118788.390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 75 | train_loss : 116624.6796875 | val_loss : 118528.4609375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 76 | train_loss : 146852.4375 | val_loss : 128467.3203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 77 | train_loss : 146698.6875 | val_loss : 104709.203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 78 | train_loss : 84454.5390625 | val_loss : 55958.140625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 79 | train_loss : 72652.90625 | val_loss : 152883.21875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 80 | train_loss : 100201.4765625 | val_loss : 113217.859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 81 | train_loss : 101436.421875 | val_loss : 130369.5 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 82 | train_loss : 137599.46875 | val_loss : 162174.3125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 83 | train_loss : 158414.8125 | val_loss : 84130.9296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 84 | train_loss : 115696.203125 | val_loss : 120464.203125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 85 | train_loss : 115993.8828125 | val_loss : 126523.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 86 | train_loss : 133701.8125 | val_loss : 62025.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 87 | train_loss : 82808.3359375 | val_loss : 56713.05859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 88 | train_loss : 83317.6328125 | val_loss : 97529.578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 89 | train_loss : 88938.21875 | val_loss : 120709.0390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 90 | train_loss : 107483.6875 | val_loss : 106401.5390625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 91 | train_loss : 107706.03125 | val_loss : 101523.3828125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 92 | train_loss : 115406.1796875 | val_loss : 78397.40625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 93 | train_loss : 116719.2734375 | val_loss : 43910.484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 94 | train_loss : 65355.0546875 | val_loss : 76819.0390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 95 | train_loss : 82267.65625 | val_loss : 60810.53515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 96 | train_loss : 86422.390625 | val_loss : 59847.66015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 97 | train_loss : 116929.8515625 | val_loss : 91418.0390625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 98 | train_loss : 82133.078125 | val_loss : 55522.921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 99 | train_loss : 79282.4453125 | val_loss : 63275.61328125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 100 | train_loss : 79308.84375 | val_loss : 84642.890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 101 | train_loss : 91476.3671875 | val_loss : 65878.75 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 102 | train_loss : 82718.5625 | val_loss : 45456.55078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 103 | train_loss : 74994.5703125 | val_loss : 102710.203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 104 | train_loss : 82094.640625 | val_loss : 50042.03515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 105 | train_loss : 53546.7890625 | val_loss : 73746.9921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 106 | train_loss : 85029.21875 | val_loss : 32703.029296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 107 | train_loss : 64475.24609375 | val_loss : 143372.71875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 108 | train_loss : 108274.703125 | val_loss : 86440.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 109 | train_loss : 82606.1015625 | val_loss : 77251.7265625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 110 | train_loss : 100358.7578125 | val_loss : 97213.28125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 111 | train_loss : 122032.7421875 | val_loss : 125684.6015625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 112 | train_loss : 110751.359375 | val_loss : 96878.578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 113 | train_loss : 125779.9296875 | val_loss : 88489.828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 114 | train_loss : 145717.09375 | val_loss : 95739.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 115 | train_loss : 74002.1875 | val_loss : 29499.16015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 116 | train_loss : 45303.7734375 | val_loss : 48773.31640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 117 | train_loss : 45786.328125 | val_loss : 85443.3984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 118 | train_loss : 62008.5234375 | val_loss : 73346.2421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 119 | train_loss : 68231.3828125 | val_loss : 36784.7734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 120 | train_loss : 44185.80078125 | val_loss : 57820.01171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 121 | train_loss : 55711.17578125 | val_loss : 41079.03515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 122 | train_loss : 55048.21484375 | val_loss : 52259.734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 123 | train_loss : 61774.73828125 | val_loss : 94536.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 124 | train_loss : 95845.0234375 | val_loss : 69208.265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 125 | train_loss : 81966.78125 | val_loss : 81898.546875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 126 | train_loss : 79506.0625 | val_loss : 57274.37890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 127 | train_loss : 72597.578125 | val_loss : 59292.9453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 128 | train_loss : 75362.71875 | val_loss : 53225.30859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 129 | train_loss : 74096.390625 | val_loss : 57101.328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 130 | train_loss : 63591.625 | val_loss : 63173.390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 131 | train_loss : 55713.5 | val_loss : 50023.88671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 132 | train_loss : 44990.3515625 | val_loss : 61025.61328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 133 | train_loss : 60999.81640625 | val_loss : 100819.53125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 134 | train_loss : 64167.2890625 | val_loss : 72961.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 135 | train_loss : 81881.875 | val_loss : 51991.1484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 136 | train_loss : 71888.4140625 | val_loss : 84476.328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 137 | train_loss : 74671.1015625 | val_loss : 79217.1015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 138 | train_loss : 77859.1328125 | val_loss : 93589.28125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 139 | train_loss : 61658.8046875 | val_loss : 55383.35546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 140 | train_loss : 64432.19140625 | val_loss : 46215.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 141 | train_loss : 70091.7578125 | val_loss : 55603.44921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 142 | train_loss : 63316.2109375 | val_loss : 136919.265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 143 | train_loss : 94366.53125 | val_loss : 83518.90625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 144 | train_loss : 91497.1875 | val_loss : 61126.15625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 145 | train_loss : 62888.921875 | val_loss : 54198.37890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 146 | train_loss : 54135.734375 | val_loss : 52233.37109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 147 | train_loss : 52720.5546875 | val_loss : 103060.140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 148 | train_loss : 85688.3828125 | val_loss : 46160.796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 149 | train_loss : 68527.6171875 | val_loss : 78855.765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 150 | train_loss : 83569.3671875 | val_loss : 46167.67578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 151 | train_loss : 64760.65625 | val_loss : 60060.28515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 152 | train_loss : 50434.7890625 | val_loss : 57736.36328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 153 | train_loss : 52734.328125 | val_loss : 88046.2109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 154 | train_loss : 81661.453125 | val_loss : 68573.3828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 155 | train_loss : 98727.2265625 | val_loss : 91540.4375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 156 | train_loss : 72807.1875 | val_loss : 63504.8984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 157 | train_loss : 68359.703125 | val_loss : 103065.21875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 158 | train_loss : 86330.40625 | val_loss : 70797.4140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 159 | train_loss : 83044.6953125 | val_loss : 60809.3203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 160 | train_loss : 62870.07421875 | val_loss : 87538.1015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 161 | train_loss : 78837.4765625 | val_loss : 114387.140625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 162 | train_loss : 93025.9296875 | val_loss : 75203.7734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 163 | train_loss : 94311.2890625 | val_loss : 17927.546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 164 | train_loss : 29667.08984375 | val_loss : 41843.62109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 165 | train_loss : 35338.55078125 | val_loss : 57883.23828125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 166 | train_loss : 36688.87109375 | val_loss : 33948.76171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 167 | train_loss : 42093.31640625 | val_loss : 70780.3515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 168 | train_loss : 68016.453125 | val_loss : 88305.6484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 169 | train_loss : 74527.3203125 | val_loss : 69370.3125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 170 | train_loss : 64887.05078125 | val_loss : 66574.0 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 171 | train_loss : 67100.765625 | val_loss : 32957.109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 172 | train_loss : 51312.87890625 | val_loss : 35485.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 173 | train_loss : 53256.30078125 | val_loss : 100530.1171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 174 | train_loss : 70782.578125 | val_loss : 78483.734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 175 | train_loss : 63020.203125 | val_loss : 58248.58984375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 176 | train_loss : 80899.1484375 | val_loss : 60952.0703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 177 | train_loss : 90741.578125 | val_loss : 87213.7109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 178 | train_loss : 96751.65625 | val_loss : 30742.27734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 179 | train_loss : 54569.921875 | val_loss : 31362.154296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 180 | train_loss : 33852.484375 | val_loss : 85462.9375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 181 | train_loss : 51014.48828125 | val_loss : 27055.705078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 182 | train_loss : 31032.48046875 | val_loss : 42990.7734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 183 | train_loss : 45064.640625 | val_loss : 58434.359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 184 | train_loss : 41572.39453125 | val_loss : 37429.39453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 185 | train_loss : 42157.3359375 | val_loss : 36737.859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 186 | train_loss : 42935.6015625 | val_loss : 63510.390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 187 | train_loss : 47648.328125 | val_loss : 42676.87109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 188 | train_loss : 46560.30859375 | val_loss : 57090.0703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 189 | train_loss : 81103.65625 | val_loss : 86231.9375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 190 | train_loss : 81346.40625 | val_loss : 43754.35546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 191 | train_loss : 65675.9375 | val_loss : 91234.296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 192 | train_loss : 80676.1640625 | val_loss : 68598.3515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 193 | train_loss : 76738.0703125 | val_loss : 79455.3515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 194 | train_loss : 82313.703125 | val_loss : 51929.390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 195 | train_loss : 44150.9296875 | val_loss : 42206.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 196 | train_loss : 44897.07421875 | val_loss : 68364.9375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 197 | train_loss : 65801.09375 | val_loss : 43576.62890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 198 | train_loss : 53906.953125 | val_loss : 64576.31640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 199 | train_loss : 46097.35546875 | val_loss : 23317.8046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 200 | train_loss : 29617.779296875 | val_loss : 48461.23828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 201 | train_loss : 51361.83984375 | val_loss : 22865.91015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 202 | train_loss : 43135.8984375 | val_loss : 48145.66015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 203 | train_loss : 52668.39453125 | val_loss : 12046.84765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 204 | train_loss : 16407.998046875 | val_loss : 16519.193359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 205 | train_loss : 31729.431640625 | val_loss : 38022.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 206 | train_loss : 51969.3515625 | val_loss : 52074.26171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 207 | train_loss : 51775.94140625 | val_loss : 30008.05078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 208 | train_loss : 31641.720703125 | val_loss : 26764.509765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 209 | train_loss : 41260.8359375 | val_loss : 43599.5703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 210 | train_loss : 38279.53125 | val_loss : 56848.80859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 211 | train_loss : 72086.75 | val_loss : 70624.0390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 212 | train_loss : 79705.828125 | val_loss : 70053.96875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 213 | train_loss : 87109.8203125 | val_loss : 51149.48828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 214 | train_loss : 48565.140625 | val_loss : 24528.130859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 215 | train_loss : 44932.4609375 | val_loss : 105059.796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 216 | train_loss : 65062.7265625 | val_loss : 47523.1640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 217 | train_loss : 40363.9765625 | val_loss : 68457.7734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 218 | train_loss : 46694.046875 | val_loss : 48711.484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 219 | train_loss : 55680.35546875 | val_loss : 60445.75390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 220 | train_loss : 39792.2734375 | val_loss : 46120.5390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 221 | train_loss : 36192.88671875 | val_loss : 51829.234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 222 | train_loss : 54219.14453125 | val_loss : 37630.98828125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 223 | train_loss : 52514.578125 | val_loss : 54682.94140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 224 | train_loss : 42226.12109375 | val_loss : 45880.08984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 225 | train_loss : 51010.171875 | val_loss : 64735.8984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 226 | train_loss : 69625.15625 | val_loss : 27639.068359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 227 | train_loss : 58223.37890625 | val_loss : 71012.7578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 228 | train_loss : 55877.34375 | val_loss : 25791.744140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 229 | train_loss : 41412.24609375 | val_loss : 62754.078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 230 | train_loss : 44372.6015625 | val_loss : 31904.494140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 231 | train_loss : 27785.630859375 | val_loss : 26381.779296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 232 | train_loss : 32845.25390625 | val_loss : 50910.80078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 233 | train_loss : 32562.279296875 | val_loss : 19517.42578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 234 | train_loss : 21071.787109375 | val_loss : 23237.505859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 235 | train_loss : 28273.1953125 | val_loss : 50756.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 236 | train_loss : 50074.3984375 | val_loss : 43845.73828125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 237 | train_loss : 42442.87109375 | val_loss : 29084.8125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 238 | train_loss : 25828.58984375 | val_loss : 53881.5390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 239 | train_loss : 51165.71875 | val_loss : 26412.34765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 240 | train_loss : 41658.7890625 | val_loss : 43453.51953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 241 | train_loss : 43676.09375 | val_loss : 30723.71484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 242 | train_loss : 26295.53515625 | val_loss : 42114.05859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 243 | train_loss : 37895.12890625 | val_loss : 100069.3203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 244 | train_loss : 94038.3125 | val_loss : 46198.69140625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 245 | train_loss : 55023.82421875 | val_loss : 21659.3125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 246 | train_loss : 36510.01953125 | val_loss : 64526.56640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 247 | train_loss : 39867.328125 | val_loss : 25738.982421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 248 | train_loss : 29341.5859375 | val_loss : 15747.14453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 249 | train_loss : 28075.908203125 | val_loss : 18139.60546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 250 | train_loss : 27785.982421875 | val_loss : 33378.0234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 251 | train_loss : 23137.4921875 | val_loss : 28021.802734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 252 | train_loss : 27860.880859375 | val_loss : 57079.28125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 253 | train_loss : 45978.96484375 | val_loss : 14140.5546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 254 | train_loss : 33801.48046875 | val_loss : 20507.7890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 255 | train_loss : 19880.3828125 | val_loss : 18904.814453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 256 | train_loss : 29923.357421875 | val_loss : 61113.76171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 257 | train_loss : 62733.6796875 | val_loss : 23111.484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 258 | train_loss : 50915.76171875 | val_loss : 53681.53125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 259 | train_loss : 42372.98046875 | val_loss : 22294.9296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 260 | train_loss : 31803.154296875 | val_loss : 30329.515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 261 | train_loss : 36032.2734375 | val_loss : 44208.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 262 | train_loss : 39364.19140625 | val_loss : 40978.32421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 263 | train_loss : 31164.595703125 | val_loss : 12167.919921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 264 | train_loss : 21055.341796875 | val_loss : 48674.94921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 265 | train_loss : 28713.345703125 | val_loss : 23592.185546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 266 | train_loss : 36098.80078125 | val_loss : 36652.6328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 267 | train_loss : 41944.14453125 | val_loss : 18139.546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 268 | train_loss : 36997.74609375 | val_loss : 51629.26171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 269 | train_loss : 36514.9765625 | val_loss : 14652.9853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 270 | train_loss : 31890.16796875 | val_loss : 31565.732421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 271 | train_loss : 42433.4453125 | val_loss : 28425.83984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 272 | train_loss : 35044.85546875 | val_loss : 21664.330078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 273 | train_loss : 35257.08984375 | val_loss : 35559.68359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 274 | train_loss : 33645.4453125 | val_loss : 21520.447265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 275 | train_loss : 32700.259765625 | val_loss : 15792.6845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 276 | train_loss : 32009.4296875 | val_loss : 36105.78125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 277 | train_loss : 28892.69921875 | val_loss : 35210.0859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 278 | train_loss : 28939.341796875 | val_loss : 36342.05078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 279 | train_loss : 45150.09375 | val_loss : 49407.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 280 | train_loss : 40276.4453125 | val_loss : 28316.841796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 281 | train_loss : 35196.17578125 | val_loss : 27451.83984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 282 | train_loss : 33451.0078125 | val_loss : 36968.86328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 283 | train_loss : 25819.017578125 | val_loss : 39870.50390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 284 | train_loss : 26505.5 | val_loss : 20753.85546875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 285 | train_loss : 30359.0 | val_loss : 54260.5703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 286 | train_loss : 41952.0859375 | val_loss : 18065.98046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 287 | train_loss : 25732.9453125 | val_loss : 45628.84375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 288 | train_loss : 29819.58203125 | val_loss : 26976.6640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 289 | train_loss : 23544.48046875 | val_loss : 23468.822265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 290 | train_loss : 27683.072265625 | val_loss : 28924.578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 291 | train_loss : 25777.345703125 | val_loss : 30655.921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 292 | train_loss : 29892.564453125 | val_loss : 40935.23828125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 293 | train_loss : 30573.185546875 | val_loss : 21765.244140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 294 | train_loss : 29270.46484375 | val_loss : 21153.17578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 295 | train_loss : 29618.859375 | val_loss : 37332.21875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 296 | train_loss : 30847.966796875 | val_loss : 13293.4873046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 297 | train_loss : 14245.4970703125 | val_loss : 11055.8525390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 298 | train_loss : 14655.791015625 | val_loss : 24780.509765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 299 | train_loss : 22494.552734375 | val_loss : 16774.6484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 300 | train_loss : 25807.09765625 | val_loss : 66064.0390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 301 | train_loss : 43372.23046875 | val_loss : 12985.66015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 302 | train_loss : 28267.3515625 | val_loss : 38319.61328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 303 | train_loss : 40054.04296875 | val_loss : 44403.33984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 304 | train_loss : 57746.7734375 | val_loss : 48019.01953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 305 | train_loss : 46070.99609375 | val_loss : 38957.71484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 306 | train_loss : 32352.9375 | val_loss : 14589.8427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 307 | train_loss : 30591.869140625 | val_loss : 45678.3046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 308 | train_loss : 40568.17578125 | val_loss : 21608.5390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 309 | train_loss : 39625.75390625 | val_loss : 33876.2578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 310 | train_loss : 31097.095703125 | val_loss : 44438.359375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 311 | train_loss : 37754.89453125 | val_loss : 22333.3203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 312 | train_loss : 31325.21484375 | val_loss : 42423.7109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 313 | train_loss : 38230.078125 | val_loss : 16751.693359375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 314 | train_loss : 39493.89453125 | val_loss : 39702.5234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 315 | train_loss : 42842.65625 | val_loss : 46073.23046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 316 | train_loss : 56735.48046875 | val_loss : 37635.29296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 317 | train_loss : 39446.6015625 | val_loss : 19691.36328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 318 | train_loss : 37155.26171875 | val_loss : 28937.931640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 319 | train_loss : 30745.359375 | val_loss : 25778.6484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 320 | train_loss : 39834.5234375 | val_loss : 73915.953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 321 | train_loss : 48368.8046875 | val_loss : 24355.234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 322 | train_loss : 29013.66015625 | val_loss : 19968.232421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 323 | train_loss : 26937.1640625 | val_loss : 23233.669921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 324 | train_loss : 31051.1796875 | val_loss : 28059.91796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 325 | train_loss : 34154.515625 | val_loss : 29041.08203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 326 | train_loss : 25067.640625 | val_loss : 13366.0 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 327 | train_loss : 17132.509765625 | val_loss : 13234.5078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 328 | train_loss : 17491.927734375 | val_loss : 11373.849609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 329 | train_loss : 26098.400390625 | val_loss : 44721.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 330 | train_loss : 28236.7265625 | val_loss : 14752.400390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 331 | train_loss : 20735.453125 | val_loss : 40241.34375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 332 | train_loss : 33800.49609375 | val_loss : 24912.689453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 333 | train_loss : 34285.171875 | val_loss : 15372.3525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 334 | train_loss : 16228.9404296875 | val_loss : 20737.197265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 335 | train_loss : 18767.234375 | val_loss : 52508.5703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 336 | train_loss : 38704.48046875 | val_loss : 11386.6025390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 337 | train_loss : 18776.462890625 | val_loss : 9380.2373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 338 | train_loss : 17847.671875 | val_loss : 57066.71875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 339 | train_loss : 37757.01953125 | val_loss : 11201.4775390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 340 | train_loss : 14871.4375 | val_loss : 10136.96484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 341 | train_loss : 17871.69921875 | val_loss : 27237.36328125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 342 | train_loss : 30160.140625 | val_loss : 20738.7890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 343 | train_loss : 35784.23046875 | val_loss : 61069.5703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 344 | train_loss : 43815.55859375 | val_loss : 17283.572265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 345 | train_loss : 28458.9453125 | val_loss : 39571.94921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 346 | train_loss : 49665.2109375 | val_loss : 59672.6484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 347 | train_loss : 41082.80859375 | val_loss : 31141.13671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 348 | train_loss : 26389.087890625 | val_loss : 18319.92578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 349 | train_loss : 30975.01953125 | val_loss : 51422.87890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 350 | train_loss : 38672.0703125 | val_loss : 16856.126953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 351 | train_loss : 27295.6953125 | val_loss : 21184.7578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 352 | train_loss : 22640.9921875 | val_loss : 29834.04296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 353 | train_loss : 25916.7734375 | val_loss : 21986.443359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 354 | train_loss : 27836.1328125 | val_loss : 28546.373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 355 | train_loss : 29041.7890625 | val_loss : 29696.9765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 356 | train_loss : 27499.125 | val_loss : 19746.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 357 | train_loss : 31660.919921875 | val_loss : 38330.81640625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 358 | train_loss : 38821.17578125 | val_loss : 30933.654296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 359 | train_loss : 27064.568359375 | val_loss : 27143.515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 360 | train_loss : 33016.6953125 | val_loss : 31334.33984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 361 | train_loss : 33012.5390625 | val_loss : 11794.7373046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 362 | train_loss : 25057.53515625 | val_loss : 33242.5625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 363 | train_loss : 30499.28515625 | val_loss : 26412.830078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 364 | train_loss : 26819.099609375 | val_loss : 45908.5 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 365 | train_loss : 40779.21484375 | val_loss : 6679.60009765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 366 | train_loss : 23541.322265625 | val_loss : 26525.88671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 367 | train_loss : 21677.078125 | val_loss : 19690.044921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 368 | train_loss : 26141.4921875 | val_loss : 47075.56640625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 369 | train_loss : 41185.87890625 | val_loss : 12692.1845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 370 | train_loss : 37196.93359375 | val_loss : 18789.892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 371 | train_loss : 19315.6171875 | val_loss : 19820.189453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 372 | train_loss : 34349.6015625 | val_loss : 44313.19921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 373 | train_loss : 31829.904296875 | val_loss : 7479.78515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 374 | train_loss : 18416.921875 | val_loss : 19619.283203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 375 | train_loss : 18702.515625 | val_loss : 13768.927734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 376 | train_loss : 19909.076171875 | val_loss : 42065.78125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 377 | train_loss : 33795.953125 | val_loss : 88962.953125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 378 | train_loss : 139156.875 | val_loss : 56489.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 379 | train_loss : 72358.1484375 | val_loss : 58760.60546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 380 | train_loss : 53158.0390625 | val_loss : 32322.501953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 381 | train_loss : 30669.27734375 | val_loss : 23085.8359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 382 | train_loss : 30676.974609375 | val_loss : 60553.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 383 | train_loss : 36238.36328125 | val_loss : 23134.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 384 | train_loss : 14219.677734375 | val_loss : 22349.98828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 385 | train_loss : 26417.482421875 | val_loss : 63179.48046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 386 | train_loss : 59137.07421875 | val_loss : 15579.58984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 387 | train_loss : 30185.4296875 | val_loss : 39707.69140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 388 | train_loss : 29107.95703125 | val_loss : 37016.01171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 389 | train_loss : 37964.8046875 | val_loss : 40662.24609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 390 | train_loss : 35909.01953125 | val_loss : 9188.6103515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 391 | train_loss : 24305.865234375 | val_loss : 32214.439453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 392 | train_loss : 29862.744140625 | val_loss : 14741.162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 393 | train_loss : 23874.57421875 | val_loss : 40712.8359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 394 | train_loss : 28521.51953125 | val_loss : 6111.767578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 395 | train_loss : 19339.88671875 | val_loss : 19720.359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 396 | train_loss : 17643.541015625 | val_loss : 12646.544921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 397 | train_loss : 21399.302734375 | val_loss : 41848.44921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 398 | train_loss : 25169.4453125 | val_loss : 8630.892578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 399 | train_loss : 10519.0791015625 | val_loss : 9562.02734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 400 | train_loss : 15739.78125 | val_loss : 22152.22265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 401 | train_loss : 15410.63671875 | val_loss : 9932.552734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 402 | train_loss : 18362.216796875 | val_loss : 20177.572265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 403 | train_loss : 14768.91796875 | val_loss : 16083.7724609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 404 | train_loss : 19801.34765625 | val_loss : 12143.2373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 405 | train_loss : 18860.615234375 | val_loss : 8772.84765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 406 | train_loss : 9039.48828125 | val_loss : 24591.88671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 407 | train_loss : 15442.7470703125 | val_loss : 15989.4296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 408 | train_loss : 19961.57421875 | val_loss : 19996.4375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 409 | train_loss : 23060.55078125 | val_loss : 37675.5078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 410 | train_loss : 31338.32421875 | val_loss : 33027.13671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 411 | train_loss : 31677.13671875 | val_loss : 24786.20703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 412 | train_loss : 26688.96484375 | val_loss : 25990.66015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 413 | train_loss : 23105.16796875 | val_loss : 26143.552734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 414 | train_loss : 28566.33203125 | val_loss : 9468.76953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 415 | train_loss : 8095.81201171875 | val_loss : 6373.28759765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 416 | train_loss : 7461.03955078125 | val_loss : 8811.27734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 417 | train_loss : 8363.8759765625 | val_loss : 9316.2529296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 418 | train_loss : 15334.169921875 | val_loss : 17054.3828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 419 | train_loss : 16201.72265625 | val_loss : 13337.3427734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 420 | train_loss : 22348.931640625 | val_loss : 38504.6484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 421 | train_loss : 27754.3828125 | val_loss : 11871.83203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 422 | train_loss : 19389.634765625 | val_loss : 13831.125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 423 | train_loss : 21912.796875 | val_loss : 24117.96484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 424 | train_loss : 22373.240234375 | val_loss : 22699.6953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 425 | train_loss : 23384.2890625 | val_loss : 13152.087890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 426 | train_loss : 17634.8828125 | val_loss : 26217.9296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 427 | train_loss : 26319.9921875 | val_loss : 8620.6748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 428 | train_loss : 24498.63671875 | val_loss : 36931.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 429 | train_loss : 28322.23828125 | val_loss : 13362.642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 430 | train_loss : 16656.1953125 | val_loss : 13059.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 431 | train_loss : 10311.1279296875 | val_loss : 14534.8251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 432 | train_loss : 16173.32421875 | val_loss : 11718.78515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 433 | train_loss : 10717.837890625 | val_loss : 141934.4375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 434 | train_loss : 152968.015625 | val_loss : 49626.34375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 435 | train_loss : 41707.37890625 | val_loss : 25056.73046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 436 | train_loss : 27685.921875 | val_loss : 17893.859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 437 | train_loss : 15637.2958984375 | val_loss : 18376.6171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 438 | train_loss : 21286.9296875 | val_loss : 29238.05078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 439 | train_loss : 22816.587890625 | val_loss : 20820.224609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 440 | train_loss : 19645.1796875 | val_loss : 25285.115234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 441 | train_loss : 21047.255859375 | val_loss : 19066.01953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 442 | train_loss : 23181.060546875 | val_loss : 15467.5322265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 443 | train_loss : 17615.591796875 | val_loss : 12356.400390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 444 | train_loss : 14088.892578125 | val_loss : 12083.3974609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 445 | train_loss : 14660.5029296875 | val_loss : 10254.5673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 446 | train_loss : 14383.017578125 | val_loss : 17847.421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 447 | train_loss : 17447.607421875 | val_loss : 19504.404296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 448 | train_loss : 18856.990234375 | val_loss : 6148.21240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 449 | train_loss : 9196.0947265625 | val_loss : 27735.158203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 450 | train_loss : 18387.443359375 | val_loss : 5082.6923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 451 | train_loss : 12949.7626953125 | val_loss : 34603.37890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 452 | train_loss : 21650.857421875 | val_loss : 10099.2802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 453 | train_loss : 19788.306640625 | val_loss : 17290.197265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 454 | train_loss : 20122.83984375 | val_loss : 17689.626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 455 | train_loss : 18635.47265625 | val_loss : 26175.072265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 456 | train_loss : 22591.7890625 | val_loss : 8588.5703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 457 | train_loss : 15125.494140625 | val_loss : 42240.36328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 458 | train_loss : 27049.80078125 | val_loss : 11576.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 459 | train_loss : 16682.28125 | val_loss : 17471.41796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 460 | train_loss : 19692.60546875 | val_loss : 14269.4072265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 461 | train_loss : 17929.7265625 | val_loss : 16460.51953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 462 | train_loss : 15645.9853515625 | val_loss : 7844.78271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 463 | train_loss : 11012.3779296875 | val_loss : 11880.2900390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 464 | train_loss : 14545.62890625 | val_loss : 11784.4501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 465 | train_loss : 12118.275390625 | val_loss : 14845.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 466 | train_loss : 13832.7373046875 | val_loss : 7289.7626953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 467 | train_loss : 7560.009765625 | val_loss : 6336.41259765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 468 | train_loss : 6160.40380859375 | val_loss : 98703.65625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 469 | train_loss : 87219.8671875 | val_loss : 57377.57421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 470 | train_loss : 52722.00390625 | val_loss : 27361.404296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 471 | train_loss : 37561.87109375 | val_loss : 34289.88671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 472 | train_loss : 29472.775390625 | val_loss : 28935.59765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 473 | train_loss : 39488.03515625 | val_loss : 32707.193359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 474 | train_loss : 27397.0078125 | val_loss : 18805.154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 475 | train_loss : 17587.32421875 | val_loss : 18735.9765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 476 | train_loss : 17479.060546875 | val_loss : 34221.29296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 477 | train_loss : 22071.125 | val_loss : 17457.078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 478 | train_loss : 19613.615234375 | val_loss : 17675.419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 479 | train_loss : 26750.67578125 | val_loss : 13248.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 480 | train_loss : 19496.845703125 | val_loss : 15292.8876953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 481 | train_loss : 14608.142578125 | val_loss : 15563.4677734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 482 | train_loss : 19147.23828125 | val_loss : 10568.080078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 483 | train_loss : 20160.431640625 | val_loss : 32826.234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 484 | train_loss : 23758.447265625 | val_loss : 10384.7890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 485 | train_loss : 17679.681640625 | val_loss : 21721.134765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 486 | train_loss : 19276.953125 | val_loss : 15032.7646484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 487 | train_loss : 16182.3896484375 | val_loss : 9639.3125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 488 | train_loss : 9784.287109375 | val_loss : 13496.9970703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 489 | train_loss : 15487.11328125 | val_loss : 20282.6875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 490 | train_loss : 16124.22265625 | val_loss : 6911.60986328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 491 | train_loss : 14950.8828125 | val_loss : 32184.0390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 492 | train_loss : 22158.875 | val_loss : 17240.5234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 493 | train_loss : 21622.7734375 | val_loss : 25860.474609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 494 | train_loss : 25531.734375 | val_loss : 13786.2978515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 495 | train_loss : 22649.1875 | val_loss : 16005.5771484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 496 | train_loss : 8797.08203125 | val_loss : 7924.62744140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 497 | train_loss : 12909.9970703125 | val_loss : 23545.681640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 498 | train_loss : 17883.740234375 | val_loss : 13932.96484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 499 | train_loss : 19932.7890625 | val_loss : 16742.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 500 | train_loss : 10511.1416015625 | val_loss : 6724.11767578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 501 | train_loss : 10838.50390625 | val_loss : 29312.240234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 502 | train_loss : 17404.998046875 | val_loss : 8692.2353515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 503 | train_loss : 14155.57421875 | val_loss : 12475.70703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 504 | train_loss : 15450.990234375 | val_loss : 5342.24755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 505 | train_loss : 15594.8876953125 | val_loss : 21619.7109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 506 | train_loss : 18512.962890625 | val_loss : 17930.38671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 507 | train_loss : 25885.296875 | val_loss : 32872.11328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 508 | train_loss : 30118.0 | val_loss : 17736.685546875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 509 | train_loss : 28019.48046875 | val_loss : 28639.259765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 510 | train_loss : 22800.55078125 | val_loss : 10430.900390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 511 | train_loss : 18797.23828125 | val_loss : 10524.763671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 512 | train_loss : 16252.416015625 | val_loss : 25481.623046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 513 | train_loss : 19966.205078125 | val_loss : 15935.6650390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 514 | train_loss : 16512.619140625 | val_loss : 14540.0654296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 515 | train_loss : 13908.482421875 | val_loss : 7223.5 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 516 | train_loss : 13594.2421875 | val_loss : 29671.630859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 517 | train_loss : 19801.5078125 | val_loss : 5983.8623046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 518 | train_loss : 14447.787109375 | val_loss : 28946.44921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 519 | train_loss : 22636.3046875 | val_loss : 6408.68017578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 520 | train_loss : 9244.95703125 | val_loss : 16091.6171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 521 | train_loss : 14546.59375 | val_loss : 10706.7763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 522 | train_loss : 19188.658203125 | val_loss : 38783.203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 523 | train_loss : 25263.953125 | val_loss : 11803.6220703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 524 | train_loss : 8756.494140625 | val_loss : 11504.232421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 525 | train_loss : 12816.767578125 | val_loss : 25185.412109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 526 | train_loss : 20126.287109375 | val_loss : 6475.392578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 527 | train_loss : 18143.6953125 | val_loss : 16648.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 528 | train_loss : 13793.66015625 | val_loss : 18549.30078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 529 | train_loss : 19706.6875 | val_loss : 30268.373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 530 | train_loss : 25133.5859375 | val_loss : 6099.771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 531 | train_loss : 18476.16796875 | val_loss : 22583.42578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 532 | train_loss : 16056.6513671875 | val_loss : 8812.1337890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 533 | train_loss : 11411.2861328125 | val_loss : 30751.501953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 534 | train_loss : 20973.955078125 | val_loss : 6109.541015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 535 | train_loss : 14295.3525390625 | val_loss : 20266.16796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 536 | train_loss : 16420.66796875 | val_loss : 5373.580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 537 | train_loss : 12186.544921875 | val_loss : 26255.05078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 538 | train_loss : 17551.154296875 | val_loss : 10005.302734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 539 | train_loss : 12819.857421875 | val_loss : 15487.1884765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 540 | train_loss : 14215.2041015625 | val_loss : 6027.26611328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 541 | train_loss : 14769.4208984375 | val_loss : 28845.48828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 542 | train_loss : 19309.060546875 | val_loss : 4857.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 543 | train_loss : 8866.30078125 | val_loss : 8027.37744140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 544 | train_loss : 9431.22265625 | val_loss : 15026.212890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 545 | train_loss : 16599.720703125 | val_loss : 16174.51953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 546 | train_loss : 10225.5966796875 | val_loss : 3555.392578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 547 | train_loss : 7114.986328125 | val_loss : 13790.677734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 548 | train_loss : 9742.9345703125 | val_loss : 9910.212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 549 | train_loss : 12060.6650390625 | val_loss : 19291.212890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 550 | train_loss : 15116.8125 | val_loss : 8327.150390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 551 | train_loss : 10089.455078125 | val_loss : 9811.9140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 552 | train_loss : 12803.09765625 | val_loss : 15922.427734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 553 | train_loss : 10694.8798828125 | val_loss : 4920.4560546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 554 | train_loss : 9012.0634765625 | val_loss : 17444.9765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 555 | train_loss : 13888.50390625 | val_loss : 22289.51953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 556 | train_loss : 28147.328125 | val_loss : 31007.380859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 557 | train_loss : 24820.400390625 | val_loss : 6957.861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 558 | train_loss : 14866.6591796875 | val_loss : 12467.6904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 559 | train_loss : 12942.806640625 | val_loss : 15212.9013671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 560 | train_loss : 12408.150390625 | val_loss : 8666.75390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 561 | train_loss : 14255.4013671875 | val_loss : 46449.453125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 562 | train_loss : 34976.52734375 | val_loss : 15095.2451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 563 | train_loss : 21297.30078125 | val_loss : 23457.41796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 564 | train_loss : 18848.408203125 | val_loss : 13097.611328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 565 | train_loss : 13784.5703125 | val_loss : 23057.484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 566 | train_loss : 24081.375 | val_loss : 21024.615234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 567 | train_loss : 27176.310546875 | val_loss : 13119.8046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 568 | train_loss : 13655.75 | val_loss : 6708.986328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 569 | train_loss : 6331.62353515625 | val_loss : 4425.29736328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 570 | train_loss : 9486.5166015625 | val_loss : 29875.04296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 571 | train_loss : 18613.158203125 | val_loss : 7229.14892578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 572 | train_loss : 14503.2822265625 | val_loss : 21632.509765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 573 | train_loss : 14571.9052734375 | val_loss : 10588.3271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 574 | train_loss : 10942.107421875 | val_loss : 4128.51513671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 575 | train_loss : 8885.8134765625 | val_loss : 20062.57421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 576 | train_loss : 15620.7109375 | val_loss : 6748.25146484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 577 | train_loss : 11908.916015625 | val_loss : 30626.59765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 578 | train_loss : 18936.203125 | val_loss : 10827.9609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 579 | train_loss : 9384.24609375 | val_loss : 8411.3037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 580 | train_loss : 14705.6962890625 | val_loss : 30199.095703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 581 | train_loss : 19683.169921875 | val_loss : 10618.0576171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 582 | train_loss : 14676.57421875 | val_loss : 11162.2646484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 583 | train_loss : 16737.509765625 | val_loss : 11390.4951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 584 | train_loss : 9823.447265625 | val_loss : 5739.3564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 585 | train_loss : 6072.84423828125 | val_loss : 12945.396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 586 | train_loss : 7796.5888671875 | val_loss : 4539.6435546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 587 | train_loss : 11089.650390625 | val_loss : 19285.53125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 588 | train_loss : 12672.6376953125 | val_loss : 7727.6376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 589 | train_loss : 12473.017578125 | val_loss : 18229.677734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 590 | train_loss : 15307.2646484375 | val_loss : 13928.642578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 591 | train_loss : 13764.21875 | val_loss : 10238.880859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 592 | train_loss : 17157.650390625 | val_loss : 37504.96484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 593 | train_loss : 25069.365234375 | val_loss : 7358.9423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 594 | train_loss : 6616.64208984375 | val_loss : 7861.330078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 595 | train_loss : 9676.0537109375 | val_loss : 28934.796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 596 | train_loss : 20368.85546875 | val_loss : 3060.701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 597 | train_loss : 6366.81640625 | val_loss : 4940.294921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 598 | train_loss : 4800.037109375 | val_loss : 4435.7001953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 599 | train_loss : 7759.4716796875 | val_loss : 17791.841796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 600 | train_loss : 16215.240234375 | val_loss : 6763.60986328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 601 | train_loss : 14866.0888671875 | val_loss : 29574.462890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 602 | train_loss : 18062.853515625 | val_loss : 9720.6240234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 603 | train_loss : 13856.4697265625 | val_loss : 10874.5615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 604 | train_loss : 16153.26953125 | val_loss : 21257.89453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 605 | train_loss : 18941.8359375 | val_loss : 23098.498046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 606 | train_loss : 32436.900390625 | val_loss : 39184.38671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 607 | train_loss : 24396.572265625 | val_loss : 15168.8701171875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 608 | train_loss : 16649.787109375 | val_loss : 11698.166015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 609 | train_loss : 17986.08203125 | val_loss : 15451.923828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 610 | train_loss : 9784.9638671875 | val_loss : 8897.900390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 611 | train_loss : 6973.814453125 | val_loss : 7357.90478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 612 | train_loss : 12067.70703125 | val_loss : 26218.330078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 613 | train_loss : 15997.4052734375 | val_loss : 8250.6259765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 614 | train_loss : 11029.93359375 | val_loss : 9132.9833984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 615 | train_loss : 10634.4521484375 | val_loss : 7426.1064453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 616 | train_loss : 9381.78125 | val_loss : 10338.3310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 617 | train_loss : 12317.1279296875 | val_loss : 16706.689453125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 618 | train_loss : 14785.0361328125 | val_loss : 5660.36767578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 619 | train_loss : 7116.59619140625 | val_loss : 24138.623046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 620 | train_loss : 16769.498046875 | val_loss : 3461.5986328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 621 | train_loss : 9123.2041015625 | val_loss : 24351.529296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 622 | train_loss : 17176.533203125 | val_loss : 8259.2509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 623 | train_loss : 8369.5341796875 | val_loss : 3266.445068359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 624 | train_loss : 9750.767578125 | val_loss : 14745.59375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 625 | train_loss : 11275.46484375 | val_loss : 7872.8388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 626 | train_loss : 8784.1416015625 | val_loss : 16475.814453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 627 | train_loss : 11238.744140625 | val_loss : 4036.639892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 628 | train_loss : 8052.1748046875 | val_loss : 11497.53515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 629 | train_loss : 10741.9365234375 | val_loss : 7052.05517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 630 | train_loss : 10581.818359375 | val_loss : 22330.845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 631 | train_loss : 12724.419921875 | val_loss : 2986.179931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 632 | train_loss : 8718.666015625 | val_loss : 10831.16015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 633 | train_loss : 8402.28515625 | val_loss : 3711.53759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 634 | train_loss : 5402.48876953125 | val_loss : 13957.8173828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 635 | train_loss : 10063.2890625 | val_loss : 4480.31494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 636 | train_loss : 10241.8515625 | val_loss : 23463.640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 637 | train_loss : 14680.7021484375 | val_loss : 8018.06884765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 638 | train_loss : 8337.7109375 | val_loss : 6213.41015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 639 | train_loss : 12569.66796875 | val_loss : 24612.85546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 640 | train_loss : 15392.267578125 | val_loss : 7245.89111328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 641 | train_loss : 6180.93994140625 | val_loss : 6163.166015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 642 | train_loss : 6034.77978515625 | val_loss : 17193.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 643 | train_loss : 9433.1552734375 | val_loss : 3515.3173828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 644 | train_loss : 9254.0185546875 | val_loss : 11083.81640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 645 | train_loss : 8842.755859375 | val_loss : 6848.50634765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 646 | train_loss : 8969.201171875 | val_loss : 16420.380859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 647 | train_loss : 11424.072265625 | val_loss : 5117.134765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 648 | train_loss : 5127.6787109375 | val_loss : 7248.1611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 649 | train_loss : 8283.1396484375 | val_loss : 12477.8837890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 650 | train_loss : 11378.8583984375 | val_loss : 9790.162109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 651 | train_loss : 10325.74609375 | val_loss : 23259.55078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 652 | train_loss : 18272.865234375 | val_loss : 6614.25 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 653 | train_loss : 12811.6865234375 | val_loss : 30740.609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 654 | train_loss : 18856.4765625 | val_loss : 8231.5966796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 655 | train_loss : 11272.32421875 | val_loss : 5418.67626953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 656 | train_loss : 6305.0908203125 | val_loss : 19453.119140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 657 | train_loss : 21868.26953125 | val_loss : 21498.6328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 658 | train_loss : 15876.27734375 | val_loss : 19210.091796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 659 | train_loss : 11764.9921875 | val_loss : 5566.7451171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 660 | train_loss : 10637.7021484375 | val_loss : 23096.849609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 661 | train_loss : 13979.302734375 | val_loss : 5370.99609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 662 | train_loss : 8644.357421875 | val_loss : 6774.06396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 663 | train_loss : 10719.0341796875 | val_loss : 11520.2490234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 664 | train_loss : 12683.5390625 | val_loss : 7865.24755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 665 | train_loss : 14087.2958984375 | val_loss : 18486.701171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 666 | train_loss : 14897.4521484375 | val_loss : 5521.923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 667 | train_loss : 6533.11767578125 | val_loss : 17775.05859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 668 | train_loss : 11459.2041015625 | val_loss : 6992.28515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 669 | train_loss : 8544.7978515625 | val_loss : 20811.90234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 670 | train_loss : 11935.419921875 | val_loss : 3516.907470703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 671 | train_loss : 9317.884765625 | val_loss : 19140.837890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 672 | train_loss : 12063.822265625 | val_loss : 8611.68359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 673 | train_loss : 10094.478515625 | val_loss : 12456.21484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 674 | train_loss : 8536.724609375 | val_loss : 5740.80859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 675 | train_loss : 5259.7314453125 | val_loss : 4687.8798828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 676 | train_loss : 7415.59423828125 | val_loss : 10669.787109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 677 | train_loss : 6624.60888671875 | val_loss : 4947.58251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 678 | train_loss : 8614.529296875 | val_loss : 30683.095703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 679 | train_loss : 18627.0 | val_loss : 5593.27490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 680 | train_loss : 9523.35546875 | val_loss : 4844.271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 681 | train_loss : 9321.7861328125 | val_loss : 16779.251953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 682 | train_loss : 11466.3583984375 | val_loss : 11154.95703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 683 | train_loss : 19506.318359375 | val_loss : 33009.2265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 684 | train_loss : 19064.310546875 | val_loss : 10449.005859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 685 | train_loss : 8676.6396484375 | val_loss : 5156.31884765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 686 | train_loss : 7860.90576171875 | val_loss : 23626.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 687 | train_loss : 14404.02734375 | val_loss : 3595.197509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 688 | train_loss : 6137.2763671875 | val_loss : 5040.021484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 689 | train_loss : 5838.2998046875 | val_loss : 9710.6845703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 690 | train_loss : 7401.2919921875 | val_loss : 6636.69482421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 691 | train_loss : 9510.5009765625 | val_loss : 22179.73046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 692 | train_loss : 11506.9951171875 | val_loss : 4004.41748046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 693 | train_loss : 5263.08203125 | val_loss : 8610.275390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 694 | train_loss : 8449.431640625 | val_loss : 6417.85986328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 695 | train_loss : 7280.5537109375 | val_loss : 5545.0849609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 696 | train_loss : 6340.396484375 | val_loss : 15555.6953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 697 | train_loss : 10995.919921875 | val_loss : 5225.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 698 | train_loss : 12633.83203125 | val_loss : 23252.224609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 699 | train_loss : 14184.990234375 | val_loss : 3560.81884765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 700 | train_loss : 4834.39697265625 | val_loss : 6862.08642578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 701 | train_loss : 4407.68310546875 | val_loss : 5156.205078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 702 | train_loss : 6375.73583984375 | val_loss : 6232.90869140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 703 | train_loss : 5300.43505859375 | val_loss : 12286.912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 704 | train_loss : 6634.4150390625 | val_loss : 7563.84619140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 705 | train_loss : 8368.40234375 | val_loss : 5171.4248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 706 | train_loss : 10474.6220703125 | val_loss : 27838.5625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 707 | train_loss : 15105.36328125 | val_loss : 7334.333984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 708 | train_loss : 5304.21875 | val_loss : 7784.4736328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 709 | train_loss : 13516.79296875 | val_loss : 23340.3671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 710 | train_loss : 15852.1953125 | val_loss : 16663.345703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 711 | train_loss : 17090.505859375 | val_loss : 11328.3876953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 712 | train_loss : 15682.3271484375 | val_loss : 18475.623046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 713 | train_loss : 10784.537109375 | val_loss : 6249.36376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 714 | train_loss : 10939.865234375 | val_loss : 20792.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 715 | train_loss : 13100.552734375 | val_loss : 4804.94873046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 716 | train_loss : 11523.0634765625 | val_loss : 20951.978515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 717 | train_loss : 14617.9775390625 | val_loss : 6612.0361328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 718 | train_loss : 9932.3916015625 | val_loss : 6302.30126953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 719 | train_loss : 9284.5810546875 | val_loss : 4350.04736328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 720 | train_loss : 7252.05517578125 | val_loss : 17566.65234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 721 | train_loss : 11658.912109375 | val_loss : 3409.527587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 722 | train_loss : 7749.0849609375 | val_loss : 13283.6953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 723 | train_loss : 9884.1279296875 | val_loss : 9582.56640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 724 | train_loss : 10259.0283203125 | val_loss : 8222.6220703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 725 | train_loss : 5446.82568359375 | val_loss : 5419.0625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 726 | train_loss : 8505.8916015625 | val_loss : 17289.677734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 727 | train_loss : 9860.916015625 | val_loss : 4228.80859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 728 | train_loss : 7429.712890625 | val_loss : 8003.97021484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 729 | train_loss : 8422.056640625 | val_loss : 12352.263671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 730 | train_loss : 13465.294921875 | val_loss : 39082.01953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 731 | train_loss : 30398.080078125 | val_loss : 23142.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 732 | train_loss : 20524.771484375 | val_loss : 9951.701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 733 | train_loss : 13037.8603515625 | val_loss : 8004.21875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 734 | train_loss : 7943.94873046875 | val_loss : 13233.142578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 735 | train_loss : 7800.884765625 | val_loss : 5615.419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 736 | train_loss : 10632.615234375 | val_loss : 13328.1650390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 737 | train_loss : 9245.927734375 | val_loss : 5474.884765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 738 | train_loss : 9506.384765625 | val_loss : 19197.287109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 739 | train_loss : 13753.119140625 | val_loss : 5728.10888671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 740 | train_loss : 9457.4482421875 | val_loss : 13200.771484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 741 | train_loss : 11741.2451171875 | val_loss : 10684.69140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 742 | train_loss : 10573.08984375 | val_loss : 6916.09619140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 743 | train_loss : 11015.89453125 | val_loss : 20004.6015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 744 | train_loss : 14579.6416015625 | val_loss : 4296.017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 745 | train_loss : 6124.8857421875 | val_loss : 8829.669921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 746 | train_loss : 6042.990234375 | val_loss : 6677.8935546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 747 | train_loss : 6121.2294921875 | val_loss : 6641.392578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 748 | train_loss : 7678.54638671875 | val_loss : 6364.54736328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 749 | train_loss : 8625.2724609375 | val_loss : 14834.5166015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 750 | train_loss : 10409.0810546875 | val_loss : 5786.65478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 751 | train_loss : 9120.318359375 | val_loss : 19697.07421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 752 | train_loss : 13775.19921875 | val_loss : 5763.49755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 753 | train_loss : 8595.0458984375 | val_loss : 5066.45361328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 754 | train_loss : 8965.18359375 | val_loss : 9212.83203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 755 | train_loss : 9143.009765625 | val_loss : 4068.152587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 756 | train_loss : 7148.5869140625 | val_loss : 10839.6708984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 757 | train_loss : 8733.7412109375 | val_loss : 6403.22021484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 758 | train_loss : 7392.83056640625 | val_loss : 5955.3125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 759 | train_loss : 7005.56103515625 | val_loss : 6390.99365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 760 | train_loss : 6461.05859375 | val_loss : 5871.6513671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 761 | train_loss : 5269.0185546875 | val_loss : 3494.28125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 762 | train_loss : 5828.8388671875 | val_loss : 15114.6298828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 763 | train_loss : 8454.861328125 | val_loss : 1895.2762451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 764 | train_loss : 6750.6875 | val_loss : 18964.2109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 765 | train_loss : 10691.978515625 | val_loss : 4328.72998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 766 | train_loss : 6715.283203125 | val_loss : 17155.166015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 767 | train_loss : 10865.16796875 | val_loss : 2805.228759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 768 | train_loss : 8498.810546875 | val_loss : 11823.7626953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 769 | train_loss : 8101.03857421875 | val_loss : 6748.20263671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 770 | train_loss : 9076.298828125 | val_loss : 17671.64453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 771 | train_loss : 10342.59375 | val_loss : 3601.561279296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 772 | train_loss : 6731.3818359375 | val_loss : 7395.80615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 773 | train_loss : 6275.1142578125 | val_loss : 4809.0625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 774 | train_loss : 6321.4736328125 | val_loss : 11610.6572265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 775 | train_loss : 9388.8349609375 | val_loss : 20180.12890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 776 | train_loss : 13931.2412109375 | val_loss : 10194.3310546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 777 | train_loss : 12916.068359375 | val_loss : 17791.787109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 778 | train_loss : 13831.88671875 | val_loss : 8476.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 779 | train_loss : 7836.6923828125 | val_loss : 9920.5283203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 780 | train_loss : 9607.970703125 | val_loss : 6122.15234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 781 | train_loss : 5898.76611328125 | val_loss : 18957.97265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 782 | train_loss : 11537.697265625 | val_loss : 2712.4599609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 783 | train_loss : 9822.6279296875 | val_loss : 13098.412109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 784 | train_loss : 10145.130859375 | val_loss : 3992.31005859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 785 | train_loss : 5088.0703125 | val_loss : 11869.2412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 786 | train_loss : 5952.24951171875 | val_loss : 3386.125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 787 | train_loss : 3724.70751953125 | val_loss : 2150.226318359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 788 | train_loss : 3159.13720703125 | val_loss : 10209.1953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 789 | train_loss : 6658.56005859375 | val_loss : 2926.93505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 790 | train_loss : 7500.3994140625 | val_loss : 17421.25390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 791 | train_loss : 9881.568359375 | val_loss : 2554.717529296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 792 | train_loss : 2487.779541015625 | val_loss : 1778.21875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 793 | train_loss : 2784.6201171875 | val_loss : 11409.1484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 794 | train_loss : 6932.55322265625 | val_loss : 4111.20751953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 795 | train_loss : 4635.10595703125 | val_loss : 20980.765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 796 | train_loss : 13271.0947265625 | val_loss : 5576.1474609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 797 | train_loss : 7179.37548828125 | val_loss : 7551.49365234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 798 | train_loss : 6769.80517578125 | val_loss : 13898.57421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 799 | train_loss : 9664.0205078125 | val_loss : 5576.63134765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 800 | train_loss : 5527.103515625 | val_loss : 5784.73876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 801 | train_loss : 4286.01416015625 | val_loss : 11406.205078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 802 | train_loss : 9197.884765625 | val_loss : 10518.2734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 803 | train_loss : 9782.1904296875 | val_loss : 5852.79248046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 804 | train_loss : 7272.31884765625 | val_loss : 7886.80859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 805 | train_loss : 6708.52978515625 | val_loss : 7073.2626953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 806 | train_loss : 5826.83251953125 | val_loss : 5269.97509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 807 | train_loss : 8081.763671875 | val_loss : 13105.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 808 | train_loss : 8749.2177734375 | val_loss : 5043.81884765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 809 | train_loss : 9334.78515625 | val_loss : 15483.5478515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 810 | train_loss : 11093.2314453125 | val_loss : 4529.90625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 811 | train_loss : 5493.4599609375 | val_loss : 2628.72509765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 812 | train_loss : 4987.85888671875 | val_loss : 6464.634765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 813 | train_loss : 4948.55615234375 | val_loss : 2867.64990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 814 | train_loss : 6186.93505859375 | val_loss : 15100.1259765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 815 | train_loss : 11187.3720703125 | val_loss : 3271.679931640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 816 | train_loss : 8766.73828125 | val_loss : 15854.271484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 817 | train_loss : 9582.9365234375 | val_loss : 4032.422607421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 818 | train_loss : 4600.974609375 | val_loss : 4499.6611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 819 | train_loss : 6793.35888671875 | val_loss : 10022.8037109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 820 | train_loss : 6888.25732421875 | val_loss : 9868.8515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 821 | train_loss : 8119.23388671875 | val_loss : 5517.7626953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 822 | train_loss : 5400.45068359375 | val_loss : 11548.40234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 823 | train_loss : 7305.94482421875 | val_loss : 5971.85888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 824 | train_loss : 7936.068359375 | val_loss : 12923.8466796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 825 | train_loss : 8803.9306640625 | val_loss : 3550.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 826 | train_loss : 7223.443359375 | val_loss : 10898.9189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 827 | train_loss : 9356.5234375 | val_loss : 5127.1064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 828 | train_loss : 10517.64453125 | val_loss : 20478.537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 829 | train_loss : 12363.7177734375 | val_loss : 6016.09130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 830 | train_loss : 3945.328369140625 | val_loss : 3655.601318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 831 | train_loss : 6213.736328125 | val_loss : 17838.630859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 832 | train_loss : 9693.80078125 | val_loss : 2609.46240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 833 | train_loss : 5836.9287109375 | val_loss : 4080.012451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 834 | train_loss : 4265.31396484375 | val_loss : 1934.3287353515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 835 | train_loss : 4530.013671875 | val_loss : 5607.80615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 836 | train_loss : 5242.07373046875 | val_loss : 2788.840087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 837 | train_loss : 5068.951171875 | val_loss : 5778.56005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 838 | train_loss : 5682.03759765625 | val_loss : 3634.112548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 839 | train_loss : 6538.57666015625 | val_loss : 18724.658203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 840 | train_loss : 10138.501953125 | val_loss : 2642.62255859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 841 | train_loss : 4070.21435546875 | val_loss : 6250.416015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 842 | train_loss : 6148.5 | val_loss : 8835.9287109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 843 | train_loss : 11522.2685546875 | val_loss : 12493.7841796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 844 | train_loss : 10252.2236328125 | val_loss : 4099.14013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 845 | train_loss : 7657.142578125 | val_loss : 12931.48046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 846 | train_loss : 7751.52392578125 | val_loss : 5838.06396484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 847 | train_loss : 7320.04638671875 | val_loss : 13089.22265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 848 | train_loss : 10457.822265625 | val_loss : 4938.00634765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 849 | train_loss : 9355.3515625 | val_loss : 16394.611328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 850 | train_loss : 10456.8896484375 | val_loss : 4706.3935546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 851 | train_loss : 7092.5341796875 | val_loss : 12522.26953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 852 | train_loss : 8797.9833984375 | val_loss : 6294.2998046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 853 | train_loss : 5733.693359375 | val_loss : 4932.10986328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 854 | train_loss : 4829.4794921875 | val_loss : 6583.51611328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 855 | train_loss : 5995.71630859375 | val_loss : 6514.86376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 856 | train_loss : 6954.62939453125 | val_loss : 4789.8701171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 857 | train_loss : 6771.509765625 | val_loss : 7339.4560546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 858 | train_loss : 6235.70458984375 | val_loss : 5224.31640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 859 | train_loss : 6333.08740234375 | val_loss : 4855.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 860 | train_loss : 6692.056640625 | val_loss : 12200.46484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 861 | train_loss : 9381.416015625 | val_loss : 6440.77490234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 862 | train_loss : 10547.7412109375 | val_loss : 22066.744140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 863 | train_loss : 13499.5498046875 | val_loss : 4171.607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 864 | train_loss : 3326.63427734375 | val_loss : 4780.490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 865 | train_loss : 4540.400390625 | val_loss : 12951.505859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 866 | train_loss : 8954.587890625 | val_loss : 2190.232421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 867 | train_loss : 6759.44189453125 | val_loss : 13044.91796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 868 | train_loss : 7657.23876953125 | val_loss : 3341.534912109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 869 | train_loss : 4224.18115234375 | val_loss : 8599.646484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 870 | train_loss : 6664.3642578125 | val_loss : 3750.797607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 871 | train_loss : 8044.7568359375 | val_loss : 17735.046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 872 | train_loss : 9757.8125 | val_loss : 4584.2099609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 873 | train_loss : 4714.03125 | val_loss : 3518.31884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 874 | train_loss : 4715.03173828125 | val_loss : 7892.978515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 875 | train_loss : 5675.958984375 | val_loss : 5202.982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 876 | train_loss : 8861.1416015625 | val_loss : 20899.435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 877 | train_loss : 11380.1328125 | val_loss : 4459.3564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 878 | train_loss : 3826.357177734375 | val_loss : 7936.90478515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 879 | train_loss : 6543.71484375 | val_loss : 9113.2177734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 880 | train_loss : 6163.6181640625 | val_loss : 5851.99267578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 881 | train_loss : 3426.91943359375 | val_loss : 7153.27734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 882 | train_loss : 4464.09912109375 | val_loss : 4259.6435546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 883 | train_loss : 7303.87451171875 | val_loss : 16084.056640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 884 | train_loss : 8508.3935546875 | val_loss : 3503.487548828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 885 | train_loss : 5980.884765625 | val_loss : 4261.85107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 886 | train_loss : 5505.80322265625 | val_loss : 3922.41748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 887 | train_loss : 7562.73486328125 | val_loss : 19216.876953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 888 | train_loss : 11126.2978515625 | val_loss : 5334.4775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 889 | train_loss : 8076.4716796875 | val_loss : 9688.224609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 890 | train_loss : 7905.69677734375 | val_loss : 8407.7373046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 891 | train_loss : 9798.5263671875 | val_loss : 9888.4072265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 892 | train_loss : 6301.14990234375 | val_loss : 3293.175048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 893 | train_loss : 4017.663818359375 | val_loss : 4491.330078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 894 | train_loss : 5494.69482421875 | val_loss : 5814.72607421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 895 | train_loss : 4175.85888671875 | val_loss : 3485.96630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 896 | train_loss : 6672.17236328125 | val_loss : 14317.224609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 897 | train_loss : 8686.490234375 | val_loss : 2580.456298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 898 | train_loss : 5086.31201171875 | val_loss : 6230.64501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 899 | train_loss : 4688.1806640625 | val_loss : 1598.1824951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 900 | train_loss : 2473.181640625 | val_loss : 9583.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 901 | train_loss : 7155.12451171875 | val_loss : 3329.77490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 902 | train_loss : 7266.02392578125 | val_loss : 17488.697265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 903 | train_loss : 9885.2998046875 | val_loss : 3500.4287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 904 | train_loss : 3632.653076171875 | val_loss : 2711.46630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 905 | train_loss : 3674.70751953125 | val_loss : 7830.45263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 906 | train_loss : 3878.0361328125 | val_loss : 3719.941162109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 907 | train_loss : 6100.17138671875 | val_loss : 17821.91015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 908 | train_loss : 9120.4990234375 | val_loss : 2081.35009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 909 | train_loss : 5289.4248046875 | val_loss : 6712.03271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 910 | train_loss : 5436.71630859375 | val_loss : 4081.813720703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 911 | train_loss : 6409.82373046875 | val_loss : 18341.91796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 912 | train_loss : 10446.49609375 | val_loss : 4067.387451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 913 | train_loss : 5446.91748046875 | val_loss : 4816.5810546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 914 | train_loss : 7572.06494140625 | val_loss : 18173.9140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 915 | train_loss : 13634.333984375 | val_loss : 5683.677734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 916 | train_loss : 8189.103515625 | val_loss : 14969.0029296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 917 | train_loss : 9330.361328125 | val_loss : 2295.69384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 918 | train_loss : 5400.29052734375 | val_loss : 7327.322265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 919 | train_loss : 5521.8037109375 | val_loss : 3647.421142578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 920 | train_loss : 5427.80615234375 | val_loss : 14056.0634765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 921 | train_loss : 7284.6044921875 | val_loss : 2194.907470703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 922 | train_loss : 4935.216796875 | val_loss : 5313.5263671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 923 | train_loss : 4596.50390625 | val_loss : 4331.728515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 924 | train_loss : 6677.34619140625 | val_loss : 17108.83984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 925 | train_loss : 9015.11328125 | val_loss : 3995.68994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 926 | train_loss : 3311.521484375 | val_loss : 2600.951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 927 | train_loss : 3643.811767578125 | val_loss : 7311.072265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 928 | train_loss : 4065.15185546875 | val_loss : 3058.9150390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 929 | train_loss : 3165.512451171875 | val_loss : 4594.18994140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 930 | train_loss : 4489.53173828125 | val_loss : 4664.9560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 931 | train_loss : 4348.6826171875 | val_loss : 7525.0673828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 932 | train_loss : 5605.78076171875 | val_loss : 4859.08642578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 933 | train_loss : 5751.25146484375 | val_loss : 6185.7900390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 934 | train_loss : 4757.09228515625 | val_loss : 7030.87353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 935 | train_loss : 6317.78759765625 | val_loss : 9839.75390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 936 | train_loss : 6595.0751953125 | val_loss : 5072.8701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 937 | train_loss : 5204.4833984375 | val_loss : 3243.0361328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 938 | train_loss : 4392.248046875 | val_loss : 4829.44384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 939 | train_loss : 3831.2080078125 | val_loss : 2362.42626953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 940 | train_loss : 3876.413818359375 | val_loss : 6609.93994140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 941 | train_loss : 6267.99951171875 | val_loss : 10282.552734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 942 | train_loss : 8039.3701171875 | val_loss : 11911.2666015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 943 | train_loss : 10118.412109375 | val_loss : 17606.359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 944 | train_loss : 13765.1025390625 | val_loss : 11333.9541015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 945 | train_loss : 11358.4404296875 | val_loss : 7918.7314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 946 | train_loss : 9000.6259765625 | val_loss : 5944.19482421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 947 | train_loss : 4296.9501953125 | val_loss : 9214.4345703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 948 | train_loss : 5541.0537109375 | val_loss : 4908.62109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 949 | train_loss : 4504.89208984375 | val_loss : 2401.398681640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 950 | train_loss : 5218.9560546875 | val_loss : 7434.90771484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 951 | train_loss : 5331.583984375 | val_loss : 2938.851318359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 952 | train_loss : 3505.478759765625 | val_loss : 9921.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 953 | train_loss : 6846.01611328125 | val_loss : 3203.34130859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 954 | train_loss : 7706.5224609375 | val_loss : 14681.9228515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 955 | train_loss : 9093.400390625 | val_loss : 4226.74365234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 956 | train_loss : 4636.94384765625 | val_loss : 2240.958740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 957 | train_loss : 4671.79541015625 | val_loss : 9082.337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 958 | train_loss : 5374.1630859375 | val_loss : 2439.570068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 959 | train_loss : 4204.83056640625 | val_loss : 13763.3564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 960 | train_loss : 9035.041015625 | val_loss : 2198.95751953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 961 | train_loss : 4331.6572265625 | val_loss : 8450.12890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 962 | train_loss : 6503.44921875 | val_loss : 3573.813720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 963 | train_loss : 3594.423828125 | val_loss : 8855.5576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 964 | train_loss : 5049.6357421875 | val_loss : 2983.416259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 965 | train_loss : 3195.5244140625 | val_loss : 2746.11865234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 966 | train_loss : 3639.398681640625 | val_loss : 10723.2841796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 967 | train_loss : 6948.048828125 | val_loss : 3768.98876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 968 | train_loss : 5897.984375 | val_loss : 16146.1650390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 969 | train_loss : 9136.3759765625 | val_loss : 3568.65625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 970 | train_loss : 4004.208740234375 | val_loss : 2852.882568359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 971 | train_loss : 3491.010986328125 | val_loss : 7789.77880859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 972 | train_loss : 5273.80078125 | val_loss : 4568.75 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 973 | train_loss : 7165.07080078125 | val_loss : 17346.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 974 | train_loss : 9467.7802734375 | val_loss : 3141.44873046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 975 | train_loss : 3286.59375 | val_loss : 3242.3076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 976 | train_loss : 4874.91845703125 | val_loss : 13280.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 977 | train_loss : 6859.7861328125 | val_loss : 2506.360107421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 978 | train_loss : 3083.356201171875 | val_loss : 4099.58642578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 979 | train_loss : 5012.93115234375 | val_loss : 2753.8525390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 980 | train_loss : 3310.779052734375 | val_loss : 5972.96484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 981 | train_loss : 4806.48876953125 | val_loss : 3771.44873046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 982 | train_loss : 5593.39990234375 | val_loss : 13293.228515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 983 | train_loss : 7551.24560546875 | val_loss : 4749.68115234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 984 | train_loss : 4083.1455078125 | val_loss : 3976.373779296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 985 | train_loss : 2877.890625 | val_loss : 8948.96484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 986 | train_loss : 5775.3251953125 | val_loss : 3831.657470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 987 | train_loss : 4875.404296875 | val_loss : 12700.01953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 988 | train_loss : 5862.876953125 | val_loss : 2672.52001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 989 | train_loss : 3785.405517578125 | val_loss : 4143.638671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 990 | train_loss : 3871.601806640625 | val_loss : 3548.40869140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 991 | train_loss : 4046.238037109375 | val_loss : 4731.80615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 992 | train_loss : 5059.98828125 | val_loss : 2864.8974609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 993 | train_loss : 4940.1279296875 | val_loss : 10155.556640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 994 | train_loss : 6966.27880859375 | val_loss : 4640.396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 995 | train_loss : 6092.916015625 | val_loss : 11032.142578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 996 | train_loss : 6992.12353515625 | val_loss : 3169.72119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 997 | train_loss : 2257.541259765625 | val_loss : 3335.516357421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 998 | train_loss : 5116.17236328125 | val_loss : 12629.927734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 999 | train_loss : 6599.53857421875 | val_loss : 3965.461181640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1000 | train_loss : 4697.12890625 | val_loss : 5044.076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1001 | train_loss : 5518.6923828125 | val_loss : 2976.43505859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1002 | train_loss : 5526.84130859375 | val_loss : 11402.2666015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1003 | train_loss : 6377.2451171875 | val_loss : 2935.094970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1004 | train_loss : 3218.73681640625 | val_loss : 7802.74609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1005 | train_loss : 4703.52294921875 | val_loss : 1864.7987060546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1006 | train_loss : 2112.096435546875 | val_loss : 4110.51513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1007 | train_loss : 3499.324951171875 | val_loss : 4219.59619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1008 | train_loss : 4789.80712890625 | val_loss : 7275.6474609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1009 | train_loss : 4632.57373046875 | val_loss : 4141.95751953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1010 | train_loss : 4281.42822265625 | val_loss : 3874.367431640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1011 | train_loss : 3233.373046875 | val_loss : 2556.092529296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1012 | train_loss : 3036.86572265625 | val_loss : 4426.48876953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1013 | train_loss : 3795.3095703125 | val_loss : 4870.7412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1014 | train_loss : 4581.72021484375 | val_loss : 9854.865234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1015 | train_loss : 5943.16259765625 | val_loss : 4267.90380859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1016 | train_loss : 3135.39697265625 | val_loss : 2523.108642578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1017 | train_loss : 4960.6787109375 | val_loss : 15560.3271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1018 | train_loss : 8469.0341796875 | val_loss : 2383.824951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1019 | train_loss : 3367.5673828125 | val_loss : 4966.89013671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1020 | train_loss : 3960.993408203125 | val_loss : 5373.580078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1021 | train_loss : 3606.096923828125 | val_loss : 3497.20751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1022 | train_loss : 3559.80615234375 | val_loss : 6421.92236328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1023 | train_loss : 4770.35205078125 | val_loss : 2766.347412109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1024 | train_loss : 2884.216796875 | val_loss : 6473.45263671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1025 | train_loss : 3362.953125 | val_loss : 2517.4326171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1026 | train_loss : 2839.9892578125 | val_loss : 6461.79638671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1027 | train_loss : 3788.108154296875 | val_loss : 3926.103759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1028 | train_loss : 4227.70263671875 | val_loss : 6545.65771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1029 | train_loss : 4702.42041015625 | val_loss : 3889.013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1030 | train_loss : 3605.685546875 | val_loss : 5252.62646484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1031 | train_loss : 4422.42724609375 | val_loss : 3666.128662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1032 | train_loss : 4619.1611328125 | val_loss : 12930.900390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1033 | train_loss : 6773.302734375 | val_loss : 3602.92626953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1034 | train_loss : 5414.267578125 | val_loss : 8343.509765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1035 | train_loss : 6004.7373046875 | val_loss : 2758.296142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1036 | train_loss : 3660.41748046875 | val_loss : 7530.197265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1037 | train_loss : 3184.99072265625 | val_loss : 1699.4775390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1038 | train_loss : 2194.9326171875 | val_loss : 6385.11767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1039 | train_loss : 3085.318359375 | val_loss : 2388.949951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1040 | train_loss : 2987.159912109375 | val_loss : 6638.36669921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1041 | train_loss : 4282.11572265625 | val_loss : 3450.018798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1042 | train_loss : 3328.364990234375 | val_loss : 4936.25634765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1043 | train_loss : 4470.58447265625 | val_loss : 3495.9599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1044 | train_loss : 4005.299072265625 | val_loss : 8303.2001953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1045 | train_loss : 4407.8466796875 | val_loss : 4083.461181640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1046 | train_loss : 2627.675048828125 | val_loss : 5073.5654296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1047 | train_loss : 5710.72021484375 | val_loss : 12726.4541015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1048 | train_loss : 7789.05078125 | val_loss : 8223.0615234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1049 | train_loss : 7129.34423828125 | val_loss : 13075.2666015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1050 | train_loss : 8476.814453125 | val_loss : 5346.7861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1051 | train_loss : 5464.333984375 | val_loss : 10183.8125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1052 | train_loss : 5753.3349609375 | val_loss : 3298.17626953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1053 | train_loss : 4152.8525390625 | val_loss : 6091.197265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1054 | train_loss : 4660.45703125 | val_loss : 2907.887451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1055 | train_loss : 4226.20458984375 | val_loss : 8862.509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1056 | train_loss : 6745.7724609375 | val_loss : 5117.697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1057 | train_loss : 6986.751953125 | val_loss : 10785.6259765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1058 | train_loss : 8807.3408203125 | val_loss : 6870.79833984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1059 | train_loss : 6317.33984375 | val_loss : 5483.333984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1060 | train_loss : 8884.5634765625 | val_loss : 15155.423828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1061 | train_loss : 9677.6884765625 | val_loss : 3123.763671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1062 | train_loss : 3839.91943359375 | val_loss : 6248.578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1063 | train_loss : 3381.648681640625 | val_loss : 3358.603759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1064 | train_loss : 3373.558837890625 | val_loss : 5916.41015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1065 | train_loss : 2649.01904296875 | val_loss : 5021.30859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1066 | train_loss : 4376.21923828125 | val_loss : 15669.3349609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1067 | train_loss : 15221.8427734375 | val_loss : 11469.6103515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1068 | train_loss : 10814.48828125 | val_loss : 7075.8525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1069 | train_loss : 6127.17236328125 | val_loss : 2332.44677734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1070 | train_loss : 4008.2294921875 | val_loss : 11868.9228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1071 | train_loss : 6395.54931640625 | val_loss : 1822.23876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1072 | train_loss : 3460.545654296875 | val_loss : 4447.2939453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1073 | train_loss : 3969.315673828125 | val_loss : 2827.56005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1074 | train_loss : 4341.43994140625 | val_loss : 16523.833984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1075 | train_loss : 9036.962890625 | val_loss : 3867.458740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1076 | train_loss : 3885.100830078125 | val_loss : 2080.2275390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1077 | train_loss : 2980.46435546875 | val_loss : 5290.1650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1078 | train_loss : 2930.992919921875 | val_loss : 4345.41064453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1079 | train_loss : 5689.1826171875 | val_loss : 14284.2509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1080 | train_loss : 6827.80322265625 | val_loss : 2811.947509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1081 | train_loss : 3874.702392578125 | val_loss : 3085.639892578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1082 | train_loss : 3192.59375 | val_loss : 3241.093017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1083 | train_loss : 3207.2109375 | val_loss : 5490.28271484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1084 | train_loss : 4176.56787109375 | val_loss : 2902.21630859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1085 | train_loss : 2935.758056640625 | val_loss : 4229.208984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1086 | train_loss : 3249.536865234375 | val_loss : 2543.05615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1087 | train_loss : 2799.578857421875 | val_loss : 4283.87255859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1088 | train_loss : 3071.84716796875 | val_loss : 2689.68505859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1089 | train_loss : 3363.15625 | val_loss : 5336.22998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1090 | train_loss : 3551.708740234375 | val_loss : 3250.94384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1091 | train_loss : 3801.222412109375 | val_loss : 5236.951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1092 | train_loss : 3772.029296875 | val_loss : 2702.31884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1093 | train_loss : 2651.49365234375 | val_loss : 3431.766357421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1094 | train_loss : 3185.7255859375 | val_loss : 4370.4423828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1095 | train_loss : 3599.133056640625 | val_loss : 6209.84375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1096 | train_loss : 5355.41259765625 | val_loss : 9995.5263671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1097 | train_loss : 5345.1181640625 | val_loss : 4327.89501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1098 | train_loss : 3045.15625 | val_loss : 2876.64990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1099 | train_loss : 4582.52294921875 | val_loss : 15784.7001953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1100 | train_loss : 8119.58935546875 | val_loss : 2550.416259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1101 | train_loss : 3345.6162109375 | val_loss : 4950.11572265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1102 | train_loss : 2860.953125 | val_loss : 2446.898681640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1103 | train_loss : 2307.99072265625 | val_loss : 4178.07666015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1104 | train_loss : 3111.996826171875 | val_loss : 2984.5673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1105 | train_loss : 2862.54541015625 | val_loss : 4357.04736328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1106 | train_loss : 3296.724609375 | val_loss : 3223.686279296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1107 | train_loss : 3216.7138671875 | val_loss : 3366.581298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1108 | train_loss : 3628.215576171875 | val_loss : 6700.95947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1109 | train_loss : 4010.35400390625 | val_loss : 3303.90625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1110 | train_loss : 3753.4267578125 | val_loss : 3880.518798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1111 | train_loss : 2937.578125 | val_loss : 2002.0374755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1112 | train_loss : 2251.40673828125 | val_loss : 3588.793212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1113 | train_loss : 3349.563232421875 | val_loss : 3772.541259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1114 | train_loss : 3183.308837890625 | val_loss : 5491.18017578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1115 | train_loss : 5090.1748046875 | val_loss : 11933.1962890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1116 | train_loss : 7151.13330078125 | val_loss : 6086.7587890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1117 | train_loss : 4997.49853515625 | val_loss : 14727.1171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1118 | train_loss : 9127.001953125 | val_loss : 6484.4033203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1119 | train_loss : 4456.79345703125 | val_loss : 12131.568359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1120 | train_loss : 8084.68994140625 | val_loss : 5568.576171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1121 | train_loss : 4495.19580078125 | val_loss : 5628.10888671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1122 | train_loss : 3724.419921875 | val_loss : 8423.646484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1123 | train_loss : 4653.39501953125 | val_loss : 4767.66064453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1124 | train_loss : 4985.3408203125 | val_loss : 6787.26171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1125 | train_loss : 4129.2783203125 | val_loss : 3517.653076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1126 | train_loss : 3023.274658203125 | val_loss : 5575.587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1127 | train_loss : 3492.545654296875 | val_loss : 3907.1474609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1128 | train_loss : 3414.195068359375 | val_loss : 8950.1728515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1129 | train_loss : 6823.70263671875 | val_loss : 3417.548095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1130 | train_loss : 3327.099365234375 | val_loss : 2801.688720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1131 | train_loss : 2495.042236328125 | val_loss : 2211.510009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1132 | train_loss : 3327.1923828125 | val_loss : 7224.771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1133 | train_loss : 3980.624267578125 | val_loss : 2868.781982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1134 | train_loss : 3412.2451171875 | val_loss : 12925.9140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1135 | train_loss : 7347.1376953125 | val_loss : 2618.267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1136 | train_loss : 2904.961181640625 | val_loss : 2576.904296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1137 | train_loss : 3253.191162109375 | val_loss : 3892.154296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1138 | train_loss : 3645.9130859375 | val_loss : 3796.75439453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1139 | train_loss : 3751.40087890625 | val_loss : 3141.081298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1140 | train_loss : 3849.320068359375 | val_loss : 13025.8076171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1141 | train_loss : 7351.837890625 | val_loss : 3655.547607421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1142 | train_loss : 3633.6064453125 | val_loss : 7512.302734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1143 | train_loss : 4583.1767578125 | val_loss : 2647.3125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1144 | train_loss : 4588.6982421875 | val_loss : 15687.36328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1145 | train_loss : 8251.71484375 | val_loss : 2367.60693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1146 | train_loss : 2818.755615234375 | val_loss : 6228.828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1147 | train_loss : 3713.355712890625 | val_loss : 2434.25927734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1148 | train_loss : 3249.180908203125 | val_loss : 5158.12646484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1149 | train_loss : 3739.253173828125 | val_loss : 2544.96435546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1150 | train_loss : 3006.95751953125 | val_loss : 7330.43359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1151 | train_loss : 4205.130859375 | val_loss : 3542.62744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1152 | train_loss : 4929.12451171875 | val_loss : 13362.013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1153 | train_loss : 7119.205078125 | val_loss : 2891.09814453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1154 | train_loss : 2776.586181640625 | val_loss : 5616.78173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1155 | train_loss : 5191.0 | val_loss : 6494.236328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1156 | train_loss : 3139.6806640625 | val_loss : 1858.06494140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1157 | train_loss : 2290.95751953125 | val_loss : 4579.12255859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1158 | train_loss : 2986.29443359375 | val_loss : 2370.843017578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1159 | train_loss : 2346.92138671875 | val_loss : 5742.38232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1160 | train_loss : 3970.69873046875 | val_loss : 2161.679931640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1161 | train_loss : 2314.333984375 | val_loss : 6918.39892578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1162 | train_loss : 3699.001220703125 | val_loss : 2287.470703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1163 | train_loss : 2985.3173828125 | val_loss : 7052.048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1164 | train_loss : 3595.824951171875 | val_loss : 3425.855712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1165 | train_loss : 4257.12939453125 | val_loss : 14216.3603515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1166 | train_loss : 6793.77978515625 | val_loss : 2915.21435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1167 | train_loss : 3465.46435546875 | val_loss : 2477.50634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1168 | train_loss : 2777.550537109375 | val_loss : 3552.8701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1169 | train_loss : 1952.7645263671875 | val_loss : 2762.907470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1170 | train_loss : 2230.857421875 | val_loss : 10002.24609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1171 | train_loss : 4883.73046875 | val_loss : 2558.9130859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1172 | train_loss : 4041.715576171875 | val_loss : 6168.123046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1173 | train_loss : 5495.5849609375 | val_loss : 4842.12353515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1174 | train_loss : 5768.744140625 | val_loss : 1467.0537109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1175 | train_loss : 3099.23681640625 | val_loss : 6795.35302734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1176 | train_loss : 4790.36279296875 | val_loss : 4226.94921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1177 | train_loss : 4728.39990234375 | val_loss : 11752.6865234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1178 | train_loss : 5598.93994140625 | val_loss : 3293.155029296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1179 | train_loss : 2706.907470703125 | val_loss : 2867.9736328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1180 | train_loss : 3446.326904296875 | val_loss : 5555.271484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1181 | train_loss : 3621.46337890625 | val_loss : 2671.4267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1182 | train_loss : 2857.986328125 | val_loss : 6534.9462890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1183 | train_loss : 3534.180908203125 | val_loss : 2777.683837890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1184 | train_loss : 3364.369140625 | val_loss : 4213.13818359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1185 | train_loss : 3014.7490234375 | val_loss : 2832.2744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1186 | train_loss : 2700.04443359375 | val_loss : 6100.23388671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1187 | train_loss : 3991.058837890625 | val_loss : 2084.763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1188 | train_loss : 2416.42724609375 | val_loss : 4085.35693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1189 | train_loss : 3290.258056640625 | val_loss : 2400.62939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1190 | train_loss : 2461.5048828125 | val_loss : 5625.52294921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1191 | train_loss : 3681.324462890625 | val_loss : 2431.16064453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1192 | train_loss : 2607.378662109375 | val_loss : 5004.287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1193 | train_loss : 3241.087890625 | val_loss : 2729.688720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1194 | train_loss : 3041.783203125 | val_loss : 7944.318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1195 | train_loss : 3875.88427734375 | val_loss : 1812.1243896484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1196 | train_loss : 2514.351806640625 | val_loss : 5043.44140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1197 | train_loss : 3097.6298828125 | val_loss : 1642.73876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1198 | train_loss : 1917.235595703125 | val_loss : 3704.577392578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1199 | train_loss : 2779.48681640625 | val_loss : 2471.353759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1200 | train_loss : 2575.2490234375 | val_loss : 9071.751953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1201 | train_loss : 4208.30224609375 | val_loss : 2586.283203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1202 | train_loss : 2024.63330078125 | val_loss : 2687.826904296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1203 | train_loss : 2911.144287109375 | val_loss : 13943.66796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1204 | train_loss : 7099.771484375 | val_loss : 3791.550048828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1205 | train_loss : 3628.909423828125 | val_loss : 2798.014892578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1206 | train_loss : 2414.942138671875 | val_loss : 5562.69921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1207 | train_loss : 3519.250244140625 | val_loss : 2547.781982421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1208 | train_loss : 2960.91845703125 | val_loss : 8332.01171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1209 | train_loss : 4129.7998046875 | val_loss : 1752.6287841796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1210 | train_loss : 1761.8583984375 | val_loss : 6514.482421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1211 | train_loss : 4573.39013671875 | val_loss : 4565.0595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1212 | train_loss : 5159.17041015625 | val_loss : 12168.3154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1213 | train_loss : 5579.548828125 | val_loss : 3540.48193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1214 | train_loss : 3920.372802734375 | val_loss : 6502.45947265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1215 | train_loss : 3621.25341796875 | val_loss : 2769.141845703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1216 | train_loss : 3171.2470703125 | val_loss : 5252.49169921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1217 | train_loss : 3379.40283203125 | val_loss : 2569.2568359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1218 | train_loss : 3124.842529296875 | val_loss : 5604.29541015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1219 | train_loss : 3850.21533203125 | val_loss : 2190.9013671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1220 | train_loss : 2587.798583984375 | val_loss : 3935.125732421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1221 | train_loss : 2771.791015625 | val_loss : 3965.76318359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1222 | train_loss : 3440.206787109375 | val_loss : 6160.01806640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1223 | train_loss : 4531.7060546875 | val_loss : 2989.5107421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1224 | train_loss : 3717.4873046875 | val_loss : 5849.71142578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1225 | train_loss : 4028.1318359375 | val_loss : 5226.35009765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1226 | train_loss : 4144.9013671875 | val_loss : 10381.7587890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1227 | train_loss : 6098.533203125 | val_loss : 9655.64453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1228 | train_loss : 6677.1875 | val_loss : 10111.3515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1229 | train_loss : 5871.21044921875 | val_loss : 5630.42919921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1230 | train_loss : 4190.75537109375 | val_loss : 8949.4619140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1231 | train_loss : 4917.62255859375 | val_loss : 5835.10009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1232 | train_loss : 3796.77880859375 | val_loss : 8216.4638671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1233 | train_loss : 5386.28369140625 | val_loss : 6731.56494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1234 | train_loss : 3630.150634765625 | val_loss : 5891.92041015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1235 | train_loss : 3250.235107421875 | val_loss : 4806.94580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1236 | train_loss : 3368.30615234375 | val_loss : 2539.439453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1237 | train_loss : 2174.716552734375 | val_loss : 3150.50634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1238 | train_loss : 2640.593505859375 | val_loss : 2354.39990234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1239 | train_loss : 2528.517578125 | val_loss : 3581.30126953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1240 | train_loss : 2686.894287109375 | val_loss : 4324.28564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1241 | train_loss : 3904.0703125 | val_loss : 5028.33740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1242 | train_loss : 2912.14208984375 | val_loss : 2530.468017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1243 | train_loss : 3137.177490234375 | val_loss : 5534.28076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1244 | train_loss : 3406.06787109375 | val_loss : 1679.8499755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1245 | train_loss : 1832.121826171875 | val_loss : 5207.81884765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1246 | train_loss : 3211.869384765625 | val_loss : 2132.2919921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1247 | train_loss : 2456.236328125 | val_loss : 5270.26953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1248 | train_loss : 2804.510009765625 | val_loss : 2187.373779296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1249 | train_loss : 2599.766357421875 | val_loss : 4895.29736328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1250 | train_loss : 2998.8662109375 | val_loss : 3871.211181640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1251 | train_loss : 3516.51416015625 | val_loss : 5225.33544921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1252 | train_loss : 3289.04345703125 | val_loss : 4201.154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1253 | train_loss : 4241.50732421875 | val_loss : 6604.58642578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1254 | train_loss : 3700.091552734375 | val_loss : 3726.992431640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1255 | train_loss : 3703.53662109375 | val_loss : 9037.25390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1256 | train_loss : 5274.56396484375 | val_loss : 2744.606201171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1257 | train_loss : 3548.70947265625 | val_loss : 8419.49609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1258 | train_loss : 5078.56103515625 | val_loss : 2326.81005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1259 | train_loss : 4007.665283203125 | val_loss : 9813.3720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1260 | train_loss : 4923.48681640625 | val_loss : 1675.6312255859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1261 | train_loss : 1461.9547119140625 | val_loss : 4970.259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1262 | train_loss : 3844.06689453125 | val_loss : 4096.43505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1263 | train_loss : 5672.5419921875 | val_loss : 13976.048828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1264 | train_loss : 7738.5439453125 | val_loss : 4465.4423828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1265 | train_loss : 3981.70458984375 | val_loss : 2871.47998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1266 | train_loss : 4366.35302734375 | val_loss : 12696.677734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1267 | train_loss : 7022.64111328125 | val_loss : 3260.96435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1268 | train_loss : 2050.453125 | val_loss : 9784.0029296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1269 | train_loss : 13701.6416015625 | val_loss : 18494.765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1270 | train_loss : 13389.7822265625 | val_loss : 7405.36865234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1271 | train_loss : 5847.60888671875 | val_loss : 4829.16455078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1272 | train_loss : 2952.815673828125 | val_loss : 2468.0263671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1273 | train_loss : 2147.477783203125 | val_loss : 2326.01318359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1274 | train_loss : 2490.88134765625 | val_loss : 1796.06689453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1275 | train_loss : 2405.115234375 | val_loss : 4352.548828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1276 | train_loss : 2794.13525390625 | val_loss : 1731.56689453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1277 | train_loss : 2826.014892578125 | val_loss : 4696.95458984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1278 | train_loss : 2950.2177734375 | val_loss : 2974.985107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1279 | train_loss : 3962.232421875 | val_loss : 11574.212890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1280 | train_loss : 6209.3994140625 | val_loss : 2789.297607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1281 | train_loss : 2728.953857421875 | val_loss : 1294.0087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1282 | train_loss : 1910.46337890625 | val_loss : 3079.976318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1283 | train_loss : 1756.5799560546875 | val_loss : 1763.826904296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1284 | train_loss : 2434.474609375 | val_loss : 5287.5693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1285 | train_loss : 2215.16259765625 | val_loss : 2258.892578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1286 | train_loss : 2589.75244140625 | val_loss : 13846.0771484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1287 | train_loss : 7484.19873046875 | val_loss : 3631.083740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1288 | train_loss : 2592.870361328125 | val_loss : 1025.927490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1289 | train_loss : 1610.2509765625 | val_loss : 5437.98681640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1290 | train_loss : 2892.06005859375 | val_loss : 2209.97509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1291 | train_loss : 3499.008056640625 | val_loss : 8117.27490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1292 | train_loss : 3851.34912109375 | val_loss : 2742.190673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1293 | train_loss : 3426.261474609375 | val_loss : 6533.4345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1294 | train_loss : 3435.934326171875 | val_loss : 2668.8232421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1295 | train_loss : 3704.719970703125 | val_loss : 10854.9970703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1296 | train_loss : 5509.76318359375 | val_loss : 3120.991943359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1297 | train_loss : 2700.683837890625 | val_loss : 4456.04541015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1298 | train_loss : 4088.6357421875 | val_loss : 4372.3681640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1299 | train_loss : 2707.022216796875 | val_loss : 58449.28125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1300 | train_loss : 59067.35546875 | val_loss : 24890.384765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1301 | train_loss : 21915.935546875 | val_loss : 18563.419921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1302 | train_loss : 11225.08984375 | val_loss : 8756.69921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1303 | train_loss : 7456.91259765625 | val_loss : 7978.35986328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1304 | train_loss : 5809.46484375 | val_loss : 4618.32568359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1305 | train_loss : 5294.89794921875 | val_loss : 2900.173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1306 | train_loss : 2090.0712890625 | val_loss : 2985.561767578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1307 | train_loss : 2593.220703125 | val_loss : 5507.36669921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1308 | train_loss : 3824.304443359375 | val_loss : 2722.666259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1309 | train_loss : 3318.810302734375 | val_loss : 6474.806640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1310 | train_loss : 4230.7900390625 | val_loss : 2450.33935546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1311 | train_loss : 2637.9794921875 | val_loss : 3349.74560546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1312 | train_loss : 1634.6331787109375 | val_loss : 1362.2694091796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1313 | train_loss : 1611.577392578125 | val_loss : 4029.003173828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1314 | train_loss : 3057.588134765625 | val_loss : 2379.16552734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1315 | train_loss : 2649.573974609375 | val_loss : 10115.80859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1316 | train_loss : 5269.28955078125 | val_loss : 2284.17822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1317 | train_loss : 1868.3175048828125 | val_loss : 2657.525634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1318 | train_loss : 2172.52099609375 | val_loss : 2148.87255859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1319 | train_loss : 2481.4375 | val_loss : 7890.25390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1320 | train_loss : 4805.10205078125 | val_loss : 3232.927490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1321 | train_loss : 3667.5361328125 | val_loss : 10002.271484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1322 | train_loss : 4464.8916015625 | val_loss : 2746.898681640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1323 | train_loss : 2421.6982421875 | val_loss : 1958.296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1324 | train_loss : 2139.9228515625 | val_loss : 4437.52001953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1325 | train_loss : 2782.82958984375 | val_loss : 3081.638671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1326 | train_loss : 2838.1787109375 | val_loss : 7249.947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1327 | train_loss : 3879.70751953125 | val_loss : 1537.4136962890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1328 | train_loss : 1540.022705078125 | val_loss : 3346.169921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1329 | train_loss : 3380.01416015625 | val_loss : 10398.9609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1330 | train_loss : 5988.67578125 | val_loss : 7948.47998046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1331 | train_loss : 4806.3798828125 | val_loss : 7836.275390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1332 | train_loss : 4408.07421875 | val_loss : 6003.29736328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1333 | train_loss : 4277.40771484375 | val_loss : 8140.66259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1334 | train_loss : 4715.265625 | val_loss : 4455.03515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1335 | train_loss : 3611.8037109375 | val_loss : 7096.513671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1336 | train_loss : 4076.844482421875 | val_loss : 4702.287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1337 | train_loss : 3321.7890625 | val_loss : 6516.794921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1338 | train_loss : 4142.7001953125 | val_loss : 6056.349609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1339 | train_loss : 4156.74951171875 | val_loss : 6660.75634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1340 | train_loss : 3871.99658203125 | val_loss : 4820.01513671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1341 | train_loss : 4067.892578125 | val_loss : 7485.19677734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1342 | train_loss : 4002.460693359375 | val_loss : 4159.447265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1343 | train_loss : 3202.97314453125 | val_loss : 4917.2705078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1344 | train_loss : 3522.57470703125 | val_loss : 3381.86865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1345 | train_loss : 2929.3876953125 | val_loss : 6116.22607421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1346 | train_loss : 3501.3330078125 | val_loss : 2695.984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1347 | train_loss : 2964.01904296875 | val_loss : 5123.6591796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1348 | train_loss : 3357.6884765625 | val_loss : 2394.3232421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1349 | train_loss : 2944.2333984375 | val_loss : 7315.20263671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1350 | train_loss : 3912.32373046875 | val_loss : 1601.9130859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1351 | train_loss : 2787.6513671875 | val_loss : 6408.81982421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1352 | train_loss : 3681.44287109375 | val_loss : 3131.36865234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1353 | train_loss : 3211.55126953125 | val_loss : 8063.892578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1354 | train_loss : 4709.71044921875 | val_loss : 2774.66552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1355 | train_loss : 3329.951904296875 | val_loss : 7629.8369140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1356 | train_loss : 4289.97705078125 | val_loss : 3301.69384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1357 | train_loss : 3376.078369140625 | val_loss : 8986.8251953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1358 | train_loss : 5324.2783203125 | val_loss : 3710.018798828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1359 | train_loss : 3766.939453125 | val_loss : 9115.30859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1360 | train_loss : 5274.52294921875 | val_loss : 1570.81689453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1361 | train_loss : 2053.210693359375 | val_loss : 5536.763671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1362 | train_loss : 3131.9501953125 | val_loss : 2181.4150390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1363 | train_loss : 2802.518798828125 | val_loss : 8232.2978515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1364 | train_loss : 4746.6201171875 | val_loss : 1411.71875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1365 | train_loss : 1895.9237060546875 | val_loss : 5026.93701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1366 | train_loss : 3175.197265625 | val_loss : 2478.500732421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1367 | train_loss : 2783.709716796875 | val_loss : 9937.7412109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1368 | train_loss : 5352.1669921875 | val_loss : 2898.82568359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1369 | train_loss : 3473.341552734375 | val_loss : 7097.22314453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1370 | train_loss : 4346.54052734375 | val_loss : 3093.78369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1371 | train_loss : 5109.21484375 | val_loss : 10412.322265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1372 | train_loss : 6474.00390625 | val_loss : 2763.765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1373 | train_loss : 4096.4267578125 | val_loss : 9104.6953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1374 | train_loss : 6053.205078125 | val_loss : 3619.284423828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1375 | train_loss : 5682.48583984375 | val_loss : 8968.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1376 | train_loss : 5953.8779296875 | val_loss : 2904.514404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1377 | train_loss : 3979.6044921875 | val_loss : 7903.24609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1378 | train_loss : 4592.66259765625 | val_loss : 2486.994384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1379 | train_loss : 4018.83056640625 | val_loss : 5243.3388671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1380 | train_loss : 2430.7490234375 | val_loss : 2060.664306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1381 | train_loss : 2157.35498046875 | val_loss : 5931.11328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1382 | train_loss : 3918.870849609375 | val_loss : 2667.445068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1383 | train_loss : 2769.8447265625 | val_loss : 7797.6181640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1384 | train_loss : 5596.353515625 | val_loss : 4421.51318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1385 | train_loss : 2775.90869140625 | val_loss : 3003.75 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1386 | train_loss : 2674.419921875 | val_loss : 3570.918212890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1387 | train_loss : 2157.042236328125 | val_loss : 2911.739990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1388 | train_loss : 2652.4111328125 | val_loss : 3753.90380859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1389 | train_loss : 2807.75 | val_loss : 6743.66357421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1390 | train_loss : 4810.33740234375 | val_loss : 3920.2763671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1391 | train_loss : 2945.162841796875 | val_loss : 4625.29248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1392 | train_loss : 2517.88818359375 | val_loss : 3831.943115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1393 | train_loss : 2798.516357421875 | val_loss : 4037.57373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1394 | train_loss : 2579.36474609375 | val_loss : 4043.8232421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1395 | train_loss : 3490.655517578125 | val_loss : 6727.095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1396 | train_loss : 3705.458740234375 | val_loss : 3936.929931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1397 | train_loss : 3070.906494140625 | val_loss : 3560.570068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1398 | train_loss : 2732.24072265625 | val_loss : 3007.969970703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1399 | train_loss : 2463.9560546875 | val_loss : 3327.92626953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1400 | train_loss : 2479.7197265625 | val_loss : 2065.0107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1401 | train_loss : 2081.780029296875 | val_loss : 3453.3662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1402 | train_loss : 2486.6162109375 | val_loss : 3039.982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1403 | train_loss : 2680.856201171875 | val_loss : 7514.0185546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1404 | train_loss : 4897.0751953125 | val_loss : 4931.7373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1405 | train_loss : 3744.648193359375 | val_loss : 4836.505859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1406 | train_loss : 2475.508056640625 | val_loss : 3184.150634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1407 | train_loss : 2323.5810546875 | val_loss : 3138.992431640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1408 | train_loss : 2460.4775390625 | val_loss : 2167.548095703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1409 | train_loss : 2305.8857421875 | val_loss : 5179.49609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1410 | train_loss : 3293.867431640625 | val_loss : 2384.31884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1411 | train_loss : 2304.93896484375 | val_loss : 3890.75244140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1412 | train_loss : 2310.9501953125 | val_loss : 2185.418701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1413 | train_loss : 2862.53564453125 | val_loss : 6306.32177734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1414 | train_loss : 3233.1513671875 | val_loss : 1577.36181640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1415 | train_loss : 2264.121337890625 | val_loss : 4755.30126953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1416 | train_loss : 2613.61328125 | val_loss : 2472.206298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1417 | train_loss : 2707.72509765625 | val_loss : 8062.7568359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1418 | train_loss : 4996.2021484375 | val_loss : 2826.716796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1419 | train_loss : 2855.13427734375 | val_loss : 3414.080078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1420 | train_loss : 1757.9981689453125 | val_loss : 1795.3006591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1421 | train_loss : 1930.9296875 | val_loss : 6307.78369140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1422 | train_loss : 3079.3623046875 | val_loss : 1645.1612548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1423 | train_loss : 2255.8515625 | val_loss : 3437.809326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1424 | train_loss : 1813.8170166015625 | val_loss : 1625.686279296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1425 | train_loss : 2628.795654296875 | val_loss : 5421.70947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1426 | train_loss : 3091.73681640625 | val_loss : 1971.3125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1427 | train_loss : 2402.88623046875 | val_loss : 8155.1904296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1428 | train_loss : 4728.88134765625 | val_loss : 2299.427490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1429 | train_loss : 1840.94970703125 | val_loss : 3925.596923828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1430 | train_loss : 2512.50634765625 | val_loss : 2516.216796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1431 | train_loss : 2910.027587890625 | val_loss : 6539.09521484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1432 | train_loss : 2991.490966796875 | val_loss : 1053.0675048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1433 | train_loss : 1151.0035400390625 | val_loss : 2354.888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1434 | train_loss : 1536.5218505859375 | val_loss : 1875.1456298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1435 | train_loss : 2337.45458984375 | val_loss : 5310.15625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1436 | train_loss : 3146.339599609375 | val_loss : 1814.2261962890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1437 | train_loss : 2822.584716796875 | val_loss : 6136.45068359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1438 | train_loss : 3470.139404296875 | val_loss : 1830.78564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1439 | train_loss : 1683.466552734375 | val_loss : 4290.58056640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1440 | train_loss : 3010.7724609375 | val_loss : 4001.8837890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1441 | train_loss : 2892.884765625 | val_loss : 3079.1474609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1442 | train_loss : 2588.4990234375 | val_loss : 3277.49755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1443 | train_loss : 2388.91552734375 | val_loss : 2741.143798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1444 | train_loss : 2399.761474609375 | val_loss : 3454.116943359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1445 | train_loss : 2440.880859375 | val_loss : 3803.010009765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1446 | train_loss : 2886.80810546875 | val_loss : 3863.1474609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1447 | train_loss : 2739.74072265625 | val_loss : 3247.226318359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1448 | train_loss : 2089.51318359375 | val_loss : 3363.610107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1449 | train_loss : 2719.033203125 | val_loss : 5187.419921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1450 | train_loss : 2984.685546875 | val_loss : 3837.72509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1451 | train_loss : 3055.993408203125 | val_loss : 87558.859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1452 | train_loss : 79310.015625 | val_loss : 12512.0859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1453 | train_loss : 8092.7431640625 | val_loss : 18511.068359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1454 | train_loss : 16830.025390625 | val_loss : 9791.0830078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1455 | train_loss : 14135.3310546875 | val_loss : 10138.71484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1456 | train_loss : 9372.4501953125 | val_loss : 2831.699462890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1457 | train_loss : 2501.13037109375 | val_loss : 5612.87109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1458 | train_loss : 3642.95751953125 | val_loss : 2359.366943359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1459 | train_loss : 2452.070068359375 | val_loss : 4098.93359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1460 | train_loss : 2072.56640625 | val_loss : 2262.36572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1461 | train_loss : 2444.022705078125 | val_loss : 5876.94482421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1462 | train_loss : 3050.333984375 | val_loss : 1584.565673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1463 | train_loss : 1983.36279296875 | val_loss : 6033.41796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1464 | train_loss : 3560.991943359375 | val_loss : 2304.85693359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1465 | train_loss : 2555.223388671875 | val_loss : 5626.693359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1466 | train_loss : 2736.44775390625 | val_loss : 1806.48193359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1467 | train_loss : 2138.8076171875 | val_loss : 4613.09375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1468 | train_loss : 2799.42724609375 | val_loss : 2182.429443359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1469 | train_loss : 2672.59814453125 | val_loss : 6120.90234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1470 | train_loss : 3117.5146484375 | val_loss : 1415.510009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1471 | train_loss : 1842.6990966796875 | val_loss : 2911.818115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1472 | train_loss : 2487.1318359375 | val_loss : 2236.177490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1473 | train_loss : 1829.8089599609375 | val_loss : 2651.82373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1474 | train_loss : 2186.5927734375 | val_loss : 2611.80810546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1475 | train_loss : 1964.84619140625 | val_loss : 2762.3330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1476 | train_loss : 2143.875244140625 | val_loss : 2873.159423828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1477 | train_loss : 1891.677490234375 | val_loss : 2352.548095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1478 | train_loss : 2170.138427734375 | val_loss : 3852.10693359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1479 | train_loss : 2510.56689453125 | val_loss : 3467.24365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1480 | train_loss : 2759.646240234375 | val_loss : 3187.97998046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1481 | train_loss : 2595.5869140625 | val_loss : 1976.369384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1482 | train_loss : 1398.3555908203125 | val_loss : 2304.1669921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1483 | train_loss : 1343.100341796875 | val_loss : 2576.373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1484 | train_loss : 2072.081298828125 | val_loss : 2735.9951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1485 | train_loss : 2354.1728515625 | val_loss : 2350.746826171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1486 | train_loss : 1479.4425048828125 | val_loss : 2932.738037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1487 | train_loss : 2130.398193359375 | val_loss : 2587.816162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1488 | train_loss : 2097.553955078125 | val_loss : 2644.8798828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1489 | train_loss : 1895.953125 | val_loss : 2821.61572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1490 | train_loss : 2144.877197265625 | val_loss : 3197.295654296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1491 | train_loss : 2137.666748046875 | val_loss : 2973.4130859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1492 | train_loss : 1878.1339111328125 | val_loss : 2296.112548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1493 | train_loss : 2340.14599609375 | val_loss : 3440.518798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1494 | train_loss : 1527.29150390625 | val_loss : 1920.778076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1495 | train_loss : 2267.226806640625 | val_loss : 9604.1806640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1496 | train_loss : 4754.201171875 | val_loss : 1943.315673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1497 | train_loss : 1820.6444091796875 | val_loss : 1432.1312255859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1498 | train_loss : 1442.06591796875 | val_loss : 4393.126953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1499 | train_loss : 2433.483154296875 | val_loss : 1755.7325439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1500 | train_loss : 2233.75341796875 | val_loss : 5356.625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1501 | train_loss : 3001.505859375 | val_loss : 3391.320556640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1502 | train_loss : 3152.62255859375 | val_loss : 4162.888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1503 | train_loss : 2110.634033203125 | val_loss : 2052.935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1504 | train_loss : 2423.80908203125 | val_loss : 6596.525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1505 | train_loss : 3039.31103515625 | val_loss : 2430.69873046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1506 | train_loss : 2373.36865234375 | val_loss : 3226.9482421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1507 | train_loss : 2118.562255859375 | val_loss : 1612.826904296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1508 | train_loss : 1749.692626953125 | val_loss : 3726.06689453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1509 | train_loss : 2318.9755859375 | val_loss : 2497.1494140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1510 | train_loss : 1794.399658203125 | val_loss : 2216.936767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1511 | train_loss : 1953.44287109375 | val_loss : 3437.333740234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1512 | train_loss : 2339.59326171875 | val_loss : 2322.955078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1513 | train_loss : 2415.9052734375 | val_loss : 7380.1123046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1514 | train_loss : 3789.92529296875 | val_loss : 2173.8330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1515 | train_loss : 1668.5294189453125 | val_loss : 1356.33251953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1516 | train_loss : 1501.9620361328125 | val_loss : 4007.58251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1517 | train_loss : 2576.727783203125 | val_loss : 2323.54052734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1518 | train_loss : 2411.994140625 | val_loss : 7715.89208984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1519 | train_loss : 3910.481201171875 | val_loss : 1813.5531005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1520 | train_loss : 1949.5302734375 | val_loss : 1953.8944091796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1521 | train_loss : 1749.1036376953125 | val_loss : 3311.780517578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1522 | train_loss : 2327.043701171875 | val_loss : 2337.7861328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1523 | train_loss : 2391.827392578125 | val_loss : 5199.85693359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1524 | train_loss : 2488.400146484375 | val_loss : 1278.9281005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1525 | train_loss : 1481.7305908203125 | val_loss : 3694.876220703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1526 | train_loss : 2003.458740234375 | val_loss : 1696.88623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1527 | train_loss : 1878.056884765625 | val_loss : 6814.95751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1528 | train_loss : 3238.21630859375 | val_loss : 1568.6868896484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1529 | train_loss : 2023.7640380859375 | val_loss : 2810.179931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1530 | train_loss : 2724.104736328125 | val_loss : 4165.765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1531 | train_loss : 3662.30810546875 | val_loss : 2563.335693359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1532 | train_loss : 2819.172119140625 | val_loss : 7251.283203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1533 | train_loss : 4013.765380859375 | val_loss : 5019.34814453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1534 | train_loss : 3843.8369140625 | val_loss : 2389.608154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1535 | train_loss : 1812.721435546875 | val_loss : 4552.32958984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1536 | train_loss : 2689.132080078125 | val_loss : 3331.71630859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1537 | train_loss : 4345.3857421875 | val_loss : 9769.322265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1538 | train_loss : 5013.7373046875 | val_loss : 2332.517578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1539 | train_loss : 1921.5718994140625 | val_loss : 2831.23876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1540 | train_loss : 2657.8330078125 | val_loss : 6213.63916015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1541 | train_loss : 3669.546142578125 | val_loss : 1079.05810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1542 | train_loss : 1016.6465454101562 | val_loss : 2128.22509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1543 | train_loss : 1214.0537109375 | val_loss : 1657.543701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1544 | train_loss : 1487.328125 | val_loss : 3444.780029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1545 | train_loss : 2564.496337890625 | val_loss : 1938.77001953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1546 | train_loss : 1695.9683837890625 | val_loss : 7560.4033203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1547 | train_loss : 3534.794677734375 | val_loss : 1832.791259765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1548 | train_loss : 2172.111328125 | val_loss : 3696.2294921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1549 | train_loss : 3281.547607421875 | val_loss : 7151.06103515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1550 | train_loss : 3404.95849609375 | val_loss : 1352.4681396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1551 | train_loss : 1611.5731201171875 | val_loss : 4256.98583984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1552 | train_loss : 3016.8427734375 | val_loss : 4138.6142578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1553 | train_loss : 3738.572509765625 | val_loss : 4493.0 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1554 | train_loss : 3063.44384765625 | val_loss : 5254.759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1555 | train_loss : 4292.42333984375 | val_loss : 3940.20068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1556 | train_loss : 2420.55810546875 | val_loss : 4141.14111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1557 | train_loss : 1906.59326171875 | val_loss : 1475.228759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1558 | train_loss : 1538.58837890625 | val_loss : 4445.5595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1559 | train_loss : 2074.2802734375 | val_loss : 1542.0262451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1560 | train_loss : 2204.453125 | val_loss : 4608.54052734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1561 | train_loss : 2118.199951171875 | val_loss : 2530.39501953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1562 | train_loss : 2083.923828125 | val_loss : 5085.13330078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1563 | train_loss : 3169.009765625 | val_loss : 1089.251220703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1564 | train_loss : 996.66796875 | val_loss : 4082.1875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1565 | train_loss : 1773.7734375 | val_loss : 1795.2618408203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1566 | train_loss : 1845.165771484375 | val_loss : 4068.003173828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1567 | train_loss : 1887.7149658203125 | val_loss : 2056.811767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1568 | train_loss : 2414.36083984375 | val_loss : 6619.71435546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1569 | train_loss : 3024.251220703125 | val_loss : 1844.6806640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1570 | train_loss : 1802.4503173828125 | val_loss : 3330.3076171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1571 | train_loss : 2272.130859375 | val_loss : 1353.478759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1572 | train_loss : 1538.2813720703125 | val_loss : 2959.4287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1573 | train_loss : 1910.2105712890625 | val_loss : 1030.9705810546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1574 | train_loss : 1398.7467041015625 | val_loss : 2424.888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1575 | train_loss : 1859.9957275390625 | val_loss : 1223.4012451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1576 | train_loss : 1275.04833984375 | val_loss : 3115.293701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1577 | train_loss : 2049.276611328125 | val_loss : 2385.871826171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1578 | train_loss : 2564.992431640625 | val_loss : 6571.69482421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1579 | train_loss : 2613.09619140625 | val_loss : 1708.7718505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1580 | train_loss : 1229.7255859375 | val_loss : 1185.5550537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1581 | train_loss : 1758.01123046875 | val_loss : 3749.580078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1582 | train_loss : 1913.3984375 | val_loss : 3456.189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1583 | train_loss : 3066.222900390625 | val_loss : 4744.61767578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1584 | train_loss : 2802.402587890625 | val_loss : 952.7949829101562 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1585 | train_loss : 1044.5628662109375 | val_loss : 4345.46240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1586 | train_loss : 1900.345947265625 | val_loss : 1449.19873046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1587 | train_loss : 1345.03564453125 | val_loss : 3857.2724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1588 | train_loss : 2263.530517578125 | val_loss : 1247.8475341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1589 | train_loss : 1393.141845703125 | val_loss : 5175.203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1590 | train_loss : 2735.9853515625 | val_loss : 913.4181518554688 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1591 | train_loss : 1178.6700439453125 | val_loss : 3012.456787109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1592 | train_loss : 1362.9715576171875 | val_loss : 2230.144287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1593 | train_loss : 2469.02099609375 | val_loss : 7243.80419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1594 | train_loss : 2963.853759765625 | val_loss : 2435.4140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1595 | train_loss : 1672.4302978515625 | val_loss : 2593.866943359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1596 | train_loss : 2118.72509765625 | val_loss : 3855.686767578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1597 | train_loss : 2404.781005859375 | val_loss : 2109.68310546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1598 | train_loss : 2357.615966796875 | val_loss : 5378.57177734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1599 | train_loss : 2803.374267578125 | val_loss : 1591.58056640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 1600 | train_loss : 1681.443115234375 | val_loss : 4327.28515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 5 | epoch : 1 | train_loss : 467773.625 | val_loss : 499092.75 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 2 | train_loss : 468058.46875 | val_loss : 627102.9375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 3 | train_loss : 530433.1875 | val_loss : 625895.0625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 4 | train_loss : 629956.8125 | val_loss : 652046.625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 5 | train_loss : 703225.25 | val_loss : 597212.75 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 6 | train_loss : 651188.25 | val_loss : 686480.25 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 7 | train_loss : 788920.0625 | val_loss : 656182.375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 8 | train_loss : 826898.875 | val_loss : 280421.46875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 9 | train_loss : 296301.75 | val_loss : 238597.859375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 10 | train_loss : 285031.375 | val_loss : 289996.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 11 | train_loss : 312608.90625 | val_loss : 300491.75 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 12 | train_loss : 262151.78125 | val_loss : 229542.078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 13 | train_loss : 255560.734375 | val_loss : 309602.75 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 14 | train_loss : 270035.25 | val_loss : 198281.421875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 15 | train_loss : 192254.953125 | val_loss : 254143.015625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 16 | train_loss : 180035.359375 | val_loss : 221133.90625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 17 | train_loss : 156054.859375 | val_loss : 238381.296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 18 | train_loss : 197294.5625 | val_loss : 248603.6875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 19 | train_loss : 256197.40625 | val_loss : 155357.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 20 | train_loss : 201774.34375 | val_loss : 109087.421875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 21 | train_loss : 90210.9609375 | val_loss : 91444.7109375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 22 | train_loss : 130422.53125 | val_loss : 149777.765625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 23 | train_loss : 174721.375 | val_loss : 185107.703125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 24 | train_loss : 146819.5 | val_loss : 166399.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 25 | train_loss : 151444.875 | val_loss : 198600.0 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 26 | train_loss : 162738.015625 | val_loss : 129871.96875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 27 | train_loss : 165993.4375 | val_loss : 235427.09375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 28 | train_loss : 167392.84375 | val_loss : 269836.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 29 | train_loss : 193546.3125 | val_loss : 262869.03125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 30 | train_loss : 222734.296875 | val_loss : 119084.8203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 31 | train_loss : 119853.2578125 | val_loss : 96505.5078125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 32 | train_loss : 96787.703125 | val_loss : 74504.234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 33 | train_loss : 111126.859375 | val_loss : 82115.515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 34 | train_loss : 80352.59375 | val_loss : 95658.6875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 35 | train_loss : 76236.4921875 | val_loss : 83917.7578125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 36 | train_loss : 107418.09375 | val_loss : 154903.765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 37 | train_loss : 67960.953125 | val_loss : 188450.8125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 38 | train_loss : 128168.328125 | val_loss : 179401.234375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 39 | train_loss : 99741.75 | val_loss : 122763.8203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 40 | train_loss : 111060.453125 | val_loss : 229674.421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 41 | train_loss : 172609.0625 | val_loss : 213165.4375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 42 | train_loss : 151118.453125 | val_loss : 233600.140625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 43 | train_loss : 177097.78125 | val_loss : 163306.34375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 44 | train_loss : 141311.625 | val_loss : 116668.203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 45 | train_loss : 129455.53125 | val_loss : 90630.578125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 46 | train_loss : 133465.515625 | val_loss : 112506.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 47 | train_loss : 136972.015625 | val_loss : 149788.953125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 48 | train_loss : 160227.953125 | val_loss : 182128.046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 49 | train_loss : 122163.53125 | val_loss : 148486.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 50 | train_loss : 127372.2421875 | val_loss : 120357.8203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 51 | train_loss : 97202.703125 | val_loss : 104504.2578125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 52 | train_loss : 112602.109375 | val_loss : 64908.92578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 53 | train_loss : 109904.796875 | val_loss : 156151.765625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 54 | train_loss : 118792.0 | val_loss : 153147.296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 55 | train_loss : 117580.3203125 | val_loss : 107411.65625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 56 | train_loss : 131121.6875 | val_loss : 120735.4375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 57 | train_loss : 73052.796875 | val_loss : 66871.0625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 58 | train_loss : 56371.6796875 | val_loss : 81133.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 59 | train_loss : 83412.09375 | val_loss : 158487.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 60 | train_loss : 113083.203125 | val_loss : 154960.84375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 61 | train_loss : 134054.78125 | val_loss : 76803.796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 62 | train_loss : 94666.03125 | val_loss : 100025.890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 63 | train_loss : 92109.546875 | val_loss : 122751.75 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 64 | train_loss : 128506.6484375 | val_loss : 71925.09375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 65 | train_loss : 80104.4765625 | val_loss : 79258.8671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 66 | train_loss : 93968.0703125 | val_loss : 119152.2578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 67 | train_loss : 69217.2421875 | val_loss : 94965.078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 68 | train_loss : 71068.328125 | val_loss : 133932.921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 69 | train_loss : 119444.578125 | val_loss : 112368.2421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 70 | train_loss : 107963.0625 | val_loss : 75295.5078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 71 | train_loss : 76475.9609375 | val_loss : 88727.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 72 | train_loss : 108426.796875 | val_loss : 63801.21484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 73 | train_loss : 65631.078125 | val_loss : 72604.421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 74 | train_loss : 83813.0546875 | val_loss : 86444.15625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 75 | train_loss : 81098.15625 | val_loss : 66145.515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 76 | train_loss : 64763.015625 | val_loss : 77016.1875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 77 | train_loss : 59719.91015625 | val_loss : 39727.51953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 78 | train_loss : 63104.09375 | val_loss : 87254.46875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 79 | train_loss : 72413.296875 | val_loss : 57310.1953125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 80 | train_loss : 85882.8984375 | val_loss : 131774.625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 81 | train_loss : 97494.546875 | val_loss : 117609.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 82 | train_loss : 104783.5078125 | val_loss : 149425.65625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 83 | train_loss : 111898.390625 | val_loss : 142225.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 84 | train_loss : 132459.203125 | val_loss : 184128.375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 85 | train_loss : 169306.21875 | val_loss : 156362.625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 86 | train_loss : 178018.5625 | val_loss : 146558.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 87 | train_loss : 119045.7578125 | val_loss : 74384.9296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 88 | train_loss : 96236.2578125 | val_loss : 113701.6875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 89 | train_loss : 123179.28125 | val_loss : 90166.9765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 90 | train_loss : 85800.09375 | val_loss : 34723.73046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 91 | train_loss : 51209.875 | val_loss : 138322.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 92 | train_loss : 75644.1015625 | val_loss : 114837.3125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 93 | train_loss : 95498.8984375 | val_loss : 134100.65625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 94 | train_loss : 125626.1796875 | val_loss : 100220.7421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 95 | train_loss : 84255.890625 | val_loss : 107264.703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 96 | train_loss : 86726.921875 | val_loss : 124098.1875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 97 | train_loss : 100829.7734375 | val_loss : 93305.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 98 | train_loss : 83719.8984375 | val_loss : 67020.9609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 99 | train_loss : 52826.12890625 | val_loss : 53190.19921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 100 | train_loss : 53884.6953125 | val_loss : 105282.0 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 101 | train_loss : 63750.85546875 | val_loss : 93039.1328125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 102 | train_loss : 77464.9296875 | val_loss : 43346.171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 103 | train_loss : 36113.296875 | val_loss : 78934.65625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 104 | train_loss : 55717.07421875 | val_loss : 63009.91015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 105 | train_loss : 81973.6796875 | val_loss : 83104.765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 106 | train_loss : 86699.53125 | val_loss : 79631.5 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 107 | train_loss : 61527.921875 | val_loss : 100702.8984375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 108 | train_loss : 85316.3515625 | val_loss : 121806.6328125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 109 | train_loss : 94345.2421875 | val_loss : 84374.65625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 110 | train_loss : 65845.5390625 | val_loss : 91680.4296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 111 | train_loss : 73224.0078125 | val_loss : 76680.0859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 112 | train_loss : 78772.390625 | val_loss : 76872.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 113 | train_loss : 64949.23828125 | val_loss : 60982.3203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 114 | train_loss : 56374.0546875 | val_loss : 69086.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 115 | train_loss : 78948.21875 | val_loss : 74949.8828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 116 | train_loss : 54409.4609375 | val_loss : 64507.12890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 117 | train_loss : 51175.94921875 | val_loss : 53104.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 118 | train_loss : 70231.1875 | val_loss : 40470.53125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 119 | train_loss : 50329.953125 | val_loss : 37779.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 120 | train_loss : 50126.3203125 | val_loss : 71077.2578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 121 | train_loss : 60701.87109375 | val_loss : 60526.484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 122 | train_loss : 56871.69921875 | val_loss : 106355.796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 123 | train_loss : 77385.84375 | val_loss : 39954.1875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 124 | train_loss : 51259.390625 | val_loss : 112205.5703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 125 | train_loss : 59165.68359375 | val_loss : 115180.28125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 126 | train_loss : 77449.1015625 | val_loss : 107289.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 127 | train_loss : 74703.96875 | val_loss : 70648.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 128 | train_loss : 58661.39453125 | val_loss : 50816.93359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 129 | train_loss : 37204.828125 | val_loss : 40311.2421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 130 | train_loss : 53011.06640625 | val_loss : 63255.9296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 131 | train_loss : 59543.25 | val_loss : 76843.6484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 132 | train_loss : 66280.84375 | val_loss : 46330.3359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 133 | train_loss : 40302.44921875 | val_loss : 59161.78125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 134 | train_loss : 46903.14453125 | val_loss : 41553.59375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 135 | train_loss : 44344.515625 | val_loss : 89946.7890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 136 | train_loss : 60825.9765625 | val_loss : 64592.46875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 137 | train_loss : 52334.98046875 | val_loss : 55748.1640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 138 | train_loss : 50140.7890625 | val_loss : 44996.0703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 139 | train_loss : 43724.9765625 | val_loss : 55572.73828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 140 | train_loss : 39068.94921875 | val_loss : 26509.4296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 141 | train_loss : 31970.169921875 | val_loss : 59967.76953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 142 | train_loss : 41947.8515625 | val_loss : 52346.1484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 143 | train_loss : 52913.08984375 | val_loss : 45253.66015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 144 | train_loss : 63207.30078125 | val_loss : 90983.671875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 145 | train_loss : 69990.8359375 | val_loss : 28868.318359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 146 | train_loss : 27166.994140625 | val_loss : 41877.76953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 147 | train_loss : 39274.50390625 | val_loss : 82343.03125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 148 | train_loss : 50563.03125 | val_loss : 77099.3515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 149 | train_loss : 57569.90625 | val_loss : 30485.83203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 150 | train_loss : 31755.0546875 | val_loss : 43219.90625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 151 | train_loss : 45295.57421875 | val_loss : 56914.625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 152 | train_loss : 46771.40625 | val_loss : 61950.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 153 | train_loss : 50993.17578125 | val_loss : 47828.12890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 154 | train_loss : 39110.68359375 | val_loss : 30040.775390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 155 | train_loss : 39413.94921875 | val_loss : 40707.45703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 156 | train_loss : 39683.30078125 | val_loss : 36139.90625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 157 | train_loss : 38876.42578125 | val_loss : 77794.9453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 158 | train_loss : 49765.14453125 | val_loss : 30256.150390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 159 | train_loss : 39767.78125 | val_loss : 55287.83984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 160 | train_loss : 39210.328125 | val_loss : 67401.09375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 161 | train_loss : 43658.203125 | val_loss : 41772.203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 162 | train_loss : 36057.1484375 | val_loss : 45020.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 163 | train_loss : 46581.62109375 | val_loss : 29613.1875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 164 | train_loss : 30766.525390625 | val_loss : 37667.546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 165 | train_loss : 28557.44921875 | val_loss : 45090.96484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 166 | train_loss : 32078.107421875 | val_loss : 45548.01171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 167 | train_loss : 36042.625 | val_loss : 29202.794921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 168 | train_loss : 42013.05859375 | val_loss : 51915.28515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 169 | train_loss : 60386.31640625 | val_loss : 33453.0625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 170 | train_loss : 45566.53125 | val_loss : 46299.11328125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 171 | train_loss : 38115.8515625 | val_loss : 67903.5703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 172 | train_loss : 58225.609375 | val_loss : 67616.1953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 173 | train_loss : 81435.71875 | val_loss : 47353.8984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 174 | train_loss : 43850.78515625 | val_loss : 77223.7421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 175 | train_loss : 44139.05078125 | val_loss : 70596.796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 176 | train_loss : 53123.2890625 | val_loss : 34040.99609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 177 | train_loss : 26643.595703125 | val_loss : 41516.453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 178 | train_loss : 37438.3203125 | val_loss : 43724.19921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 179 | train_loss : 45983.53125 | val_loss : 65956.2578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 180 | train_loss : 53644.51953125 | val_loss : 40224.86328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 181 | train_loss : 42464.8984375 | val_loss : 80696.9140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 182 | train_loss : 55515.00390625 | val_loss : 41184.37890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 183 | train_loss : 33786.0546875 | val_loss : 55334.30078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 184 | train_loss : 46847.5 | val_loss : 70718.7578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 185 | train_loss : 52598.390625 | val_loss : 48001.33984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 186 | train_loss : 37390.875 | val_loss : 31578.017578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 187 | train_loss : 26611.453125 | val_loss : 57337.5 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 188 | train_loss : 34431.1328125 | val_loss : 33622.48828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 189 | train_loss : 23239.5390625 | val_loss : 49408.61328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 190 | train_loss : 26592.7109375 | val_loss : 25693.08203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 191 | train_loss : 20677.048828125 | val_loss : 64181.17578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 192 | train_loss : 40126.359375 | val_loss : 34715.94921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 193 | train_loss : 31822.244140625 | val_loss : 43987.3984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 194 | train_loss : 39991.828125 | val_loss : 38621.0703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 195 | train_loss : 38721.1796875 | val_loss : 46670.0 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 196 | train_loss : 37525.51171875 | val_loss : 30109.654296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 197 | train_loss : 28184.82421875 | val_loss : 32082.349609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 198 | train_loss : 16757.3125 | val_loss : 35388.26171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 199 | train_loss : 24972.20703125 | val_loss : 49355.8046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 200 | train_loss : 35322.43359375 | val_loss : 40385.8359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 201 | train_loss : 38706.09765625 | val_loss : 38363.78125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 202 | train_loss : 39230.15625 | val_loss : 39485.203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 203 | train_loss : 42201.5859375 | val_loss : 59831.46875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 204 | train_loss : 38368.31640625 | val_loss : 20211.349609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 205 | train_loss : 26968.76953125 | val_loss : 51355.0390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 206 | train_loss : 30081.560546875 | val_loss : 52225.1796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 207 | train_loss : 31355.494140625 | val_loss : 27585.619140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 208 | train_loss : 29453.515625 | val_loss : 47983.21484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 209 | train_loss : 35439.453125 | val_loss : 17108.75 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 210 | train_loss : 21680.7265625 | val_loss : 17459.931640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 211 | train_loss : 19418.1953125 | val_loss : 29004.77734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 212 | train_loss : 25522.001953125 | val_loss : 27914.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 213 | train_loss : 32485.76953125 | val_loss : 48557.171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 214 | train_loss : 40968.9453125 | val_loss : 41613.73828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 215 | train_loss : 47621.83984375 | val_loss : 55456.26953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 216 | train_loss : 46448.078125 | val_loss : 90705.203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 217 | train_loss : 106664.0234375 | val_loss : 86074.2890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 218 | train_loss : 50980.91015625 | val_loss : 82442.171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 219 | train_loss : 53526.8203125 | val_loss : 42059.98828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 220 | train_loss : 35098.59765625 | val_loss : 35070.23046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 221 | train_loss : 37463.82421875 | val_loss : 44954.3515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 222 | train_loss : 38443.140625 | val_loss : 44075.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 223 | train_loss : 33414.80859375 | val_loss : 46354.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 224 | train_loss : 27343.33984375 | val_loss : 26707.26953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 225 | train_loss : 37627.0546875 | val_loss : 68156.6171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 226 | train_loss : 42568.5546875 | val_loss : 44393.50390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 227 | train_loss : 31247.39453125 | val_loss : 38793.671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 228 | train_loss : 34253.33203125 | val_loss : 43338.71484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 229 | train_loss : 25168.427734375 | val_loss : 34616.23046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 230 | train_loss : 38352.80078125 | val_loss : 61566.2109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 231 | train_loss : 38772.10546875 | val_loss : 19645.193359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 232 | train_loss : 21025.4140625 | val_loss : 39542.87109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 233 | train_loss : 21021.5859375 | val_loss : 36031.25 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 234 | train_loss : 25879.42578125 | val_loss : 31514.51953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 235 | train_loss : 28395.119140625 | val_loss : 23884.1953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 236 | train_loss : 36757.37890625 | val_loss : 57512.61328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 237 | train_loss : 35349.421875 | val_loss : 24276.189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 238 | train_loss : 17525.29296875 | val_loss : 32298.876953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 239 | train_loss : 22585.142578125 | val_loss : 24282.400390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 240 | train_loss : 32318.6640625 | val_loss : 54408.0390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 241 | train_loss : 34181.76953125 | val_loss : 26981.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 242 | train_loss : 32985.3046875 | val_loss : 34414.1328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 243 | train_loss : 46156.57421875 | val_loss : 51793.2265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 244 | train_loss : 49856.06640625 | val_loss : 32401.865234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 245 | train_loss : 35306.71875 | val_loss : 43902.42578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 246 | train_loss : 49211.81640625 | val_loss : 47928.80078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 247 | train_loss : 37742.65625 | val_loss : 30530.625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 248 | train_loss : 20083.470703125 | val_loss : 44652.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 249 | train_loss : 25464.359375 | val_loss : 21665.14453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 250 | train_loss : 21435.814453125 | val_loss : 59979.87109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 251 | train_loss : 30702.609375 | val_loss : 24672.66015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 252 | train_loss : 21853.01953125 | val_loss : 27451.158203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 253 | train_loss : 24763.595703125 | val_loss : 27379.501953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 254 | train_loss : 28530.98046875 | val_loss : 32455.720703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 255 | train_loss : 32349.69921875 | val_loss : 20636.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 256 | train_loss : 21237.640625 | val_loss : 48385.578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 257 | train_loss : 25076.94921875 | val_loss : 18657.58203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 258 | train_loss : 12737.5791015625 | val_loss : 41881.74609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 259 | train_loss : 23994.677734375 | val_loss : 28391.328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 260 | train_loss : 36368.578125 | val_loss : 52430.05078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 261 | train_loss : 37534.40625 | val_loss : 30462.41796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 262 | train_loss : 30339.2578125 | val_loss : 59845.796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 263 | train_loss : 40693.765625 | val_loss : 42125.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 264 | train_loss : 22631.966796875 | val_loss : 30652.484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 265 | train_loss : 27614.48046875 | val_loss : 40555.7265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 266 | train_loss : 40265.28515625 | val_loss : 61817.46875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 267 | train_loss : 43771.31640625 | val_loss : 27519.9140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 268 | train_loss : 26214.244140625 | val_loss : 43722.0546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 269 | train_loss : 23687.3984375 | val_loss : 27305.07421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 270 | train_loss : 31941.587890625 | val_loss : 52722.91015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 271 | train_loss : 34592.12890625 | val_loss : 25636.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 272 | train_loss : 23898.056640625 | val_loss : 35345.1953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 273 | train_loss : 24970.55078125 | val_loss : 19599.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 274 | train_loss : 29156.990234375 | val_loss : 39747.41015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 275 | train_loss : 22450.9375 | val_loss : 17610.54296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 276 | train_loss : 12410.1337890625 | val_loss : 35580.80859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 277 | train_loss : 17786.45703125 | val_loss : 29838.09765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 278 | train_loss : 24279.400390625 | val_loss : 26561.765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 279 | train_loss : 21410.86328125 | val_loss : 18467.65234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 280 | train_loss : 12243.2646484375 | val_loss : 26904.802734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 281 | train_loss : 21644.16015625 | val_loss : 34617.60546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 282 | train_loss : 25144.73828125 | val_loss : 20063.5390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 283 | train_loss : 19504.0234375 | val_loss : 15994.8623046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 284 | train_loss : 19809.8828125 | val_loss : 53187.12890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 285 | train_loss : 34141.796875 | val_loss : 22278.162109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 286 | train_loss : 15841.6337890625 | val_loss : 48260.84375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 287 | train_loss : 22550.654296875 | val_loss : 26892.66796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 288 | train_loss : 22287.83984375 | val_loss : 34241.03125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 289 | train_loss : 30054.455078125 | val_loss : 26041.107421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 290 | train_loss : 22412.404296875 | val_loss : 33783.1953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 291 | train_loss : 18279.587890625 | val_loss : 29372.3046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 292 | train_loss : 14749.0390625 | val_loss : 24714.48828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 293 | train_loss : 19605.537109375 | val_loss : 37336.953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 294 | train_loss : 26324.1875 | val_loss : 24545.51953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 295 | train_loss : 11253.9453125 | val_loss : 16009.1845703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 296 | train_loss : 12519.875 | val_loss : 59400.76171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 297 | train_loss : 26912.2109375 | val_loss : 34445.28125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 298 | train_loss : 25004.0 | val_loss : 38002.7109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 299 | train_loss : 35123.46484375 | val_loss : 35251.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 300 | train_loss : 32476.45703125 | val_loss : 39936.80078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 301 | train_loss : 28665.65234375 | val_loss : 38686.44921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 302 | train_loss : 22881.3515625 | val_loss : 25591.150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 303 | train_loss : 17264.400390625 | val_loss : 27278.568359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 304 | train_loss : 21629.28515625 | val_loss : 32118.28515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 305 | train_loss : 22821.845703125 | val_loss : 33783.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 306 | train_loss : 20337.705078125 | val_loss : 29571.580078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 307 | train_loss : 15651.8447265625 | val_loss : 23604.404296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 308 | train_loss : 18160.8671875 | val_loss : 20114.658203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 309 | train_loss : 14066.2021484375 | val_loss : 19339.85546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 310 | train_loss : 20934.73828125 | val_loss : 40931.3046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 311 | train_loss : 31443.060546875 | val_loss : 32470.66015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 312 | train_loss : 38151.0625 | val_loss : 26803.365234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 313 | train_loss : 16930.373046875 | val_loss : 39014.37109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 314 | train_loss : 32258.1015625 | val_loss : 41347.0390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 315 | train_loss : 22605.38671875 | val_loss : 16058.021484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 316 | train_loss : 16179.1650390625 | val_loss : 38305.09375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 317 | train_loss : 22754.3515625 | val_loss : 37844.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 318 | train_loss : 27613.595703125 | val_loss : 30363.0859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 319 | train_loss : 23153.564453125 | val_loss : 25511.296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 320 | train_loss : 17264.439453125 | val_loss : 39116.05859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 321 | train_loss : 23358.02734375 | val_loss : 39949.953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 322 | train_loss : 20973.443359375 | val_loss : 29328.142578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 323 | train_loss : 22819.75 | val_loss : 21215.1484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 324 | train_loss : 16610.6328125 | val_loss : 59329.80859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 325 | train_loss : 43857.390625 | val_loss : 49278.01953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 326 | train_loss : 30329.349609375 | val_loss : 41633.0625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 327 | train_loss : 33611.86328125 | val_loss : 37383.12109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 328 | train_loss : 29552.681640625 | val_loss : 32069.890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 329 | train_loss : 24419.9296875 | val_loss : 37320.77734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 330 | train_loss : 23358.97265625 | val_loss : 32443.310546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 331 | train_loss : 17361.1796875 | val_loss : 30834.134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 332 | train_loss : 19027.65234375 | val_loss : 18999.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 333 | train_loss : 12625.5322265625 | val_loss : 33692.96484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 334 | train_loss : 20046.421875 | val_loss : 16843.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 335 | train_loss : 15031.513671875 | val_loss : 38616.07421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 336 | train_loss : 20280.29296875 | val_loss : 29315.3046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 337 | train_loss : 28028.48828125 | val_loss : 37685.76171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 338 | train_loss : 31639.88671875 | val_loss : 19530.994140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 339 | train_loss : 13015.181640625 | val_loss : 34232.84765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 340 | train_loss : 17669.625 | val_loss : 33144.96484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 341 | train_loss : 18517.064453125 | val_loss : 17892.921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 342 | train_loss : 12530.2841796875 | val_loss : 22706.224609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 343 | train_loss : 13095.837890625 | val_loss : 25740.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 344 | train_loss : 16898.92578125 | val_loss : 26260.099609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 345 | train_loss : 18428.005859375 | val_loss : 24378.1328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 346 | train_loss : 11612.443359375 | val_loss : 14047.7353515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 347 | train_loss : 15565.982421875 | val_loss : 44542.90625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 348 | train_loss : 26814.787109375 | val_loss : 36431.11328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 349 | train_loss : 22123.552734375 | val_loss : 32875.37109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 350 | train_loss : 28910.05078125 | val_loss : 31063.07421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 351 | train_loss : 25127.462890625 | val_loss : 39592.80078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 352 | train_loss : 19712.5546875 | val_loss : 19665.169921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 353 | train_loss : 10944.361328125 | val_loss : 38074.00390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 354 | train_loss : 18319.984375 | val_loss : 15266.0009765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 355 | train_loss : 10502.6533203125 | val_loss : 25262.51171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 356 | train_loss : 15459.4951171875 | val_loss : 24516.556640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 357 | train_loss : 16978.767578125 | val_loss : 28381.150390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 358 | train_loss : 16073.6845703125 | val_loss : 25350.029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 359 | train_loss : 23622.189453125 | val_loss : 23956.626953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 360 | train_loss : 19366.86328125 | val_loss : 23989.849609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 361 | train_loss : 17208.61328125 | val_loss : 30739.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 362 | train_loss : 22816.34765625 | val_loss : 29546.185546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 363 | train_loss : 18821.359375 | val_loss : 45969.19140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 364 | train_loss : 30643.19921875 | val_loss : 28840.314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 365 | train_loss : 13836.7373046875 | val_loss : 35506.91015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 366 | train_loss : 18440.947265625 | val_loss : 29546.197265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 367 | train_loss : 19200.330078125 | val_loss : 26675.3046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 368 | train_loss : 24016.8828125 | val_loss : 23685.33984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 369 | train_loss : 9478.611328125 | val_loss : 24765.5703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 370 | train_loss : 14074.462890625 | val_loss : 33230.171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 371 | train_loss : 21572.1796875 | val_loss : 21846.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 372 | train_loss : 17606.083984375 | val_loss : 30406.740234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 373 | train_loss : 17838.677734375 | val_loss : 21540.9765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 374 | train_loss : 22580.39453125 | val_loss : 36296.0546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 375 | train_loss : 23256.650390625 | val_loss : 27248.462890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 376 | train_loss : 21128.77734375 | val_loss : 30663.216796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 377 | train_loss : 17636.466796875 | val_loss : 16447.728515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 378 | train_loss : 16677.359375 | val_loss : 35110.28515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 379 | train_loss : 14885.84765625 | val_loss : 23328.623046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 380 | train_loss : 14745.990234375 | val_loss : 28988.470703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 381 | train_loss : 15997.552734375 | val_loss : 18639.92578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 382 | train_loss : 10398.740234375 | val_loss : 20947.412109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 383 | train_loss : 13374.576171875 | val_loss : 26072.306640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 384 | train_loss : 18593.953125 | val_loss : 19800.7890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 385 | train_loss : 11612.7216796875 | val_loss : 21616.3515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 386 | train_loss : 13125.01953125 | val_loss : 21496.044921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 387 | train_loss : 21962.76171875 | val_loss : 170408.9375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 388 | train_loss : 105183.5234375 | val_loss : 18004.337890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 389 | train_loss : 19117.634765625 | val_loss : 37206.64453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 390 | train_loss : 20090.38671875 | val_loss : 32592.255859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 391 | train_loss : 21619.61328125 | val_loss : 31722.8125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 392 | train_loss : 20967.203125 | val_loss : 16321.013671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 393 | train_loss : 12868.587890625 | val_loss : 36599.4609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 394 | train_loss : 17294.51953125 | val_loss : 25374.5390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 395 | train_loss : 12388.78125 | val_loss : 26753.029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 396 | train_loss : 15352.5478515625 | val_loss : 22518.193359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 397 | train_loss : 15199.0791015625 | val_loss : 25428.33984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 398 | train_loss : 12233.96875 | val_loss : 19645.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 399 | train_loss : 18384.984375 | val_loss : 36922.18359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 400 | train_loss : 19998.029296875 | val_loss : 26067.0859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 401 | train_loss : 14702.0009765625 | val_loss : 23194.35546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 402 | train_loss : 13431.4423828125 | val_loss : 18461.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 403 | train_loss : 12140.98828125 | val_loss : 26961.544921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 404 | train_loss : 18803.876953125 | val_loss : 20556.08203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 405 | train_loss : 13304.6689453125 | val_loss : 29957.837890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 406 | train_loss : 17903.689453125 | val_loss : 21587.515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 407 | train_loss : 23079.1171875 | val_loss : 34307.6640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 408 | train_loss : 17813.689453125 | val_loss : 19795.630859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 409 | train_loss : 15401.3525390625 | val_loss : 41098.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 410 | train_loss : 18751.6953125 | val_loss : 31176.38671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 411 | train_loss : 14055.8662109375 | val_loss : 18555.794921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 412 | train_loss : 10770.4228515625 | val_loss : 271925.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 413 | train_loss : 188758.5 | val_loss : 94634.7421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 414 | train_loss : 129610.140625 | val_loss : 78955.1796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 415 | train_loss : 74414.59375 | val_loss : 105053.8828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 416 | train_loss : 67529.7578125 | val_loss : 60439.73046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 417 | train_loss : 39057.98828125 | val_loss : 44847.25 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 418 | train_loss : 35052.12109375 | val_loss : 40769.15234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 419 | train_loss : 27440.068359375 | val_loss : 29098.654296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 420 | train_loss : 22265.994140625 | val_loss : 40037.65625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 421 | train_loss : 23651.48046875 | val_loss : 40252.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 422 | train_loss : 27432.130859375 | val_loss : 31753.279296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 423 | train_loss : 17618.8203125 | val_loss : 22230.1953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 424 | train_loss : 21041.607421875 | val_loss : 40089.01953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 425 | train_loss : 18796.943359375 | val_loss : 23452.45703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 426 | train_loss : 9771.8271484375 | val_loss : 32893.73828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 427 | train_loss : 13694.259765625 | val_loss : 30640.015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 428 | train_loss : 18772.529296875 | val_loss : 27206.556640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 429 | train_loss : 13689.1083984375 | val_loss : 23026.158203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 430 | train_loss : 12165.8515625 | val_loss : 20573.42578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 431 | train_loss : 13001.15234375 | val_loss : 22643.380859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 432 | train_loss : 15829.50390625 | val_loss : 33984.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 433 | train_loss : 20039.06640625 | val_loss : 15547.1435546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 434 | train_loss : 13573.5654296875 | val_loss : 18396.19921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 435 | train_loss : 10392.708984375 | val_loss : 31829.58203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 436 | train_loss : 19360.369140625 | val_loss : 35511.4140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 437 | train_loss : 18410.63671875 | val_loss : 17340.330078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 438 | train_loss : 6165.3173828125 | val_loss : 31431.91796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 439 | train_loss : 14822.92578125 | val_loss : 29127.3359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 440 | train_loss : 13231.083984375 | val_loss : 16937.7421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 441 | train_loss : 26156.005859375 | val_loss : 39375.19921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 442 | train_loss : 27116.169921875 | val_loss : 28739.205078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 443 | train_loss : 19969.724609375 | val_loss : 20455.724609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 444 | train_loss : 19291.986328125 | val_loss : 25385.5234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 445 | train_loss : 8489.0283203125 | val_loss : 20610.046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 446 | train_loss : 8758.4091796875 | val_loss : 32126.322265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 447 | train_loss : 14093.197265625 | val_loss : 30280.794921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 448 | train_loss : 16683.8359375 | val_loss : 23986.619140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 449 | train_loss : 13218.462890625 | val_loss : 20320.32421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 450 | train_loss : 16987.720703125 | val_loss : 26693.564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 451 | train_loss : 12659.474609375 | val_loss : 22027.51953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 452 | train_loss : 9052.625 | val_loss : 13990.0625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 453 | train_loss : 4737.51416015625 | val_loss : 30540.677734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 454 | train_loss : 14359.4599609375 | val_loss : 33417.68359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 455 | train_loss : 21363.859375 | val_loss : 27488.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 456 | train_loss : 13056.607421875 | val_loss : 33527.80859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 457 | train_loss : 29680.966796875 | val_loss : 30698.0546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 458 | train_loss : 22857.857421875 | val_loss : 27184.349609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 459 | train_loss : 15825.326171875 | val_loss : 17725.04296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 460 | train_loss : 17337.912109375 | val_loss : 38334.54296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 461 | train_loss : 20256.59375 | val_loss : 21217.484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 462 | train_loss : 11323.7412109375 | val_loss : 21544.5859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 463 | train_loss : 12207.6435546875 | val_loss : 27326.431640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 464 | train_loss : 16278.27734375 | val_loss : 26727.470703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 465 | train_loss : 19351.41015625 | val_loss : 14460.3662109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 466 | train_loss : 3893.1337890625 | val_loss : 21968.919921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 467 | train_loss : 7517.13623046875 | val_loss : 22621.392578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 468 | train_loss : 12239.36328125 | val_loss : 27145.650390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 469 | train_loss : 14631.005859375 | val_loss : 14206.2978515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 470 | train_loss : 9665.93359375 | val_loss : 25144.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 471 | train_loss : 11906.9013671875 | val_loss : 16603.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 472 | train_loss : 11748.99609375 | val_loss : 28401.169921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 473 | train_loss : 13401.2998046875 | val_loss : 17505.46484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 474 | train_loss : 9732.82421875 | val_loss : 25873.724609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 475 | train_loss : 13973.4453125 | val_loss : 16717.525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 476 | train_loss : 12325.5478515625 | val_loss : 30059.88671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 477 | train_loss : 15143.02734375 | val_loss : 12948.3583984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 478 | train_loss : 10467.4033203125 | val_loss : 30412.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 479 | train_loss : 15290.40234375 | val_loss : 19526.091796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 480 | train_loss : 14261.6591796875 | val_loss : 33437.0859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 481 | train_loss : 21608.9296875 | val_loss : 24798.64453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 482 | train_loss : 15587.318359375 | val_loss : 23010.71484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 483 | train_loss : 14253.955078125 | val_loss : 17464.6953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 484 | train_loss : 8009.552734375 | val_loss : 31722.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 485 | train_loss : 13356.0537109375 | val_loss : 27802.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 486 | train_loss : 14878.951171875 | val_loss : 23063.080078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 487 | train_loss : 12052.7548828125 | val_loss : 15744.705078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 488 | train_loss : 11095.259765625 | val_loss : 36532.16796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 489 | train_loss : 19754.248046875 | val_loss : 15400.919921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 490 | train_loss : 8599.830078125 | val_loss : 19787.517578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 491 | train_loss : 8805.7080078125 | val_loss : 20857.611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 492 | train_loss : 10591.642578125 | val_loss : 19814.162109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 493 | train_loss : 7458.896484375 | val_loss : 17005.796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 494 | train_loss : 10066.396484375 | val_loss : 25210.875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 495 | train_loss : 12816.103515625 | val_loss : 15779.4072265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 496 | train_loss : 8347.6591796875 | val_loss : 15109.6259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 497 | train_loss : 6662.68603515625 | val_loss : 20906.5546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 498 | train_loss : 10673.9150390625 | val_loss : 21705.51953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 499 | train_loss : 12833.462890625 | val_loss : 15066.232421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 500 | train_loss : 7940.90771484375 | val_loss : 21394.64453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 501 | train_loss : 10434.958984375 | val_loss : 18447.23046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 502 | train_loss : 12678.6484375 | val_loss : 23657.892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 503 | train_loss : 11894.197265625 | val_loss : 14646.8974609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 504 | train_loss : 5363.7060546875 | val_loss : 19371.501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 505 | train_loss : 8563.8896484375 | val_loss : 18156.630859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 506 | train_loss : 10291.8486328125 | val_loss : 24673.740234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 507 | train_loss : 12147.2685546875 | val_loss : 17157.056640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 508 | train_loss : 8324.5625 | val_loss : 16613.91015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 509 | train_loss : 9592.53125 | val_loss : 17122.873046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 510 | train_loss : 11260.5224609375 | val_loss : 19700.94921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 511 | train_loss : 9246.9560546875 | val_loss : 13696.041015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 512 | train_loss : 4463.27978515625 | val_loss : 15665.9560546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 513 | train_loss : 9075.3583984375 | val_loss : 30889.193359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 514 | train_loss : 21382.9140625 | val_loss : 29707.912109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 515 | train_loss : 25259.623046875 | val_loss : 17915.40234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 516 | train_loss : 10230.2607421875 | val_loss : 19426.6875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 517 | train_loss : 11089.7822265625 | val_loss : 29217.39453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 518 | train_loss : 14851.9111328125 | val_loss : 15326.5478515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 519 | train_loss : 8803.9130859375 | val_loss : 18911.814453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 520 | train_loss : 8651.279296875 | val_loss : 19175.404296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 521 | train_loss : 8215.7548828125 | val_loss : 21386.60546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 522 | train_loss : 12681.322265625 | val_loss : 18820.630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 523 | train_loss : 8405.42578125 | val_loss : 15811.3583984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 524 | train_loss : 9093.517578125 | val_loss : 18830.248046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 525 | train_loss : 9414.72265625 | val_loss : 23105.1640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 526 | train_loss : 14076.6796875 | val_loss : 25842.994140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 527 | train_loss : 21916.947265625 | val_loss : 25897.615234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 528 | train_loss : 22013.02734375 | val_loss : 26312.9375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 529 | train_loss : 12925.791015625 | val_loss : 16562.3359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 530 | train_loss : 13780.0595703125 | val_loss : 24385.51171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 531 | train_loss : 15204.1201171875 | val_loss : 21756.7734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 532 | train_loss : 9996.7265625 | val_loss : 24031.171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 533 | train_loss : 15624.2001953125 | val_loss : 20721.72265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 534 | train_loss : 17713.0859375 | val_loss : 34857.9765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 535 | train_loss : 19522.28515625 | val_loss : 18460.109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 536 | train_loss : 7511.8974609375 | val_loss : 16356.611328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 537 | train_loss : 5753.58642578125 | val_loss : 16574.609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 538 | train_loss : 8347.083984375 | val_loss : 28398.080078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 539 | train_loss : 14928.5849609375 | val_loss : 25145.064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 540 | train_loss : 16799.3828125 | val_loss : 25555.7578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 541 | train_loss : 17165.2890625 | val_loss : 15511.45703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 542 | train_loss : 9358.8583984375 | val_loss : 28101.76953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 543 | train_loss : 12463.0400390625 | val_loss : 18206.443359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 544 | train_loss : 10119.52734375 | val_loss : 16184.900390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 545 | train_loss : 8353.28125 | val_loss : 16926.2578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 546 | train_loss : 7576.2783203125 | val_loss : 23198.515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 547 | train_loss : 9286.9765625 | val_loss : 14346.8662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 548 | train_loss : 4674.9970703125 | val_loss : 15900.9501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 549 | train_loss : 6385.82080078125 | val_loss : 15216.2890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 550 | train_loss : 7966.78271484375 | val_loss : 21960.279296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 551 | train_loss : 9477.9912109375 | val_loss : 15602.369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 552 | train_loss : 5301.4013671875 | val_loss : 17258.58984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 553 | train_loss : 8093.0185546875 | val_loss : 16595.796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 554 | train_loss : 9397.26953125 | val_loss : 21283.650390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 555 | train_loss : 9713.9501953125 | val_loss : 19034.701171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 556 | train_loss : 7616.654296875 | val_loss : 19497.287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 557 | train_loss : 8392.75390625 | val_loss : 15530.037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 558 | train_loss : 4972.75146484375 | val_loss : 11719.28125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 559 | train_loss : 9493.025390625 | val_loss : 19470.58984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 560 | train_loss : 14711.8134765625 | val_loss : 25975.564453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 561 | train_loss : 15130.884765625 | val_loss : 14349.71484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 562 | train_loss : 10510.46484375 | val_loss : 40382.10546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 563 | train_loss : 16375.73828125 | val_loss : 23592.8203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 564 | train_loss : 15145.6083984375 | val_loss : 22063.21484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 565 | train_loss : 10374.306640625 | val_loss : 18362.88671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 566 | train_loss : 6418.3017578125 | val_loss : 15415.8251953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 567 | train_loss : 4307.15478515625 | val_loss : 19479.701171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 568 | train_loss : 7109.36767578125 | val_loss : 17678.52734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 569 | train_loss : 8730.4775390625 | val_loss : 17080.8125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 570 | train_loss : 10990.7626953125 | val_loss : 25322.96484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 571 | train_loss : 14244.318359375 | val_loss : 18296.443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 572 | train_loss : 7588.74072265625 | val_loss : 14917.2158203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 573 | train_loss : 9268.9990234375 | val_loss : 14136.7490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 574 | train_loss : 8404.150390625 | val_loss : 27168.435546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 575 | train_loss : 12613.365234375 | val_loss : 15484.541015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 576 | train_loss : 10011.1162109375 | val_loss : 15407.173828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 577 | train_loss : 7515.2255859375 | val_loss : 18299.2265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 578 | train_loss : 8750.0732421875 | val_loss : 19122.6953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 579 | train_loss : 9075.59375 | val_loss : 15080.4140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 580 | train_loss : 7027.896484375 | val_loss : 15363.1748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 581 | train_loss : 5880.92822265625 | val_loss : 20736.05859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 582 | train_loss : 9325.1396484375 | val_loss : 22843.4609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 583 | train_loss : 11137.61328125 | val_loss : 18441.6796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 584 | train_loss : 8544.580078125 | val_loss : 24203.6953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 585 | train_loss : 18864.248046875 | val_loss : 23168.474609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 586 | train_loss : 12008.7373046875 | val_loss : 22448.578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 587 | train_loss : 13920.552734375 | val_loss : 28568.5546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 588 | train_loss : 14316.724609375 | val_loss : 24085.814453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 589 | train_loss : 13452.2353515625 | val_loss : 22406.61328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 590 | train_loss : 11470.146484375 | val_loss : 25412.96484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 591 | train_loss : 11951.24609375 | val_loss : 17250.455078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 592 | train_loss : 6762.3662109375 | val_loss : 16795.2734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 593 | train_loss : 8675.4921875 | val_loss : 21483.54296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 594 | train_loss : 10533.732421875 | val_loss : 22689.107421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 595 | train_loss : 12428.1015625 | val_loss : 15625.630859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 596 | train_loss : 9416.04296875 | val_loss : 20168.814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 597 | train_loss : 9329.70703125 | val_loss : 14540.0673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 598 | train_loss : 5551.689453125 | val_loss : 23106.564453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 599 | train_loss : 8842.4658203125 | val_loss : 17049.083984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 600 | train_loss : 7050.59375 | val_loss : 17465.095703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 601 | train_loss : 9774.8447265625 | val_loss : 13966.0478515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 602 | train_loss : 12238.8310546875 | val_loss : 24035.623046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 603 | train_loss : 10192.0234375 | val_loss : 13503.8212890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 604 | train_loss : 7263.578125 | val_loss : 33437.15625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 605 | train_loss : 14991.5849609375 | val_loss : 15098.853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 606 | train_loss : 8395.7109375 | val_loss : 24799.17578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 607 | train_loss : 12305.97265625 | val_loss : 19225.673828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 608 | train_loss : 8460.294921875 | val_loss : 18965.654296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 609 | train_loss : 7194.34765625 | val_loss : 18881.79296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 610 | train_loss : 12242.0009765625 | val_loss : 28893.533203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 611 | train_loss : 13513.6376953125 | val_loss : 19780.615234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 612 | train_loss : 8209.0390625 | val_loss : 22312.46484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 613 | train_loss : 9197.6796875 | val_loss : 33030.2421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 614 | train_loss : 24530.373046875 | val_loss : 26611.099609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 615 | train_loss : 15195.9033203125 | val_loss : 23244.08203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 616 | train_loss : 10388.9384765625 | val_loss : 23298.158203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 617 | train_loss : 14060.1220703125 | val_loss : 21061.5078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 618 | train_loss : 10616.6875 | val_loss : 21852.119140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 619 | train_loss : 10452.2734375 | val_loss : 24945.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 620 | train_loss : 9438.5078125 | val_loss : 21166.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 621 | train_loss : 12619.7509765625 | val_loss : 31398.685546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 622 | train_loss : 13715.7060546875 | val_loss : 20735.82421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 623 | train_loss : 12680.2197265625 | val_loss : 37297.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 624 | train_loss : 15966.287109375 | val_loss : 19033.38671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 625 | train_loss : 7554.8837890625 | val_loss : 19263.193359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 626 | train_loss : 5227.10205078125 | val_loss : 23660.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 627 | train_loss : 6420.3056640625 | val_loss : 14598.7822265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 628 | train_loss : 6535.44140625 | val_loss : 27719.724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 629 | train_loss : 13294.15234375 | val_loss : 15419.1572265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 630 | train_loss : 3237.4306640625 | val_loss : 17398.115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 631 | train_loss : 5183.34228515625 | val_loss : 17887.251953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 632 | train_loss : 7678.03759765625 | val_loss : 18638.90234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 633 | train_loss : 7744.32373046875 | val_loss : 17889.7578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 634 | train_loss : 6875.82958984375 | val_loss : 16577.130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 635 | train_loss : 5937.93115234375 | val_loss : 16741.673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 636 | train_loss : 4272.61865234375 | val_loss : 18132.373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 637 | train_loss : 6251.4814453125 | val_loss : 16711.91796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 638 | train_loss : 7348.28076171875 | val_loss : 18328.66796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 639 | train_loss : 7058.099609375 | val_loss : 20394.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 640 | train_loss : 10472.9248046875 | val_loss : 13474.7021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 641 | train_loss : 9157.5654296875 | val_loss : 17612.55859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 642 | train_loss : 8517.1298828125 | val_loss : 26094.57421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 643 | train_loss : 12569.6279296875 | val_loss : 12939.427734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 644 | train_loss : 7308.1787109375 | val_loss : 22042.69921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 645 | train_loss : 7698.39111328125 | val_loss : 14507.1552734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 646 | train_loss : 3990.701171875 | val_loss : 19250.33984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 647 | train_loss : 4711.0869140625 | val_loss : 17120.474609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 648 | train_loss : 6579.8349609375 | val_loss : 17585.876953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 649 | train_loss : 6988.91259765625 | val_loss : 11639.2177734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 650 | train_loss : 9257.357421875 | val_loss : 20114.32421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 651 | train_loss : 6865.27294921875 | val_loss : 19648.318359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 652 | train_loss : 9490.212890625 | val_loss : 23000.91015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 653 | train_loss : 13120.4609375 | val_loss : 16649.064453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 654 | train_loss : 4448.306640625 | val_loss : 13701.35546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 655 | train_loss : 2968.074462890625 | val_loss : 17848.798828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 656 | train_loss : 4168.88134765625 | val_loss : 18364.306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 657 | train_loss : 7643.40869140625 | val_loss : 16549.51953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 658 | train_loss : 7229.5810546875 | val_loss : 10952.4853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 659 | train_loss : 2652.626953125 | val_loss : 20333.443359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 660 | train_loss : 6605.00830078125 | val_loss : 16414.455078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 661 | train_loss : 8912.3740234375 | val_loss : 21439.376953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 662 | train_loss : 8583.0654296875 | val_loss : 14205.6865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 663 | train_loss : 4394.3232421875 | val_loss : 23832.005859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 664 | train_loss : 10070.7275390625 | val_loss : 15141.6162109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 665 | train_loss : 5995.3349609375 | val_loss : 15388.9404296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 666 | train_loss : 7038.87890625 | val_loss : 14717.568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 667 | train_loss : 7308.826171875 | val_loss : 28368.900390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 668 | train_loss : 12752.787109375 | val_loss : 14517.47265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 669 | train_loss : 6340.23291015625 | val_loss : 32851.01171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 670 | train_loss : 12784.150390625 | val_loss : 23590.16015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 671 | train_loss : 8260.580078125 | val_loss : 27482.69921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 672 | train_loss : 16878.974609375 | val_loss : 31006.78515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 673 | train_loss : 17605.71484375 | val_loss : 22084.703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 674 | train_loss : 11261.9375 | val_loss : 35113.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 675 | train_loss : 23879.1015625 | val_loss : 20697.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 676 | train_loss : 11711.2587890625 | val_loss : 24567.3046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 677 | train_loss : 15097.35546875 | val_loss : 17738.501953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 678 | train_loss : 8628.583984375 | val_loss : 22900.72265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 679 | train_loss : 13554.6708984375 | val_loss : 22065.025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 680 | train_loss : 9854.7294921875 | val_loss : 21657.759765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 681 | train_loss : 10312.359375 | val_loss : 15784.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 682 | train_loss : 5406.2744140625 | val_loss : 17545.658203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 683 | train_loss : 8710.2080078125 | val_loss : 17653.41796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 684 | train_loss : 8692.7216796875 | val_loss : 20606.0703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 685 | train_loss : 9983.6484375 | val_loss : 12984.1201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 686 | train_loss : 7045.93798828125 | val_loss : 21687.154296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 687 | train_loss : 9167.037109375 | val_loss : 13350.625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 688 | train_loss : 3949.683349609375 | val_loss : 14184.7373046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 689 | train_loss : 6403.5341796875 | val_loss : 14433.259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 690 | train_loss : 5743.794921875 | val_loss : 21051.0390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 691 | train_loss : 8018.9873046875 | val_loss : 14123.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 692 | train_loss : 5107.40185546875 | val_loss : 16214.9775390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 693 | train_loss : 8017.89306640625 | val_loss : 14617.03515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 694 | train_loss : 5621.18603515625 | val_loss : 22804.44921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 695 | train_loss : 8840.4912109375 | val_loss : 14605.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 696 | train_loss : 5147.53076171875 | val_loss : 20413.412109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 697 | train_loss : 9312.1240234375 | val_loss : 18864.310546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 698 | train_loss : 11564.6923828125 | val_loss : 27393.02734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 699 | train_loss : 13575.962890625 | val_loss : 13133.1572265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 700 | train_loss : 8919.1376953125 | val_loss : 29880.6484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 701 | train_loss : 8737.37890625 | val_loss : 17190.162109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 702 | train_loss : 6063.11376953125 | val_loss : 27906.080078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 703 | train_loss : 11671.228515625 | val_loss : 18079.94921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 704 | train_loss : 6733.42236328125 | val_loss : 13806.73828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 705 | train_loss : 6733.8623046875 | val_loss : 14032.224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 706 | train_loss : 5438.8056640625 | val_loss : 19567.771484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 707 | train_loss : 9520.3974609375 | val_loss : 18582.931640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 708 | train_loss : 7484.96923828125 | val_loss : 16758.85546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 709 | train_loss : 7633.64990234375 | val_loss : 14605.7861328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 710 | train_loss : 5063.06494140625 | val_loss : 19938.998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 711 | train_loss : 7531.24609375 | val_loss : 12604.2900390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 712 | train_loss : 3902.518798828125 | val_loss : 18533.00390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 713 | train_loss : 7716.140625 | val_loss : 14585.693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 714 | train_loss : 6074.06005859375 | val_loss : 22250.58984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 715 | train_loss : 8936.244140625 | val_loss : 14226.8515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 716 | train_loss : 7232.72607421875 | val_loss : 15649.056640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 717 | train_loss : 9186.646484375 | val_loss : 18611.654296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 718 | train_loss : 11040.755859375 | val_loss : 18622.642578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 719 | train_loss : 9378.0927734375 | val_loss : 13058.34375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 720 | train_loss : 2942.5419921875 | val_loss : 17072.4296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 721 | train_loss : 6715.8173828125 | val_loss : 16534.689453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 722 | train_loss : 7205.3662109375 | val_loss : 20255.91015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 723 | train_loss : 7708.24267578125 | val_loss : 14882.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 724 | train_loss : 6115.8837890625 | val_loss : 15735.2412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 725 | train_loss : 5791.60791015625 | val_loss : 15555.8134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 726 | train_loss : 6412.8876953125 | val_loss : 21420.82421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 727 | train_loss : 9790.4228515625 | val_loss : 13762.53125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 728 | train_loss : 6115.1279296875 | val_loss : 99116.609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 729 | train_loss : 97683.671875 | val_loss : 25125.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 730 | train_loss : 27435.53515625 | val_loss : 23712.099609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 731 | train_loss : 17407.296875 | val_loss : 27006.609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 732 | train_loss : 23104.4609375 | val_loss : 28196.654296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 733 | train_loss : 24668.078125 | val_loss : 159669.734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 734 | train_loss : 181318.34375 | val_loss : 59273.9453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 735 | train_loss : 37798.0703125 | val_loss : 23778.494140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 736 | train_loss : 11548.013671875 | val_loss : 28896.501953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 737 | train_loss : 27255.2890625 | val_loss : 25056.015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 738 | train_loss : 21225.216796875 | val_loss : 20214.66015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 739 | train_loss : 17362.412109375 | val_loss : 21161.73046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 740 | train_loss : 12257.2529296875 | val_loss : 17996.16796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 741 | train_loss : 9463.8359375 | val_loss : 18799.6484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 742 | train_loss : 8970.673828125 | val_loss : 13175.6103515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 743 | train_loss : 8195.125 | val_loss : 18314.060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 744 | train_loss : 8163.99609375 | val_loss : 13317.2509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 745 | train_loss : 5733.8408203125 | val_loss : 13213.037109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 746 | train_loss : 4873.07421875 | val_loss : 13953.384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 747 | train_loss : 5220.79638671875 | val_loss : 16787.060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 748 | train_loss : 6318.17138671875 | val_loss : 13761.3779296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 749 | train_loss : 5131.5478515625 | val_loss : 16153.044921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 750 | train_loss : 6886.587890625 | val_loss : 12134.80859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 751 | train_loss : 3762.601318359375 | val_loss : 15768.0361328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 752 | train_loss : 5998.27490234375 | val_loss : 15772.197265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 753 | train_loss : 6047.166015625 | val_loss : 16480.611328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 754 | train_loss : 7467.1845703125 | val_loss : 12566.2783203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 755 | train_loss : 4752.55126953125 | val_loss : 18746.005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 756 | train_loss : 7148.46630859375 | val_loss : 12446.1337890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 757 | train_loss : 4154.94384765625 | val_loss : 13477.076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 758 | train_loss : 5285.34619140625 | val_loss : 18024.146484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 759 | train_loss : 9925.7421875 | val_loss : 16851.123046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 760 | train_loss : 8973.115234375 | val_loss : 18257.505859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 761 | train_loss : 7471.240234375 | val_loss : 13965.7275390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 762 | train_loss : 7537.47119140625 | val_loss : 19191.48828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 763 | train_loss : 8153.107421875 | val_loss : 17630.44921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 764 | train_loss : 7563.1650390625 | val_loss : 14849.173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 765 | train_loss : 6750.46142578125 | val_loss : 18575.1875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 766 | train_loss : 11584.666015625 | val_loss : 14115.9677734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 767 | train_loss : 9550.4345703125 | val_loss : 15656.51171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 768 | train_loss : 6773.955078125 | val_loss : 16465.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 769 | train_loss : 9818.19921875 | val_loss : 16070.87890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 770 | train_loss : 12684.669921875 | val_loss : 21496.490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 771 | train_loss : 7557.0556640625 | val_loss : 16421.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 772 | train_loss : 6184.00390625 | val_loss : 11184.12890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 773 | train_loss : 5796.74951171875 | val_loss : 17740.64453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 774 | train_loss : 6274.90771484375 | val_loss : 14722.4013671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 775 | train_loss : 13935.22265625 | val_loss : 31716.134765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 776 | train_loss : 14976.22265625 | val_loss : 22404.525390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 777 | train_loss : 9980.7939453125 | val_loss : 25402.9296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 778 | train_loss : 15528.16015625 | val_loss : 20794.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 779 | train_loss : 12262.3310546875 | val_loss : 19238.40234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 780 | train_loss : 7351.59130859375 | val_loss : 14145.587890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 781 | train_loss : 8684.068359375 | val_loss : 19966.755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 782 | train_loss : 8608.6474609375 | val_loss : 17497.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 783 | train_loss : 8213.615234375 | val_loss : 15075.1845703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 784 | train_loss : 7189.44140625 | val_loss : 18939.916015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 785 | train_loss : 7093.076171875 | val_loss : 16018.2646484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 786 | train_loss : 5910.798828125 | val_loss : 16411.099609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 787 | train_loss : 7029.072265625 | val_loss : 15058.97265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 788 | train_loss : 3985.280517578125 | val_loss : 15834.5185546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 789 | train_loss : 3887.41259765625 | val_loss : 13400.08203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 790 | train_loss : 4910.67626953125 | val_loss : 13675.7548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 791 | train_loss : 3960.3701171875 | val_loss : 11628.9287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 792 | train_loss : 2488.60205078125 | val_loss : 29271.142578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 793 | train_loss : 21961.658203125 | val_loss : 14987.326171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 794 | train_loss : 8493.8447265625 | val_loss : 27384.23046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 795 | train_loss : 12889.1826171875 | val_loss : 17872.3046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 796 | train_loss : 6556.70361328125 | val_loss : 18873.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 797 | train_loss : 5850.2880859375 | val_loss : 18778.275390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 798 | train_loss : 7409.4375 | val_loss : 12230.7490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 799 | train_loss : 5904.12060546875 | val_loss : 17757.779296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 800 | train_loss : 8308.5859375 | val_loss : 12964.818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 801 | train_loss : 3344.88623046875 | val_loss : 13066.11328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 802 | train_loss : 4527.232421875 | val_loss : 14578.705078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 803 | train_loss : 6115.79296875 | val_loss : 18013.912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 804 | train_loss : 8243.1708984375 | val_loss : 10438.87109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 805 | train_loss : 4965.65283203125 | val_loss : 14223.23046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 806 | train_loss : 6478.59375 | val_loss : 12415.857421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 807 | train_loss : 6350.82666015625 | val_loss : 17132.84375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 808 | train_loss : 6476.64013671875 | val_loss : 11816.3798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 809 | train_loss : 3731.35009765625 | val_loss : 11956.150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 810 | train_loss : 4328.91259765625 | val_loss : 14878.2578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 811 | train_loss : 7128.58544921875 | val_loss : 15092.5224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 812 | train_loss : 8010.087890625 | val_loss : 51372.8515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 813 | train_loss : 49835.30078125 | val_loss : 24182.681640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 814 | train_loss : 29983.365234375 | val_loss : 22312.5546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 815 | train_loss : 21937.51953125 | val_loss : 28260.345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 816 | train_loss : 12797.6923828125 | val_loss : 13084.5146484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 817 | train_loss : 5204.00244140625 | val_loss : 18253.607421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 818 | train_loss : 6756.57666015625 | val_loss : 14194.486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 819 | train_loss : 5088.06396484375 | val_loss : 16437.67578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 820 | train_loss : 6738.5419921875 | val_loss : 10674.26953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 821 | train_loss : 5634.07373046875 | val_loss : 18803.78125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 822 | train_loss : 7086.95361328125 | val_loss : 11724.861328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 823 | train_loss : 3253.989990234375 | val_loss : 14638.2578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 824 | train_loss : 5002.63232421875 | val_loss : 12298.955078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 825 | train_loss : 5652.7451171875 | val_loss : 16315.1162109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 826 | train_loss : 6140.80615234375 | val_loss : 10838.0146484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 827 | train_loss : 3293.170654296875 | val_loss : 13848.8037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 828 | train_loss : 4498.4970703125 | val_loss : 12767.2861328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 829 | train_loss : 6442.37548828125 | val_loss : 16636.30078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 830 | train_loss : 5616.62353515625 | val_loss : 11316.4658203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 831 | train_loss : 3074.654052734375 | val_loss : 16772.7890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 832 | train_loss : 6789.62939453125 | val_loss : 13351.80078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 833 | train_loss : 4024.262451171875 | val_loss : 11674.63671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 834 | train_loss : 4329.72998046875 | val_loss : 12245.2041015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 835 | train_loss : 4994.48828125 | val_loss : 15780.08984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 836 | train_loss : 7836.85009765625 | val_loss : 12561.7958984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 837 | train_loss : 3923.99365234375 | val_loss : 13646.16796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 838 | train_loss : 6505.0380859375 | val_loss : 11122.8701171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 839 | train_loss : 5941.119140625 | val_loss : 20583.3828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 840 | train_loss : 7991.02294921875 | val_loss : 11023.2060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 841 | train_loss : 4730.2900390625 | val_loss : 19534.068359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 842 | train_loss : 6692.4638671875 | val_loss : 11284.900390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 843 | train_loss : 5100.6357421875 | val_loss : 21587.619140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 844 | train_loss : 9081.5263671875 | val_loss : 13117.298828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 845 | train_loss : 5482.55322265625 | val_loss : 18466.630859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 846 | train_loss : 8783.37890625 | val_loss : 15569.41015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 847 | train_loss : 7406.267578125 | val_loss : 12829.2265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 848 | train_loss : 8399.96875 | val_loss : 14657.7666015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 849 | train_loss : 6197.9091796875 | val_loss : 15875.0029296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 850 | train_loss : 5686.24267578125 | val_loss : 10666.90625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 851 | train_loss : 3202.088134765625 | val_loss : 12506.8564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 852 | train_loss : 4393.794921875 | val_loss : 11193.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 853 | train_loss : 5355.2626953125 | val_loss : 15493.7060546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 854 | train_loss : 6445.677734375 | val_loss : 12623.677734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 855 | train_loss : 4550.642578125 | val_loss : 13056.4912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 856 | train_loss : 5566.53076171875 | val_loss : 12329.521484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 857 | train_loss : 5586.01123046875 | val_loss : 18131.03125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 858 | train_loss : 7409.43359375 | val_loss : 12649.71875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 859 | train_loss : 3571.8173828125 | val_loss : 14660.7939453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 860 | train_loss : 6174.978515625 | val_loss : 12560.5087890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 861 | train_loss : 5480.40185546875 | val_loss : 17501.94140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 862 | train_loss : 7016.0048828125 | val_loss : 11461.052734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 863 | train_loss : 3649.363037109375 | val_loss : 12524.9013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 864 | train_loss : 5202.2109375 | val_loss : 12031.076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 865 | train_loss : 6359.75244140625 | val_loss : 17480.01953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 866 | train_loss : 7916.0986328125 | val_loss : 11529.30078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 867 | train_loss : 3114.9140625 | val_loss : 11034.994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 868 | train_loss : 4210.162109375 | val_loss : 12447.63671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 869 | train_loss : 4612.029296875 | val_loss : 15582.5341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 870 | train_loss : 6604.2236328125 | val_loss : 12635.3720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 871 | train_loss : 3069.5634765625 | val_loss : 12442.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 872 | train_loss : 4065.38720703125 | val_loss : 12269.1328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 873 | train_loss : 4159.70068359375 | val_loss : 15350.9091796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 874 | train_loss : 6450.74853515625 | val_loss : 11857.986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 875 | train_loss : 3384.824951171875 | val_loss : 15699.3251953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 876 | train_loss : 5476.41796875 | val_loss : 11833.400390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 877 | train_loss : 5467.923828125 | val_loss : 17734.208984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 878 | train_loss : 7697.212890625 | val_loss : 11977.3603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 879 | train_loss : 3757.541259765625 | val_loss : 13710.1640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 880 | train_loss : 4968.76806640625 | val_loss : 12030.21875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 881 | train_loss : 4818.61669921875 | val_loss : 15015.20703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 882 | train_loss : 7641.0751953125 | val_loss : 10050.787109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 883 | train_loss : 3306.556884765625 | val_loss : 14151.0048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 884 | train_loss : 4898.01708984375 | val_loss : 11534.58203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 885 | train_loss : 4996.712890625 | val_loss : 17311.08203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 886 | train_loss : 6864.41259765625 | val_loss : 10482.2158203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 887 | train_loss : 5990.05078125 | val_loss : 11189.5791015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 888 | train_loss : 3405.6181640625 | val_loss : 12420.0986328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 889 | train_loss : 4860.41455078125 | val_loss : 14722.5888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 890 | train_loss : 6062.94384765625 | val_loss : 10888.95703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 891 | train_loss : 3435.144775390625 | val_loss : 11866.416015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 892 | train_loss : 5045.140625 | val_loss : 84560.8828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 893 | train_loss : 72416.6953125 | val_loss : 32967.71875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 894 | train_loss : 26124.783203125 | val_loss : 38520.48828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 895 | train_loss : 22271.05078125 | val_loss : 14649.8486328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 896 | train_loss : 7088.26611328125 | val_loss : 11379.6484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 897 | train_loss : 6159.96875 | val_loss : 18496.87890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 898 | train_loss : 7521.5400390625 | val_loss : 13509.017578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 899 | train_loss : 5812.60888671875 | val_loss : 14336.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 900 | train_loss : 4733.71826171875 | val_loss : 13031.2236328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 901 | train_loss : 4482.4580078125 | val_loss : 15809.669921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 902 | train_loss : 5958.28515625 | val_loss : 12412.048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 903 | train_loss : 4858.1630859375 | val_loss : 11688.47265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 904 | train_loss : 3907.4951171875 | val_loss : 11953.912109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 905 | train_loss : 4476.21484375 | val_loss : 14823.4736328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 906 | train_loss : 8211.7470703125 | val_loss : 13831.451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 907 | train_loss : 5118.3974609375 | val_loss : 14419.861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 908 | train_loss : 7740.00390625 | val_loss : 10615.1513671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 909 | train_loss : 8582.60546875 | val_loss : 16973.818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 910 | train_loss : 6697.02001953125 | val_loss : 10604.5302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 911 | train_loss : 2461.361572265625 | val_loss : 14027.705078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 912 | train_loss : 4757.66943359375 | val_loss : 10192.9384765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 913 | train_loss : 2547.25439453125 | val_loss : 11890.798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 914 | train_loss : 3626.260986328125 | val_loss : 13358.2197265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 915 | train_loss : 6289.173828125 | val_loss : 32665.525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 916 | train_loss : 25261.158203125 | val_loss : 22131.474609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 917 | train_loss : 9294.3427734375 | val_loss : 21100.294921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 918 | train_loss : 15177.599609375 | val_loss : 37250.83984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 919 | train_loss : 15291.7021484375 | val_loss : 28676.580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 920 | train_loss : 10173.9765625 | val_loss : 22344.837890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 921 | train_loss : 23937.32421875 | val_loss : 33060.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 922 | train_loss : 19517.443359375 | val_loss : 22160.8203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 923 | train_loss : 14208.4365234375 | val_loss : 18898.544921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 924 | train_loss : 11695.888671875 | val_loss : 18213.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 925 | train_loss : 7363.1533203125 | val_loss : 14730.8583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 926 | train_loss : 4141.0732421875 | val_loss : 20398.880859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 927 | train_loss : 6258.92822265625 | val_loss : 17163.1640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 928 | train_loss : 6772.0185546875 | val_loss : 18634.10546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 929 | train_loss : 6916.1669921875 | val_loss : 13720.7783203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 930 | train_loss : 3540.516357421875 | val_loss : 15644.068359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 931 | train_loss : 4635.66455078125 | val_loss : 15212.9833984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 932 | train_loss : 5402.1611328125 | val_loss : 14550.0595703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 933 | train_loss : 5362.21630859375 | val_loss : 13251.44921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 934 | train_loss : 3925.337890625 | val_loss : 18932.087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 935 | train_loss : 5941.79248046875 | val_loss : 12817.4951171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 936 | train_loss : 3866.425537109375 | val_loss : 14252.61328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 937 | train_loss : 5398.1650390625 | val_loss : 13605.9521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 938 | train_loss : 3675.092529296875 | val_loss : 16031.8037109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 939 | train_loss : 5451.65625 | val_loss : 13435.7509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 940 | train_loss : 3599.5712890625 | val_loss : 11818.7939453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 941 | train_loss : 3682.74365234375 | val_loss : 12239.267578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 942 | train_loss : 3393.838134765625 | val_loss : 16725.265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 943 | train_loss : 6084.70166015625 | val_loss : 12344.64453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 944 | train_loss : 2732.133544921875 | val_loss : 13157.7451171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 945 | train_loss : 4402.31494140625 | val_loss : 12668.7802734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 946 | train_loss : 3775.312255859375 | val_loss : 23272.234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 947 | train_loss : 15509.5927734375 | val_loss : 16507.97265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 948 | train_loss : 8618.5703125 | val_loss : 14319.1884765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 949 | train_loss : 6348.947265625 | val_loss : 26758.681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 950 | train_loss : 8273.9462890625 | val_loss : 20687.77734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 951 | train_loss : 6217.7685546875 | val_loss : 14706.35546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 952 | train_loss : 5608.361328125 | val_loss : 18844.150390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 953 | train_loss : 6014.6162109375 | val_loss : 12455.0302734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 954 | train_loss : 3406.0517578125 | val_loss : 14275.76953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 955 | train_loss : 4557.6865234375 | val_loss : 12761.451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 956 | train_loss : 4381.15673828125 | val_loss : 15407.0341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 957 | train_loss : 5900.80615234375 | val_loss : 12703.9775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 958 | train_loss : 3666.608642578125 | val_loss : 12553.6787109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 959 | train_loss : 4829.154296875 | val_loss : 13111.3251953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 960 | train_loss : 4562.1376953125 | val_loss : 15296.51171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 961 | train_loss : 5545.81298828125 | val_loss : 11074.7646484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 962 | train_loss : 3235.116943359375 | val_loss : 12355.818359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 963 | train_loss : 4354.92919921875 | val_loss : 12104.4052734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 964 | train_loss : 3857.423828125 | val_loss : 14821.396484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 965 | train_loss : 5765.78369140625 | val_loss : 11130.6796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 966 | train_loss : 2715.02001953125 | val_loss : 163655.625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 967 | train_loss : 127336.9921875 | val_loss : 42240.71484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 968 | train_loss : 38657.421875 | val_loss : 26604.21484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 969 | train_loss : 17083.841796875 | val_loss : 25746.810546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 970 | train_loss : 12026.30859375 | val_loss : 19336.916015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 971 | train_loss : 6751.4033203125 | val_loss : 19396.91796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 972 | train_loss : 7482.78125 | val_loss : 19701.587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 973 | train_loss : 7347.3173828125 | val_loss : 13752.85546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 974 | train_loss : 4096.57861328125 | val_loss : 15014.23046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 975 | train_loss : 3479.662109375 | val_loss : 14924.6162109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 976 | train_loss : 3401.7822265625 | val_loss : 15024.37890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 977 | train_loss : 4520.888671875 | val_loss : 14568.5078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 978 | train_loss : 6167.453125 | val_loss : 21485.5703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 979 | train_loss : 9760.662109375 | val_loss : 16065.99609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 980 | train_loss : 7521.17626953125 | val_loss : 14444.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 981 | train_loss : 6537.798828125 | val_loss : 14755.197265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 982 | train_loss : 6124.47607421875 | val_loss : 16240.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 983 | train_loss : 6051.4873046875 | val_loss : 14770.14453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 984 | train_loss : 5468.2548828125 | val_loss : 14153.6064453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 985 | train_loss : 5823.20556640625 | val_loss : 11608.0048828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 986 | train_loss : 4321.2861328125 | val_loss : 15932.2265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 987 | train_loss : 5111.27685546875 | val_loss : 13324.5078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 988 | train_loss : 3930.490966796875 | val_loss : 15579.099609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 989 | train_loss : 4809.8466796875 | val_loss : 11897.6025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 990 | train_loss : 3033.159423828125 | val_loss : 12530.3212890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 991 | train_loss : 3726.10498046875 | val_loss : 11692.5966796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 992 | train_loss : 4821.83544921875 | val_loss : 15336.26953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 993 | train_loss : 4970.12890625 | val_loss : 12698.9453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 994 | train_loss : 3248.01220703125 | val_loss : 15376.85546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 995 | train_loss : 2856.932861328125 | val_loss : 12416.55078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 996 | train_loss : 4693.0185546875 | val_loss : 18777.80078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 997 | train_loss : 6713.39111328125 | val_loss : 12123.6591796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 998 | train_loss : 4891.85546875 | val_loss : 12348.46484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 999 | train_loss : 3471.362548828125 | val_loss : 13846.59375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1000 | train_loss : 4161.8095703125 | val_loss : 13801.4775390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1001 | train_loss : 5633.94384765625 | val_loss : 12927.349609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1002 | train_loss : 6109.8779296875 | val_loss : 13815.5625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1003 | train_loss : 6047.75732421875 | val_loss : 14015.0712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1004 | train_loss : 5799.61767578125 | val_loss : 13954.9599609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1005 | train_loss : 4741.90478515625 | val_loss : 13340.7958984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1006 | train_loss : 3489.114990234375 | val_loss : 15477.5 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1007 | train_loss : 4255.13134765625 | val_loss : 12130.9677734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1008 | train_loss : 2979.527587890625 | val_loss : 12592.837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1009 | train_loss : 4742.537109375 | val_loss : 11941.7001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1010 | train_loss : 3250.30615234375 | val_loss : 14918.0263671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1011 | train_loss : 4773.8642578125 | val_loss : 12663.3447265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1012 | train_loss : 3351.25244140625 | val_loss : 10450.513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1013 | train_loss : 6029.3564453125 | val_loss : 11737.0771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1014 | train_loss : 2821.258056640625 | val_loss : 12847.3212890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1015 | train_loss : 3785.0712890625 | val_loss : 13320.7333984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1016 | train_loss : 4882.9658203125 | val_loss : 13351.7783203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1017 | train_loss : 7656.42041015625 | val_loss : 10324.5810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1018 | train_loss : 2994.376220703125 | val_loss : 13162.5126953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1019 | train_loss : 4254.30126953125 | val_loss : 10026.208984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1020 | train_loss : 3321.5185546875 | val_loss : 16575.93359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1021 | train_loss : 6704.84521484375 | val_loss : 11030.12109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1022 | train_loss : 2935.719482421875 | val_loss : 12606.580078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1023 | train_loss : 4258.65380859375 | val_loss : 10876.419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1024 | train_loss : 2963.576171875 | val_loss : 14675.572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1025 | train_loss : 4366.833984375 | val_loss : 11623.630859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1026 | train_loss : 3976.780517578125 | val_loss : 13893.1162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1027 | train_loss : 4238.65771484375 | val_loss : 10816.8759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1028 | train_loss : 4277.412109375 | val_loss : 14843.142578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1029 | train_loss : 5082.03173828125 | val_loss : 10976.4833984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1030 | train_loss : 5371.23876953125 | val_loss : 14950.087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1031 | train_loss : 5769.498046875 | val_loss : 14550.7421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1032 | train_loss : 6722.65380859375 | val_loss : 12135.521484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1033 | train_loss : 7220.25244140625 | val_loss : 14036.919921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1034 | train_loss : 4620.927734375 | val_loss : 15061.837890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1035 | train_loss : 4436.8876953125 | val_loss : 11935.2041015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1036 | train_loss : 3438.57373046875 | val_loss : 17455.369140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1037 | train_loss : 5617.9580078125 | val_loss : 12273.7109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1038 | train_loss : 5624.50390625 | val_loss : 14200.4921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1039 | train_loss : 5334.4580078125 | val_loss : 13603.81640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1040 | train_loss : 4186.61328125 | val_loss : 14980.892578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1041 | train_loss : 4626.974609375 | val_loss : 11500.1708984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1042 | train_loss : 3975.195556640625 | val_loss : 16746.66796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1043 | train_loss : 6797.8232421875 | val_loss : 10607.04296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1044 | train_loss : 2958.7431640625 | val_loss : 16341.55078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1045 | train_loss : 4566.458984375 | val_loss : 10850.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1046 | train_loss : 3829.859375 | val_loss : 16672.462890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1047 | train_loss : 5107.12939453125 | val_loss : 11036.13671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1048 | train_loss : 3501.596923828125 | val_loss : 15896.712890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1049 | train_loss : 5062.8486328125 | val_loss : 10726.732421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1050 | train_loss : 6376.10888671875 | val_loss : 14468.3427734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1051 | train_loss : 4554.41455078125 | val_loss : 11676.6240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1052 | train_loss : 3259.119384765625 | val_loss : 13806.22265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1053 | train_loss : 4315.68896484375 | val_loss : 12232.94921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1054 | train_loss : 3009.831298828125 | val_loss : 14922.806640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1055 | train_loss : 4507.35107421875 | val_loss : 12207.81640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1056 | train_loss : 3623.7900390625 | val_loss : 14195.2802734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1057 | train_loss : 4604.0283203125 | val_loss : 11089.416015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1058 | train_loss : 2638.02490234375 | val_loss : 11913.697265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1059 | train_loss : 4514.392578125 | val_loss : 11366.392578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1060 | train_loss : 3631.344970703125 | val_loss : 14738.74609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1061 | train_loss : 6158.39453125 | val_loss : 9767.6591796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1062 | train_loss : 3672.59716796875 | val_loss : 14286.91015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1063 | train_loss : 4337.7138671875 | val_loss : 10553.5078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1064 | train_loss : 4412.03857421875 | val_loss : 14179.5390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1065 | train_loss : 5027.7568359375 | val_loss : 10688.3779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1066 | train_loss : 2969.43603515625 | val_loss : 11800.0361328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1067 | train_loss : 4756.1845703125 | val_loss : 11039.5029296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1068 | train_loss : 3427.137451171875 | val_loss : 13422.6748046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1069 | train_loss : 4936.05078125 | val_loss : 11860.70703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1070 | train_loss : 2820.96630859375 | val_loss : 10739.072265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1071 | train_loss : 3520.082275390625 | val_loss : 11163.6826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1072 | train_loss : 2824.63623046875 | val_loss : 12340.0771484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1073 | train_loss : 4880.58056640625 | val_loss : 11037.8154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1074 | train_loss : 4018.980224609375 | val_loss : 15488.1337890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1075 | train_loss : 6052.75830078125 | val_loss : 10551.7353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1076 | train_loss : 3362.377197265625 | val_loss : 15158.0400390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1077 | train_loss : 5697.56982421875 | val_loss : 10343.3876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1078 | train_loss : 3392.345947265625 | val_loss : 12048.3408203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1079 | train_loss : 4610.42919921875 | val_loss : 10348.7841796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1080 | train_loss : 2970.155029296875 | val_loss : 12774.75 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1081 | train_loss : 3779.34814453125 | val_loss : 12255.14453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1082 | train_loss : 3967.422607421875 | val_loss : 15938.212890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1083 | train_loss : 5119.14453125 | val_loss : 9967.349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1084 | train_loss : 2199.531494140625 | val_loss : 493620.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1085 | train_loss : 332067.8125 | val_loss : 17894.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1086 | train_loss : 13724.8359375 | val_loss : 100830.5390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1087 | train_loss : 57879.89453125 | val_loss : 52632.18359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1088 | train_loss : 37717.2578125 | val_loss : 17908.279296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1089 | train_loss : 16984.958984375 | val_loss : 20854.943359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1090 | train_loss : 11189.6025390625 | val_loss : 14592.4873046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1091 | train_loss : 8673.1689453125 | val_loss : 20373.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1092 | train_loss : 8630.0751953125 | val_loss : 13832.2373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1093 | train_loss : 6873.97119140625 | val_loss : 17829.751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1094 | train_loss : 5272.63623046875 | val_loss : 14168.1650390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1095 | train_loss : 4749.828125 | val_loss : 16573.349609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1096 | train_loss : 5105.0439453125 | val_loss : 14419.6845703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1097 | train_loss : 3490.40966796875 | val_loss : 15355.669921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1098 | train_loss : 4406.0693359375 | val_loss : 14280.2509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1099 | train_loss : 2830.811279296875 | val_loss : 13210.03125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1100 | train_loss : 4384.53125 | val_loss : 16375.5595703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1101 | train_loss : 4610.041015625 | val_loss : 14072.6279296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1102 | train_loss : 2508.26708984375 | val_loss : 13207.134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1103 | train_loss : 2613.261474609375 | val_loss : 13861.35546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1104 | train_loss : 4616.998046875 | val_loss : 13859.2421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1105 | train_loss : 3299.49755859375 | val_loss : 15826.2529296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1106 | train_loss : 4404.9970703125 | val_loss : 14348.0341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1107 | train_loss : 4457.81103515625 | val_loss : 12733.6728515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1108 | train_loss : 2961.84375 | val_loss : 13514.53515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1109 | train_loss : 3294.59130859375 | val_loss : 13282.6328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1110 | train_loss : 4363.32177734375 | val_loss : 15950.5224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1111 | train_loss : 5923.9443359375 | val_loss : 15798.7412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1112 | train_loss : 4752.169921875 | val_loss : 12822.02734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1113 | train_loss : 4202.31298828125 | val_loss : 16427.125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1114 | train_loss : 5703.505859375 | val_loss : 12132.0634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1115 | train_loss : 3529.06005859375 | val_loss : 13006.166015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1116 | train_loss : 3371.885009765625 | val_loss : 13416.544921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1117 | train_loss : 4757.61083984375 | val_loss : 15844.2529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1118 | train_loss : 5715.29736328125 | val_loss : 12183.021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1119 | train_loss : 3239.934326171875 | val_loss : 12715.0087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1120 | train_loss : 3024.8798828125 | val_loss : 12828.8916015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1121 | train_loss : 3413.418212890625 | val_loss : 12748.4404296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1122 | train_loss : 3467.58447265625 | val_loss : 12008.9521484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1123 | train_loss : 3394.728515625 | val_loss : 12137.1953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1124 | train_loss : 3310.99560546875 | val_loss : 12615.19140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1125 | train_loss : 3939.5380859375 | val_loss : 16259.19921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1126 | train_loss : 5004.18310546875 | val_loss : 11059.3603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1127 | train_loss : 3294.05908203125 | val_loss : 14002.142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1128 | train_loss : 4868.2177734375 | val_loss : 10464.4677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1129 | train_loss : 3023.09814453125 | val_loss : 12428.2890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1130 | train_loss : 3607.63720703125 | val_loss : 10756.884765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1131 | train_loss : 3294.534912109375 | val_loss : 14746.76953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1132 | train_loss : 4677.8310546875 | val_loss : 10454.4033203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1133 | train_loss : 3101.621826171875 | val_loss : 12824.5703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1134 | train_loss : 3456.234619140625 | val_loss : 12123.4453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1135 | train_loss : 4026.593017578125 | val_loss : 14792.3798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1136 | train_loss : 5719.2900390625 | val_loss : 10571.3525390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1137 | train_loss : 3150.3251953125 | val_loss : 11906.6123046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1138 | train_loss : 3633.722412109375 | val_loss : 10684.1708984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1139 | train_loss : 3507.87060546875 | val_loss : 14029.37109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1140 | train_loss : 4417.44384765625 | val_loss : 9915.6923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1141 | train_loss : 3007.88916015625 | val_loss : 14859.3115234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1142 | train_loss : 4612.251953125 | val_loss : 11172.2724609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1143 | train_loss : 3489.198486328125 | val_loss : 15644.7109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1144 | train_loss : 4696.51318359375 | val_loss : 10227.0185546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1145 | train_loss : 2780.231201171875 | val_loss : 14650.7490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1146 | train_loss : 4390.01171875 | val_loss : 10482.6669921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1147 | train_loss : 3091.764892578125 | val_loss : 12838.86328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1148 | train_loss : 3418.859619140625 | val_loss : 10892.677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1149 | train_loss : 4022.830078125 | val_loss : 14389.865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1150 | train_loss : 5143.087890625 | val_loss : 11299.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1151 | train_loss : 3732.550048828125 | val_loss : 12846.830078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1152 | train_loss : 3296.4482421875 | val_loss : 10912.8759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1153 | train_loss : 3603.28759765625 | val_loss : 14033.412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1154 | train_loss : 4310.814453125 | val_loss : 10392.2041015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1155 | train_loss : 3018.077392578125 | val_loss : 12650.9345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1156 | train_loss : 3232.234130859375 | val_loss : 10341.2958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1157 | train_loss : 3582.984375 | val_loss : 14090.3251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1158 | train_loss : 4803.13671875 | val_loss : 11746.61328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1159 | train_loss : 3783.7626953125 | val_loss : 11309.9326171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1160 | train_loss : 3388.368408203125 | val_loss : 16786.76171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1161 | train_loss : 5122.37548828125 | val_loss : 15399.66015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1162 | train_loss : 4358.69580078125 | val_loss : 10671.3310546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1163 | train_loss : 4415.44189453125 | val_loss : 14530.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1164 | train_loss : 4502.72607421875 | val_loss : 13977.125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1165 | train_loss : 4790.0615234375 | val_loss : 17064.80078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1166 | train_loss : 7018.8779296875 | val_loss : 15639.4052734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1167 | train_loss : 7066.07958984375 | val_loss : 17400.49609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1168 | train_loss : 7135.826171875 | val_loss : 12625.3876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1169 | train_loss : 4597.47314453125 | val_loss : 15457.478515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1170 | train_loss : 4593.28759765625 | val_loss : 11168.9365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1171 | train_loss : 3701.168212890625 | val_loss : 15554.4248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1172 | train_loss : 4563.26123046875 | val_loss : 9485.6953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1173 | train_loss : 3600.818359375 | val_loss : 15561.2802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1174 | train_loss : 3796.539794921875 | val_loss : 8819.08984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1175 | train_loss : 2739.79248046875 | val_loss : 30055.123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1176 | train_loss : 18778.1953125 | val_loss : 23358.751953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1177 | train_loss : 14649.138671875 | val_loss : 17926.1875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1178 | train_loss : 13452.08984375 | val_loss : 23926.23828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1179 | train_loss : 10544.708984375 | val_loss : 19397.109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1180 | train_loss : 4939.76611328125 | val_loss : 13664.8837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1181 | train_loss : 4164.51953125 | val_loss : 19208.65625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1182 | train_loss : 6368.09423828125 | val_loss : 13424.0234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1183 | train_loss : 3814.650390625 | val_loss : 18228.404296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1184 | train_loss : 5718.3642578125 | val_loss : 12978.44921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1185 | train_loss : 2646.561279296875 | val_loss : 12267.5537109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1186 | train_loss : 2279.141357421875 | val_loss : 11983.2626953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1187 | train_loss : 3068.5537109375 | val_loss : 11140.205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1188 | train_loss : 2488.71337890625 | val_loss : 13388.400390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1189 | train_loss : 3247.5302734375 | val_loss : 11050.9248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1190 | train_loss : 2504.5771484375 | val_loss : 11177.7998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1191 | train_loss : 2936.3525390625 | val_loss : 11985.1162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1192 | train_loss : 4513.67138671875 | val_loss : 11892.2958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1193 | train_loss : 2919.5888671875 | val_loss : 15540.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1194 | train_loss : 4970.43896484375 | val_loss : 11654.2822265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1195 | train_loss : 2283.197021484375 | val_loss : 10408.06640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1196 | train_loss : 3321.44677734375 | val_loss : 14699.4716796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1197 | train_loss : 4949.65478515625 | val_loss : 11515.9150390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1198 | train_loss : 3341.52880859375 | val_loss : 11726.62890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1199 | train_loss : 3808.59228515625 | val_loss : 14044.2900390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1200 | train_loss : 3386.398681640625 | val_loss : 11940.740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1201 | train_loss : 3601.722900390625 | val_loss : 12733.009765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1202 | train_loss : 3660.314453125 | val_loss : 11064.333984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1203 | train_loss : 3966.275634765625 | val_loss : 15667.150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1204 | train_loss : 4880.74951171875 | val_loss : 10507.9501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1205 | train_loss : 2568.733154296875 | val_loss : 11640.169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1206 | train_loss : 3225.6533203125 | val_loss : 10457.9912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1207 | train_loss : 3040.393798828125 | val_loss : 13813.5439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1208 | train_loss : 4394.03076171875 | val_loss : 9546.69140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1209 | train_loss : 2414.318359375 | val_loss : 10986.0712890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1210 | train_loss : 2692.2060546875 | val_loss : 9890.134765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1211 | train_loss : 2493.6708984375 | val_loss : 10984.1328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1212 | train_loss : 3051.6220703125 | val_loss : 9885.4638671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1213 | train_loss : 3165.039306640625 | val_loss : 13668.5927734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1214 | train_loss : 4045.4638671875 | val_loss : 9860.529296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1215 | train_loss : 3052.8115234375 | val_loss : 11680.6826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1216 | train_loss : 3223.4150390625 | val_loss : 10504.1474609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1217 | train_loss : 3956.483642578125 | val_loss : 13696.587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1218 | train_loss : 4741.1533203125 | val_loss : 9969.9873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1219 | train_loss : 3082.074462890625 | val_loss : 10616.6474609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1220 | train_loss : 2895.0068359375 | val_loss : 25497.64453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1221 | train_loss : 20594.822265625 | val_loss : 30002.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1222 | train_loss : 14276.625 | val_loss : 15388.650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1223 | train_loss : 7279.39501953125 | val_loss : 19511.54296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1224 | train_loss : 6664.33984375 | val_loss : 14712.52734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1225 | train_loss : 5556.587890625 | val_loss : 12870.26953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1226 | train_loss : 6015.216796875 | val_loss : 14667.8798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1227 | train_loss : 4635.47900390625 | val_loss : 11279.7978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1228 | train_loss : 2325.34228515625 | val_loss : 16070.97265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1229 | train_loss : 4973.998046875 | val_loss : 10553.7734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1230 | train_loss : 2174.568359375 | val_loss : 12280.1279296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1231 | train_loss : 3229.206298828125 | val_loss : 10952.3251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1232 | train_loss : 2837.808837890625 | val_loss : 12527.58203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1233 | train_loss : 3375.90478515625 | val_loss : 10460.9990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1234 | train_loss : 3088.184326171875 | val_loss : 13572.30078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1235 | train_loss : 4098.748046875 | val_loss : 9620.4345703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1236 | train_loss : 2240.2041015625 | val_loss : 12146.697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1237 | train_loss : 3579.708740234375 | val_loss : 10690.0771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1238 | train_loss : 2237.672119140625 | val_loss : 14102.072265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1239 | train_loss : 3802.173828125 | val_loss : 11555.78125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1240 | train_loss : 4666.9580078125 | val_loss : 10846.20703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1241 | train_loss : 3932.83935546875 | val_loss : 11791.384765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1242 | train_loss : 4494.44970703125 | val_loss : 14884.46875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1243 | train_loss : 5924.046875 | val_loss : 10770.6923828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1244 | train_loss : 1892.029052734375 | val_loss : 11404.138671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1245 | train_loss : 3027.6982421875 | val_loss : 10812.583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1246 | train_loss : 3988.71728515625 | val_loss : 12684.2001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1247 | train_loss : 4220.38134765625 | val_loss : 10899.7421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1248 | train_loss : 2917.79833984375 | val_loss : 10352.2158203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1249 | train_loss : 3169.740234375 | val_loss : 11772.412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1250 | train_loss : 4056.04248046875 | val_loss : 12804.83203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1251 | train_loss : 4620.42919921875 | val_loss : 9827.8134765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1252 | train_loss : 2268.128173828125 | val_loss : 10148.2666015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1253 | train_loss : 3665.784423828125 | val_loss : 11011.6396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1254 | train_loss : 3665.21875 | val_loss : 14904.759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1255 | train_loss : 3621.695068359375 | val_loss : 10199.865234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1256 | train_loss : 2987.269287109375 | val_loss : 16067.8115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1257 | train_loss : 5366.0517578125 | val_loss : 9952.6240234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1258 | train_loss : 1437.3759765625 | val_loss : 10313.767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1259 | train_loss : 2319.2705078125 | val_loss : 10586.33984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1260 | train_loss : 3027.4697265625 | val_loss : 10822.8798828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1261 | train_loss : 4683.85302734375 | val_loss : 9502.443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1262 | train_loss : 3044.147705078125 | val_loss : 12807.5263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1263 | train_loss : 3886.727783203125 | val_loss : 9758.02734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1264 | train_loss : 2481.232666015625 | val_loss : 12372.333984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1265 | train_loss : 2875.07275390625 | val_loss : 10276.9833984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1266 | train_loss : 2527.1064453125 | val_loss : 12357.0087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1267 | train_loss : 3500.370849609375 | val_loss : 9760.3720703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1268 | train_loss : 2774.3828125 | val_loss : 13368.3466796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1269 | train_loss : 3922.507080078125 | val_loss : 10173.279296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1270 | train_loss : 2313.937744140625 | val_loss : 10967.2470703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1271 | train_loss : 2275.53564453125 | val_loss : 12200.0537109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1272 | train_loss : 2987.098388671875 | val_loss : 10771.9658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1273 | train_loss : 3187.125 | val_loss : 11399.11328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1274 | train_loss : 3565.3125 | val_loss : 10193.5390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1275 | train_loss : 2903.08251953125 | val_loss : 11321.2001953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1276 | train_loss : 2660.5517578125 | val_loss : 12420.6865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1277 | train_loss : 3675.448974609375 | val_loss : 10033.248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1278 | train_loss : 4012.89501953125 | val_loss : 12719.9921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1279 | train_loss : 3576.750732421875 | val_loss : 9123.064453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1280 | train_loss : 2312.019287109375 | val_loss : 17297.595703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1281 | train_loss : 4403.703125 | val_loss : 9739.052734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1282 | train_loss : 5324.232421875 | val_loss : 15019.1708984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1283 | train_loss : 4563.0556640625 | val_loss : 8469.91015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1284 | train_loss : 2104.225830078125 | val_loss : 11525.052734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1285 | train_loss : 2873.2939453125 | val_loss : 9325.943359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1286 | train_loss : 2403.485595703125 | val_loss : 13447.013671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1287 | train_loss : 4602.974609375 | val_loss : 8858.82421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1288 | train_loss : 1832.42724609375 | val_loss : 10874.900390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1289 | train_loss : 3529.97998046875 | val_loss : 9141.1806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1290 | train_loss : 2512.12744140625 | val_loss : 11882.47265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1291 | train_loss : 3857.157470703125 | val_loss : 8724.166015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1292 | train_loss : 2426.8505859375 | val_loss : 10124.294921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1293 | train_loss : 2523.7080078125 | val_loss : 8972.56640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1294 | train_loss : 3209.699462890625 | val_loss : 12533.990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1295 | train_loss : 4005.81396484375 | val_loss : 8988.578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1296 | train_loss : 2769.788818359375 | val_loss : 11068.1748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1297 | train_loss : 3296.224365234375 | val_loss : 10080.1884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1298 | train_loss : 3120.366943359375 | val_loss : 9779.099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1299 | train_loss : 3512.8271484375 | val_loss : 9348.7919921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1300 | train_loss : 2749.180419921875 | val_loss : 11534.0146484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1301 | train_loss : 4614.42822265625 | val_loss : 8619.533203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1302 | train_loss : 1733.13818359375 | val_loss : 11483.0283203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1303 | train_loss : 3434.8583984375 | val_loss : 10887.0224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1304 | train_loss : 3982.008544921875 | val_loss : 12393.669921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1305 | train_loss : 3836.4775390625 | val_loss : 10289.353515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1306 | train_loss : 3038.14501953125 | val_loss : 13815.5498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1307 | train_loss : 4797.11328125 | val_loss : 9172.80859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1308 | train_loss : 1884.051513671875 | val_loss : 15333.6279296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1309 | train_loss : 5048.11767578125 | val_loss : 12485.884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1310 | train_loss : 4546.0712890625 | val_loss : 12510.0478515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1311 | train_loss : 4884.91455078125 | val_loss : 11730.3779296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1312 | train_loss : 5628.09326171875 | val_loss : 18213.69921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1313 | train_loss : 6682.375 | val_loss : 13850.9033203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1314 | train_loss : 7619.9345703125 | val_loss : 15467.169921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1315 | train_loss : 5173.052734375 | val_loss : 13314.431640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1316 | train_loss : 6661.50048828125 | val_loss : 16795.181640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1317 | train_loss : 5250.0224609375 | val_loss : 11105.3251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1318 | train_loss : 5309.04248046875 | val_loss : 16577.14453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1319 | train_loss : 4305.50390625 | val_loss : 9008.3076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1320 | train_loss : 2657.488037109375 | val_loss : 14791.6171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1321 | train_loss : 3410.6904296875 | val_loss : 8521.28515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1322 | train_loss : 2302.641357421875 | val_loss : 13304.115234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1323 | train_loss : 3140.073974609375 | val_loss : 8494.0703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1324 | train_loss : 2818.684326171875 | val_loss : 11832.8798828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1325 | train_loss : 2311.5986328125 | val_loss : 8702.2666015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1326 | train_loss : 3450.45068359375 | val_loss : 12645.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1327 | train_loss : 3158.804443359375 | val_loss : 8348.541015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1328 | train_loss : 3364.734375 | val_loss : 12556.89453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1329 | train_loss : 3090.948486328125 | val_loss : 8663.4560546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1330 | train_loss : 3979.10791015625 | val_loss : 18024.140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1331 | train_loss : 4843.50537109375 | val_loss : 11534.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1332 | train_loss : 4131.30322265625 | val_loss : 14577.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1333 | train_loss : 4143.990234375 | val_loss : 8816.5595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1334 | train_loss : 3366.484375 | val_loss : 11829.6640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1335 | train_loss : 3001.52587890625 | val_loss : 14160.005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1336 | train_loss : 4302.912109375 | val_loss : 14918.3603515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1337 | train_loss : 4480.9482421875 | val_loss : 12512.0947265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1338 | train_loss : 4054.2548828125 | val_loss : 14400.697265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1339 | train_loss : 3564.74365234375 | val_loss : 9209.7021484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1340 | train_loss : 3011.13818359375 | val_loss : 14684.2470703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1341 | train_loss : 3724.0888671875 | val_loss : 9581.5498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1342 | train_loss : 3141.989013671875 | val_loss : 13825.146484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1343 | train_loss : 4073.5283203125 | val_loss : 10748.3291015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1344 | train_loss : 2624.140380859375 | val_loss : 17037.013671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1345 | train_loss : 4135.451171875 | val_loss : 11077.75390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1346 | train_loss : 3172.9326171875 | val_loss : 14227.107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1347 | train_loss : 3478.4306640625 | val_loss : 9925.4501953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1348 | train_loss : 2904.154296875 | val_loss : 14206.7021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1349 | train_loss : 3374.340576171875 | val_loss : 9794.9140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1350 | train_loss : 2503.179931640625 | val_loss : 14088.400390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1351 | train_loss : 3712.609130859375 | val_loss : 9044.1123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1352 | train_loss : 2487.329833984375 | val_loss : 14319.677734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1353 | train_loss : 4390.1650390625 | val_loss : 9584.3603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1354 | train_loss : 3844.91748046875 | val_loss : 13599.12109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1355 | train_loss : 4075.683349609375 | val_loss : 9519.201171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1356 | train_loss : 2585.40380859375 | val_loss : 14442.3671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1357 | train_loss : 4141.09765625 | val_loss : 12516.23046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1358 | train_loss : 3416.9306640625 | val_loss : 13846.2841796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1359 | train_loss : 3985.379150390625 | val_loss : 9585.7177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1360 | train_loss : 2556.5458984375 | val_loss : 14389.4365234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1361 | train_loss : 3831.423095703125 | val_loss : 8972.763671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1362 | train_loss : 2725.055908203125 | val_loss : 13047.638671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1363 | train_loss : 3984.195068359375 | val_loss : 8995.8408203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1364 | train_loss : 2288.363037109375 | val_loss : 14278.0185546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1365 | train_loss : 3695.606201171875 | val_loss : 9926.28515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1366 | train_loss : 2640.4638671875 | val_loss : 11953.01953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1367 | train_loss : 3767.920654296875 | val_loss : 7875.38134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1368 | train_loss : 2117.734130859375 | val_loss : 12715.583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1369 | train_loss : 2973.104736328125 | val_loss : 10101.73828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1370 | train_loss : 3588.252197265625 | val_loss : 15030.048828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1371 | train_loss : 3525.144287109375 | val_loss : 9010.2900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1372 | train_loss : 3643.075927734375 | val_loss : 14195.072265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1373 | train_loss : 3079.869384765625 | val_loss : 7798.13623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1374 | train_loss : 5090.298828125 | val_loss : 14144.6201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1375 | train_loss : 4643.8193359375 | val_loss : 7320.673828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1376 | train_loss : 3234.246826171875 | val_loss : 13992.60546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1377 | train_loss : 4385.0732421875 | val_loss : 15468.1259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1378 | train_loss : 4612.32666015625 | val_loss : 14531.580078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1379 | train_loss : 3288.703125 | val_loss : 12870.39453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1380 | train_loss : 4302.72705078125 | val_loss : 14360.2529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1381 | train_loss : 3489.878173828125 | val_loss : 10158.7509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1382 | train_loss : 2675.33740234375 | val_loss : 12326.2626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1383 | train_loss : 2199.226806640625 | val_loss : 10774.9833984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1384 | train_loss : 2796.574951171875 | val_loss : 12136.712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1385 | train_loss : 2462.71435546875 | val_loss : 9738.896484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1386 | train_loss : 2805.13818359375 | val_loss : 10867.267578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1387 | train_loss : 2342.310546875 | val_loss : 11574.7353515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1388 | train_loss : 3620.2099609375 | val_loss : 10797.77734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1389 | train_loss : 3307.305908203125 | val_loss : 12768.7236328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1390 | train_loss : 4580.65234375 | val_loss : 9744.3916015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1391 | train_loss : 1992.883544921875 | val_loss : 11393.7001953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1392 | train_loss : 3247.575927734375 | val_loss : 10854.349609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1393 | train_loss : 3347.578125 | val_loss : 12782.44921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1394 | train_loss : 4523.8486328125 | val_loss : 9325.0478515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1395 | train_loss : 1845.51220703125 | val_loss : 12580.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1396 | train_loss : 4082.71630859375 | val_loss : 10159.955078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1397 | train_loss : 2212.707275390625 | val_loss : 9398.4990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1398 | train_loss : 3337.05810546875 | val_loss : 9790.400390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1399 | train_loss : 2667.25 | val_loss : 14120.537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1400 | train_loss : 4580.234375 | val_loss : 10066.060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1401 | train_loss : 2246.9833984375 | val_loss : 9962.09765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1402 | train_loss : 3706.95458984375 | val_loss : 9767.0634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1403 | train_loss : 2913.668212890625 | val_loss : 13055.1708984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1404 | train_loss : 4737.630859375 | val_loss : 9366.75390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1405 | train_loss : 2321.6728515625 | val_loss : 10355.443359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1406 | train_loss : 3566.981201171875 | val_loss : 9246.8828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1407 | train_loss : 2554.9208984375 | val_loss : 11872.7265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1408 | train_loss : 3907.806884765625 | val_loss : 9970.2353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1409 | train_loss : 2091.08154296875 | val_loss : 10791.3310546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1410 | train_loss : 2654.953125 | val_loss : 9838.259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1411 | train_loss : 2412.254150390625 | val_loss : 12630.169921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1412 | train_loss : 4639.890625 | val_loss : 9300.0556640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1413 | train_loss : 1921.21533203125 | val_loss : 10906.0927734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1414 | train_loss : 3239.749755859375 | val_loss : 10315.669921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1415 | train_loss : 2823.779052734375 | val_loss : 12272.4453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1416 | train_loss : 3937.84375 | val_loss : 9641.60546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1417 | train_loss : 2065.159423828125 | val_loss : 10539.6240234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1418 | train_loss : 2871.206298828125 | val_loss : 10271.615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1419 | train_loss : 2834.771240234375 | val_loss : 12853.650390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1420 | train_loss : 4403.5107421875 | val_loss : 9432.5087890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1421 | train_loss : 1934.2822265625 | val_loss : 11948.927734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1422 | train_loss : 3713.278076171875 | val_loss : 9715.630859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1423 | train_loss : 2892.3876953125 | val_loss : 12491.2451171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1424 | train_loss : 4244.34814453125 | val_loss : 9136.443359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1425 | train_loss : 2509.37890625 | val_loss : 11093.84765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1426 | train_loss : 4290.96484375 | val_loss : 9009.71484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1427 | train_loss : 2212.5556640625 | val_loss : 11042.0400390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1428 | train_loss : 4215.8974609375 | val_loss : 9593.638671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1429 | train_loss : 2078.588623046875 | val_loss : 11089.357421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1430 | train_loss : 3578.72802734375 | val_loss : 10167.6181640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1431 | train_loss : 3287.090087890625 | val_loss : 19464.224609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1432 | train_loss : 6592.40185546875 | val_loss : 10642.740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1433 | train_loss : 3483.2490234375 | val_loss : 13609.5322265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1434 | train_loss : 5773.33447265625 | val_loss : 10303.322265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1435 | train_loss : 3949.516845703125 | val_loss : 23255.740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1436 | train_loss : 6636.34814453125 | val_loss : 13130.080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1437 | train_loss : 3618.1826171875 | val_loss : 15927.4072265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1438 | train_loss : 5454.87353515625 | val_loss : 11469.2548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1439 | train_loss : 3821.836181640625 | val_loss : 12770.431640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1440 | train_loss : 4651.18017578125 | val_loss : 9652.2880859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1441 | train_loss : 2607.091796875 | val_loss : 11689.1611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1442 | train_loss : 4565.63623046875 | val_loss : 9817.318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1443 | train_loss : 2130.885986328125 | val_loss : 9486.4267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1444 | train_loss : 3076.9140625 | val_loss : 10198.0576171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1445 | train_loss : 2731.679443359375 | val_loss : 8969.2080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1446 | train_loss : 3067.456787109375 | val_loss : 9468.5361328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1447 | train_loss : 2441.564697265625 | val_loss : 9865.29296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1448 | train_loss : 3366.302490234375 | val_loss : 9927.328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1449 | train_loss : 2550.5849609375 | val_loss : 11021.724609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1450 | train_loss : 3482.080322265625 | val_loss : 9982.287109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1451 | train_loss : 2036.3521728515625 | val_loss : 8964.447265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1452 | train_loss : 2612.910400390625 | val_loss : 9587.056640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1453 | train_loss : 2047.34130859375 | val_loss : 10872.134765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1454 | train_loss : 2463.14404296875 | val_loss : 10759.5302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1455 | train_loss : 2684.06494140625 | val_loss : 9744.3603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1456 | train_loss : 2663.9033203125 | val_loss : 9334.4384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1457 | train_loss : 2022.5081787109375 | val_loss : 12552.353515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1458 | train_loss : 3686.539306640625 | val_loss : 9882.572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1459 | train_loss : 2300.6015625 | val_loss : 11221.66015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1460 | train_loss : 4119.1513671875 | val_loss : 8717.27734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1461 | train_loss : 1695.164794921875 | val_loss : 10358.8466796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1462 | train_loss : 3706.061767578125 | val_loss : 9285.5107421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1463 | train_loss : 2503.185302734375 | val_loss : 11356.326171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1464 | train_loss : 4382.61669921875 | val_loss : 9441.9169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1465 | train_loss : 2446.631591796875 | val_loss : 9319.490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1466 | train_loss : 3044.9580078125 | val_loss : 9354.876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1467 | train_loss : 2225.516357421875 | val_loss : 9545.87109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1468 | train_loss : 2966.343505859375 | val_loss : 9804.62109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1469 | train_loss : 2301.789794921875 | val_loss : 9751.921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1470 | train_loss : 3485.587158203125 | val_loss : 9356.2509765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1471 | train_loss : 2265.22119140625 | val_loss : 12451.0322265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1472 | train_loss : 3768.000732421875 | val_loss : 10866.4638671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1473 | train_loss : 2579.5068359375 | val_loss : 9552.1474609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1474 | train_loss : 3218.40771484375 | val_loss : 9097.8134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1475 | train_loss : 1842.90625 | val_loss : 12938.3671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1476 | train_loss : 3264.02490234375 | val_loss : 9942.482421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1477 | train_loss : 2397.64990234375 | val_loss : 12838.982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1478 | train_loss : 4118.4755859375 | val_loss : 10382.83203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1479 | train_loss : 3511.9765625 | val_loss : 10050.7607421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1480 | train_loss : 3370.614013671875 | val_loss : 11363.7646484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1481 | train_loss : 4406.37548828125 | val_loss : 11443.0224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1482 | train_loss : 5469.8974609375 | val_loss : 9485.80078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1483 | train_loss : 3721.21435546875 | val_loss : 12386.322265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1484 | train_loss : 3299.175537109375 | val_loss : 9095.5107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1485 | train_loss : 2645.955078125 | val_loss : 10319.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1486 | train_loss : 2779.231201171875 | val_loss : 9145.5068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1487 | train_loss : 2397.5830078125 | val_loss : 10945.236328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1488 | train_loss : 3225.4453125 | val_loss : 8777.482421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1489 | train_loss : 1911.77783203125 | val_loss : 11768.6728515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1490 | train_loss : 3822.13525390625 | val_loss : 8856.14453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1491 | train_loss : 1952.1168212890625 | val_loss : 10175.0361328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1492 | train_loss : 2199.673828125 | val_loss : 9702.0595703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1493 | train_loss : 2327.22216796875 | val_loss : 10616.4501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1494 | train_loss : 2939.703857421875 | val_loss : 11547.099609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1495 | train_loss : 2812.8994140625 | val_loss : 11272.61328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1496 | train_loss : 3141.91259765625 | val_loss : 10121.74609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1497 | train_loss : 3800.936279296875 | val_loss : 12134.787109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1498 | train_loss : 3908.981201171875 | val_loss : 14947.6748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1499 | train_loss : 3496.04833984375 | val_loss : 13676.1396484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1500 | train_loss : 3608.153076171875 | val_loss : 8084.0380859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1501 | train_loss : 2132.369384765625 | val_loss : 12111.0126953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1502 | train_loss : 3651.27197265625 | val_loss : 8743.56640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1503 | train_loss : 2310.9619140625 | val_loss : 9792.68359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1504 | train_loss : 1977.5330810546875 | val_loss : 10070.787109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1505 | train_loss : 2931.8251953125 | val_loss : 12691.8271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1506 | train_loss : 4491.771484375 | val_loss : 9314.96484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1507 | train_loss : 3101.88427734375 | val_loss : 9443.6240234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1508 | train_loss : 6147.12939453125 | val_loss : 11128.603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1509 | train_loss : 3404.935546875 | val_loss : 12030.26953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1510 | train_loss : 4841.58935546875 | val_loss : 9269.162109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1511 | train_loss : 5119.27197265625 | val_loss : 18370.91015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1512 | train_loss : 4904.24560546875 | val_loss : 10303.5595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1513 | train_loss : 3538.208984375 | val_loss : 19886.951171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1514 | train_loss : 6938.20556640625 | val_loss : 11438.3720703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1515 | train_loss : 4229.583984375 | val_loss : 14836.4453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1516 | train_loss : 4994.49853515625 | val_loss : 9135.9033203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1517 | train_loss : 4419.314453125 | val_loss : 15045.2802734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1518 | train_loss : 5593.66015625 | val_loss : 9950.373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1519 | train_loss : 3144.688720703125 | val_loss : 11402.99609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1520 | train_loss : 4425.982421875 | val_loss : 8765.841796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1521 | train_loss : 1836.54931640625 | val_loss : 9885.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1522 | train_loss : 2472.099609375 | val_loss : 9044.87109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1523 | train_loss : 2552.729248046875 | val_loss : 10225.5517578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1524 | train_loss : 3254.800048828125 | val_loss : 7903.20947265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1525 | train_loss : 2397.417236328125 | val_loss : 11467.8876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1526 | train_loss : 3509.34814453125 | val_loss : 8050.466796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1527 | train_loss : 2823.133056640625 | val_loss : 11540.59765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1528 | train_loss : 3609.750732421875 | val_loss : 7910.62451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1529 | train_loss : 1848.567138671875 | val_loss : 12044.1787109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1530 | train_loss : 3548.78125 | val_loss : 8653.3662109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1531 | train_loss : 2528.923828125 | val_loss : 11089.9873046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1532 | train_loss : 3322.25146484375 | val_loss : 8481.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1533 | train_loss : 2400.20166015625 | val_loss : 9067.4873046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1534 | train_loss : 1512.7694091796875 | val_loss : 11452.6572265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1535 | train_loss : 1827.7596435546875 | val_loss : 13292.53515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1536 | train_loss : 3690.860595703125 | val_loss : 10068.365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1537 | train_loss : 3242.7177734375 | val_loss : 9354.6376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1538 | train_loss : 1870.39501953125 | val_loss : 9772.7626953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1539 | train_loss : 2504.9736328125 | val_loss : 10627.50390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1540 | train_loss : 2735.19873046875 | val_loss : 9460.81640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1541 | train_loss : 1930.4715576171875 | val_loss : 12637.513671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1542 | train_loss : 3655.29833984375 | val_loss : 10894.9521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1543 | train_loss : 2704.988037109375 | val_loss : 9528.2265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1544 | train_loss : 2710.86376953125 | val_loss : 10571.0673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1545 | train_loss : 3123.9697265625 | val_loss : 11416.9404296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1546 | train_loss : 3113.49560546875 | val_loss : 10065.4580078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1547 | train_loss : 2272.849609375 | val_loss : 9542.615234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1548 | train_loss : 3106.688720703125 | val_loss : 10897.2373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1549 | train_loss : 2804.482177734375 | val_loss : 9252.4248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1550 | train_loss : 2145.853271484375 | val_loss : 9109.8515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1551 | train_loss : 1983.2974853515625 | val_loss : 11393.08984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1552 | train_loss : 3602.138671875 | val_loss : 10408.8740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1553 | train_loss : 2561.38916015625 | val_loss : 8881.01171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1554 | train_loss : 1811.603271484375 | val_loss : 9638.6591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1555 | train_loss : 2458.34912109375 | val_loss : 12355.0751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1556 | train_loss : 4400.01416015625 | val_loss : 8411.0185546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1557 | train_loss : 2303.5546875 | val_loss : 11694.2646484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1558 | train_loss : 3492.341552734375 | val_loss : 12631.5078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1559 | train_loss : 2944.611572265625 | val_loss : 14138.4853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1560 | train_loss : 3793.680419921875 | val_loss : 11791.7666015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1561 | train_loss : 3989.899658203125 | val_loss : 13253.1796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1562 | train_loss : 3425.22900390625 | val_loss : 15010.4404296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1563 | train_loss : 4479.0986328125 | val_loss : 13401.6650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1564 | train_loss : 3095.9912109375 | val_loss : 9058.43359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1565 | train_loss : 3726.940673828125 | val_loss : 13475.1748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1566 | train_loss : 4239.17138671875 | val_loss : 9828.759765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1567 | train_loss : 3688.578369140625 | val_loss : 12261.7578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1568 | train_loss : 3025.998779296875 | val_loss : 8001.1923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1569 | train_loss : 2763.716552734375 | val_loss : 13112.8251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1570 | train_loss : 3571.86376953125 | val_loss : 7764.8408203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1571 | train_loss : 3318.388671875 | val_loss : 12257.9697265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1572 | train_loss : 2872.136474609375 | val_loss : 8813.1728515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1573 | train_loss : 3122.833740234375 | val_loss : 12921.65234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1574 | train_loss : 3069.54345703125 | val_loss : 8544.7109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1575 | train_loss : 2419.716064453125 | val_loss : 12713.5849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1576 | train_loss : 3037.339599609375 | val_loss : 7556.1376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1577 | train_loss : 2727.364990234375 | val_loss : 12174.9599609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1578 | train_loss : 2855.24560546875 | val_loss : 9798.2998046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1579 | train_loss : 2792.514892578125 | val_loss : 12971.1474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1580 | train_loss : 3768.221923828125 | val_loss : 10954.4091796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1581 | train_loss : 4563.9580078125 | val_loss : 13059.8427734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1582 | train_loss : 3256.12060546875 | val_loss : 8683.55859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1583 | train_loss : 1465.296142578125 | val_loss : 13160.642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1584 | train_loss : 2826.198486328125 | val_loss : 9464.5966796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1585 | train_loss : 2942.82568359375 | val_loss : 13507.5791015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1586 | train_loss : 3203.116943359375 | val_loss : 8640.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1587 | train_loss : 2972.1015625 | val_loss : 12840.021484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1588 | train_loss : 3363.69287109375 | val_loss : 10437.658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1589 | train_loss : 3500.123046875 | val_loss : 13127.806640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1590 | train_loss : 3105.316162109375 | val_loss : 8274.0009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1591 | train_loss : 2888.88525390625 | val_loss : 12921.982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1592 | train_loss : 3171.5751953125 | val_loss : 7751.41455078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1593 | train_loss : 2589.162841796875 | val_loss : 11188.01953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1594 | train_loss : 2197.43017578125 | val_loss : 8204.7294921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1595 | train_loss : 2495.3662109375 | val_loss : 11131.884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1596 | train_loss : 1952.83447265625 | val_loss : 7558.08544921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1597 | train_loss : 2011.074951171875 | val_loss : 10726.4599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1598 | train_loss : 1947.8441162109375 | val_loss : 7802.68603515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1599 | train_loss : 2594.2158203125 | val_loss : 10663.91796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 1600 | train_loss : 2100.87353515625 | val_loss : 10384.5556640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 6 | epoch : 1 | train_loss : 1244910.875 | val_loss : 748035.5 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 2 | train_loss : 767528.5625 | val_loss : 552669.625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 3 | train_loss : 512793.125 | val_loss : 211368.15625 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 4 | train_loss : 217659.4375 | val_loss : 452985.53125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 5 | train_loss : 339462.28125 | val_loss : 551287.25 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 6 | train_loss : 485013.125 | val_loss : 195546.578125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 7 | train_loss : 169333.359375 | val_loss : 249117.5 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 8 | train_loss : 251260.1875 | val_loss : 230363.421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 9 | train_loss : 272947.46875 | val_loss : 329092.4375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 10 | train_loss : 277063.46875 | val_loss : 370815.71875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 11 | train_loss : 290235.25 | val_loss : 276737.28125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 12 | train_loss : 214128.9375 | val_loss : 313321.96875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 13 | train_loss : 253880.4375 | val_loss : 255731.921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 14 | train_loss : 243604.34375 | val_loss : 171630.9375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 15 | train_loss : 177815.015625 | val_loss : 183874.875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 16 | train_loss : 140298.5 | val_loss : 281070.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 17 | train_loss : 272490.53125 | val_loss : 297035.53125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 18 | train_loss : 211893.703125 | val_loss : 291027.03125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 19 | train_loss : 227939.421875 | val_loss : 225873.375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 20 | train_loss : 183973.453125 | val_loss : 208417.5 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 21 | train_loss : 189622.015625 | val_loss : 164552.640625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 22 | train_loss : 164332.625 | val_loss : 124864.921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 23 | train_loss : 109786.203125 | val_loss : 110003.9375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 24 | train_loss : 132752.9375 | val_loss : 191346.203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 25 | train_loss : 184279.140625 | val_loss : 168148.84375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 26 | train_loss : 156927.296875 | val_loss : 126273.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 27 | train_loss : 114158.953125 | val_loss : 107738.0234375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 28 | train_loss : 127064.8984375 | val_loss : 138396.125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 29 | train_loss : 137558.6875 | val_loss : 139219.4375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 30 | train_loss : 139189.234375 | val_loss : 168071.953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 31 | train_loss : 175375.078125 | val_loss : 289031.78125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 32 | train_loss : 224585.09375 | val_loss : 290115.84375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 33 | train_loss : 191809.375 | val_loss : 267179.375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 34 | train_loss : 202183.796875 | val_loss : 232292.6875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 35 | train_loss : 204667.84375 | val_loss : 243535.8125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 36 | train_loss : 190462.296875 | val_loss : 202306.0625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 37 | train_loss : 178175.640625 | val_loss : 176894.046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 38 | train_loss : 153050.453125 | val_loss : 109895.09375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 39 | train_loss : 102183.7421875 | val_loss : 130605.7265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 40 | train_loss : 146970.3125 | val_loss : 114280.3828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 41 | train_loss : 88831.0703125 | val_loss : 149693.9375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 42 | train_loss : 140913.9375 | val_loss : 103295.5703125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 43 | train_loss : 93567.9375 | val_loss : 96865.0390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 44 | train_loss : 105072.53125 | val_loss : 212786.6875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 45 | train_loss : 148210.15625 | val_loss : 228515.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 46 | train_loss : 171891.765625 | val_loss : 194637.484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 47 | train_loss : 139919.703125 | val_loss : 134037.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 48 | train_loss : 109403.203125 | val_loss : 110339.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 49 | train_loss : 85334.3125 | val_loss : 99290.90625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 50 | train_loss : 93297.3984375 | val_loss : 95632.796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 51 | train_loss : 109627.7734375 | val_loss : 87927.5625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 52 | train_loss : 124523.78125 | val_loss : 280396.75 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 53 | train_loss : 215636.8125 | val_loss : 273031.09375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 54 | train_loss : 156589.984375 | val_loss : 241742.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 55 | train_loss : 168154.8125 | val_loss : 139011.703125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 56 | train_loss : 98489.890625 | val_loss : 141170.0625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 57 | train_loss : 113133.421875 | val_loss : 166462.59375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 58 | train_loss : 136525.671875 | val_loss : 93314.0234375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 59 | train_loss : 88343.5703125 | val_loss : 79261.7265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 60 | train_loss : 99696.1875 | val_loss : 110654.3515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 61 | train_loss : 91242.5234375 | val_loss : 83255.2578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 62 | train_loss : 98104.296875 | val_loss : 114381.1484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 63 | train_loss : 89683.921875 | val_loss : 108216.109375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 64 | train_loss : 93617.8984375 | val_loss : 146649.734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 65 | train_loss : 112797.1015625 | val_loss : 166902.625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 66 | train_loss : 123889.578125 | val_loss : 120813.140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 67 | train_loss : 94594.9921875 | val_loss : 107430.140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 68 | train_loss : 65224.69921875 | val_loss : 93774.96875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 69 | train_loss : 84716.40625 | val_loss : 76413.765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 70 | train_loss : 98040.78125 | val_loss : 119783.1171875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 71 | train_loss : 94285.6875 | val_loss : 199279.515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 72 | train_loss : 118411.2265625 | val_loss : 149636.765625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 73 | train_loss : 120441.703125 | val_loss : 158624.40625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 74 | train_loss : 150436.828125 | val_loss : 137083.265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 75 | train_loss : 97222.796875 | val_loss : 133752.546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 76 | train_loss : 96793.578125 | val_loss : 52580.76171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 77 | train_loss : 53010.64453125 | val_loss : 116840.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 78 | train_loss : 117651.5390625 | val_loss : 70598.59375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 79 | train_loss : 50916.07421875 | val_loss : 95152.0703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 80 | train_loss : 76424.40625 | val_loss : 66407.4765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 81 | train_loss : 61878.890625 | val_loss : 116027.6328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 82 | train_loss : 88715.3828125 | val_loss : 149496.640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 83 | train_loss : 105338.453125 | val_loss : 102298.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 84 | train_loss : 66534.0390625 | val_loss : 115280.21875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 85 | train_loss : 74255.6171875 | val_loss : 136217.640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 86 | train_loss : 112700.1171875 | val_loss : 95071.6796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 87 | train_loss : 82415.296875 | val_loss : 103121.1171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 88 | train_loss : 55792.0 | val_loss : 100038.7421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 89 | train_loss : 80056.375 | val_loss : 62535.81640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 90 | train_loss : 72299.9921875 | val_loss : 92040.2421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 91 | train_loss : 89906.9765625 | val_loss : 83115.75 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 92 | train_loss : 42149.1953125 | val_loss : 88991.8984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 93 | train_loss : 76973.2734375 | val_loss : 90316.0625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 94 | train_loss : 83907.2421875 | val_loss : 71850.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 95 | train_loss : 82169.2734375 | val_loss : 175108.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 96 | train_loss : 104944.953125 | val_loss : 189881.78125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 97 | train_loss : 128967.578125 | val_loss : 142019.8125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 98 | train_loss : 110525.6171875 | val_loss : 124828.7578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 99 | train_loss : 81623.0390625 | val_loss : 119582.7578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 100 | train_loss : 94867.546875 | val_loss : 91554.0 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 101 | train_loss : 96708.21875 | val_loss : 68506.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 102 | train_loss : 73218.6875 | val_loss : 31662.431640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 103 | train_loss : 31016.185546875 | val_loss : 56409.42578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 104 | train_loss : 36551.48046875 | val_loss : 41293.953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 105 | train_loss : 45020.65625 | val_loss : 113173.21875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 106 | train_loss : 105679.7265625 | val_loss : 105144.7890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 107 | train_loss : 77346.796875 | val_loss : 109563.296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 108 | train_loss : 97942.421875 | val_loss : 80129.3359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 109 | train_loss : 65836.9921875 | val_loss : 58267.76953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 110 | train_loss : 79930.046875 | val_loss : 82260.4921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 111 | train_loss : 70392.1875 | val_loss : 108937.2265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 112 | train_loss : 64655.2890625 | val_loss : 69862.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 113 | train_loss : 55215.74609375 | val_loss : 82725.3671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 114 | train_loss : 57469.08984375 | val_loss : 64540.875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 115 | train_loss : 69918.2890625 | val_loss : 65849.9609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 116 | train_loss : 86856.3515625 | val_loss : 86844.4609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 117 | train_loss : 83502.1171875 | val_loss : 117495.6796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 118 | train_loss : 82449.75 | val_loss : 102496.2421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 119 | train_loss : 67290.375 | val_loss : 77909.8984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 120 | train_loss : 70129.359375 | val_loss : 80256.2109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 121 | train_loss : 60097.13671875 | val_loss : 97481.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 122 | train_loss : 49412.87109375 | val_loss : 106698.0390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 123 | train_loss : 79301.2421875 | val_loss : 176225.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 124 | train_loss : 117916.859375 | val_loss : 177020.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 125 | train_loss : 135862.40625 | val_loss : 74322.8203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 126 | train_loss : 40241.87109375 | val_loss : 56059.953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 127 | train_loss : 58502.328125 | val_loss : 54502.12109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 128 | train_loss : 55747.375 | val_loss : 57525.05859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 129 | train_loss : 74718.734375 | val_loss : 128181.5703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 130 | train_loss : 78437.7578125 | val_loss : 153404.125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 131 | train_loss : 84535.2734375 | val_loss : 154964.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 132 | train_loss : 103569.0234375 | val_loss : 143313.9375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 133 | train_loss : 134409.75 | val_loss : 33646.3359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 134 | train_loss : 31664.4453125 | val_loss : 99355.0390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 135 | train_loss : 88771.4765625 | val_loss : 91948.6015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 136 | train_loss : 60313.984375 | val_loss : 42966.62109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 137 | train_loss : 40869.46875 | val_loss : 54741.2890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 138 | train_loss : 53734.703125 | val_loss : 81760.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 139 | train_loss : 51080.48828125 | val_loss : 84912.53125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 140 | train_loss : 69104.125 | val_loss : 39191.76953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 141 | train_loss : 40315.73828125 | val_loss : 35227.24609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 142 | train_loss : 38435.3828125 | val_loss : 117881.0625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 143 | train_loss : 63532.67578125 | val_loss : 146619.546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 144 | train_loss : 95027.390625 | val_loss : 115331.359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 145 | train_loss : 68921.4453125 | val_loss : 132004.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 146 | train_loss : 94278.28125 | val_loss : 91977.421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 147 | train_loss : 81093.4296875 | val_loss : 64892.12890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 148 | train_loss : 43509.00390625 | val_loss : 47179.21875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 149 | train_loss : 33629.86328125 | val_loss : 73912.0546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 150 | train_loss : 63726.80859375 | val_loss : 93282.6484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 151 | train_loss : 84767.3984375 | val_loss : 63609.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 152 | train_loss : 62016.71875 | val_loss : 34153.87109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 153 | train_loss : 48508.5 | val_loss : 117623.1015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 154 | train_loss : 101082.7109375 | val_loss : 128449.703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 155 | train_loss : 69891.21875 | val_loss : 111913.9609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 156 | train_loss : 90194.4765625 | val_loss : 106342.640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 157 | train_loss : 96906.859375 | val_loss : 101935.6796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 158 | train_loss : 70270.2890625 | val_loss : 53319.21484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 159 | train_loss : 56356.66015625 | val_loss : 29437.072265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 160 | train_loss : 32237.712890625 | val_loss : 100077.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 161 | train_loss : 68521.8828125 | val_loss : 94794.96875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 162 | train_loss : 60738.46484375 | val_loss : 47776.01953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 163 | train_loss : 36474.8359375 | val_loss : 41712.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 164 | train_loss : 43192.86328125 | val_loss : 55125.69921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 165 | train_loss : 44186.7265625 | val_loss : 95604.828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 166 | train_loss : 53595.46484375 | val_loss : 89096.5390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 167 | train_loss : 75111.4296875 | val_loss : 82045.53125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 168 | train_loss : 68221.9140625 | val_loss : 44224.82421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 169 | train_loss : 42272.5234375 | val_loss : 92887.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 170 | train_loss : 61422.578125 | val_loss : 145994.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 171 | train_loss : 71551.921875 | val_loss : 137598.4375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 172 | train_loss : 91767.90625 | val_loss : 120829.0078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 173 | train_loss : 106435.9765625 | val_loss : 64086.99609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 174 | train_loss : 44661.43359375 | val_loss : 39507.421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 175 | train_loss : 27767.296875 | val_loss : 71348.0078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 176 | train_loss : 59462.53125 | val_loss : 57051.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 177 | train_loss : 35053.12109375 | val_loss : 68693.4765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 178 | train_loss : 45586.87890625 | val_loss : 36294.05078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 179 | train_loss : 38325.6171875 | val_loss : 73248.453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 180 | train_loss : 62491.421875 | val_loss : 68442.234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 181 | train_loss : 54322.1953125 | val_loss : 43778.63671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 182 | train_loss : 39424.80859375 | val_loss : 46399.6484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 183 | train_loss : 49319.8203125 | val_loss : 46603.328125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 184 | train_loss : 37467.828125 | val_loss : 65520.18359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 185 | train_loss : 45411.44140625 | val_loss : 77936.1953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 186 | train_loss : 42726.4609375 | val_loss : 68753.46875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 187 | train_loss : 61703.2265625 | val_loss : 61587.26953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 188 | train_loss : 48957.62890625 | val_loss : 88138.140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 189 | train_loss : 49534.015625 | val_loss : 86799.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 190 | train_loss : 53513.98046875 | val_loss : 71992.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 191 | train_loss : 60419.140625 | val_loss : 59219.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 192 | train_loss : 47581.328125 | val_loss : 57865.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 193 | train_loss : 59980.62109375 | val_loss : 84660.4296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 194 | train_loss : 60280.28515625 | val_loss : 40181.12109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 195 | train_loss : 29232.498046875 | val_loss : 24822.6796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 196 | train_loss : 17358.154296875 | val_loss : 43658.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 197 | train_loss : 31704.220703125 | val_loss : 97838.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 198 | train_loss : 88171.3671875 | val_loss : 90814.65625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 199 | train_loss : 61564.4296875 | val_loss : 36407.046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 200 | train_loss : 26555.625 | val_loss : 48205.36328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 201 | train_loss : 38002.99609375 | val_loss : 20913.16015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 202 | train_loss : 30060.61328125 | val_loss : 52279.140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 203 | train_loss : 37433.4140625 | val_loss : 39769.83984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 204 | train_loss : 42517.9453125 | val_loss : 27733.1015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 205 | train_loss : 25232.900390625 | val_loss : 60646.34375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 206 | train_loss : 37315.015625 | val_loss : 52502.13671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 207 | train_loss : 32129.2265625 | val_loss : 48056.609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 208 | train_loss : 44161.61328125 | val_loss : 24261.560546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 209 | train_loss : 33076.80859375 | val_loss : 67475.578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 210 | train_loss : 47577.2890625 | val_loss : 82372.046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 211 | train_loss : 60766.87109375 | val_loss : 40220.7265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 212 | train_loss : 50506.30078125 | val_loss : 35180.34375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 213 | train_loss : 28031.177734375 | val_loss : 32735.20703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 214 | train_loss : 30906.02734375 | val_loss : 50425.00390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 215 | train_loss : 49328.76171875 | val_loss : 47131.84375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 216 | train_loss : 41612.40625 | val_loss : 50788.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 217 | train_loss : 36738.453125 | val_loss : 26209.845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 218 | train_loss : 24712.330078125 | val_loss : 33491.6484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 219 | train_loss : 35749.12109375 | val_loss : 59817.58984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 220 | train_loss : 45291.3984375 | val_loss : 79879.359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 221 | train_loss : 44961.55078125 | val_loss : 30352.0859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 222 | train_loss : 26337.0234375 | val_loss : 54097.76171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 223 | train_loss : 60866.1015625 | val_loss : 74326.21875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 224 | train_loss : 55169.5390625 | val_loss : 91158.703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 225 | train_loss : 70374.8984375 | val_loss : 45628.64453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 226 | train_loss : 55917.5546875 | val_loss : 93271.7421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 227 | train_loss : 88946.28125 | val_loss : 100917.8515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 228 | train_loss : 59084.0859375 | val_loss : 96778.59375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 229 | train_loss : 48977.68359375 | val_loss : 60647.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 230 | train_loss : 33248.23046875 | val_loss : 65330.53125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 231 | train_loss : 43021.51171875 | val_loss : 37628.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 232 | train_loss : 31182.744140625 | val_loss : 57810.12890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 233 | train_loss : 46663.10546875 | val_loss : 37869.234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 234 | train_loss : 41457.796875 | val_loss : 64908.546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 235 | train_loss : 36576.859375 | val_loss : 70754.8046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 236 | train_loss : 38166.78515625 | val_loss : 63918.05078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 237 | train_loss : 39109.296875 | val_loss : 60688.55859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 238 | train_loss : 45028.2890625 | val_loss : 37873.9921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 239 | train_loss : 38825.625 | val_loss : 38483.7734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 240 | train_loss : 45205.0234375 | val_loss : 72183.953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 241 | train_loss : 39617.46484375 | val_loss : 45335.8515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 242 | train_loss : 26131.3515625 | val_loss : 39922.671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 243 | train_loss : 42608.80078125 | val_loss : 32168.783203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 244 | train_loss : 29057.181640625 | val_loss : 76184.09375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 245 | train_loss : 40043.1796875 | val_loss : 84562.828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 246 | train_loss : 41373.71484375 | val_loss : 83878.484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 247 | train_loss : 48141.06640625 | val_loss : 50160.85546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 248 | train_loss : 41946.1640625 | val_loss : 48317.12890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 249 | train_loss : 49102.83984375 | val_loss : 34031.1015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 250 | train_loss : 37097.390625 | val_loss : 84908.859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 251 | train_loss : 58354.28515625 | val_loss : 88700.9375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 252 | train_loss : 46766.984375 | val_loss : 73688.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 253 | train_loss : 44423.1484375 | val_loss : 61986.86328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 254 | train_loss : 36367.8203125 | val_loss : 45672.10546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 255 | train_loss : 28732.767578125 | val_loss : 33729.703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 256 | train_loss : 24966.75 | val_loss : 27409.17578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 257 | train_loss : 32565.625 | val_loss : 52092.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 258 | train_loss : 47597.125 | val_loss : 57425.3359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 259 | train_loss : 28151.3203125 | val_loss : 72925.09375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 260 | train_loss : 32856.4140625 | val_loss : 46862.61328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 261 | train_loss : 32775.73828125 | val_loss : 40313.02734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 262 | train_loss : 34223.50390625 | val_loss : 34301.0234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 263 | train_loss : 35188.60546875 | val_loss : 55469.06640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 264 | train_loss : 50747.328125 | val_loss : 64821.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 265 | train_loss : 45722.19140625 | val_loss : 65286.35546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 266 | train_loss : 37672.9609375 | val_loss : 33787.41796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 267 | train_loss : 24295.359375 | val_loss : 43347.24609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 268 | train_loss : 39490.671875 | val_loss : 51270.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 269 | train_loss : 33241.45703125 | val_loss : 67008.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 270 | train_loss : 33143.90625 | val_loss : 39666.0703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 271 | train_loss : 28251.52734375 | val_loss : 29959.08203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 272 | train_loss : 30270.78515625 | val_loss : 40485.28125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 273 | train_loss : 30893.0078125 | val_loss : 42550.28125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 274 | train_loss : 22562.712890625 | val_loss : 41766.0859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 275 | train_loss : 22638.935546875 | val_loss : 23560.345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 276 | train_loss : 19828.07421875 | val_loss : 27194.77734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 277 | train_loss : 19941.552734375 | val_loss : 43006.953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 278 | train_loss : 32096.3046875 | val_loss : 30571.990234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 279 | train_loss : 22510.724609375 | val_loss : 17328.767578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 280 | train_loss : 19481.515625 | val_loss : 35653.55859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 281 | train_loss : 26223.142578125 | val_loss : 117963.84375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 282 | train_loss : 108215.578125 | val_loss : 70090.875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 283 | train_loss : 48123.9453125 | val_loss : 38197.42578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 284 | train_loss : 32891.21484375 | val_loss : 43809.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 285 | train_loss : 35782.35546875 | val_loss : 38145.34375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 286 | train_loss : 19766.59375 | val_loss : 19399.490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 287 | train_loss : 16708.216796875 | val_loss : 29206.890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 288 | train_loss : 27727.41015625 | val_loss : 52806.046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 289 | train_loss : 29133.73046875 | val_loss : 51362.82421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 290 | train_loss : 26134.220703125 | val_loss : 35699.29296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 291 | train_loss : 28764.02734375 | val_loss : 21760.9140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 292 | train_loss : 32173.4921875 | val_loss : 49361.73828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 293 | train_loss : 41391.37890625 | val_loss : 60229.87109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 294 | train_loss : 30224.66015625 | val_loss : 41773.28515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 295 | train_loss : 25650.76953125 | val_loss : 36038.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 296 | train_loss : 19595.3671875 | val_loss : 23210.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 297 | train_loss : 20224.61328125 | val_loss : 18822.060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 298 | train_loss : 18792.9609375 | val_loss : 44578.53125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 299 | train_loss : 30829.671875 | val_loss : 53673.28125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 300 | train_loss : 34140.17578125 | val_loss : 65355.65625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 301 | train_loss : 40037.359375 | val_loss : 46682.30859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 302 | train_loss : 34528.4375 | val_loss : 23652.36328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 303 | train_loss : 22831.22265625 | val_loss : 26217.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 304 | train_loss : 21263.6171875 | val_loss : 51026.578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 305 | train_loss : 27032.435546875 | val_loss : 27578.33984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 306 | train_loss : 18716.0859375 | val_loss : 25666.345703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 307 | train_loss : 19256.490234375 | val_loss : 45061.9453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 308 | train_loss : 33109.76171875 | val_loss : 43124.23046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 309 | train_loss : 29152.994140625 | val_loss : 18297.27734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 310 | train_loss : 12617.8876953125 | val_loss : 42318.62890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 311 | train_loss : 27393.08203125 | val_loss : 34144.0078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 312 | train_loss : 23174.42578125 | val_loss : 27751.001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 313 | train_loss : 16029.11328125 | val_loss : 42921.1640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 314 | train_loss : 19555.166015625 | val_loss : 25549.095703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 315 | train_loss : 20654.630859375 | val_loss : 35404.78125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 316 | train_loss : 28020.380859375 | val_loss : 42813.80859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 317 | train_loss : 29993.259765625 | val_loss : 24545.0078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 318 | train_loss : 19758.380859375 | val_loss : 28647.380859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 319 | train_loss : 24688.8203125 | val_loss : 30005.2109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 320 | train_loss : 22408.130859375 | val_loss : 23749.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 321 | train_loss : 26977.732421875 | val_loss : 39673.8671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 322 | train_loss : 36040.546875 | val_loss : 55712.4140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 323 | train_loss : 33222.7265625 | val_loss : 63532.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 324 | train_loss : 36309.390625 | val_loss : 47669.89453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 325 | train_loss : 31280.884765625 | val_loss : 50947.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 326 | train_loss : 29892.98828125 | val_loss : 27662.841796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 327 | train_loss : 12886.8525390625 | val_loss : 19381.876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 328 | train_loss : 20439.53515625 | val_loss : 38990.546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 329 | train_loss : 20442.474609375 | val_loss : 24934.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 330 | train_loss : 19705.216796875 | val_loss : 25791.3515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 331 | train_loss : 20667.6640625 | val_loss : 36348.51171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 332 | train_loss : 21730.125 | val_loss : 33753.3203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 333 | train_loss : 29209.16015625 | val_loss : 29010.54296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 334 | train_loss : 19018.01953125 | val_loss : 32861.828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 335 | train_loss : 13537.5439453125 | val_loss : 18117.5859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 336 | train_loss : 18392.7890625 | val_loss : 31344.158203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 337 | train_loss : 24926.607421875 | val_loss : 15415.0224609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 338 | train_loss : 13258.6875 | val_loss : 45456.66015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 339 | train_loss : 24300.505859375 | val_loss : 28608.595703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 340 | train_loss : 22484.52734375 | val_loss : 32298.822265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 341 | train_loss : 25274.931640625 | val_loss : 28247.783203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 342 | train_loss : 17647.5859375 | val_loss : 31116.39453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 343 | train_loss : 27291.990234375 | val_loss : 21066.552734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 344 | train_loss : 26661.990234375 | val_loss : 53252.2265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 345 | train_loss : 43750.796875 | val_loss : 52191.86328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 346 | train_loss : 31390.9375 | val_loss : 46615.41015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 347 | train_loss : 30627.25 | val_loss : 30398.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 348 | train_loss : 21225.498046875 | val_loss : 43283.2265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 349 | train_loss : 20686.94921875 | val_loss : 29695.501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 350 | train_loss : 25747.328125 | val_loss : 40865.9609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 351 | train_loss : 24629.005859375 | val_loss : 30657.36328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 352 | train_loss : 21000.337890625 | val_loss : 37328.203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 353 | train_loss : 23741.58203125 | val_loss : 18252.078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 354 | train_loss : 13360.3525390625 | val_loss : 25283.982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 355 | train_loss : 15463.5966796875 | val_loss : 24114.427734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 356 | train_loss : 12325.2578125 | val_loss : 29179.5546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 357 | train_loss : 22960.880859375 | val_loss : 38547.31640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 358 | train_loss : 27210.109375 | val_loss : 53584.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 359 | train_loss : 29864.970703125 | val_loss : 49651.6015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 360 | train_loss : 26077.970703125 | val_loss : 30124.3125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 361 | train_loss : 15892.7763671875 | val_loss : 39417.328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 362 | train_loss : 19536.107421875 | val_loss : 18096.58203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 363 | train_loss : 13447.4921875 | val_loss : 21540.0859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 364 | train_loss : 19312.439453125 | val_loss : 33603.12890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 365 | train_loss : 19230.412109375 | val_loss : 46747.50390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 366 | train_loss : 30110.537109375 | val_loss : 17059.669921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 367 | train_loss : 15353.0146484375 | val_loss : 22275.830078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 368 | train_loss : 17349.5078125 | val_loss : 40395.94140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 369 | train_loss : 25447.4140625 | val_loss : 56644.48046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 370 | train_loss : 27571.1640625 | val_loss : 34182.3984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 371 | train_loss : 21427.0546875 | val_loss : 17945.4140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 372 | train_loss : 19137.025390625 | val_loss : 29533.5859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 373 | train_loss : 18217.7578125 | val_loss : 31030.17578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 374 | train_loss : 18383.392578125 | val_loss : 35436.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 375 | train_loss : 18358.376953125 | val_loss : 34601.44140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 376 | train_loss : 23431.044921875 | val_loss : 32389.248046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 377 | train_loss : 29271.595703125 | val_loss : 35597.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 378 | train_loss : 32578.595703125 | val_loss : 45824.39453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 379 | train_loss : 35671.2265625 | val_loss : 22837.7890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 380 | train_loss : 23829.837890625 | val_loss : 29377.091796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 381 | train_loss : 20049.193359375 | val_loss : 20811.12890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 382 | train_loss : 21301.5234375 | val_loss : 37834.12109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 383 | train_loss : 21003.76953125 | val_loss : 31414.017578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 384 | train_loss : 17123.55859375 | val_loss : 44457.640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 385 | train_loss : 28742.5234375 | val_loss : 18503.513671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 386 | train_loss : 22852.267578125 | val_loss : 45238.80859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 387 | train_loss : 35905.8515625 | val_loss : 50349.328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 388 | train_loss : 24868.70703125 | val_loss : 45946.390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 389 | train_loss : 26303.09765625 | val_loss : 33729.4921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 390 | train_loss : 25697.5390625 | val_loss : 47456.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 391 | train_loss : 30441.8125 | val_loss : 19674.609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 392 | train_loss : 17162.2890625 | val_loss : 14300.076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 393 | train_loss : 8975.2802734375 | val_loss : 24126.765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 394 | train_loss : 13571.8837890625 | val_loss : 28586.76171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 395 | train_loss : 17525.724609375 | val_loss : 17281.568359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 396 | train_loss : 9031.5498046875 | val_loss : 27330.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 397 | train_loss : 18944.955078125 | val_loss : 16015.294921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 398 | train_loss : 16604.19921875 | val_loss : 38597.7421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 399 | train_loss : 22667.595703125 | val_loss : 36990.13671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 400 | train_loss : 20509.58203125 | val_loss : 23054.412109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 401 | train_loss : 18269.693359375 | val_loss : 17543.15234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 402 | train_loss : 19217.185546875 | val_loss : 43619.37109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 403 | train_loss : 24131.7734375 | val_loss : 32921.046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 404 | train_loss : 22472.6640625 | val_loss : 18485.55078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 405 | train_loss : 12229.8583984375 | val_loss : 10843.4814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 406 | train_loss : 8604.806640625 | val_loss : 23905.662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 407 | train_loss : 14912.9384765625 | val_loss : 16753.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 408 | train_loss : 12294.392578125 | val_loss : 35761.29296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 409 | train_loss : 19204.623046875 | val_loss : 33691.00390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 410 | train_loss : 20142.498046875 | val_loss : 38041.5859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 411 | train_loss : 25313.46484375 | val_loss : 14298.638671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 412 | train_loss : 15197.197265625 | val_loss : 26311.966796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 413 | train_loss : 13428.3486328125 | val_loss : 22146.349609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 414 | train_loss : 18792.103515625 | val_loss : 24814.630859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 415 | train_loss : 21984.765625 | val_loss : 20661.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 416 | train_loss : 16982.66015625 | val_loss : 30364.28515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 417 | train_loss : 17551.55078125 | val_loss : 15339.4287109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 418 | train_loss : 14748.30078125 | val_loss : 10973.724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 419 | train_loss : 12383.0146484375 | val_loss : 19795.439453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 420 | train_loss : 8307.51171875 | val_loss : 18389.59375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 421 | train_loss : 12896.3095703125 | val_loss : 31166.662109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 422 | train_loss : 22518.58203125 | val_loss : 21554.16015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 423 | train_loss : 20133.2734375 | val_loss : 25815.990234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 424 | train_loss : 17378.265625 | val_loss : 30061.552734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 425 | train_loss : 22919.154296875 | val_loss : 32567.640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 426 | train_loss : 23381.197265625 | val_loss : 19210.712890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 427 | train_loss : 14590.9501953125 | val_loss : 19812.998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 428 | train_loss : 21502.0703125 | val_loss : 32980.421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 429 | train_loss : 12751.708984375 | val_loss : 18952.564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 430 | train_loss : 10786.4970703125 | val_loss : 18005.51953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 431 | train_loss : 11420.3896484375 | val_loss : 38137.28125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 432 | train_loss : 24844.091796875 | val_loss : 28579.029296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 433 | train_loss : 17335.529296875 | val_loss : 26896.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 434 | train_loss : 14745.9423828125 | val_loss : 11747.107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 435 | train_loss : 9743.61328125 | val_loss : 28283.6015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 436 | train_loss : 18569.501953125 | val_loss : 28328.927734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 437 | train_loss : 14232.52734375 | val_loss : 41399.81640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 438 | train_loss : 18221.7265625 | val_loss : 22199.6875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 439 | train_loss : 13288.3837890625 | val_loss : 11431.697265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 440 | train_loss : 13446.6533203125 | val_loss : 29708.1875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 441 | train_loss : 14760.58203125 | val_loss : 30455.796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 442 | train_loss : 21856.849609375 | val_loss : 18425.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 443 | train_loss : 26595.599609375 | val_loss : 32182.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 444 | train_loss : 16745.625 | val_loss : 16111.9072265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 445 | train_loss : 10798.5341796875 | val_loss : 26729.64453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 446 | train_loss : 17442.890625 | val_loss : 25894.169921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 447 | train_loss : 13765.8896484375 | val_loss : 21394.220703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 448 | train_loss : 15591.1748046875 | val_loss : 37385.69140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 449 | train_loss : 26016.96484375 | val_loss : 45751.56640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 450 | train_loss : 21872.962890625 | val_loss : 41040.2734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 451 | train_loss : 19925.5859375 | val_loss : 49691.7734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 452 | train_loss : 29514.630859375 | val_loss : 28435.525390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 453 | train_loss : 16495.025390625 | val_loss : 18670.93359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 454 | train_loss : 11407.818359375 | val_loss : 21270.431640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 455 | train_loss : 18392.36328125 | val_loss : 41396.234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 456 | train_loss : 28422.01171875 | val_loss : 39218.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 457 | train_loss : 21700.26171875 | val_loss : 30588.5859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 458 | train_loss : 14802.5546875 | val_loss : 33591.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 459 | train_loss : 20638.482421875 | val_loss : 14585.5234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 460 | train_loss : 13468.0625 | val_loss : 34424.26953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 461 | train_loss : 25320.1015625 | val_loss : 37442.7734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 462 | train_loss : 19695.92578125 | val_loss : 28081.580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 463 | train_loss : 19118.751953125 | val_loss : 29373.064453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 464 | train_loss : 16180.1171875 | val_loss : 20828.052734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 465 | train_loss : 22428.4453125 | val_loss : 25943.1875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 466 | train_loss : 15305.34765625 | val_loss : 31020.328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 467 | train_loss : 21971.931640625 | val_loss : 38687.69140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 468 | train_loss : 18224.212890625 | val_loss : 19762.08203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 469 | train_loss : 11567.9951171875 | val_loss : 12512.5986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 470 | train_loss : 11591.673828125 | val_loss : 27392.337890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 471 | train_loss : 18298.392578125 | val_loss : 17206.83203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 472 | train_loss : 14502.5078125 | val_loss : 26111.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 473 | train_loss : 19364.974609375 | val_loss : 34386.87890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 474 | train_loss : 21569.431640625 | val_loss : 42023.234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 475 | train_loss : 18777.23046875 | val_loss : 16810.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 476 | train_loss : 9381.4697265625 | val_loss : 12358.71484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 477 | train_loss : 8258.7177734375 | val_loss : 16402.13671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 478 | train_loss : 12386.45703125 | val_loss : 13989.9541015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 479 | train_loss : 10546.080078125 | val_loss : 18070.310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 480 | train_loss : 14945.205078125 | val_loss : 43936.14453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 481 | train_loss : 20943.337890625 | val_loss : 39779.32421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 482 | train_loss : 18586.91796875 | val_loss : 34068.21484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 483 | train_loss : 24325.884765625 | val_loss : 20446.181640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 484 | train_loss : 19532.09765625 | val_loss : 22367.76953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 485 | train_loss : 15844.2158203125 | val_loss : 38805.86328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 486 | train_loss : 17936.76953125 | val_loss : 38840.93359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 487 | train_loss : 21077.72265625 | val_loss : 38346.890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 488 | train_loss : 21483.337890625 | val_loss : 14321.73828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 489 | train_loss : 11064.6083984375 | val_loss : 15390.458984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 490 | train_loss : 11493.9921875 | val_loss : 20272.314453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 491 | train_loss : 18426.306640625 | val_loss : 30711.86328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 492 | train_loss : 20716.693359375 | val_loss : 14558.0087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 493 | train_loss : 13488.7197265625 | val_loss : 19788.443359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 494 | train_loss : 9166.5400390625 | val_loss : 17003.1015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 495 | train_loss : 14450.794921875 | val_loss : 22278.51171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 496 | train_loss : 17413.572265625 | val_loss : 20826.1015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 497 | train_loss : 11622.7421875 | val_loss : 29395.705078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 498 | train_loss : 17995.201171875 | val_loss : 15575.5263671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 499 | train_loss : 14375.482421875 | val_loss : 25498.716796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 500 | train_loss : 15111.5712890625 | val_loss : 24503.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 501 | train_loss : 12382.701171875 | val_loss : 23128.32421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 502 | train_loss : 14915.568359375 | val_loss : 17249.001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 503 | train_loss : 16015.107421875 | val_loss : 33925.75390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 504 | train_loss : 21346.607421875 | val_loss : 23330.6875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 505 | train_loss : 12779.4150390625 | val_loss : 26231.48046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 506 | train_loss : 13078.62890625 | val_loss : 13702.2626953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 507 | train_loss : 11688.84765625 | val_loss : 28939.310546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 508 | train_loss : 14337.8515625 | val_loss : 11462.2412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 509 | train_loss : 8941.16015625 | val_loss : 23998.2265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 510 | train_loss : 15227.802734375 | val_loss : 31398.005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 511 | train_loss : 17746.056640625 | val_loss : 49034.80859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 512 | train_loss : 22543.845703125 | val_loss : 30832.89453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 513 | train_loss : 18780.546875 | val_loss : 16177.494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 514 | train_loss : 20494.822265625 | val_loss : 26393.150390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 515 | train_loss : 16793.671875 | val_loss : 31124.224609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 516 | train_loss : 17860.19921875 | val_loss : 40867.83984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 517 | train_loss : 15552.4091796875 | val_loss : 17213.7734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 518 | train_loss : 10122.177734375 | val_loss : 21747.275390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 519 | train_loss : 10662.5 | val_loss : 14860.287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 520 | train_loss : 7620.2236328125 | val_loss : 28515.76953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 521 | train_loss : 12379.865234375 | val_loss : 19001.037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 522 | train_loss : 13999.3154296875 | val_loss : 24833.71484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 523 | train_loss : 11206.6650390625 | val_loss : 15090.7724609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 524 | train_loss : 9426.0478515625 | val_loss : 15198.9716796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 525 | train_loss : 10486.08203125 | val_loss : 17441.251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 526 | train_loss : 8413.7900390625 | val_loss : 11793.8251953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 527 | train_loss : 12858.0126953125 | val_loss : 33514.34375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 528 | train_loss : 14823.3037109375 | val_loss : 17634.771484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 529 | train_loss : 11302.24609375 | val_loss : 11350.4873046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 530 | train_loss : 13369.9423828125 | val_loss : 29073.349609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 531 | train_loss : 11328.7412109375 | val_loss : 16820.65234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 532 | train_loss : 10638.1689453125 | val_loss : 14240.0302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 533 | train_loss : 8583.1826171875 | val_loss : 22499.3359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 534 | train_loss : 10341.728515625 | val_loss : 16136.2802734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 535 | train_loss : 11132.9453125 | val_loss : 15698.4716796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 536 | train_loss : 10973.7578125 | val_loss : 15418.8408203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 537 | train_loss : 17762.294921875 | val_loss : 36973.38671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 538 | train_loss : 25287.724609375 | val_loss : 30899.375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 539 | train_loss : 17584.587890625 | val_loss : 32446.4140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 540 | train_loss : 13894.662109375 | val_loss : 32560.32421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 541 | train_loss : 19528.365234375 | val_loss : 12516.1552734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 542 | train_loss : 13087.6533203125 | val_loss : 26595.41796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 543 | train_loss : 19098.6328125 | val_loss : 30777.09765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 544 | train_loss : 15512.2587890625 | val_loss : 44741.32421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 545 | train_loss : 20254.970703125 | val_loss : 23252.037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 546 | train_loss : 15307.478515625 | val_loss : 22096.421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 547 | train_loss : 10524.99609375 | val_loss : 16648.115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 548 | train_loss : 11300.0654296875 | val_loss : 19217.916015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 549 | train_loss : 12151.080078125 | val_loss : 21490.546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 550 | train_loss : 14235.4951171875 | val_loss : 30933.275390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 551 | train_loss : 16360.5810546875 | val_loss : 19803.376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 552 | train_loss : 7350.61083984375 | val_loss : 13042.62109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 553 | train_loss : 5276.5556640625 | val_loss : 16800.3671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 554 | train_loss : 9029.384765625 | val_loss : 13792.3173828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 555 | train_loss : 12483.888671875 | val_loss : 38832.87109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 556 | train_loss : 27664.966796875 | val_loss : 29912.67578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 557 | train_loss : 20653.41796875 | val_loss : 33207.61328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 558 | train_loss : 16579.7890625 | val_loss : 35155.53125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 559 | train_loss : 20707.798828125 | val_loss : 12700.4423828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 560 | train_loss : 18988.548828125 | val_loss : 23667.818359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 561 | train_loss : 10543.3564453125 | val_loss : 11399.2177734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 562 | train_loss : 7289.4951171875 | val_loss : 17578.076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 563 | train_loss : 7842.59130859375 | val_loss : 17774.5546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 564 | train_loss : 8410.9443359375 | val_loss : 28177.01171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 565 | train_loss : 14638.0595703125 | val_loss : 15830.7373046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 566 | train_loss : 11472.5302734375 | val_loss : 23591.1953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 567 | train_loss : 16944.169921875 | val_loss : 28962.556640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 568 | train_loss : 20501.556640625 | val_loss : 26712.60546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 569 | train_loss : 13647.28515625 | val_loss : 11279.619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 570 | train_loss : 4586.623046875 | val_loss : 12145.7939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 571 | train_loss : 7429.7783203125 | val_loss : 18944.234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 572 | train_loss : 12023.837890625 | val_loss : 30636.392578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 573 | train_loss : 17566.064453125 | val_loss : 14259.4990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 574 | train_loss : 9761.94921875 | val_loss : 17685.853515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 575 | train_loss : 9528.81640625 | val_loss : 18795.66015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 576 | train_loss : 10682.3408203125 | val_loss : 32117.095703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 577 | train_loss : 14752.4072265625 | val_loss : 15349.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 578 | train_loss : 10043.2158203125 | val_loss : 12517.22265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 579 | train_loss : 17363.5 | val_loss : 25941.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 580 | train_loss : 17434.595703125 | val_loss : 28842.375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 581 | train_loss : 17389.861328125 | val_loss : 37596.49609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 582 | train_loss : 13594.865234375 | val_loss : 22486.650390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 583 | train_loss : 18405.287109375 | val_loss : 32930.86328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 584 | train_loss : 21387.072265625 | val_loss : 15970.1923828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 585 | train_loss : 8844.9189453125 | val_loss : 23557.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 586 | train_loss : 10750.9248046875 | val_loss : 24150.59765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 587 | train_loss : 9771.150390625 | val_loss : 11015.8935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 588 | train_loss : 6009.50634765625 | val_loss : 19251.06640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 589 | train_loss : 11588.318359375 | val_loss : 25256.873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 590 | train_loss : 9452.931640625 | val_loss : 20835.962890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 591 | train_loss : 11343.21875 | val_loss : 11318.5078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 592 | train_loss : 12773.2041015625 | val_loss : 30022.7421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 593 | train_loss : 18225.357421875 | val_loss : 26270.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 594 | train_loss : 12045.39453125 | val_loss : 33129.86328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 595 | train_loss : 14199.3720703125 | val_loss : 29714.787109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 596 | train_loss : 16338.572265625 | val_loss : 13646.28125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 597 | train_loss : 11551.3720703125 | val_loss : 19829.587890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 598 | train_loss : 13542.1328125 | val_loss : 27565.900390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 599 | train_loss : 13596.2822265625 | val_loss : 41834.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 600 | train_loss : 17157.291015625 | val_loss : 18428.138671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 601 | train_loss : 9240.2158203125 | val_loss : 13528.2021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 602 | train_loss : 9672.4736328125 | val_loss : 20922.6953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 603 | train_loss : 12178.357421875 | val_loss : 10930.6123046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 604 | train_loss : 13758.150390625 | val_loss : 25959.41796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 605 | train_loss : 14011.3935546875 | val_loss : 24020.365234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 606 | train_loss : 9482.85546875 | val_loss : 24659.935546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 607 | train_loss : 13218.8603515625 | val_loss : 15933.2685546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 608 | train_loss : 13508.0302734375 | val_loss : 25870.494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 609 | train_loss : 14141.9873046875 | val_loss : 21288.869140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 610 | train_loss : 8877.5673828125 | val_loss : 24974.669921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 611 | train_loss : 9681.4697265625 | val_loss : 12583.5029296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 612 | train_loss : 8769.111328125 | val_loss : 14018.8837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 613 | train_loss : 12437.7978515625 | val_loss : 15022.8935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 614 | train_loss : 9901.2958984375 | val_loss : 25303.25 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 615 | train_loss : 11404.4677734375 | val_loss : 23803.265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 616 | train_loss : 11890.5703125 | val_loss : 29083.35546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 617 | train_loss : 17194.939453125 | val_loss : 11742.490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 618 | train_loss : 10333.5771484375 | val_loss : 25964.009765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 619 | train_loss : 12648.3798828125 | val_loss : 16586.171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 620 | train_loss : 11191.4765625 | val_loss : 15088.9248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 621 | train_loss : 9533.48046875 | val_loss : 15987.5048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 622 | train_loss : 10892.34375 | val_loss : 22187.369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 623 | train_loss : 10422.3857421875 | val_loss : 10985.5537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 624 | train_loss : 6025.56494140625 | val_loss : 15583.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 625 | train_loss : 13424.427734375 | val_loss : 249073.640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 626 | train_loss : 291320.75 | val_loss : 165033.796875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 627 | train_loss : 186476.09375 | val_loss : 88197.8203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 628 | train_loss : 52073.39453125 | val_loss : 89094.4765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 629 | train_loss : 41973.44140625 | val_loss : 77556.21875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 630 | train_loss : 42783.33984375 | val_loss : 82534.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 631 | train_loss : 38954.96484375 | val_loss : 68555.7421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 632 | train_loss : 31683.943359375 | val_loss : 61010.7109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 633 | train_loss : 31102.994140625 | val_loss : 53919.87109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 634 | train_loss : 32601.162109375 | val_loss : 57571.82421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 635 | train_loss : 27665.498046875 | val_loss : 46826.25390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 636 | train_loss : 21150.216796875 | val_loss : 32057.5703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 637 | train_loss : 17673.494140625 | val_loss : 23334.89453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 638 | train_loss : 18299.220703125 | val_loss : 27586.27734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 639 | train_loss : 15761.26953125 | val_loss : 22332.251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 640 | train_loss : 10274.419921875 | val_loss : 13441.0478515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 641 | train_loss : 7927.13916015625 | val_loss : 13308.2412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 642 | train_loss : 8591.8271484375 | val_loss : 18106.419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 643 | train_loss : 13305.1708984375 | val_loss : 14542.8251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 644 | train_loss : 8179.1787109375 | val_loss : 16276.4326171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 645 | train_loss : 10392.7822265625 | val_loss : 12064.7109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 646 | train_loss : 9795.80859375 | val_loss : 21400.080078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 647 | train_loss : 13999.3525390625 | val_loss : 12903.958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 648 | train_loss : 8211.8779296875 | val_loss : 15336.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 649 | train_loss : 10479.4853515625 | val_loss : 16312.4521484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 650 | train_loss : 12302.5771484375 | val_loss : 21928.373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 651 | train_loss : 10163.5029296875 | val_loss : 11226.6396484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 652 | train_loss : 7962.72607421875 | val_loss : 15189.6513671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 653 | train_loss : 7459.5751953125 | val_loss : 8493.6572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 654 | train_loss : 6442.57861328125 | val_loss : 17159.7421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 655 | train_loss : 7284.19189453125 | val_loss : 10813.8115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 656 | train_loss : 6955.91015625 | val_loss : 13686.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 657 | train_loss : 7283.23876953125 | val_loss : 8541.3671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 658 | train_loss : 5528.40771484375 | val_loss : 19356.359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 659 | train_loss : 11428.3154296875 | val_loss : 16629.0234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 660 | train_loss : 12186.6298828125 | val_loss : 25256.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 661 | train_loss : 13142.0439453125 | val_loss : 19341.5859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 662 | train_loss : 11262.1904296875 | val_loss : 23072.240234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 663 | train_loss : 11450.40625 | val_loss : 9843.650390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 664 | train_loss : 8158.736328125 | val_loss : 22425.150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 665 | train_loss : 9255.0546875 | val_loss : 8461.4453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 666 | train_loss : 4034.70947265625 | val_loss : 11459.1064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 667 | train_loss : 5493.7939453125 | val_loss : 14471.0771484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 668 | train_loss : 7050.89208984375 | val_loss : 14894.5615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 669 | train_loss : 7477.11083984375 | val_loss : 16820.591796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 670 | train_loss : 5539.36328125 | val_loss : 10361.2998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 671 | train_loss : 6834.830078125 | val_loss : 11696.44921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 672 | train_loss : 7690.271484375 | val_loss : 12273.380859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 673 | train_loss : 7699.37548828125 | val_loss : 23947.7890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 674 | train_loss : 10657.9921875 | val_loss : 18291.42578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 675 | train_loss : 9585.625 | val_loss : 21514.099609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 676 | train_loss : 12528.4873046875 | val_loss : 10173.87890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 677 | train_loss : 9092.2626953125 | val_loss : 22480.515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 678 | train_loss : 9145.24609375 | val_loss : 14257.0771484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 679 | train_loss : 8811.587890625 | val_loss : 10887.525390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 680 | train_loss : 8451.2431640625 | val_loss : 18972.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 681 | train_loss : 7228.82958984375 | val_loss : 19894.3046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 682 | train_loss : 11953.419921875 | val_loss : 25202.546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 683 | train_loss : 13670.9521484375 | val_loss : 9292.50390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 684 | train_loss : 6489.13232421875 | val_loss : 13254.447265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 685 | train_loss : 10274.5810546875 | val_loss : 26582.302734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 686 | train_loss : 10095.8251953125 | val_loss : 18745.654296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 687 | train_loss : 9447.513671875 | val_loss : 14187.0673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 688 | train_loss : 13012.037109375 | val_loss : 24871.705078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 689 | train_loss : 14399.162109375 | val_loss : 16699.998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 690 | train_loss : 8610.8173828125 | val_loss : 20400.078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 691 | train_loss : 10761.30078125 | val_loss : 18322.0546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 692 | train_loss : 11076.677734375 | val_loss : 8647.837890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 693 | train_loss : 11933.1162109375 | val_loss : 17637.912109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 694 | train_loss : 6505.90234375 | val_loss : 13523.7529296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 695 | train_loss : 7692.46484375 | val_loss : 30012.056640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 696 | train_loss : 12206.7490234375 | val_loss : 15216.90234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 697 | train_loss : 6417.96240234375 | val_loss : 13844.16015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 698 | train_loss : 5952.92041015625 | val_loss : 12696.5078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 699 | train_loss : 6338.85498046875 | val_loss : 6632.99267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 700 | train_loss : 3511.83447265625 | val_loss : 10337.083984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 701 | train_loss : 3342.0712890625 | val_loss : 13174.3115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 702 | train_loss : 6677.5625 | val_loss : 15608.4599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 703 | train_loss : 8322.7578125 | val_loss : 25503.08203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 704 | train_loss : 10837.7646484375 | val_loss : 14827.32421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 705 | train_loss : 11213.7275390625 | val_loss : 12030.33203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 706 | train_loss : 14873.052734375 | val_loss : 23091.509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 707 | train_loss : 12975.6845703125 | val_loss : 21312.447265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 708 | train_loss : 10013.958984375 | val_loss : 28186.14453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 709 | train_loss : 11190.599609375 | val_loss : 18274.57421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 710 | train_loss : 12365.791015625 | val_loss : 15363.5673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 711 | train_loss : 11342.0009765625 | val_loss : 15683.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 712 | train_loss : 8541.423828125 | val_loss : 21968.107421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 713 | train_loss : 12068.787109375 | val_loss : 12373.7412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 714 | train_loss : 8640.833984375 | val_loss : 21873.494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 715 | train_loss : 9301.51953125 | val_loss : 12194.537109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 716 | train_loss : 5577.20947265625 | val_loss : 14795.1220703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 717 | train_loss : 9030.9326171875 | val_loss : 8347.666015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 718 | train_loss : 6573.31396484375 | val_loss : 20945.3828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 719 | train_loss : 12425.7265625 | val_loss : 16669.662109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 720 | train_loss : 7590.263671875 | val_loss : 19895.9609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 721 | train_loss : 7379.93798828125 | val_loss : 7844.04638671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 722 | train_loss : 4131.15673828125 | val_loss : 18867.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 723 | train_loss : 7791.0751953125 | val_loss : 11078.4228515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 724 | train_loss : 5757.69140625 | val_loss : 8846.38671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 725 | train_loss : 7088.95361328125 | val_loss : 15321.55859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 726 | train_loss : 6021.0986328125 | val_loss : 12317.26171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 727 | train_loss : 9838.50390625 | val_loss : 22883.685546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 728 | train_loss : 12833.5078125 | val_loss : 7085.44873046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 729 | train_loss : 6860.87744140625 | val_loss : 16470.97265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 730 | train_loss : 7541.41943359375 | val_loss : 21319.9453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 731 | train_loss : 10423.69921875 | val_loss : 30903.1171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 732 | train_loss : 17978.015625 | val_loss : 9067.1513671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 733 | train_loss : 9092.3603515625 | val_loss : 13517.63671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 734 | train_loss : 4626.63232421875 | val_loss : 8756.990234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 735 | train_loss : 4881.2666015625 | val_loss : 19228.849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 736 | train_loss : 8063.7431640625 | val_loss : 9996.80078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 737 | train_loss : 4683.095703125 | val_loss : 9844.373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 738 | train_loss : 5888.19140625 | val_loss : 10711.3271484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 739 | train_loss : 4789.82177734375 | val_loss : 9363.1376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 740 | train_loss : 4579.9609375 | val_loss : 10247.615234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 741 | train_loss : 4315.53564453125 | val_loss : 11170.2978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 742 | train_loss : 7361.4013671875 | val_loss : 14894.3798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 743 | train_loss : 7026.77880859375 | val_loss : 11133.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 744 | train_loss : 9371.369140625 | val_loss : 22561.234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 745 | train_loss : 8160.25146484375 | val_loss : 12716.69921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 746 | train_loss : 7464.16259765625 | val_loss : 25830.5390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 747 | train_loss : 13416.83984375 | val_loss : 19922.39453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 748 | train_loss : 13242.4248046875 | val_loss : 25242.681640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 749 | train_loss : 13207.4609375 | val_loss : 10133.4716796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 750 | train_loss : 6779.93359375 | val_loss : 15809.66015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 751 | train_loss : 6159.6923828125 | val_loss : 10110.1689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 752 | train_loss : 7420.50390625 | val_loss : 18206.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 753 | train_loss : 9187.3125 | val_loss : 19362.58984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 754 | train_loss : 7389.8525390625 | val_loss : 19941.931640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 755 | train_loss : 8320.1435546875 | val_loss : 15030.75390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 756 | train_loss : 8212.19140625 | val_loss : 20871.84375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 757 | train_loss : 12584.5146484375 | val_loss : 7462.9189453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 758 | train_loss : 4885.904296875 | val_loss : 17711.41015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 759 | train_loss : 10908.5126953125 | val_loss : 19349.169921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 760 | train_loss : 9239.2646484375 | val_loss : 25529.939453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 761 | train_loss : 10891.7041015625 | val_loss : 16664.9921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 762 | train_loss : 13845.275390625 | val_loss : 23764.404296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 763 | train_loss : 11983.01171875 | val_loss : 13760.4638671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 764 | train_loss : 5985.41748046875 | val_loss : 14478.8935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 765 | train_loss : 5418.97265625 | val_loss : 13323.7001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 766 | train_loss : 6736.35546875 | val_loss : 7232.6123046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 767 | train_loss : 7286.96728515625 | val_loss : 18133.734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 768 | train_loss : 9224.357421875 | val_loss : 16649.013671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 769 | train_loss : 8231.830078125 | val_loss : 20071.044921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 770 | train_loss : 8442.59375 | val_loss : 12190.48828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 771 | train_loss : 6648.986328125 | val_loss : 17581.416015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 772 | train_loss : 8825.2431640625 | val_loss : 7894.8720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 773 | train_loss : 4189.53369140625 | val_loss : 14313.3916015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 774 | train_loss : 5345.90771484375 | val_loss : 16727.0859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 775 | train_loss : 8252.76171875 | val_loss : 20948.6328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 776 | train_loss : 13049.5859375 | val_loss : 11944.525390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 777 | train_loss : 11940.70703125 | val_loss : 17593.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 778 | train_loss : 7873.34130859375 | val_loss : 12520.3466796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 779 | train_loss : 4497.0966796875 | val_loss : 17300.6015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 780 | train_loss : 8548.4052734375 | val_loss : 8557.744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 781 | train_loss : 4869.18994140625 | val_loss : 13239.923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 782 | train_loss : 5759.3212890625 | val_loss : 11752.931640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 783 | train_loss : 4783.52978515625 | val_loss : 12767.37109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 784 | train_loss : 7427.15673828125 | val_loss : 7558.24169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 785 | train_loss : 7636.5087890625 | val_loss : 18323.513671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 786 | train_loss : 7488.36669921875 | val_loss : 7611.451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 787 | train_loss : 3616.929443359375 | val_loss : 12125.5966796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 788 | train_loss : 7444.4560546875 | val_loss : 15404.2900390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 789 | train_loss : 7476.37353515625 | val_loss : 12709.03125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 790 | train_loss : 12088.0283203125 | val_loss : 20756.8828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 791 | train_loss : 7575.26611328125 | val_loss : 9911.7509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 792 | train_loss : 5115.8525390625 | val_loss : 11015.1220703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 793 | train_loss : 5910.8251953125 | val_loss : 17257.099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 794 | train_loss : 7492.6875 | val_loss : 87795.34375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 795 | train_loss : 72069.1484375 | val_loss : 13632.755859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 796 | train_loss : 17655.3046875 | val_loss : 19459.630859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 797 | train_loss : 16739.078125 | val_loss : 24265.44921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 798 | train_loss : 15267.41796875 | val_loss : 25283.689453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 799 | train_loss : 11799.52734375 | val_loss : 13666.0986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 800 | train_loss : 5914.06689453125 | val_loss : 15144.181640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 801 | train_loss : 7846.77490234375 | val_loss : 9760.09375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 802 | train_loss : 6990.74365234375 | val_loss : 17909.583984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 803 | train_loss : 8731.25 | val_loss : 13050.3876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 804 | train_loss : 6368.248046875 | val_loss : 12777.4462890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 805 | train_loss : 6206.669921875 | val_loss : 7686.6025390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 806 | train_loss : 5888.5048828125 | val_loss : 19778.7578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 807 | train_loss : 11112.4599609375 | val_loss : 12456.9287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 808 | train_loss : 5364.89111328125 | val_loss : 9776.3359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 809 | train_loss : 2899.5625 | val_loss : 10561.826171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 810 | train_loss : 4002.1181640625 | val_loss : 11003.90234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 811 | train_loss : 5820.1787109375 | val_loss : 17461.5859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 812 | train_loss : 7611.03857421875 | val_loss : 12644.69140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 813 | train_loss : 6713.50146484375 | val_loss : 13720.8671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 814 | train_loss : 8639.291015625 | val_loss : 14740.4248046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 815 | train_loss : 9842.2841796875 | val_loss : 22286.51953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 816 | train_loss : 8408.1328125 | val_loss : 11059.3720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 817 | train_loss : 5605.853515625 | val_loss : 13459.23828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 818 | train_loss : 7867.59765625 | val_loss : 12418.9560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 819 | train_loss : 7143.708984375 | val_loss : 9415.0751953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 820 | train_loss : 6753.77685546875 | val_loss : 7652.34521484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 821 | train_loss : 2061.754150390625 | val_loss : 6612.7275390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 822 | train_loss : 2056.49365234375 | val_loss : 11495.0390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 823 | train_loss : 4442.9658203125 | val_loss : 10307.8720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 824 | train_loss : 5995.49609375 | val_loss : 7374.3798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 825 | train_loss : 6650.93798828125 | val_loss : 17623.689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 826 | train_loss : 8048.32568359375 | val_loss : 13947.40234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 827 | train_loss : 6218.9736328125 | val_loss : 12511.83984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 828 | train_loss : 6652.5576171875 | val_loss : 166374.984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 829 | train_loss : 178048.84375 | val_loss : 51919.078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 830 | train_loss : 44383.359375 | val_loss : 34409.359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 831 | train_loss : 32304.82421875 | val_loss : 47985.46875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 832 | train_loss : 25436.83984375 | val_loss : 29126.0546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 833 | train_loss : 17190.5390625 | val_loss : 29041.435546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 834 | train_loss : 15332.1396484375 | val_loss : 10670.4599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 835 | train_loss : 4472.53857421875 | val_loss : 11928.44140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 836 | train_loss : 4997.59228515625 | val_loss : 11032.2001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 837 | train_loss : 5561.4033203125 | val_loss : 19987.478515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 838 | train_loss : 11013.9208984375 | val_loss : 8146.2919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 839 | train_loss : 5860.5107421875 | val_loss : 13986.2822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 840 | train_loss : 5213.212890625 | val_loss : 69387.46875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 841 | train_loss : 67251.78125 | val_loss : 58794.14453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 842 | train_loss : 40284.43359375 | val_loss : 25717.869140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 843 | train_loss : 19241.0390625 | val_loss : 14874.58203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 844 | train_loss : 10615.5947265625 | val_loss : 8963.4814453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 845 | train_loss : 6701.77685546875 | val_loss : 18197.994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 846 | train_loss : 9820.71484375 | val_loss : 7228.87109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 847 | train_loss : 6295.88818359375 | val_loss : 17526.755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 848 | train_loss : 6753.76953125 | val_loss : 15081.4326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 849 | train_loss : 5503.15673828125 | val_loss : 11294.5029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 850 | train_loss : 5814.626953125 | val_loss : 9514.8203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 851 | train_loss : 7572.80322265625 | val_loss : 18439.736328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 852 | train_loss : 9258.05078125 | val_loss : 12568.0087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 853 | train_loss : 5001.36572265625 | val_loss : 11622.2666015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 854 | train_loss : 3523.91552734375 | val_loss : 7305.09521484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 855 | train_loss : 2888.20947265625 | val_loss : 13048.0654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 856 | train_loss : 4594.60888671875 | val_loss : 5658.64306640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 857 | train_loss : 2064.6337890625 | val_loss : 7552.02734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 858 | train_loss : 2712.030517578125 | val_loss : 17134.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 859 | train_loss : 7363.44384765625 | val_loss : 9695.8388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 860 | train_loss : 6270.6611328125 | val_loss : 16130.892578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 861 | train_loss : 6652.1689453125 | val_loss : 7696.3095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 862 | train_loss : 3727.3564453125 | val_loss : 6748.154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 863 | train_loss : 4023.061279296875 | val_loss : 9336.7490234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 864 | train_loss : 5397.8037109375 | val_loss : 9047.4501953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 865 | train_loss : 4898.85986328125 | val_loss : 7220.267578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 866 | train_loss : 5673.16748046875 | val_loss : 17289.189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 867 | train_loss : 7779.82568359375 | val_loss : 7275.15673828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 868 | train_loss : 3419.647216796875 | val_loss : 10746.2138671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 869 | train_loss : 7768.63623046875 | val_loss : 18314.36328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 870 | train_loss : 9814.1181640625 | val_loss : 8064.6826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 871 | train_loss : 8266.5205078125 | val_loss : 19000.873046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 872 | train_loss : 7009.46435546875 | val_loss : 10331.6865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 873 | train_loss : 3631.781005859375 | val_loss : 8551.380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 874 | train_loss : 4830.724609375 | val_loss : 10417.38671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 875 | train_loss : 3202.311767578125 | val_loss : 7530.095703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 876 | train_loss : 2695.158447265625 | val_loss : 8961.23828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 877 | train_loss : 5333.00146484375 | val_loss : 17361.109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 878 | train_loss : 9576.94140625 | val_loss : 8379.5673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 879 | train_loss : 3990.0732421875 | val_loss : 9613.169921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 880 | train_loss : 4079.63818359375 | val_loss : 8249.744140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 881 | train_loss : 2983.9462890625 | val_loss : 10636.1435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 882 | train_loss : 4093.5771484375 | val_loss : 10233.06640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 883 | train_loss : 5971.2529296875 | val_loss : 18925.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 884 | train_loss : 9920.1240234375 | val_loss : 10403.615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 885 | train_loss : 7069.44677734375 | val_loss : 33764.12890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 886 | train_loss : 18046.8125 | val_loss : 29353.033203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 887 | train_loss : 20238.869140625 | val_loss : 13456.6904296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 888 | train_loss : 12629.5361328125 | val_loss : 26455.5078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 889 | train_loss : 15860.0625 | val_loss : 11589.7158203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 890 | train_loss : 10224.458984375 | val_loss : 20099.515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 891 | train_loss : 9457.708984375 | val_loss : 10415.1884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 892 | train_loss : 6774.345703125 | val_loss : 12970.9384765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 893 | train_loss : 5852.18603515625 | val_loss : 12062.74609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 894 | train_loss : 6282.54638671875 | val_loss : 18791.205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 895 | train_loss : 7667.70166015625 | val_loss : 8924.4853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 896 | train_loss : 4397.39892578125 | val_loss : 7674.74365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 897 | train_loss : 4417.66259765625 | val_loss : 11606.3447265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 898 | train_loss : 4014.873779296875 | val_loss : 12602.93359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 899 | train_loss : 5887.1064453125 | val_loss : 14270.2421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 900 | train_loss : 7117.0361328125 | val_loss : 8457.4189453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 901 | train_loss : 6780.373046875 | val_loss : 16352.068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 902 | train_loss : 6888.1123046875 | val_loss : 11202.3740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 903 | train_loss : 6033.41015625 | val_loss : 14375.427734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 904 | train_loss : 6825.81298828125 | val_loss : 7000.31982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 905 | train_loss : 6828.078125 | val_loss : 17880.06640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 906 | train_loss : 6737.486328125 | val_loss : 13097.65625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 907 | train_loss : 7051.00732421875 | val_loss : 18665.734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 908 | train_loss : 9907.552734375 | val_loss : 6956.23388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 909 | train_loss : 4569.4560546875 | val_loss : 12306.5322265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 910 | train_loss : 3712.133056640625 | val_loss : 16108.8359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 911 | train_loss : 5485.25244140625 | val_loss : 12455.8154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 912 | train_loss : 3862.916259765625 | val_loss : 7778.95166015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 913 | train_loss : 4118.43310546875 | val_loss : 13076.5673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 914 | train_loss : 6613.77978515625 | val_loss : 7958.208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 915 | train_loss : 3643.004638671875 | val_loss : 15138.7236328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 916 | train_loss : 6276.97314453125 | val_loss : 12333.3447265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 917 | train_loss : 4122.11181640625 | val_loss : 10037.0654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 918 | train_loss : 4768.0869140625 | val_loss : 7980.60498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 919 | train_loss : 7269.1435546875 | val_loss : 20090.029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 920 | train_loss : 7584.865234375 | val_loss : 8625.056640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 921 | train_loss : 3395.13134765625 | val_loss : 9826.642578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 922 | train_loss : 4607.72265625 | val_loss : 9222.271484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 923 | train_loss : 4408.814453125 | val_loss : 7901.5029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 924 | train_loss : 3309.65625 | val_loss : 6600.24169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 925 | train_loss : 3337.4677734375 | val_loss : 14329.462890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 926 | train_loss : 6336.42822265625 | val_loss : 6375.6142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 927 | train_loss : 2499.395263671875 | val_loss : 10215.357421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 928 | train_loss : 3480.72216796875 | val_loss : 6886.27734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 929 | train_loss : 3780.7880859375 | val_loss : 15266.45703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 930 | train_loss : 7329.71435546875 | val_loss : 6292.611328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 931 | train_loss : 4602.89501953125 | val_loss : 20437.025390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 932 | train_loss : 9934.5263671875 | val_loss : 7398.85888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 933 | train_loss : 3828.53369140625 | val_loss : 14297.5654296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 934 | train_loss : 10465.7216796875 | val_loss : 17439.599609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 935 | train_loss : 8652.5615234375 | val_loss : 13985.3095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 936 | train_loss : 8788.4501953125 | val_loss : 22236.984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 937 | train_loss : 7759.78076171875 | val_loss : 10822.7646484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 938 | train_loss : 3503.11572265625 | val_loss : 11777.1953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 939 | train_loss : 3990.283203125 | val_loss : 10059.1123046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 940 | train_loss : 4585.47998046875 | val_loss : 15830.0771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 941 | train_loss : 7109.37353515625 | val_loss : 6608.20068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 942 | train_loss : 1867.7315673828125 | val_loss : 8725.888671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 943 | train_loss : 3201.04052734375 | val_loss : 10918.232421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 944 | train_loss : 4005.188232421875 | val_loss : 10050.0791015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 945 | train_loss : 3846.802490234375 | val_loss : 9353.1865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 946 | train_loss : 8197.666015625 | val_loss : 15729.80078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 947 | train_loss : 6764.83447265625 | val_loss : 9874.7001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 948 | train_loss : 5973.03369140625 | val_loss : 17392.546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 949 | train_loss : 7080.36572265625 | val_loss : 11119.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 950 | train_loss : 5893.67626953125 | val_loss : 13545.5400390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 951 | train_loss : 6423.27490234375 | val_loss : 7162.267578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 952 | train_loss : 4579.71630859375 | val_loss : 13664.3447265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 953 | train_loss : 7560.65576171875 | val_loss : 11028.759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 954 | train_loss : 4699.1279296875 | val_loss : 8731.0615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 955 | train_loss : 3210.91943359375 | val_loss : 8682.4462890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 956 | train_loss : 4647.61669921875 | val_loss : 14488.0595703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 957 | train_loss : 6925.43701171875 | val_loss : 17867.126953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 958 | train_loss : 7221.1142578125 | val_loss : 8720.1181640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 959 | train_loss : 2600.66064453125 | val_loss : 8554.681640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 960 | train_loss : 4242.7001953125 | val_loss : 8426.4267578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 961 | train_loss : 3181.64501953125 | val_loss : 10639.115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 962 | train_loss : 4691.00390625 | val_loss : 22103.94921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 963 | train_loss : 9286.140625 | val_loss : 13256.255859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 964 | train_loss : 6475.87890625 | val_loss : 11600.7724609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 965 | train_loss : 5777.48046875 | val_loss : 9241.6220703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 966 | train_loss : 4608.572265625 | val_loss : 8089.68994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 967 | train_loss : 2633.93505859375 | val_loss : 8114.59326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 968 | train_loss : 3300.090087890625 | val_loss : 5384.029296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 969 | train_loss : 4286.66357421875 | val_loss : 15851.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 970 | train_loss : 7337.8330078125 | val_loss : 10237.255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 971 | train_loss : 4050.882568359375 | val_loss : 8956.9833984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 972 | train_loss : 5488.572265625 | val_loss : 22599.455078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 973 | train_loss : 10744.1875 | val_loss : 15306.302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 974 | train_loss : 5466.55419921875 | val_loss : 8563.4755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 975 | train_loss : 3392.568115234375 | val_loss : 5614.859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 976 | train_loss : 2561.105224609375 | val_loss : 13164.6953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 977 | train_loss : 5954.97802734375 | val_loss : 7523.07763671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 978 | train_loss : 5413.97607421875 | val_loss : 17101.54296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 979 | train_loss : 8700.5810546875 | val_loss : 6176.9326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 980 | train_loss : 4083.945068359375 | val_loss : 15425.5576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 981 | train_loss : 6421.29833984375 | val_loss : 10987.5224609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 982 | train_loss : 4933.373046875 | val_loss : 10501.39453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 983 | train_loss : 4152.25634765625 | val_loss : 9507.2275390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 984 | train_loss : 4727.01953125 | val_loss : 9603.779296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 985 | train_loss : 3045.696044921875 | val_loss : 5855.38916015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 986 | train_loss : 2561.433349609375 | val_loss : 9238.9013671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 987 | train_loss : 4295.048828125 | val_loss : 13978.7998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 988 | train_loss : 7295.27978515625 | val_loss : 7027.0595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 989 | train_loss : 3084.349365234375 | val_loss : 8070.33251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 990 | train_loss : 4522.40283203125 | val_loss : 9331.61328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 991 | train_loss : 6257.84228515625 | val_loss : 20882.37109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 992 | train_loss : 11042.87109375 | val_loss : 8000.24365234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 993 | train_loss : 3512.914794921875 | val_loss : 87245.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 994 | train_loss : 94033.3984375 | val_loss : 35088.578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 995 | train_loss : 23301.69921875 | val_loss : 19196.51171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 996 | train_loss : 9966.181640625 | val_loss : 18418.064453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 997 | train_loss : 15811.6298828125 | val_loss : 12337.3271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 998 | train_loss : 11871.7060546875 | val_loss : 15757.2109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 999 | train_loss : 7487.8349609375 | val_loss : 14153.3203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1000 | train_loss : 6427.95947265625 | val_loss : 18637.7734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1001 | train_loss : 8057.97802734375 | val_loss : 13395.794921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1002 | train_loss : 4493.25 | val_loss : 8148.98291015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1003 | train_loss : 3142.8681640625 | val_loss : 8690.0888671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1004 | train_loss : 5113.3330078125 | val_loss : 19132.7890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1005 | train_loss : 9641.509765625 | val_loss : 9437.4912109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1006 | train_loss : 3549.7333984375 | val_loss : 6056.36572265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1007 | train_loss : 1931.27197265625 | val_loss : 12432.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1008 | train_loss : 4623.61669921875 | val_loss : 9519.349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1009 | train_loss : 5318.46044921875 | val_loss : 12125.99609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1010 | train_loss : 5505.7763671875 | val_loss : 12141.048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1011 | train_loss : 5715.57373046875 | val_loss : 22564.92578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1012 | train_loss : 10835.69921875 | val_loss : 9310.939453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1013 | train_loss : 3266.693115234375 | val_loss : 5449.9375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1014 | train_loss : 1531.868896484375 | val_loss : 7746.462890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1015 | train_loss : 2806.205078125 | val_loss : 7204.16552734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1016 | train_loss : 4195.88818359375 | val_loss : 18453.41015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1017 | train_loss : 7418.232421875 | val_loss : 8682.5634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1018 | train_loss : 2537.071044921875 | val_loss : 5704.291015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1019 | train_loss : 1861.1005859375 | val_loss : 8491.1474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1020 | train_loss : 5143.26904296875 | val_loss : 8886.037109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1021 | train_loss : 3256.719970703125 | val_loss : 9660.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1022 | train_loss : 4559.798828125 | val_loss : 19224.884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1023 | train_loss : 9783.529296875 | val_loss : 6309.16748046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1024 | train_loss : 2667.27978515625 | val_loss : 9375.37890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1025 | train_loss : 3264.79052734375 | val_loss : 9790.8935546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1026 | train_loss : 3675.93994140625 | val_loss : 7457.3544921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1027 | train_loss : 2969.9921875 | val_loss : 6444.2119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1028 | train_loss : 4603.22802734375 | val_loss : 11495.76171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1029 | train_loss : 4763.10205078125 | val_loss : 10503.9599609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1030 | train_loss : 5126.60107421875 | val_loss : 9062.03515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1031 | train_loss : 6892.77490234375 | val_loss : 22406.6484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1032 | train_loss : 13531.0 | val_loss : 15204.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1033 | train_loss : 7408.05517578125 | val_loss : 11421.2841796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1034 | train_loss : 4668.00537109375 | val_loss : 13339.857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1035 | train_loss : 6165.2607421875 | val_loss : 5741.646484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1036 | train_loss : 4063.45947265625 | val_loss : 9953.23828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1037 | train_loss : 4198.0595703125 | val_loss : 9741.6220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1038 | train_loss : 4423.703125 | val_loss : 7650.09228515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1039 | train_loss : 2168.37109375 | val_loss : 6658.8095703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1040 | train_loss : 2736.316162109375 | val_loss : 9354.7705078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1041 | train_loss : 3836.078857421875 | val_loss : 9281.806640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1042 | train_loss : 4043.474609375 | val_loss : 9982.373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1043 | train_loss : 6198.62451171875 | val_loss : 21427.17578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1044 | train_loss : 10672.826171875 | val_loss : 9879.08203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1045 | train_loss : 4386.0869140625 | val_loss : 8622.76171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1046 | train_loss : 4959.71240234375 | val_loss : 18986.267578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1047 | train_loss : 9812.62109375 | val_loss : 7970.8701171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1048 | train_loss : 3339.39208984375 | val_loss : 5686.837890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1049 | train_loss : 1643.0970458984375 | val_loss : 11536.7314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1050 | train_loss : 3999.891357421875 | val_loss : 6333.49609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1051 | train_loss : 3110.1318359375 | val_loss : 10431.2744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1052 | train_loss : 5117.05419921875 | val_loss : 14977.4599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1053 | train_loss : 6725.41015625 | val_loss : 21976.177734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1054 | train_loss : 10319.3212890625 | val_loss : 9940.115234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1055 | train_loss : 4880.31787109375 | val_loss : 8431.9755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1056 | train_loss : 4145.81640625 | val_loss : 12120.224609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1057 | train_loss : 5666.330078125 | val_loss : 12263.27734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1058 | train_loss : 5850.27490234375 | val_loss : 18784.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1059 | train_loss : 9593.99609375 | val_loss : 9642.693359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1060 | train_loss : 6488.10107421875 | val_loss : 7846.18017578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1061 | train_loss : 4531.287109375 | val_loss : 5308.037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1062 | train_loss : 2163.81201171875 | val_loss : 5860.138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1063 | train_loss : 1556.0771484375 | val_loss : 12555.263671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1064 | train_loss : 3928.310546875 | val_loss : 5651.24609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1065 | train_loss : 2294.93603515625 | val_loss : 8896.9921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1066 | train_loss : 3051.011962890625 | val_loss : 7241.939453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1067 | train_loss : 2954.876953125 | val_loss : 18055.908203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1068 | train_loss : 7869.4169921875 | val_loss : 11538.2353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1069 | train_loss : 4460.61083984375 | val_loss : 5043.560546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1070 | train_loss : 2427.119140625 | val_loss : 9971.9609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1071 | train_loss : 4179.41845703125 | val_loss : 5520.96875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1072 | train_loss : 1705.02734375 | val_loss : 5523.27978515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1073 | train_loss : 2253.409423828125 | val_loss : 5754.35986328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1074 | train_loss : 2890.652587890625 | val_loss : 7822.0751953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1075 | train_loss : 3337.919921875 | val_loss : 7246.060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1076 | train_loss : 3251.28125 | val_loss : 21075.765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1077 | train_loss : 9175.9189453125 | val_loss : 6641.5537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1078 | train_loss : 2851.578125 | val_loss : 7093.96435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1079 | train_loss : 4335.30029296875 | val_loss : 18412.28515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1080 | train_loss : 7519.5576171875 | val_loss : 10773.7900390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1081 | train_loss : 3309.04052734375 | val_loss : 4725.4150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1082 | train_loss : 1757.1605224609375 | val_loss : 8326.4892578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1083 | train_loss : 4987.89697265625 | val_loss : 7582.44921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1084 | train_loss : 3269.36865234375 | val_loss : 7247.75390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1085 | train_loss : 2468.43310546875 | val_loss : 6965.71435546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1086 | train_loss : 2340.818603515625 | val_loss : 7489.17431640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1087 | train_loss : 2683.958740234375 | val_loss : 5325.49267578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1088 | train_loss : 1338.0699462890625 | val_loss : 7564.515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1089 | train_loss : 2747.1025390625 | val_loss : 7596.36669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1090 | train_loss : 2996.35693359375 | val_loss : 7596.453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1091 | train_loss : 3122.669921875 | val_loss : 16719.158203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1092 | train_loss : 8776.05859375 | val_loss : 6319.3310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1093 | train_loss : 3199.11865234375 | val_loss : 17785.20703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1094 | train_loss : 7240.775390625 | val_loss : 5977.8876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1095 | train_loss : 2747.1806640625 | val_loss : 9305.4296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1096 | train_loss : 3707.497802734375 | val_loss : 10944.0849609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1097 | train_loss : 3644.2451171875 | val_loss : 5937.15869140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1098 | train_loss : 1952.9542236328125 | val_loss : 6851.34521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1099 | train_loss : 3098.1884765625 | val_loss : 11240.8212890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1100 | train_loss : 3889.43115234375 | val_loss : 9615.89453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1101 | train_loss : 5224.330078125 | val_loss : 10006.9521484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1102 | train_loss : 5127.71435546875 | val_loss : 7693.4794921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1103 | train_loss : 4554.79150390625 | val_loss : 9926.890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1104 | train_loss : 3833.516845703125 | val_loss : 8999.4052734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1105 | train_loss : 3499.579345703125 | val_loss : 7380.5556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1106 | train_loss : 5113.9326171875 | val_loss : 21717.744140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1107 | train_loss : 9635.1064453125 | val_loss : 8229.41796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1108 | train_loss : 3117.81396484375 | val_loss : 5912.4716796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1109 | train_loss : 3387.7509765625 | val_loss : 18583.806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1110 | train_loss : 8372.44140625 | val_loss : 7692.82861328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1111 | train_loss : 3038.2255859375 | val_loss : 5278.83740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1112 | train_loss : 5947.86669921875 | val_loss : 8611.65625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1113 | train_loss : 2691.945068359375 | val_loss : 7137.2919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1114 | train_loss : 2327.09521484375 | val_loss : 7961.169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1115 | train_loss : 3259.838134765625 | val_loss : 7243.37060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1116 | train_loss : 3018.66650390625 | val_loss : 5759.67822265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1117 | train_loss : 1425.96630859375 | val_loss : 5310.82763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1118 | train_loss : 2208.4326171875 | val_loss : 8880.2724609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1119 | train_loss : 3373.25927734375 | val_loss : 8104.31103515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1120 | train_loss : 3745.739990234375 | val_loss : 6552.43310546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1121 | train_loss : 4590.70654296875 | val_loss : 21404.509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1122 | train_loss : 9143.4833984375 | val_loss : 7042.10888671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1123 | train_loss : 2757.984619140625 | val_loss : 7050.75927734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1124 | train_loss : 2983.013671875 | val_loss : 8123.14794921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1125 | train_loss : 3525.32177734375 | val_loss : 4823.69140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1126 | train_loss : 2734.14599609375 | val_loss : 7097.431640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1127 | train_loss : 3507.581787109375 | val_loss : 6428.37939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1128 | train_loss : 3416.019775390625 | val_loss : 14749.05078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1129 | train_loss : 7886.14697265625 | val_loss : 6155.84521484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1130 | train_loss : 2050.1083984375 | val_loss : 7202.697265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1131 | train_loss : 2155.3271484375 | val_loss : 7297.00146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1132 | train_loss : 2839.052490234375 | val_loss : 4639.1220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1133 | train_loss : 2324.2001953125 | val_loss : 19987.099609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1134 | train_loss : 8774.2529296875 | val_loss : 6464.96435546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1135 | train_loss : 2217.408203125 | val_loss : 5397.9755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1136 | train_loss : 3075.538818359375 | val_loss : 8840.87109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1137 | train_loss : 3772.06103515625 | val_loss : 6338.48583984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1138 | train_loss : 2653.490234375 | val_loss : 8051.47998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1139 | train_loss : 3606.392578125 | val_loss : 6846.1904296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1140 | train_loss : 3754.677490234375 | val_loss : 5553.509765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1141 | train_loss : 3054.465576171875 | val_loss : 8051.46435546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1142 | train_loss : 3452.58447265625 | val_loss : 12190.40625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1143 | train_loss : 6154.7861328125 | val_loss : 5085.88134765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1144 | train_loss : 4717.26611328125 | val_loss : 4830.5966796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1145 | train_loss : 2376.861328125 | val_loss : 12025.3447265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1146 | train_loss : 5070.39501953125 | val_loss : 11252.30078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1147 | train_loss : 5023.30078125 | val_loss : 15526.6298828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1148 | train_loss : 7262.78076171875 | val_loss : 6174.044921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1149 | train_loss : 1975.91162109375 | val_loss : 5689.50146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1150 | train_loss : 2021.627685546875 | val_loss : 7012.14208984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1151 | train_loss : 2831.3603515625 | val_loss : 10213.5419921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1152 | train_loss : 4263.90869140625 | val_loss : 17212.525390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1153 | train_loss : 8087.94482421875 | val_loss : 8383.0791015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1154 | train_loss : 3380.089599609375 | val_loss : 8549.4765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1155 | train_loss : 3518.11474609375 | val_loss : 8159.4287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1156 | train_loss : 4495.11572265625 | val_loss : 6074.71484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1157 | train_loss : 3278.377197265625 | val_loss : 7561.08447265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1158 | train_loss : 3119.056640625 | val_loss : 6007.1044921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1159 | train_loss : 2373.138671875 | val_loss : 6193.52001953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1160 | train_loss : 3083.080078125 | val_loss : 7087.5126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1161 | train_loss : 3795.6259765625 | val_loss : 8685.9970703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1162 | train_loss : 4556.88525390625 | val_loss : 7748.1455078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1163 | train_loss : 4232.234375 | val_loss : 18764.369140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1164 | train_loss : 8771.447265625 | val_loss : 11776.576171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1165 | train_loss : 6288.47509765625 | val_loss : 6446.4443359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1166 | train_loss : 3457.611328125 | val_loss : 2991.45556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1167 | train_loss : 1538.9827880859375 | val_loss : 4994.2138671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1168 | train_loss : 1736.3284912109375 | val_loss : 7275.7705078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1169 | train_loss : 2647.708740234375 | val_loss : 4678.4462890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1170 | train_loss : 1807.4190673828125 | val_loss : 5117.71826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1171 | train_loss : 2073.379150390625 | val_loss : 6853.75146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1172 | train_loss : 2379.4482421875 | val_loss : 6491.09228515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1173 | train_loss : 3834.27685546875 | val_loss : 6100.63330078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1174 | train_loss : 3119.054931640625 | val_loss : 6365.5126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1175 | train_loss : 3087.39501953125 | val_loss : 7392.24755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1176 | train_loss : 3232.326171875 | val_loss : 6965.3349609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1177 | train_loss : 4262.326171875 | val_loss : 9923.0439453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1178 | train_loss : 4152.18798828125 | val_loss : 10865.2265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1179 | train_loss : 4072.047119140625 | val_loss : 6437.64013671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1180 | train_loss : 2607.2177734375 | val_loss : 4944.1435546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1181 | train_loss : 3088.260009765625 | val_loss : 16960.615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1182 | train_loss : 9630.4677734375 | val_loss : 7845.68505859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1183 | train_loss : 3673.9619140625 | val_loss : 6773.1591796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1184 | train_loss : 2886.38916015625 | val_loss : 7471.7919921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1185 | train_loss : 4762.27783203125 | val_loss : 6453.17138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1186 | train_loss : 3474.66748046875 | val_loss : 8259.220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1187 | train_loss : 3257.282470703125 | val_loss : 3734.656982421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1188 | train_loss : 1464.378173828125 | val_loss : 4669.16943359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1189 | train_loss : 1823.91748046875 | val_loss : 8233.3828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1190 | train_loss : 2930.35400390625 | val_loss : 7429.95751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1191 | train_loss : 3331.418212890625 | val_loss : 8457.462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1192 | train_loss : 5083.3779296875 | val_loss : 19233.609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1193 | train_loss : 8131.41015625 | val_loss : 6958.64208984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1194 | train_loss : 2343.41552734375 | val_loss : 5864.15576171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1195 | train_loss : 2263.491455078125 | val_loss : 8611.2021484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1196 | train_loss : 3476.3701171875 | val_loss : 3847.0849609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1197 | train_loss : 1990.38525390625 | val_loss : 5568.51806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1198 | train_loss : 2758.455078125 | val_loss : 7293.14013671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1199 | train_loss : 2908.389404296875 | val_loss : 4124.55859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1200 | train_loss : 2012.7020263671875 | val_loss : 4504.21826171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1201 | train_loss : 1584.57763671875 | val_loss : 5507.666015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1202 | train_loss : 2623.574462890625 | val_loss : 6684.3125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1203 | train_loss : 4003.46875 | val_loss : 7405.7158203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1204 | train_loss : 3622.147216796875 | val_loss : 7371.24072265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1205 | train_loss : 2238.767578125 | val_loss : 7403.2548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1206 | train_loss : 3499.6064453125 | val_loss : 9430.806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1207 | train_loss : 5030.30419921875 | val_loss : 18555.4453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1208 | train_loss : 8729.177734375 | val_loss : 8819.6962890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1209 | train_loss : 4843.03857421875 | val_loss : 7265.72509765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1210 | train_loss : 4703.51171875 | val_loss : 9062.9140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1211 | train_loss : 4647.99658203125 | val_loss : 7215.24365234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1212 | train_loss : 6077.34326171875 | val_loss : 18321.779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1213 | train_loss : 10891.650390625 | val_loss : 10307.111328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1214 | train_loss : 6207.17333984375 | val_loss : 9390.25390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1215 | train_loss : 2934.633056640625 | val_loss : 5340.81201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1216 | train_loss : 1828.6021728515625 | val_loss : 6948.50390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1217 | train_loss : 2760.613525390625 | val_loss : 5406.28955078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1218 | train_loss : 3127.890625 | val_loss : 6990.5068359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1219 | train_loss : 3956.023681640625 | val_loss : 8635.0458984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1220 | train_loss : 4877.9697265625 | val_loss : 6422.81689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1221 | train_loss : 2928.20068359375 | val_loss : 6313.0400390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1222 | train_loss : 3150.2421875 | val_loss : 5853.12255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1223 | train_loss : 2506.287841796875 | val_loss : 4971.81103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1224 | train_loss : 2035.3509521484375 | val_loss : 5243.44873046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1225 | train_loss : 2399.1611328125 | val_loss : 11774.6689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1226 | train_loss : 5890.9404296875 | val_loss : 4431.83740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1227 | train_loss : 2221.422119140625 | val_loss : 7670.677734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1228 | train_loss : 3517.0888671875 | val_loss : 6665.63671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1229 | train_loss : 3705.77783203125 | val_loss : 7664.43017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1230 | train_loss : 3889.414306640625 | val_loss : 5756.31103515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1231 | train_loss : 4680.45361328125 | val_loss : 12736.4541015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1232 | train_loss : 5822.56298828125 | val_loss : 8820.0703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1233 | train_loss : 4992.74853515625 | val_loss : 7436.51611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1234 | train_loss : 2990.78125 | val_loss : 4245.73046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1235 | train_loss : 2879.4697265625 | val_loss : 12489.599609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1236 | train_loss : 4940.0068359375 | val_loss : 6801.72509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1237 | train_loss : 3786.1298828125 | val_loss : 8462.9677734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1238 | train_loss : 4770.5419921875 | val_loss : 4251.98388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1239 | train_loss : 2900.744140625 | val_loss : 19080.8046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1240 | train_loss : 9122.87109375 | val_loss : 6282.044921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1241 | train_loss : 2687.321044921875 | val_loss : 7397.97509765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1242 | train_loss : 3509.301513671875 | val_loss : 17344.158203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1243 | train_loss : 8181.3388671875 | val_loss : 5852.38623046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1244 | train_loss : 4148.8974609375 | val_loss : 5741.048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1245 | train_loss : 3916.19287109375 | val_loss : 8861.25 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1246 | train_loss : 3206.63427734375 | val_loss : 3657.570068359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1247 | train_loss : 1316.53369140625 | val_loss : 6429.95361328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1248 | train_loss : 2342.390380859375 | val_loss : 6090.7919921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1249 | train_loss : 2726.0517578125 | val_loss : 8579.85546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1250 | train_loss : 3903.034912109375 | val_loss : 5860.42333984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1251 | train_loss : 1886.614990234375 | val_loss : 5704.43896484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1252 | train_loss : 3145.111328125 | val_loss : 5947.4580078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1253 | train_loss : 2402.2041015625 | val_loss : 5230.29052734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1254 | train_loss : 3915.561279296875 | val_loss : 5404.2080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1255 | train_loss : 2387.80322265625 | val_loss : 6843.33935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1256 | train_loss : 4150.140625 | val_loss : 7486.9619140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1257 | train_loss : 3731.0244140625 | val_loss : 14071.3095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1258 | train_loss : 6135.39453125 | val_loss : 5965.3701171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1259 | train_loss : 3104.645263671875 | val_loss : 9623.6748046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1260 | train_loss : 4610.56884765625 | val_loss : 15420.7958984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1261 | train_loss : 7390.97802734375 | val_loss : 6127.34765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1262 | train_loss : 2354.60595703125 | val_loss : 5360.52685546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1263 | train_loss : 4696.9794921875 | val_loss : 8014.07080078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1264 | train_loss : 2990.851806640625 | val_loss : 9076.4365234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1265 | train_loss : 3917.375 | val_loss : 7001.32861328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1266 | train_loss : 4182.88330078125 | val_loss : 6215.111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1267 | train_loss : 2930.6630859375 | val_loss : 7434.123046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1268 | train_loss : 3581.212158203125 | val_loss : 6772.17919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1269 | train_loss : 2980.821533203125 | val_loss : 8141.7373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1270 | train_loss : 4624.0185546875 | val_loss : 8218.658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1271 | train_loss : 4252.37744140625 | val_loss : 17588.197265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1272 | train_loss : 7595.2314453125 | val_loss : 7712.7060546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1273 | train_loss : 3403.357421875 | val_loss : 7454.05615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1274 | train_loss : 2991.3212890625 | val_loss : 10374.2578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1275 | train_loss : 4868.66552734375 | val_loss : 6437.25927734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1276 | train_loss : 1528.3994140625 | val_loss : 6256.07958984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1277 | train_loss : 3315.230712890625 | val_loss : 11668.5791015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1278 | train_loss : 4976.53076171875 | val_loss : 11760.1728515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1279 | train_loss : 5724.529296875 | val_loss : 7206.63623046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1280 | train_loss : 3145.623046875 | val_loss : 4667.34326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1281 | train_loss : 2600.16943359375 | val_loss : 15315.8203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1282 | train_loss : 6445.6787109375 | val_loss : 5260.81494140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1283 | train_loss : 1315.8621826171875 | val_loss : 4123.154296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1284 | train_loss : 1326.84716796875 | val_loss : 6542.38623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1285 | train_loss : 2710.760009765625 | val_loss : 4683.8818359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1286 | train_loss : 2412.429931640625 | val_loss : 5385.28125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1287 | train_loss : 2904.397705078125 | val_loss : 4321.4912109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1288 | train_loss : 1835.66064453125 | val_loss : 5788.5498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1289 | train_loss : 2646.17822265625 | val_loss : 5021.08544921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1290 | train_loss : 2453.0869140625 | val_loss : 5418.92138671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1291 | train_loss : 2570.504150390625 | val_loss : 3842.3369140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1292 | train_loss : 1109.4775390625 | val_loss : 6513.5048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1293 | train_loss : 2680.031982421875 | val_loss : 3967.87060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1294 | train_loss : 1755.3812255859375 | val_loss : 4221.16943359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1295 | train_loss : 1624.5758056640625 | val_loss : 3784.00927734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1296 | train_loss : 1429.8128662109375 | val_loss : 6636.4951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1297 | train_loss : 3155.7607421875 | val_loss : 3990.6943359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1298 | train_loss : 1412.4632568359375 | val_loss : 11779.7041015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1299 | train_loss : 4615.92822265625 | val_loss : 3714.898681640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1300 | train_loss : 1214.0985107421875 | val_loss : 6704.74755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1301 | train_loss : 2098.648681640625 | val_loss : 3685.828857421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1302 | train_loss : 1393.819580078125 | val_loss : 6208.83984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1303 | train_loss : 1970.280029296875 | val_loss : 54461.4765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1304 | train_loss : 63790.1640625 | val_loss : 8548.513671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1305 | train_loss : 11822.791015625 | val_loss : 21218.744140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1306 | train_loss : 19557.251953125 | val_loss : 28048.9453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1307 | train_loss : 19665.791015625 | val_loss : 6815.4169921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1308 | train_loss : 6609.64453125 | val_loss : 14031.291015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1309 | train_loss : 6084.73681640625 | val_loss : 4868.3876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1310 | train_loss : 2336.9697265625 | val_loss : 10669.9384765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1311 | train_loss : 3904.48193359375 | val_loss : 6545.39013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1312 | train_loss : 2414.871826171875 | val_loss : 5422.81884765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1313 | train_loss : 1570.6763916015625 | val_loss : 5904.51611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1314 | train_loss : 2193.8291015625 | val_loss : 4694.7626953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1315 | train_loss : 2422.378662109375 | val_loss : 10854.7587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1316 | train_loss : 4171.1875 | val_loss : 5364.3505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1317 | train_loss : 1916.6455078125 | val_loss : 6576.47119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1318 | train_loss : 2500.09814453125 | val_loss : 4357.9951171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1319 | train_loss : 1812.07958984375 | val_loss : 5878.302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1320 | train_loss : 2738.108642578125 | val_loss : 3759.016845703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1321 | train_loss : 1373.84130859375 | val_loss : 6415.01708984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1322 | train_loss : 3295.938720703125 | val_loss : 7933.21630859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1323 | train_loss : 3073.31884765625 | val_loss : 9143.365234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1324 | train_loss : 4383.64892578125 | val_loss : 4956.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1325 | train_loss : 1451.87158203125 | val_loss : 4740.4580078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1326 | train_loss : 1534.8134765625 | val_loss : 4926.4599609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1327 | train_loss : 2107.240234375 | val_loss : 5471.35791015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1328 | train_loss : 2183.757568359375 | val_loss : 3230.231201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1329 | train_loss : 707.4634399414062 | val_loss : 6129.3310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1330 | train_loss : 1664.918701171875 | val_loss : 5616.43359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1331 | train_loss : 2013.825927734375 | val_loss : 9274.640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1332 | train_loss : 3692.5322265625 | val_loss : 4215.2451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1333 | train_loss : 983.4453735351562 | val_loss : 5696.95947265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1334 | train_loss : 2331.553955078125 | val_loss : 3853.140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1335 | train_loss : 1094.1993408203125 | val_loss : 6563.28564453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1336 | train_loss : 2799.9638671875 | val_loss : 5368.14501953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1337 | train_loss : 2779.514404296875 | val_loss : 4880.70703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1338 | train_loss : 3835.966552734375 | val_loss : 6143.9501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1339 | train_loss : 3028.8525390625 | val_loss : 6207.93310546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1340 | train_loss : 2691.59716796875 | val_loss : 4700.1064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1341 | train_loss : 1851.635009765625 | val_loss : 2718.761962890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1342 | train_loss : 1492.8128662109375 | val_loss : 5968.85498046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1343 | train_loss : 2094.291259765625 | val_loss : 5835.61572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1344 | train_loss : 2378.303955078125 | val_loss : 3292.4580078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1345 | train_loss : 1461.8681640625 | val_loss : 4374.34814453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1346 | train_loss : 1759.467529296875 | val_loss : 5056.6923828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1347 | train_loss : 2557.564453125 | val_loss : 7110.64501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1348 | train_loss : 3098.094482421875 | val_loss : 3174.98193359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1349 | train_loss : 1525.1134033203125 | val_loss : 3746.322509765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1350 | train_loss : 2517.1005859375 | val_loss : 6365.97802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1351 | train_loss : 2574.816650390625 | val_loss : 3975.18505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1352 | train_loss : 1821.0054931640625 | val_loss : 7445.74560546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1353 | train_loss : 3288.34814453125 | val_loss : 6733.59423828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1354 | train_loss : 2475.843994140625 | val_loss : 2646.63623046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1355 | train_loss : 963.7398681640625 | val_loss : 6198.92431640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1356 | train_loss : 2071.6416015625 | val_loss : 4191.07177734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1357 | train_loss : 2064.35693359375 | val_loss : 14762.3896484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1358 | train_loss : 6522.89453125 | val_loss : 3889.79052734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1359 | train_loss : 1224.4488525390625 | val_loss : 4274.51416015625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1360 | train_loss : 1406.589111328125 | val_loss : 7751.24169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1361 | train_loss : 3035.51416015625 | val_loss : 5506.8662109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1362 | train_loss : 1552.2064208984375 | val_loss : 4607.39501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1363 | train_loss : 2392.401123046875 | val_loss : 5566.93994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1364 | train_loss : 1764.958740234375 | val_loss : 2186.843017578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1365 | train_loss : 860.7312622070312 | val_loss : 2654.110107421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1366 | train_loss : 402.03656005859375 | val_loss : 2362.141357421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1367 | train_loss : 939.2380981445312 | val_loss : 6008.017578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1368 | train_loss : 1803.5345458984375 | val_loss : 3310.15625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1369 | train_loss : 1198.1146240234375 | val_loss : 5895.3037109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1370 | train_loss : 1750.28759765625 | val_loss : 9053.4765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1371 | train_loss : 4104.2109375 | val_loss : 5922.5712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1372 | train_loss : 1733.7901611328125 | val_loss : 3246.29931640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1373 | train_loss : 1085.1351318359375 | val_loss : 3493.97314453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1374 | train_loss : 1430.9190673828125 | val_loss : 4463.619140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1375 | train_loss : 1721.7398681640625 | val_loss : 3689.179931640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1376 | train_loss : 3455.219970703125 | val_loss : 6841.583984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1377 | train_loss : 2295.474609375 | val_loss : 4206.84326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1378 | train_loss : 2210.0205078125 | val_loss : 5646.28076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1379 | train_loss : 2345.105224609375 | val_loss : 13667.76953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1380 | train_loss : 5126.13232421875 | val_loss : 4347.00439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1381 | train_loss : 1970.6871337890625 | val_loss : 6343.4462890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1382 | train_loss : 2511.034912109375 | val_loss : 6392.66552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1383 | train_loss : 3726.559326171875 | val_loss : 12836.53515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1384 | train_loss : 6017.56201171875 | val_loss : 6030.42431640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1385 | train_loss : 3300.577880859375 | val_loss : 4563.24951171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1386 | train_loss : 1978.87841796875 | val_loss : 8029.490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1387 | train_loss : 2583.234130859375 | val_loss : 7477.939453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1388 | train_loss : 4013.773681640625 | val_loss : 11673.5126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1389 | train_loss : 4948.4013671875 | val_loss : 7946.06982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1390 | train_loss : 4033.310546875 | val_loss : 5947.81201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1391 | train_loss : 2484.57080078125 | val_loss : 5063.1904296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1392 | train_loss : 2464.91162109375 | val_loss : 8779.490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1393 | train_loss : 3706.89990234375 | val_loss : 4034.60009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1394 | train_loss : 1894.4176025390625 | val_loss : 4546.2294921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1395 | train_loss : 3056.53759765625 | val_loss : 6681.220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1396 | train_loss : 2615.119140625 | val_loss : 2455.206298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1397 | train_loss : 1432.4566650390625 | val_loss : 5760.541015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1398 | train_loss : 2845.13037109375 | val_loss : 6569.55859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1399 | train_loss : 2891.52001953125 | val_loss : 3993.4814453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1400 | train_loss : 2140.51513671875 | val_loss : 4590.35888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1401 | train_loss : 2492.71728515625 | val_loss : 5508.02392578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1402 | train_loss : 2677.489990234375 | val_loss : 6181.89013671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1403 | train_loss : 3379.07568359375 | val_loss : 13735.5 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1404 | train_loss : 8004.291015625 | val_loss : 8132.931640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1405 | train_loss : 4286.07763671875 | val_loss : 7099.83544921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1406 | train_loss : 4373.2900390625 | val_loss : 5825.15673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1407 | train_loss : 2399.78466796875 | val_loss : 5985.15380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1408 | train_loss : 2214.96826171875 | val_loss : 5098.83935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1409 | train_loss : 3379.858154296875 | val_loss : 5277.18310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1410 | train_loss : 2477.799560546875 | val_loss : 3516.346923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1411 | train_loss : 1712.0106201171875 | val_loss : 4303.87109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1412 | train_loss : 2848.615966796875 | val_loss : 6019.46923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1413 | train_loss : 2609.189208984375 | val_loss : 4163.59130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1414 | train_loss : 1557.2271728515625 | val_loss : 2910.98876953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1415 | train_loss : 1328.875 | val_loss : 5837.53857421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1416 | train_loss : 1683.58837890625 | val_loss : 3604.132568359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1417 | train_loss : 1872.5975341796875 | val_loss : 5288.142578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1418 | train_loss : 1956.3323974609375 | val_loss : 3100.893798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1419 | train_loss : 1563.657470703125 | val_loss : 4257.33544921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1420 | train_loss : 2595.71240234375 | val_loss : 2940.830078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1421 | train_loss : 429.3221740722656 | val_loss : 2601.7255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1422 | train_loss : 866.7564697265625 | val_loss : 11790.6689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1423 | train_loss : 4496.6875 | val_loss : 2009.1075439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1424 | train_loss : 621.1876831054688 | val_loss : 7545.80615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1425 | train_loss : 3180.44189453125 | val_loss : 8100.97998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1426 | train_loss : 3400.6279296875 | val_loss : 7913.0029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1427 | train_loss : 3311.05810546875 | val_loss : 3032.576904296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1428 | train_loss : 896.8900146484375 | val_loss : 5139.50146484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1429 | train_loss : 1810.3526611328125 | val_loss : 3064.650634765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1430 | train_loss : 1318.8695068359375 | val_loss : 3912.190673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1431 | train_loss : 1816.768310546875 | val_loss : 3744.512451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1432 | train_loss : 1913.538330078125 | val_loss : 3202.34619140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1433 | train_loss : 2701.6669921875 | val_loss : 7173.30517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1434 | train_loss : 4226.45263671875 | val_loss : 7781.30126953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1435 | train_loss : 4762.37548828125 | val_loss : 4915.6201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1436 | train_loss : 2161.40283203125 | val_loss : 4060.6181640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1437 | train_loss : 2643.1669921875 | val_loss : 6606.42578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1438 | train_loss : 2252.03955078125 | val_loss : 6159.90771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1439 | train_loss : 2760.591796875 | val_loss : 5155.208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1440 | train_loss : 2266.735595703125 | val_loss : 17567.390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1441 | train_loss : 8490.87890625 | val_loss : 6933.98681640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1442 | train_loss : 4500.76220703125 | val_loss : 8783.9609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1443 | train_loss : 5379.29296875 | val_loss : 4264.36083984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1444 | train_loss : 3536.561279296875 | val_loss : 5663.056640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1445 | train_loss : 2716.93408203125 | val_loss : 7075.03564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1446 | train_loss : 3586.775634765625 | val_loss : 4247.57080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1447 | train_loss : 2323.070068359375 | val_loss : 5897.51806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1448 | train_loss : 3762.063232421875 | val_loss : 4730.63134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1449 | train_loss : 2833.404296875 | val_loss : 5262.927734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1450 | train_loss : 2345.989990234375 | val_loss : 4502.9638671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1451 | train_loss : 1752.3721923828125 | val_loss : 3216.136962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1452 | train_loss : 1214.5589599609375 | val_loss : 3860.943115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1453 | train_loss : 1320.2003173828125 | val_loss : 4180.6044921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1454 | train_loss : 2275.19677734375 | val_loss : 5193.298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1455 | train_loss : 2067.306640625 | val_loss : 2875.97802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1456 | train_loss : 1088.308837890625 | val_loss : 3664.889892578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1457 | train_loss : 1534.8695068359375 | val_loss : 7496.099609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1458 | train_loss : 2927.93994140625 | val_loss : 3031.480712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1459 | train_loss : 1011.6670532226562 | val_loss : 3045.972412109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1460 | train_loss : 1077.5113525390625 | val_loss : 4455.34521484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1461 | train_loss : 1212.8026123046875 | val_loss : 1731.3419189453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1462 | train_loss : 745.73046875 | val_loss : 4805.58642578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1463 | train_loss : 1238.3955078125 | val_loss : 3472.508056640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1464 | train_loss : 2138.176025390625 | val_loss : 9741.916015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1465 | train_loss : 3561.24560546875 | val_loss : 5241.830078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1466 | train_loss : 3033.025390625 | val_loss : 14328.1787109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1467 | train_loss : 8307.0791015625 | val_loss : 7392.91259765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1468 | train_loss : 3945.496337890625 | val_loss : 3518.2080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1469 | train_loss : 1698.8134765625 | val_loss : 5574.640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1470 | train_loss : 2142.323486328125 | val_loss : 5085.08935546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1471 | train_loss : 2566.258544921875 | val_loss : 9557.9619140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1472 | train_loss : 3950.124267578125 | val_loss : 8343.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1473 | train_loss : 4401.58447265625 | val_loss : 7439.95166015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1474 | train_loss : 3664.65185546875 | val_loss : 5304.24755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1475 | train_loss : 4342.4755859375 | val_loss : 16848.619140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1476 | train_loss : 7623.771484375 | val_loss : 6844.4287109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1477 | train_loss : 3039.9970703125 | val_loss : 5586.79638671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1478 | train_loss : 2429.16552734375 | val_loss : 3461.030029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1479 | train_loss : 2085.14501953125 | val_loss : 5998.333984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1480 | train_loss : 2204.911865234375 | val_loss : 4035.327392578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1481 | train_loss : 1611.10009765625 | val_loss : 4417.9169921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1482 | train_loss : 1569.7010498046875 | val_loss : 3307.610595703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1483 | train_loss : 1031.41845703125 | val_loss : 3812.34130859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1484 | train_loss : 1447.2935791015625 | val_loss : 3808.921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1485 | train_loss : 1330.427001953125 | val_loss : 3818.985595703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1486 | train_loss : 1264.2734375 | val_loss : 4748.353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1487 | train_loss : 2235.79296875 | val_loss : 3861.35009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1488 | train_loss : 2315.40087890625 | val_loss : 1708.443115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1489 | train_loss : 2062.289306640625 | val_loss : 4021.485595703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1490 | train_loss : 2402.3369140625 | val_loss : 7211.69140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1491 | train_loss : 4204.8212890625 | val_loss : 5125.5654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1492 | train_loss : 2214.044677734375 | val_loss : 8407.0947265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1493 | train_loss : 3045.24853515625 | val_loss : 5324.20947265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1494 | train_loss : 1892.2427978515625 | val_loss : 8045.0810546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1495 | train_loss : 3768.060302734375 | val_loss : 4807.74169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1496 | train_loss : 2662.631591796875 | val_loss : 13876.4521484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1497 | train_loss : 5609.19482421875 | val_loss : 4912.35107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1498 | train_loss : 1370.993896484375 | val_loss : 2947.921142578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1499 | train_loss : 710.2454833984375 | val_loss : 3441.648193359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1500 | train_loss : 1248.434814453125 | val_loss : 3988.76123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1501 | train_loss : 1837.7655029296875 | val_loss : 4596.263671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1502 | train_loss : 1670.3829345703125 | val_loss : 2916.09375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1503 | train_loss : 1496.259521484375 | val_loss : 5478.5576171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1504 | train_loss : 2284.26416015625 | val_loss : 3344.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1505 | train_loss : 1819.9654541015625 | val_loss : 5144.962890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1506 | train_loss : 2018.0643310546875 | val_loss : 2620.358154296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1507 | train_loss : 1002.671875 | val_loss : 4051.47314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1508 | train_loss : 1385.6595458984375 | val_loss : 2969.389404296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1509 | train_loss : 1238.4879150390625 | val_loss : 5000.53271484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1510 | train_loss : 1853.61376953125 | val_loss : 3540.5263671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1511 | train_loss : 1187.68798828125 | val_loss : 4205.15185546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1512 | train_loss : 1320.1077880859375 | val_loss : 3665.999267578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1513 | train_loss : 1171.2530517578125 | val_loss : 4738.78125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1514 | train_loss : 1917.9676513671875 | val_loss : 3959.16064453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1515 | train_loss : 1495.08837890625 | val_loss : 5576.072265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1516 | train_loss : 3646.81689453125 | val_loss : 14005.37890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1517 | train_loss : 8248.3505859375 | val_loss : 5032.29833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1518 | train_loss : 2685.965087890625 | val_loss : 5467.56298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1519 | train_loss : 2479.913330078125 | val_loss : 5496.6181640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1520 | train_loss : 3329.629150390625 | val_loss : 4834.62109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1521 | train_loss : 2185.25927734375 | val_loss : 4824.64697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1522 | train_loss : 1757.32568359375 | val_loss : 3234.496826171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1523 | train_loss : 1001.3329467773438 | val_loss : 4420.3017578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1524 | train_loss : 1095.059814453125 | val_loss : 4237.57373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1525 | train_loss : 1335.0823974609375 | val_loss : 5579.84765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1526 | train_loss : 2065.4326171875 | val_loss : 4285.2900390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1527 | train_loss : 1394.49462890625 | val_loss : 2902.003173828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1528 | train_loss : 889.3848266601562 | val_loss : 2829.666259765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1529 | train_loss : 742.4146118164062 | val_loss : 6538.333984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1530 | train_loss : 2152.415283203125 | val_loss : 3097.24072265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1531 | train_loss : 939.626220703125 | val_loss : 5863.80078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1532 | train_loss : 1990.8006591796875 | val_loss : 3668.4130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1533 | train_loss : 2195.694091796875 | val_loss : 12589.005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1534 | train_loss : 5159.07763671875 | val_loss : 2768.87744140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1535 | train_loss : 834.1648559570312 | val_loss : 4572.39208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1536 | train_loss : 1448.62939453125 | val_loss : 9629.31640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1537 | train_loss : 3017.491943359375 | val_loss : 5490.86865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1538 | train_loss : 1845.0823974609375 | val_loss : 6835.5576171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1539 | train_loss : 2780.3544921875 | val_loss : 4311.3798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1540 | train_loss : 2272.304443359375 | val_loss : 7542.3408203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1541 | train_loss : 2814.676025390625 | val_loss : 3451.844970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1542 | train_loss : 1483.6925048828125 | val_loss : 7497.37744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1543 | train_loss : 2246.86279296875 | val_loss : 4253.7841796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1544 | train_loss : 1221.96875 | val_loss : 5416.76513671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1545 | train_loss : 1543.9146728515625 | val_loss : 3376.6181640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1546 | train_loss : 677.836669921875 | val_loss : 2937.607421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1547 | train_loss : 642.82958984375 | val_loss : 3729.923095703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1548 | train_loss : 1134.73193359375 | val_loss : 4344.5224609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1549 | train_loss : 1901.5308837890625 | val_loss : 4960.984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1550 | train_loss : 2233.11083984375 | val_loss : 4598.39013671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1551 | train_loss : 3624.219482421875 | val_loss : 4565.65234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1552 | train_loss : 2542.2685546875 | val_loss : 4393.90673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1553 | train_loss : 2649.800537109375 | val_loss : 4495.21435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1554 | train_loss : 2427.211181640625 | val_loss : 12001.5888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1555 | train_loss : 5013.0732421875 | val_loss : 8062.85498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1556 | train_loss : 3446.9619140625 | val_loss : 14417.71484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1557 | train_loss : 7724.0888671875 | val_loss : 5287.990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1558 | train_loss : 2852.12744140625 | val_loss : 10751.787109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1559 | train_loss : 3665.549072265625 | val_loss : 7369.439453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1560 | train_loss : 2878.48681640625 | val_loss : 7198.01416015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1561 | train_loss : 2830.380615234375 | val_loss : 4616.7705078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1562 | train_loss : 3054.686279296875 | val_loss : 13756.4287109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1563 | train_loss : 5711.201171875 | val_loss : 5625.31494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1564 | train_loss : 2297.3681640625 | val_loss : 6730.78759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1565 | train_loss : 2784.6728515625 | val_loss : 3720.413818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1566 | train_loss : 1491.6260986328125 | val_loss : 6869.87353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1567 | train_loss : 1722.97216796875 | val_loss : 3242.298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1568 | train_loss : 1265.9744873046875 | val_loss : 5343.0048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1569 | train_loss : 2646.443359375 | val_loss : 4855.3779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1570 | train_loss : 1960.3455810546875 | val_loss : 7236.71240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1571 | train_loss : 2307.694580078125 | val_loss : 4246.68701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1572 | train_loss : 1398.061279296875 | val_loss : 2762.213134765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1573 | train_loss : 647.7774047851562 | val_loss : 2921.320068359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1574 | train_loss : 794.8272094726562 | val_loss : 3685.568115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1575 | train_loss : 1825.514404296875 | val_loss : 5194.80078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1576 | train_loss : 1669.0350341796875 | val_loss : 3424.610595703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1577 | train_loss : 801.4539794921875 | val_loss : 3616.24072265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1578 | train_loss : 1165.0478515625 | val_loss : 4995.40771484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1579 | train_loss : 1477.1312255859375 | val_loss : 4103.900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1580 | train_loss : 1613.6546630859375 | val_loss : 7756.00146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1581 | train_loss : 2593.33447265625 | val_loss : 4135.4755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1582 | train_loss : 2149.541015625 | val_loss : 12485.6435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1583 | train_loss : 5510.9326171875 | val_loss : 3736.871826171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1584 | train_loss : 2403.141357421875 | val_loss : 4672.9580078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1585 | train_loss : 1317.3414306640625 | val_loss : 5205.876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1586 | train_loss : 2085.611083984375 | val_loss : 4162.10009765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1587 | train_loss : 2013.126220703125 | val_loss : 6507.5224609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1588 | train_loss : 2265.101318359375 | val_loss : 3057.99560546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1589 | train_loss : 639.2906494140625 | val_loss : 3896.913818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1590 | train_loss : 1195.9561767578125 | val_loss : 4129.73876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1591 | train_loss : 1647.9298095703125 | val_loss : 7741.869140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1592 | train_loss : 2667.041259765625 | val_loss : 4135.56982421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1593 | train_loss : 1228.9281005859375 | val_loss : 4825.29052734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1594 | train_loss : 1763.3974609375 | val_loss : 4422.578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1595 | train_loss : 2110.420166015625 | val_loss : 11049.65234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1596 | train_loss : 4376.45849609375 | val_loss : 2643.77490234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1597 | train_loss : 730.52197265625 | val_loss : 5284.03759765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1598 | train_loss : 1226.4417724609375 | val_loss : 3729.12744140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1599 | train_loss : 1079.549560546875 | val_loss : 5380.49853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 1600 | train_loss : 1499.912841796875 | val_loss : 2998.70068359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 7 | epoch : 1 | train_loss : 1521273.5 | val_loss : 905789.125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 2 | train_loss : 1163113.875 | val_loss : 860517.4375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 3 | train_loss : 1002165.5 | val_loss : 602700.875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 4 | train_loss : 630296.0 | val_loss : 545978.625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 5 | train_loss : 544660.75 | val_loss : 527059.875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 6 | train_loss : 498172.6875 | val_loss : 579248.8125 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 7 | train_loss : 537299.0625 | val_loss : 175446.515625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 8 | train_loss : 183036.5 | val_loss : 293492.8125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 9 | train_loss : 267094.375 | val_loss : 300075.09375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 10 | train_loss : 306024.125 | val_loss : 201004.0 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 11 | train_loss : 222939.875 | val_loss : 102153.1328125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 12 | train_loss : 127734.0078125 | val_loss : 128795.21875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 13 | train_loss : 129843.90625 | val_loss : 190111.046875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 14 | train_loss : 178457.21875 | val_loss : 244853.796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 15 | train_loss : 231815.546875 | val_loss : 141826.34375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 16 | train_loss : 164722.015625 | val_loss : 183585.203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 17 | train_loss : 123333.6796875 | val_loss : 201122.28125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 18 | train_loss : 155903.078125 | val_loss : 257804.703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 19 | train_loss : 270937.59375 | val_loss : 141259.15625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 20 | train_loss : 165341.46875 | val_loss : 91386.703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 21 | train_loss : 108292.6015625 | val_loss : 139873.734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 22 | train_loss : 143564.6875 | val_loss : 80308.8515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 23 | train_loss : 120912.15625 | val_loss : 174551.5625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 24 | train_loss : 162151.078125 | val_loss : 194554.5625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 25 | train_loss : 151680.953125 | val_loss : 63509.703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 26 | train_loss : 62850.19140625 | val_loss : 119331.4765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 27 | train_loss : 123026.9375 | val_loss : 119093.796875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 28 | train_loss : 139028.40625 | val_loss : 161386.421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 29 | train_loss : 189942.546875 | val_loss : 244335.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 30 | train_loss : 219820.0 | val_loss : 199370.203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 31 | train_loss : 212783.34375 | val_loss : 231161.921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 32 | train_loss : 252661.234375 | val_loss : 294662.78125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 33 | train_loss : 215925.359375 | val_loss : 184116.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 34 | train_loss : 145011.625 | val_loss : 127760.4765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 35 | train_loss : 126541.7109375 | val_loss : 182123.3125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 36 | train_loss : 188762.8125 | val_loss : 181279.0625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 37 | train_loss : 197104.734375 | val_loss : 173782.9375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 38 | train_loss : 182612.21875 | val_loss : 112480.8984375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 39 | train_loss : 117540.546875 | val_loss : 175025.078125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 40 | train_loss : 168452.5 | val_loss : 131380.046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 41 | train_loss : 181959.984375 | val_loss : 195743.78125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 42 | train_loss : 222261.421875 | val_loss : 236221.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 43 | train_loss : 210903.90625 | val_loss : 310647.71875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 44 | train_loss : 298744.9375 | val_loss : 152569.25 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 45 | train_loss : 181317.65625 | val_loss : 192651.28125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 46 | train_loss : 189252.359375 | val_loss : 95042.109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 47 | train_loss : 125696.671875 | val_loss : 186390.578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 48 | train_loss : 180705.015625 | val_loss : 236581.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 49 | train_loss : 205761.78125 | val_loss : 164510.109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 50 | train_loss : 153144.921875 | val_loss : 167938.359375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 51 | train_loss : 176106.375 | val_loss : 208710.484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 52 | train_loss : 187704.953125 | val_loss : 206567.859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 53 | train_loss : 172248.8125 | val_loss : 147527.0 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 54 | train_loss : 136016.140625 | val_loss : 131303.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 55 | train_loss : 132007.625 | val_loss : 162488.546875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 56 | train_loss : 158616.671875 | val_loss : 97185.7578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 57 | train_loss : 138272.375 | val_loss : 120680.5625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 58 | train_loss : 112696.71875 | val_loss : 107357.359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 59 | train_loss : 114492.671875 | val_loss : 193925.203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 60 | train_loss : 155713.484375 | val_loss : 108063.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 61 | train_loss : 122815.296875 | val_loss : 79517.71875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 62 | train_loss : 100017.7421875 | val_loss : 185234.0 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 63 | train_loss : 130970.9609375 | val_loss : 126995.1171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 64 | train_loss : 116539.046875 | val_loss : 131100.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 65 | train_loss : 108132.7734375 | val_loss : 104759.6171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 66 | train_loss : 118517.09375 | val_loss : 96815.28125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 67 | train_loss : 109022.0625 | val_loss : 116767.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 68 | train_loss : 127837.1484375 | val_loss : 134524.234375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 69 | train_loss : 142458.65625 | val_loss : 73005.1015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 70 | train_loss : 77883.34375 | val_loss : 144325.453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 71 | train_loss : 105607.2890625 | val_loss : 102162.3671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 72 | train_loss : 90432.4765625 | val_loss : 103669.609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 73 | train_loss : 119081.90625 | val_loss : 90903.75 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 74 | train_loss : 127787.15625 | val_loss : 110895.28125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 75 | train_loss : 106412.078125 | val_loss : 92003.3984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 76 | train_loss : 92201.8828125 | val_loss : 105626.8515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 77 | train_loss : 112588.0234375 | val_loss : 98470.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 78 | train_loss : 101066.296875 | val_loss : 78343.4140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 79 | train_loss : 96881.1171875 | val_loss : 144783.703125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 80 | train_loss : 108290.578125 | val_loss : 101987.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 81 | train_loss : 110087.4609375 | val_loss : 178444.59375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 82 | train_loss : 130496.390625 | val_loss : 108452.0234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 83 | train_loss : 80573.203125 | val_loss : 73548.453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 84 | train_loss : 70979.453125 | val_loss : 79867.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 85 | train_loss : 80800.46875 | val_loss : 72274.53125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 86 | train_loss : 85718.609375 | val_loss : 151501.90625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 87 | train_loss : 102614.2265625 | val_loss : 97163.3984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 88 | train_loss : 105710.7265625 | val_loss : 94842.2890625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 89 | train_loss : 96348.0703125 | val_loss : 103903.171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 90 | train_loss : 138037.3125 | val_loss : 102977.09375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 91 | train_loss : 118042.78125 | val_loss : 107419.7265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 92 | train_loss : 98863.15625 | val_loss : 76516.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 93 | train_loss : 106407.3203125 | val_loss : 71789.96875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 94 | train_loss : 89551.7578125 | val_loss : 81711.7578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 95 | train_loss : 81424.625 | val_loss : 146233.984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 96 | train_loss : 105422.0 | val_loss : 63415.87109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 97 | train_loss : 66907.03125 | val_loss : 50840.453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 98 | train_loss : 62552.64453125 | val_loss : 78032.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 99 | train_loss : 55130.66015625 | val_loss : 57927.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 100 | train_loss : 49340.73046875 | val_loss : 55237.99609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 101 | train_loss : 73045.1171875 | val_loss : 96583.9765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 102 | train_loss : 94196.9296875 | val_loss : 83758.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 103 | train_loss : 80463.578125 | val_loss : 144137.953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 104 | train_loss : 121749.4921875 | val_loss : 125621.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 105 | train_loss : 111258.6328125 | val_loss : 89467.578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 106 | train_loss : 116085.3828125 | val_loss : 90510.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 107 | train_loss : 76385.8828125 | val_loss : 106266.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 108 | train_loss : 84021.6484375 | val_loss : 122729.140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 109 | train_loss : 153932.953125 | val_loss : 155902.34375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 110 | train_loss : 118187.65625 | val_loss : 92019.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 111 | train_loss : 98069.828125 | val_loss : 87811.65625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 112 | train_loss : 93914.109375 | val_loss : 107026.8828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 113 | train_loss : 126747.3984375 | val_loss : 110326.296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 114 | train_loss : 110732.671875 | val_loss : 116715.0234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 115 | train_loss : 113172.25 | val_loss : 53969.34375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 116 | train_loss : 47410.859375 | val_loss : 50199.68359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 117 | train_loss : 53360.265625 | val_loss : 71682.1875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 118 | train_loss : 80026.6328125 | val_loss : 73447.296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 119 | train_loss : 78590.3515625 | val_loss : 67775.15625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 120 | train_loss : 69807.65625 | val_loss : 64597.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 121 | train_loss : 62305.80078125 | val_loss : 42552.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 122 | train_loss : 45510.1015625 | val_loss : 64567.390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 123 | train_loss : 78291.8828125 | val_loss : 114004.703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 124 | train_loss : 86377.7578125 | val_loss : 70434.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 125 | train_loss : 71828.7890625 | val_loss : 39982.05859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 126 | train_loss : 59641.8203125 | val_loss : 98651.0078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 127 | train_loss : 72660.328125 | val_loss : 79108.46875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 128 | train_loss : 75419.421875 | val_loss : 62283.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 129 | train_loss : 67399.203125 | val_loss : 66132.546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 130 | train_loss : 84420.6328125 | val_loss : 58540.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 131 | train_loss : 77835.3046875 | val_loss : 102375.9375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 132 | train_loss : 97111.3828125 | val_loss : 112995.7578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 133 | train_loss : 103590.15625 | val_loss : 93576.8828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 134 | train_loss : 86205.0234375 | val_loss : 121403.859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 135 | train_loss : 103732.2890625 | val_loss : 64412.03515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 136 | train_loss : 61060.9609375 | val_loss : 44806.83984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 137 | train_loss : 67850.1015625 | val_loss : 68051.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 138 | train_loss : 47374.88671875 | val_loss : 20156.42578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 139 | train_loss : 30369.17578125 | val_loss : 57671.1015625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 140 | train_loss : 58779.05859375 | val_loss : 36396.265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 141 | train_loss : 35162.140625 | val_loss : 22857.3046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 142 | train_loss : 39547.92578125 | val_loss : 91084.71875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 143 | train_loss : 65276.55859375 | val_loss : 56690.87890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 144 | train_loss : 47812.9453125 | val_loss : 49631.140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 145 | train_loss : 60108.58984375 | val_loss : 95326.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 146 | train_loss : 66719.4609375 | val_loss : 41280.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 147 | train_loss : 43482.75 | val_loss : 37295.75390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 148 | train_loss : 57935.93359375 | val_loss : 72738.6953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 149 | train_loss : 62154.1953125 | val_loss : 37232.5 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 150 | train_loss : 38411.62109375 | val_loss : 25723.759765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 151 | train_loss : 30473.1875 | val_loss : 89415.953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 152 | train_loss : 58651.125 | val_loss : 17579.53515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 153 | train_loss : 29765.443359375 | val_loss : 22038.490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 154 | train_loss : 34915.6796875 | val_loss : 73000.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 155 | train_loss : 55268.94140625 | val_loss : 56668.39453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 156 | train_loss : 46755.8984375 | val_loss : 66846.609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 157 | train_loss : 89813.390625 | val_loss : 77922.2578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 158 | train_loss : 69993.4375 | val_loss : 45025.63671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 159 | train_loss : 64999.7734375 | val_loss : 112882.9609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 160 | train_loss : 95833.75 | val_loss : 99396.3125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 161 | train_loss : 98513.2265625 | val_loss : 57839.88671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 162 | train_loss : 71747.6875 | val_loss : 58910.46875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 163 | train_loss : 57326.359375 | val_loss : 78708.8828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 164 | train_loss : 73414.171875 | val_loss : 53232.75390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 165 | train_loss : 52145.76171875 | val_loss : 36133.74609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 166 | train_loss : 50834.93359375 | val_loss : 79083.7734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 167 | train_loss : 66543.15625 | val_loss : 34142.5703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 168 | train_loss : 44251.171875 | val_loss : 73650.578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 169 | train_loss : 71299.65625 | val_loss : 43679.12890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 170 | train_loss : 67722.984375 | val_loss : 86280.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 171 | train_loss : 64713.12109375 | val_loss : 57848.21484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 172 | train_loss : 51272.19140625 | val_loss : 51506.5859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 173 | train_loss : 58484.328125 | val_loss : 42189.80078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 174 | train_loss : 48738.7265625 | val_loss : 54036.19921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 175 | train_loss : 60567.7265625 | val_loss : 62459.078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 176 | train_loss : 59571.921875 | val_loss : 50465.06640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 177 | train_loss : 51240.5546875 | val_loss : 75753.1328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 178 | train_loss : 90475.53125 | val_loss : 40781.87109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 179 | train_loss : 56835.4140625 | val_loss : 104068.5625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 180 | train_loss : 81638.8515625 | val_loss : 99515.2265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 181 | train_loss : 81404.796875 | val_loss : 81167.2265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 182 | train_loss : 83717.703125 | val_loss : 108718.546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 183 | train_loss : 87353.1484375 | val_loss : 49661.98046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 184 | train_loss : 63391.0 | val_loss : 54452.203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 185 | train_loss : 56694.51171875 | val_loss : 88818.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 186 | train_loss : 77663.1875 | val_loss : 75413.7265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 187 | train_loss : 60000.07421875 | val_loss : 52471.98828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 188 | train_loss : 82270.53125 | val_loss : 42866.46875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 189 | train_loss : 55747.61328125 | val_loss : 62583.5390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 190 | train_loss : 54104.10546875 | val_loss : 52458.66015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 191 | train_loss : 51330.66015625 | val_loss : 70631.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 192 | train_loss : 59016.1953125 | val_loss : 75521.046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 193 | train_loss : 70751.1171875 | val_loss : 42352.7890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 194 | train_loss : 60675.41015625 | val_loss : 61124.80078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 195 | train_loss : 47372.74609375 | val_loss : 17448.85546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 196 | train_loss : 26850.84765625 | val_loss : 56790.10546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 197 | train_loss : 39440.43359375 | val_loss : 33638.84375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 198 | train_loss : 34358.78515625 | val_loss : 48620.71484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 199 | train_loss : 46201.984375 | val_loss : 63722.3359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 200 | train_loss : 55229.6484375 | val_loss : 35301.56640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 201 | train_loss : 40785.0078125 | val_loss : 42174.2109375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 202 | train_loss : 61269.48828125 | val_loss : 87894.2265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 203 | train_loss : 66020.84375 | val_loss : 35876.34375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 204 | train_loss : 37981.0390625 | val_loss : 27450.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 205 | train_loss : 22131.533203125 | val_loss : 25699.029296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 206 | train_loss : 46612.359375 | val_loss : 71116.6875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 207 | train_loss : 66505.1328125 | val_loss : 44705.81640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 208 | train_loss : 48746.25390625 | val_loss : 55066.8515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 209 | train_loss : 42606.23828125 | val_loss : 23627.08203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 210 | train_loss : 39531.8671875 | val_loss : 54165.37890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 211 | train_loss : 51196.69140625 | val_loss : 41541.1328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 212 | train_loss : 51635.00390625 | val_loss : 78238.453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 213 | train_loss : 57738.21484375 | val_loss : 32054.873046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 214 | train_loss : 38591.48046875 | val_loss : 22944.97265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 215 | train_loss : 26690.13671875 | val_loss : 46011.44140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 216 | train_loss : 44940.01171875 | val_loss : 35806.42578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 217 | train_loss : 36961.2265625 | val_loss : 47985.8515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 218 | train_loss : 38598.1953125 | val_loss : 42879.73046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 219 | train_loss : 47924.21484375 | val_loss : 46501.06640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 220 | train_loss : 34876.5859375 | val_loss : 20844.9453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 221 | train_loss : 17768.494140625 | val_loss : 28986.08984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 222 | train_loss : 37958.37890625 | val_loss : 43087.390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 223 | train_loss : 37145.67578125 | val_loss : 22903.318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 224 | train_loss : 32549.404296875 | val_loss : 42039.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 225 | train_loss : 38069.29296875 | val_loss : 28518.32421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 226 | train_loss : 41673.89453125 | val_loss : 71932.2578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 227 | train_loss : 52176.28515625 | val_loss : 29878.748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 228 | train_loss : 34241.40625 | val_loss : 46613.87109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 229 | train_loss : 47717.30078125 | val_loss : 56365.390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 230 | train_loss : 58147.984375 | val_loss : 33963.5234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 231 | train_loss : 29106.2890625 | val_loss : 49775.87890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 232 | train_loss : 46827.75390625 | val_loss : 21685.158203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 233 | train_loss : 25907.3984375 | val_loss : 48159.30078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 234 | train_loss : 40778.859375 | val_loss : 28186.5 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 235 | train_loss : 30457.609375 | val_loss : 39297.71484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 236 | train_loss : 37113.96484375 | val_loss : 70276.703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 237 | train_loss : 61781.87109375 | val_loss : 50778.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 238 | train_loss : 44591.40625 | val_loss : 46936.765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 239 | train_loss : 61066.890625 | val_loss : 51174.63671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 240 | train_loss : 36716.55859375 | val_loss : 18357.525390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 241 | train_loss : 27959.794921875 | val_loss : 50339.19921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 242 | train_loss : 37586.8984375 | val_loss : 30569.404296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 243 | train_loss : 34727.8359375 | val_loss : 55666.546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 244 | train_loss : 43677.23828125 | val_loss : 56705.9453125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 245 | train_loss : 86802.4921875 | val_loss : 72322.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 246 | train_loss : 59556.71484375 | val_loss : 104340.1015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 247 | train_loss : 72332.4375 | val_loss : 38450.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 248 | train_loss : 33896.49609375 | val_loss : 43930.140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 249 | train_loss : 42202.35546875 | val_loss : 41676.4453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 250 | train_loss : 43675.7109375 | val_loss : 48264.85546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 251 | train_loss : 48889.69921875 | val_loss : 36404.55859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 252 | train_loss : 31825.64453125 | val_loss : 22424.892578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 253 | train_loss : 23528.689453125 | val_loss : 32660.3984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 254 | train_loss : 34150.6875 | val_loss : 17504.76171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 255 | train_loss : 29307.712890625 | val_loss : 25906.740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 256 | train_loss : 31596.568359375 | val_loss : 56580.6484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 257 | train_loss : 52798.21484375 | val_loss : 20081.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 258 | train_loss : 20651.248046875 | val_loss : 22787.52734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 259 | train_loss : 33642.69921875 | val_loss : 62951.8203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 260 | train_loss : 42063.6484375 | val_loss : 25683.845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 261 | train_loss : 32220.64453125 | val_loss : 33916.00390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 262 | train_loss : 38225.74609375 | val_loss : 39347.47265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 263 | train_loss : 39248.8828125 | val_loss : 30914.35546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 264 | train_loss : 29483.0703125 | val_loss : 38273.5 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 265 | train_loss : 41780.75 | val_loss : 37702.75 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 266 | train_loss : 41713.359375 | val_loss : 45514.01171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 267 | train_loss : 42916.74609375 | val_loss : 47627.3203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 268 | train_loss : 52673.69140625 | val_loss : 70380.234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 269 | train_loss : 61026.0 | val_loss : 49706.76953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 270 | train_loss : 41387.6640625 | val_loss : 60674.421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 271 | train_loss : 53366.19921875 | val_loss : 34352.546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 272 | train_loss : 39629.93359375 | val_loss : 26383.439453125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 273 | train_loss : 33571.3359375 | val_loss : 56593.98828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 274 | train_loss : 52335.9765625 | val_loss : 48050.765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 275 | train_loss : 49562.05078125 | val_loss : 57632.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 276 | train_loss : 45884.3984375 | val_loss : 22782.54296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 277 | train_loss : 32597.552734375 | val_loss : 51913.05078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 278 | train_loss : 40686.9453125 | val_loss : 43927.14453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 279 | train_loss : 37995.078125 | val_loss : 32928.23828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 280 | train_loss : 33462.98828125 | val_loss : 73808.390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 281 | train_loss : 110827.359375 | val_loss : 55684.66015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 282 | train_loss : 41147.71875 | val_loss : 16088.892578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 283 | train_loss : 16307.3896484375 | val_loss : 26026.5703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 284 | train_loss : 31976.734375 | val_loss : 50723.64453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 285 | train_loss : 38141.2578125 | val_loss : 19032.908203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 286 | train_loss : 30290.328125 | val_loss : 23659.8125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 287 | train_loss : 24239.5234375 | val_loss : 31101.33984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 288 | train_loss : 26416.880859375 | val_loss : 31382.2734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 289 | train_loss : 32043.025390625 | val_loss : 16133.51953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 290 | train_loss : 23575.193359375 | val_loss : 31854.9921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 291 | train_loss : 27927.4765625 | val_loss : 18669.703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 292 | train_loss : 21781.634765625 | val_loss : 16291.66796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 293 | train_loss : 20307.0234375 | val_loss : 33512.2734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 294 | train_loss : 28314.83984375 | val_loss : 32707.7734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 295 | train_loss : 29791.470703125 | val_loss : 49686.08984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 296 | train_loss : 42358.640625 | val_loss : 31169.255859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 297 | train_loss : 31636.677734375 | val_loss : 34962.72265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 298 | train_loss : 39176.4609375 | val_loss : 21995.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 299 | train_loss : 27673.251953125 | val_loss : 20657.494140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 300 | train_loss : 30962.392578125 | val_loss : 40772.265625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 301 | train_loss : 50560.69140625 | val_loss : 51728.1015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 302 | train_loss : 45342.3203125 | val_loss : 11288.927734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 303 | train_loss : 12452.0712890625 | val_loss : 23624.642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 304 | train_loss : 26179.36328125 | val_loss : 39679.125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 305 | train_loss : 36918.578125 | val_loss : 47113.328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 306 | train_loss : 49137.48828125 | val_loss : 34381.47265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 307 | train_loss : 34013.76171875 | val_loss : 26089.123046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 308 | train_loss : 25059.40234375 | val_loss : 19288.2734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 309 | train_loss : 21243.296875 | val_loss : 42280.765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 310 | train_loss : 33093.4921875 | val_loss : 22611.54296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 311 | train_loss : 24289.494140625 | val_loss : 24254.578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 312 | train_loss : 33542.6640625 | val_loss : 38890.18359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 313 | train_loss : 31550.892578125 | val_loss : 27823.794921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 314 | train_loss : 31894.01171875 | val_loss : 57111.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 315 | train_loss : 43132.88671875 | val_loss : 16440.955078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 316 | train_loss : 28943.947265625 | val_loss : 32927.8203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 317 | train_loss : 24745.3984375 | val_loss : 19440.27734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 318 | train_loss : 35751.515625 | val_loss : 54193.2109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 319 | train_loss : 41240.87109375 | val_loss : 28978.408203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 320 | train_loss : 29763.6875 | val_loss : 27709.849609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 321 | train_loss : 30148.740234375 | val_loss : 53634.2109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 322 | train_loss : 37540.62109375 | val_loss : 169963.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 323 | train_loss : 181337.875 | val_loss : 56686.328125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 324 | train_loss : 56041.296875 | val_loss : 28087.26953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 325 | train_loss : 28507.23046875 | val_loss : 39846.53125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 326 | train_loss : 35718.03125 | val_loss : 20749.6953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 327 | train_loss : 22382.287109375 | val_loss : 27050.865234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 328 | train_loss : 30506.57421875 | val_loss : 21868.82421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 329 | train_loss : 29764.3203125 | val_loss : 54114.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 330 | train_loss : 41129.0625 | val_loss : 36119.796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 331 | train_loss : 28718.814453125 | val_loss : 31141.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 332 | train_loss : 34118.3515625 | val_loss : 22385.994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 333 | train_loss : 23200.60546875 | val_loss : 24338.693359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 334 | train_loss : 29934.306640625 | val_loss : 48262.1015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 335 | train_loss : 31649.85546875 | val_loss : 19683.697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 336 | train_loss : 18500.841796875 | val_loss : 26178.1875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 337 | train_loss : 32192.345703125 | val_loss : 28483.17578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 338 | train_loss : 23235.921875 | val_loss : 22042.748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 339 | train_loss : 21239.22265625 | val_loss : 37804.54296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 340 | train_loss : 26368.814453125 | val_loss : 13463.2802734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 341 | train_loss : 22260.3046875 | val_loss : 33566.28515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 342 | train_loss : 23286.025390625 | val_loss : 18076.7265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 343 | train_loss : 30734.705078125 | val_loss : 47272.1796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 344 | train_loss : 35069.72265625 | val_loss : 34896.75390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 345 | train_loss : 35841.32421875 | val_loss : 43745.328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 346 | train_loss : 35971.47265625 | val_loss : 29313.84765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 347 | train_loss : 31500.9921875 | val_loss : 37007.90234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 348 | train_loss : 30806.078125 | val_loss : 17169.453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 349 | train_loss : 24516.412109375 | val_loss : 21049.984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 350 | train_loss : 18196.568359375 | val_loss : 10925.5126953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 351 | train_loss : 24507.005859375 | val_loss : 36561.57421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 352 | train_loss : 28936.78515625 | val_loss : 14021.9775390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 353 | train_loss : 18699.6328125 | val_loss : 28796.875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 354 | train_loss : 20645.32421875 | val_loss : 11245.7900390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 355 | train_loss : 21456.9140625 | val_loss : 41287.30859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 356 | train_loss : 28699.80078125 | val_loss : 14561.3896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 357 | train_loss : 20044.974609375 | val_loss : 37310.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 358 | train_loss : 27956.599609375 | val_loss : 18380.607421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 359 | train_loss : 27372.3125 | val_loss : 44391.55859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 360 | train_loss : 29968.23046875 | val_loss : 19635.572265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 361 | train_loss : 20191.982421875 | val_loss : 21244.568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 362 | train_loss : 17834.10546875 | val_loss : 27524.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 363 | train_loss : 28959.82421875 | val_loss : 35286.9765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 364 | train_loss : 27107.759765625 | val_loss : 24213.419921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 365 | train_loss : 28109.734375 | val_loss : 28388.69921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 366 | train_loss : 20926.98828125 | val_loss : 30778.091796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 367 | train_loss : 27687.658203125 | val_loss : 10970.1201171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 368 | train_loss : 15006.1328125 | val_loss : 16118.8125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 369 | train_loss : 14667.9599609375 | val_loss : 20696.232421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 370 | train_loss : 17341.8359375 | val_loss : 19159.931640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 371 | train_loss : 20797.33203125 | val_loss : 27379.3671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 372 | train_loss : 16985.837890625 | val_loss : 18500.064453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 373 | train_loss : 16564.796875 | val_loss : 31602.0390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 374 | train_loss : 27955.8359375 | val_loss : 20206.275390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 375 | train_loss : 24850.935546875 | val_loss : 41916.37890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 376 | train_loss : 36378.96875 | val_loss : 35638.73828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 377 | train_loss : 33470.43359375 | val_loss : 30875.20703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 378 | train_loss : 33851.20703125 | val_loss : 15893.8203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 379 | train_loss : 15262.6884765625 | val_loss : 15163.6103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 380 | train_loss : 17380.767578125 | val_loss : 39791.51953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 381 | train_loss : 26728.435546875 | val_loss : 8317.3125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 382 | train_loss : 8526.4052734375 | val_loss : 16658.58984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 383 | train_loss : 16774.4140625 | val_loss : 38776.3046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 384 | train_loss : 24647.25 | val_loss : 7578.982421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 385 | train_loss : 14618.4404296875 | val_loss : 31939.94921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 386 | train_loss : 20022.0703125 | val_loss : 19351.46484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 387 | train_loss : 25876.654296875 | val_loss : 37665.578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 388 | train_loss : 28119.419921875 | val_loss : 19997.296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 389 | train_loss : 26079.9765625 | val_loss : 41186.15625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 390 | train_loss : 28505.0078125 | val_loss : 26080.4375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 391 | train_loss : 26973.30078125 | val_loss : 34303.58203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 392 | train_loss : 23189.8984375 | val_loss : 9846.51953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 393 | train_loss : 8943.267578125 | val_loss : 22132.4140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 394 | train_loss : 13097.45703125 | val_loss : 9952.45703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 395 | train_loss : 16909.501953125 | val_loss : 34093.38671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 396 | train_loss : 22182.490234375 | val_loss : 14012.9248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 397 | train_loss : 11303.423828125 | val_loss : 11080.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 398 | train_loss : 13539.9599609375 | val_loss : 29040.232421875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 399 | train_loss : 27629.8125 | val_loss : 35324.8125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 400 | train_loss : 29142.20703125 | val_loss : 15259.8046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 401 | train_loss : 21074.4921875 | val_loss : 34574.26171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 402 | train_loss : 22460.5546875 | val_loss : 15009.4248046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 403 | train_loss : 16447.935546875 | val_loss : 21222.171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 404 | train_loss : 14225.3828125 | val_loss : 8249.3271484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 405 | train_loss : 12734.6552734375 | val_loss : 16351.5126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 406 | train_loss : 13705.056640625 | val_loss : 12762.2373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 407 | train_loss : 12907.88671875 | val_loss : 18841.79296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 408 | train_loss : 13122.822265625 | val_loss : 12338.34765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 409 | train_loss : 24003.064453125 | val_loss : 21598.95703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 410 | train_loss : 22750.533203125 | val_loss : 30856.83203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 411 | train_loss : 34420.3359375 | val_loss : 23285.4140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 412 | train_loss : 23238.8046875 | val_loss : 24708.267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 413 | train_loss : 20961.564453125 | val_loss : 19995.515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 414 | train_loss : 21419.134765625 | val_loss : 35035.0859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 415 | train_loss : 27601.525390625 | val_loss : 12846.6123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 416 | train_loss : 12188.3916015625 | val_loss : 11451.01953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 417 | train_loss : 13456.787109375 | val_loss : 23800.470703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 418 | train_loss : 22260.064453125 | val_loss : 29470.767578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 419 | train_loss : 24224.125 | val_loss : 7704.7626953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 420 | train_loss : 10647.8212890625 | val_loss : 39841.41015625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 421 | train_loss : 25064.669921875 | val_loss : 17159.455078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 422 | train_loss : 13657.11328125 | val_loss : 18716.025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 423 | train_loss : 24453.927734375 | val_loss : 27480.158203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 424 | train_loss : 31563.05078125 | val_loss : 40382.87109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 425 | train_loss : 26128.400390625 | val_loss : 19744.865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 426 | train_loss : 18315.08203125 | val_loss : 25237.248046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 427 | train_loss : 26917.841796875 | val_loss : 18922.650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 428 | train_loss : 15784.2021484375 | val_loss : 22093.64453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 429 | train_loss : 22814.123046875 | val_loss : 43929.9140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 430 | train_loss : 29563.220703125 | val_loss : 15942.462890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 431 | train_loss : 15016.5009765625 | val_loss : 14263.78515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 432 | train_loss : 13434.8212890625 | val_loss : 12135.3173828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 433 | train_loss : 14991.708984375 | val_loss : 27754.693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 434 | train_loss : 24040.412109375 | val_loss : 12736.6845703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 435 | train_loss : 12472.869140625 | val_loss : 13247.865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 436 | train_loss : 16788.287109375 | val_loss : 21841.689453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 437 | train_loss : 23885.97265625 | val_loss : 32781.09765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 438 | train_loss : 24697.0234375 | val_loss : 4995.8251953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 439 | train_loss : 6466.7275390625 | val_loss : 22192.216796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 440 | train_loss : 18647.7578125 | val_loss : 35932.640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 441 | train_loss : 30824.935546875 | val_loss : 29896.341796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 442 | train_loss : 35892.0703125 | val_loss : 16068.3427734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 443 | train_loss : 17639.126953125 | val_loss : 18127.904296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 444 | train_loss : 23484.25 | val_loss : 17723.982421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 445 | train_loss : 19910.70703125 | val_loss : 34191.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 446 | train_loss : 25719.0078125 | val_loss : 9922.73046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 447 | train_loss : 9919.8720703125 | val_loss : 10915.8076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 448 | train_loss : 16621.29296875 | val_loss : 43937.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 449 | train_loss : 31739.10546875 | val_loss : 9217.837890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 450 | train_loss : 14808.15625 | val_loss : 18589.099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 451 | train_loss : 13306.45703125 | val_loss : 10965.677734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 452 | train_loss : 19153.890625 | val_loss : 32913.1484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 453 | train_loss : 21281.314453125 | val_loss : 11804.732421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 454 | train_loss : 11481.9052734375 | val_loss : 20623.52734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 455 | train_loss : 15224.8984375 | val_loss : 8659.9375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 456 | train_loss : 11579.603515625 | val_loss : 18196.169921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 457 | train_loss : 14923.12890625 | val_loss : 12932.3701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 458 | train_loss : 12765.91015625 | val_loss : 20173.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 459 | train_loss : 20508.77734375 | val_loss : 10545.232421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 460 | train_loss : 10507.7724609375 | val_loss : 23538.150390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 461 | train_loss : 18118.884765625 | val_loss : 17945.810546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 462 | train_loss : 16682.32421875 | val_loss : 26482.09765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 463 | train_loss : 18135.384765625 | val_loss : 15491.2021484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 464 | train_loss : 15793.4873046875 | val_loss : 35442.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 465 | train_loss : 27880.4609375 | val_loss : 17031.279296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 466 | train_loss : 16570.48046875 | val_loss : 28843.216796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 467 | train_loss : 27237.119140625 | val_loss : 20527.7734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 468 | train_loss : 21498.234375 | val_loss : 17100.109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 469 | train_loss : 18753.150390625 | val_loss : 14003.4521484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 470 | train_loss : 17019.662109375 | val_loss : 38863.734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 471 | train_loss : 24782.330078125 | val_loss : 12721.5927734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 472 | train_loss : 10493.830078125 | val_loss : 6389.240234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 473 | train_loss : 12029.2421875 | val_loss : 11279.0625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 474 | train_loss : 8605.2197265625 | val_loss : 9867.29296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 475 | train_loss : 15803.052734375 | val_loss : 39510.078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 476 | train_loss : 24495.3984375 | val_loss : 12632.46484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 477 | train_loss : 10530.0302734375 | val_loss : 6809.72998046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 478 | train_loss : 9941.947265625 | val_loss : 30123.974609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 479 | train_loss : 19895.404296875 | val_loss : 22301.57421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 480 | train_loss : 28070.044921875 | val_loss : 40015.234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 481 | train_loss : 35376.04296875 | val_loss : 43831.2265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 482 | train_loss : 34784.19921875 | val_loss : 22157.20703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 483 | train_loss : 20687.9140625 | val_loss : 33692.7265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 484 | train_loss : 25158.3671875 | val_loss : 23561.90234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 485 | train_loss : 23369.505859375 | val_loss : 33702.859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 486 | train_loss : 32319.705078125 | val_loss : 16805.48828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 487 | train_loss : 16670.345703125 | val_loss : 15771.1396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 488 | train_loss : 17164.20703125 | val_loss : 18071.927734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 489 | train_loss : 17736.36328125 | val_loss : 25166.359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 490 | train_loss : 22207.240234375 | val_loss : 12462.6328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 491 | train_loss : 10946.0546875 | val_loss : 17702.7890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 492 | train_loss : 17806.890625 | val_loss : 13212.4150390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 493 | train_loss : 16995.296875 | val_loss : 28463.126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 494 | train_loss : 23447.212890625 | val_loss : 16052.90234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 495 | train_loss : 13708.3427734375 | val_loss : 17065.73046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 496 | train_loss : 16224.603515625 | val_loss : 7302.34765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 497 | train_loss : 11859.8076171875 | val_loss : 28801.1953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 498 | train_loss : 18134.818359375 | val_loss : 5499.71728515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 499 | train_loss : 6767.486328125 | val_loss : 14418.6826171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 500 | train_loss : 10584.7177734375 | val_loss : 18378.20703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 501 | train_loss : 19351.677734375 | val_loss : 26204.267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 502 | train_loss : 18738.78125 | val_loss : 13354.4345703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 503 | train_loss : 16935.896484375 | val_loss : 32004.375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 504 | train_loss : 21455.126953125 | val_loss : 12396.724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 505 | train_loss : 14241.0234375 | val_loss : 17926.322265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 506 | train_loss : 15000.4345703125 | val_loss : 14930.0224609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 507 | train_loss : 20936.830078125 | val_loss : 33230.87109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 508 | train_loss : 22390.48828125 | val_loss : 14937.6826171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 509 | train_loss : 15709.3564453125 | val_loss : 29884.46484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 510 | train_loss : 21966.806640625 | val_loss : 19100.2421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 511 | train_loss : 22229.02734375 | val_loss : 34211.81640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 512 | train_loss : 21911.947265625 | val_loss : 8145.81982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 513 | train_loss : 6768.68505859375 | val_loss : 18426.283203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 514 | train_loss : 13870.9208984375 | val_loss : 17053.142578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 515 | train_loss : 19069.265625 | val_loss : 28832.212890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 516 | train_loss : 19367.650390625 | val_loss : 21412.935546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 517 | train_loss : 21285.537109375 | val_loss : 38611.7265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 518 | train_loss : 23576.8828125 | val_loss : 7496.2900390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 519 | train_loss : 6135.8779296875 | val_loss : 13395.89453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 520 | train_loss : 15943.8671875 | val_loss : 39029.53125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 521 | train_loss : 23666.671875 | val_loss : 14345.5673828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 522 | train_loss : 11700.0810546875 | val_loss : 17063.990234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 523 | train_loss : 19314.642578125 | val_loss : 33342.24609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 524 | train_loss : 20867.8984375 | val_loss : 11239.6328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 525 | train_loss : 9310.0341796875 | val_loss : 11909.4150390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 526 | train_loss : 18136.94921875 | val_loss : 33066.296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 527 | train_loss : 20660.611328125 | val_loss : 11187.9375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 528 | train_loss : 11830.6474609375 | val_loss : 15547.8896484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 529 | train_loss : 16765.537109375 | val_loss : 27183.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 530 | train_loss : 24516.1875 | val_loss : 12269.6953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 531 | train_loss : 11561.8291015625 | val_loss : 10316.2900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 532 | train_loss : 11818.1171875 | val_loss : 14955.232421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 533 | train_loss : 16313.8720703125 | val_loss : 43821.87890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 534 | train_loss : 30992.294921875 | val_loss : 18391.69921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 535 | train_loss : 13648.40234375 | val_loss : 16133.3154296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 536 | train_loss : 23920.068359375 | val_loss : 35394.99609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 537 | train_loss : 25572.060546875 | val_loss : 8948.3974609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 538 | train_loss : 8498.580078125 | val_loss : 9275.6826171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 539 | train_loss : 10323.25 | val_loss : 15864.0654296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 540 | train_loss : 14596.3583984375 | val_loss : 14702.865234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 541 | train_loss : 15173.505859375 | val_loss : 32399.1796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 542 | train_loss : 22419.9140625 | val_loss : 15125.2197265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 543 | train_loss : 15678.5400390625 | val_loss : 24532.02734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 544 | train_loss : 23728.14453125 | val_loss : 12297.53515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 545 | train_loss : 12280.7314453125 | val_loss : 13040.767578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 546 | train_loss : 13383.3759765625 | val_loss : 15721.20703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 547 | train_loss : 16267.5478515625 | val_loss : 16603.912109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 548 | train_loss : 12030.4052734375 | val_loss : 7052.59765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 549 | train_loss : 10628.052734375 | val_loss : 18093.1875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 550 | train_loss : 13405.9775390625 | val_loss : 18938.73828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 551 | train_loss : 18881.6875 | val_loss : 15231.5029296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 552 | train_loss : 18753.39453125 | val_loss : 24312.48828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 553 | train_loss : 20282.08984375 | val_loss : 12565.537109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 554 | train_loss : 13879.1171875 | val_loss : 24466.5078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 555 | train_loss : 15955.236328125 | val_loss : 15758.4296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 556 | train_loss : 13964.0302734375 | val_loss : 17147.880859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 557 | train_loss : 14815.724609375 | val_loss : 21727.1875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 558 | train_loss : 18995.064453125 | val_loss : 14248.0400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 559 | train_loss : 12091.3564453125 | val_loss : 9844.9248046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 560 | train_loss : 12113.759765625 | val_loss : 27902.119140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 561 | train_loss : 17309.330078125 | val_loss : 9511.34765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 562 | train_loss : 7111.25634765625 | val_loss : 5058.427734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 563 | train_loss : 8235.2529296875 | val_loss : 24582.89453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 564 | train_loss : 15336.64453125 | val_loss : 9899.9599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 565 | train_loss : 10846.8984375 | val_loss : 19281.359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 566 | train_loss : 15140.5048828125 | val_loss : 19463.32421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 567 | train_loss : 28454.572265625 | val_loss : 22828.197265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 568 | train_loss : 20116.5546875 | val_loss : 27456.845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 569 | train_loss : 24471.3828125 | val_loss : 25473.203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 570 | train_loss : 25523.990234375 | val_loss : 15227.1298828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 571 | train_loss : 14217.3662109375 | val_loss : 140776.9375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 572 | train_loss : 184065.90625 | val_loss : 53148.67578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 573 | train_loss : 37964.78125 | val_loss : 25233.287109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 574 | train_loss : 23718.744140625 | val_loss : 24570.591796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 575 | train_loss : 30945.689453125 | val_loss : 20280.5546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 576 | train_loss : 16332.38671875 | val_loss : 8892.4677734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 577 | train_loss : 11478.43359375 | val_loss : 15052.8046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 578 | train_loss : 11458.7724609375 | val_loss : 7231.3349609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 579 | train_loss : 9353.57421875 | val_loss : 26459.169921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 580 | train_loss : 17124.876953125 | val_loss : 10377.3154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 581 | train_loss : 10049.7578125 | val_loss : 13698.4326171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 582 | train_loss : 12607.4072265625 | val_loss : 26066.373046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 583 | train_loss : 22626.6328125 | val_loss : 17308.818359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 584 | train_loss : 14647.61328125 | val_loss : 9111.712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 585 | train_loss : 10119.103515625 | val_loss : 10266.7646484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 586 | train_loss : 9526.21484375 | val_loss : 23336.6953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 587 | train_loss : 21939.78515625 | val_loss : 15082.892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 588 | train_loss : 18384.244140625 | val_loss : 39216.12109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 589 | train_loss : 24475.087890625 | val_loss : 14178.697265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 590 | train_loss : 12623.85546875 | val_loss : 13797.7451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 591 | train_loss : 11042.4375 | val_loss : 20111.71484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 592 | train_loss : 14262.0458984375 | val_loss : 9192.3251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 593 | train_loss : 11296.552734375 | val_loss : 30422.943359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 594 | train_loss : 20873.412109375 | val_loss : 12956.2177734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 595 | train_loss : 12397.5595703125 | val_loss : 12838.6845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 596 | train_loss : 10386.2822265625 | val_loss : 25934.005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 597 | train_loss : 17661.216796875 | val_loss : 9910.84765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 598 | train_loss : 8208.6904296875 | val_loss : 8926.3447265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 599 | train_loss : 9182.8603515625 | val_loss : 26034.1953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 600 | train_loss : 17800.607421875 | val_loss : 11683.26953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 601 | train_loss : 11647.955078125 | val_loss : 9823.8828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 602 | train_loss : 10807.9248046875 | val_loss : 28370.95703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 603 | train_loss : 16380.236328125 | val_loss : 7456.08740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 604 | train_loss : 11718.5849609375 | val_loss : 16278.1923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 605 | train_loss : 14520.5341796875 | val_loss : 16050.830078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 606 | train_loss : 14222.1435546875 | val_loss : 10937.349609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 607 | train_loss : 10360.1533203125 | val_loss : 12701.1923828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 608 | train_loss : 12921.8662109375 | val_loss : 16577.515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 609 | train_loss : 15485.6240234375 | val_loss : 28667.099609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 610 | train_loss : 21222.6796875 | val_loss : 10012.3779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 611 | train_loss : 10128.76953125 | val_loss : 12225.634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 612 | train_loss : 14433.482421875 | val_loss : 12384.2353515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 613 | train_loss : 11460.353515625 | val_loss : 27275.9765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 614 | train_loss : 19619.904296875 | val_loss : 7884.53515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 615 | train_loss : 6692.23681640625 | val_loss : 6148.990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 616 | train_loss : 5072.501953125 | val_loss : 15255.4228515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 617 | train_loss : 10044.9072265625 | val_loss : 8538.4677734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 618 | train_loss : 7781.37353515625 | val_loss : 12266.66015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 619 | train_loss : 11038.2275390625 | val_loss : 15367.7451171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 620 | train_loss : 16928.537109375 | val_loss : 26721.79296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 621 | train_loss : 22706.984375 | val_loss : 8559.20703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 622 | train_loss : 9756.619140625 | val_loss : 21103.990234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 623 | train_loss : 24843.884765625 | val_loss : 31888.5390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 624 | train_loss : 23767.619140625 | val_loss : 13038.3076171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 625 | train_loss : 19470.419921875 | val_loss : 26723.4375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 626 | train_loss : 20700.0 | val_loss : 5570.677734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 627 | train_loss : 9284.0986328125 | val_loss : 11096.2822265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 628 | train_loss : 11632.1953125 | val_loss : 18017.974609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 629 | train_loss : 17909.921875 | val_loss : 13884.73046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 630 | train_loss : 12788.40234375 | val_loss : 22789.47265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 631 | train_loss : 16951.72265625 | val_loss : 11914.3701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 632 | train_loss : 11402.97265625 | val_loss : 116141.65625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 633 | train_loss : 107672.09375 | val_loss : 30430.390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 634 | train_loss : 30239.3359375 | val_loss : 27021.140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 635 | train_loss : 27468.109375 | val_loss : 14305.892578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 636 | train_loss : 13794.2841796875 | val_loss : 10776.7421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 637 | train_loss : 10273.2890625 | val_loss : 3718.217529296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 638 | train_loss : 5929.35986328125 | val_loss : 12604.5927734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 639 | train_loss : 8703.955078125 | val_loss : 4987.61767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 640 | train_loss : 5714.0107421875 | val_loss : 4053.1826171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 641 | train_loss : 3538.27490234375 | val_loss : 4811.3701171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 642 | train_loss : 5119.52197265625 | val_loss : 16127.3701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 643 | train_loss : 11821.2978515625 | val_loss : 8688.3271484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 644 | train_loss : 7788.14892578125 | val_loss : 14419.669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 645 | train_loss : 11799.5302734375 | val_loss : 12097.0224609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 646 | train_loss : 12630.9248046875 | val_loss : 21677.970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 647 | train_loss : 14727.3525390625 | val_loss : 12636.3935546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 648 | train_loss : 17080.9765625 | val_loss : 16686.654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 649 | train_loss : 12609.1484375 | val_loss : 5119.2900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 650 | train_loss : 6603.21728515625 | val_loss : 17497.58203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 651 | train_loss : 11633.8046875 | val_loss : 8997.697265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 652 | train_loss : 8892.240234375 | val_loss : 32263.072265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 653 | train_loss : 22722.60546875 | val_loss : 7310.759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 654 | train_loss : 19074.380859375 | val_loss : 13560.955078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 655 | train_loss : 11481.173828125 | val_loss : 28678.189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 656 | train_loss : 29553.591796875 | val_loss : 43655.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 657 | train_loss : 30383.697265625 | val_loss : 15269.740234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 658 | train_loss : 19732.099609375 | val_loss : 23653.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 659 | train_loss : 18819.189453125 | val_loss : 17585.98828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 660 | train_loss : 13779.51171875 | val_loss : 16838.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 661 | train_loss : 14451.1787109375 | val_loss : 10569.1728515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 662 | train_loss : 10169.83984375 | val_loss : 9267.69140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 663 | train_loss : 7102.7529296875 | val_loss : 11268.5400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 664 | train_loss : 7898.9326171875 | val_loss : 7192.86767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 665 | train_loss : 6672.00244140625 | val_loss : 27279.337890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 666 | train_loss : 17204.07421875 | val_loss : 9496.787109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 667 | train_loss : 8405.23828125 | val_loss : 8342.9970703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 668 | train_loss : 9637.4892578125 | val_loss : 6303.607421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 669 | train_loss : 6644.853515625 | val_loss : 10230.57421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 670 | train_loss : 8629.787109375 | val_loss : 16624.966796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 671 | train_loss : 10739.3408203125 | val_loss : 6991.4638671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 672 | train_loss : 13235.9501953125 | val_loss : 9251.080078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 673 | train_loss : 7509.146484375 | val_loss : 5899.46728515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 674 | train_loss : 9368.8798828125 | val_loss : 23903.58203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 675 | train_loss : 15089.4716796875 | val_loss : 3006.56005859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 676 | train_loss : 3923.4873046875 | val_loss : 12560.892578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 677 | train_loss : 9910.0927734375 | val_loss : 22020.125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 678 | train_loss : 14502.880859375 | val_loss : 3435.222412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 679 | train_loss : 3315.772216796875 | val_loss : 5371.3173828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 680 | train_loss : 5525.05517578125 | val_loss : 11010.3583984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 681 | train_loss : 11159.6240234375 | val_loss : 17755.13671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 682 | train_loss : 12697.3896484375 | val_loss : 7378.3125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 683 | train_loss : 12635.6826171875 | val_loss : 15875.3291015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 684 | train_loss : 14101.1962890625 | val_loss : 10026.3583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 685 | train_loss : 10307.6826171875 | val_loss : 16003.82421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 686 | train_loss : 14434.53125 | val_loss : 16421.91015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 687 | train_loss : 19632.89453125 | val_loss : 16154.7978515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 688 | train_loss : 12384.2109375 | val_loss : 14445.865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 689 | train_loss : 21437.712890625 | val_loss : 28146.51171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 690 | train_loss : 21418.255859375 | val_loss : 3880.0400390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 691 | train_loss : 7078.646484375 | val_loss : 10081.8466796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 692 | train_loss : 8402.826171875 | val_loss : 16320.9501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 693 | train_loss : 13184.4287109375 | val_loss : 7347.1826171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 694 | train_loss : 8417.2177734375 | val_loss : 20038.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 695 | train_loss : 15425.2783203125 | val_loss : 8945.8798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 696 | train_loss : 7070.00927734375 | val_loss : 8626.6298828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 697 | train_loss : 9393.32421875 | val_loss : 11361.5615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 698 | train_loss : 9876.51171875 | val_loss : 23797.4140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 699 | train_loss : 14855.1396484375 | val_loss : 5457.46484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 700 | train_loss : 7130.3310546875 | val_loss : 11805.173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 701 | train_loss : 9847.5390625 | val_loss : 11047.087890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 702 | train_loss : 8879.2861328125 | val_loss : 7740.67236328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 703 | train_loss : 11220.58203125 | val_loss : 26239.955078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 704 | train_loss : 17189.064453125 | val_loss : 5883.72509765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 705 | train_loss : 5225.83251953125 | val_loss : 7512.1923828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 706 | train_loss : 7571.5986328125 | val_loss : 16245.794921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 707 | train_loss : 9893.119140625 | val_loss : 6148.02978515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 708 | train_loss : 5811.59130859375 | val_loss : 11183.068359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 709 | train_loss : 7822.68115234375 | val_loss : 7246.6787109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 710 | train_loss : 7433.2861328125 | val_loss : 12418.8310546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 711 | train_loss : 8227.654296875 | val_loss : 7366.96875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 712 | train_loss : 7791.28125 | val_loss : 7673.361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 713 | train_loss : 5009.0625 | val_loss : 6235.76123046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 714 | train_loss : 12668.587890625 | val_loss : 17805.01953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 715 | train_loss : 13357.26953125 | val_loss : 12159.88671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 716 | train_loss : 13464.6376953125 | val_loss : 8768.5849609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 717 | train_loss : 5833.5712890625 | val_loss : 1893.40625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 718 | train_loss : 3529.458740234375 | val_loss : 8587.75390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 719 | train_loss : 5022.26416015625 | val_loss : 8963.181640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 720 | train_loss : 8168.4326171875 | val_loss : 12106.375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 721 | train_loss : 8074.572265625 | val_loss : 4403.482421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 722 | train_loss : 7353.89990234375 | val_loss : 25498.7109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 723 | train_loss : 16772.21484375 | val_loss : 7592.84375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 724 | train_loss : 7042.72314453125 | val_loss : 10424.1484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 725 | train_loss : 9193.9677734375 | val_loss : 21881.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 726 | train_loss : 17173.041015625 | val_loss : 8439.861328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 727 | train_loss : 6449.23681640625 | val_loss : 5481.134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 728 | train_loss : 3984.55322265625 | val_loss : 5942.2373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 729 | train_loss : 4430.94580078125 | val_loss : 5770.07763671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 730 | train_loss : 4831.13623046875 | val_loss : 18058.33203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 731 | train_loss : 12318.8740234375 | val_loss : 7267.02880859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 732 | train_loss : 8069.3017578125 | val_loss : 14756.650390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 733 | train_loss : 11527.107421875 | val_loss : 8497.63671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 734 | train_loss : 17903.587890625 | val_loss : 7990.62646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 735 | train_loss : 7002.11669921875 | val_loss : 6403.62744140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 736 | train_loss : 9569.638671875 | val_loss : 22335.796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 737 | train_loss : 14231.7451171875 | val_loss : 4640.1650390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 738 | train_loss : 4334.3125 | val_loss : 4950.50732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 739 | train_loss : 4796.185546875 | val_loss : 16069.3466796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 740 | train_loss : 9599.2841796875 | val_loss : 4932.701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 741 | train_loss : 4183.34375 | val_loss : 7455.6875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 742 | train_loss : 6524.3955078125 | val_loss : 5739.38232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 743 | train_loss : 4863.8388671875 | val_loss : 15562.9150390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 744 | train_loss : 9769.7744140625 | val_loss : 4899.13134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 745 | train_loss : 4189.52587890625 | val_loss : 6267.62255859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 746 | train_loss : 4557.78955078125 | val_loss : 3877.8837890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 747 | train_loss : 4241.20947265625 | val_loss : 9115.50390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 748 | train_loss : 7323.927734375 | val_loss : 17956.150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 749 | train_loss : 11853.9677734375 | val_loss : 7469.03515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 750 | train_loss : 8532.2158203125 | val_loss : 19992.484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 751 | train_loss : 14866.0361328125 | val_loss : 10714.5595703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 752 | train_loss : 9807.8955078125 | val_loss : 6991.146484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 753 | train_loss : 8172.125 | val_loss : 9504.8076171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 754 | train_loss : 11970.2802734375 | val_loss : 10463.072265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 755 | train_loss : 10481.736328125 | val_loss : 24072.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 756 | train_loss : 19460.875 | val_loss : 6336.1748046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 757 | train_loss : 8105.06494140625 | val_loss : 10044.798828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 758 | train_loss : 11465.5283203125 | val_loss : 9606.8525390625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 759 | train_loss : 6940.25 | val_loss : 1954.8787841796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 760 | train_loss : 4211.17138671875 | val_loss : 8964.5302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 761 | train_loss : 5476.3076171875 | val_loss : 4473.9638671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 762 | train_loss : 4974.3310546875 | val_loss : 9149.46875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 763 | train_loss : 7382.814453125 | val_loss : 7285.205078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 764 | train_loss : 6533.52685546875 | val_loss : 20986.9453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 765 | train_loss : 13299.7060546875 | val_loss : 4677.2275390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 766 | train_loss : 5359.59521484375 | val_loss : 7273.55615234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 767 | train_loss : 5195.6376953125 | val_loss : 4395.1435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 768 | train_loss : 4350.6279296875 | val_loss : 6634.9287109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 769 | train_loss : 7691.130859375 | val_loss : 18925.2109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 770 | train_loss : 12824.73828125 | val_loss : 6783.43115234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 771 | train_loss : 5896.87255859375 | val_loss : 6885.822265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 772 | train_loss : 6803.6962890625 | val_loss : 17390.720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 773 | train_loss : 11694.5302734375 | val_loss : 6868.669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 774 | train_loss : 6612.82421875 | val_loss : 6808.91748046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 775 | train_loss : 4402.9794921875 | val_loss : 8417.068359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 776 | train_loss : 9333.3623046875 | val_loss : 6479.93603515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 777 | train_loss : 4617.6943359375 | val_loss : 4767.646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 778 | train_loss : 5382.166015625 | val_loss : 6393.65771484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 779 | train_loss : 5450.8310546875 | val_loss : 9340.169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 780 | train_loss : 7803.51416015625 | val_loss : 8686.755859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 781 | train_loss : 8744.8896484375 | val_loss : 12791.9287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 782 | train_loss : 11099.4189453125 | val_loss : 2197.796142578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 783 | train_loss : 2057.265380859375 | val_loss : 3368.478759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 784 | train_loss : 3954.638671875 | val_loss : 11078.2109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 785 | train_loss : 7554.126953125 | val_loss : 5845.9375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 786 | train_loss : 6984.09423828125 | val_loss : 8603.955078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 787 | train_loss : 7071.75732421875 | val_loss : 19201.400390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 788 | train_loss : 13020.8740234375 | val_loss : 6567.86376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 789 | train_loss : 4973.923828125 | val_loss : 7625.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 790 | train_loss : 6372.42138671875 | val_loss : 8777.3046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 791 | train_loss : 7220.36669921875 | val_loss : 6770.83251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 792 | train_loss : 4754.0546875 | val_loss : 4180.62646484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 793 | train_loss : 4844.65478515625 | val_loss : 11951.8125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 794 | train_loss : 9005.66015625 | val_loss : 5941.0849609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 795 | train_loss : 4092.983642578125 | val_loss : 12873.712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 796 | train_loss : 10261.291015625 | val_loss : 6284.90478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 797 | train_loss : 5833.31396484375 | val_loss : 9217.7314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 798 | train_loss : 7469.521484375 | val_loss : 5303.07373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 799 | train_loss : 5263.91259765625 | val_loss : 11803.3115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 800 | train_loss : 9108.166015625 | val_loss : 8610.6376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 801 | train_loss : 8997.2353515625 | val_loss : 16375.4228515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 802 | train_loss : 13717.46484375 | val_loss : 6919.76123046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 803 | train_loss : 5510.24609375 | val_loss : 6584.7587890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 804 | train_loss : 6688.62744140625 | val_loss : 9859.5048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 805 | train_loss : 9972.48046875 | val_loss : 8804.6376953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 806 | train_loss : 10673.4921875 | val_loss : 19761.689453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 807 | train_loss : 13225.2578125 | val_loss : 5337.68505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 808 | train_loss : 4244.77294921875 | val_loss : 4161.60498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 809 | train_loss : 5009.091796875 | val_loss : 2615.623779296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 810 | train_loss : 2968.38818359375 | val_loss : 5881.208984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 811 | train_loss : 4401.88427734375 | val_loss : 7436.14111328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 812 | train_loss : 5749.14013671875 | val_loss : 7994.78515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 813 | train_loss : 5031.2119140625 | val_loss : 4397.625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 814 | train_loss : 6048.0654296875 | val_loss : 18865.525390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 815 | train_loss : 11413.0771484375 | val_loss : 4346.68603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 816 | train_loss : 4737.458984375 | val_loss : 9177.78125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 817 | train_loss : 6487.8662109375 | val_loss : 16218.5234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 818 | train_loss : 9672.5439453125 | val_loss : 4212.87890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 819 | train_loss : 4404.12646484375 | val_loss : 9346.3134765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 820 | train_loss : 7440.1591796875 | val_loss : 4277.80126953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 821 | train_loss : 4997.392578125 | val_loss : 8943.4609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 822 | train_loss : 5246.00146484375 | val_loss : 3935.37744140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 823 | train_loss : 5957.99267578125 | val_loss : 11378.87890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 824 | train_loss : 8434.65625 | val_loss : 3360.766357421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 825 | train_loss : 6062.5185546875 | val_loss : 36024.48046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 826 | train_loss : 31313.072265625 | val_loss : 13877.8798828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 827 | train_loss : 14333.4453125 | val_loss : 16981.560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 828 | train_loss : 14226.61328125 | val_loss : 9522.86328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 829 | train_loss : 6306.85302734375 | val_loss : 10608.580078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 830 | train_loss : 10980.65234375 | val_loss : 22858.517578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 831 | train_loss : 13406.650390625 | val_loss : 1803.4100341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 832 | train_loss : 5366.20751953125 | val_loss : 7788.45263671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 833 | train_loss : 5144.78271484375 | val_loss : 2907.11865234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 834 | train_loss : 2169.782958984375 | val_loss : 3162.5224609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 835 | train_loss : 4520.3203125 | val_loss : 4547.9560546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 836 | train_loss : 4272.166015625 | val_loss : 3023.108642578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 837 | train_loss : 2757.9384765625 | val_loss : 8181.013671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 838 | train_loss : 6517.4755859375 | val_loss : 5529.53125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 839 | train_loss : 5132.22314453125 | val_loss : 17417.619140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 840 | train_loss : 11358.5166015625 | val_loss : 5200.4775390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 841 | train_loss : 5278.84130859375 | val_loss : 3728.757568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 842 | train_loss : 2921.78466796875 | val_loss : 10968.82421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 843 | train_loss : 9328.73046875 | val_loss : 4358.6123046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 844 | train_loss : 3365.625732421875 | val_loss : 10772.3740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 845 | train_loss : 9133.1962890625 | val_loss : 3935.6201171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 846 | train_loss : 3259.719970703125 | val_loss : 9843.6650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 847 | train_loss : 8397.0859375 | val_loss : 8959.4658203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 848 | train_loss : 7309.958984375 | val_loss : 6515.97021484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 849 | train_loss : 5571.90478515625 | val_loss : 4006.57373046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 850 | train_loss : 4073.22998046875 | val_loss : 17191.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 851 | train_loss : 11363.7353515625 | val_loss : 6455.94873046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 852 | train_loss : 7515.330078125 | val_loss : 13521.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 853 | train_loss : 9004.4296875 | val_loss : 3408.592529296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 854 | train_loss : 5658.55810546875 | val_loss : 12732.3212890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 855 | train_loss : 10574.3984375 | val_loss : 6599.39013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 856 | train_loss : 7508.271484375 | val_loss : 19577.564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 857 | train_loss : 13568.8271484375 | val_loss : 3453.888671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 858 | train_loss : 5176.115234375 | val_loss : 7261.0751953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 859 | train_loss : 5042.4501953125 | val_loss : 1967.802490234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 860 | train_loss : 3172.74560546875 | val_loss : 3992.169921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 861 | train_loss : 3386.826904296875 | val_loss : 8797.208984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 862 | train_loss : 6967.2373046875 | val_loss : 5419.58642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 863 | train_loss : 4572.728515625 | val_loss : 8550.490234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 864 | train_loss : 7082.076171875 | val_loss : 4797.0126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 865 | train_loss : 3274.533203125 | val_loss : 2232.030029296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 866 | train_loss : 4487.02392578125 | val_loss : 4642.42236328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 867 | train_loss : 3689.054443359375 | val_loss : 4379.634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 868 | train_loss : 6695.1904296875 | val_loss : 9924.5927734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 869 | train_loss : 7316.6123046875 | val_loss : 16687.763671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 870 | train_loss : 11569.4033203125 | val_loss : 4141.12744140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 871 | train_loss : 3779.77587890625 | val_loss : 9361.2470703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 872 | train_loss : 9002.369140625 | val_loss : 8361.943359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 873 | train_loss : 7047.0517578125 | val_loss : 19294.779296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 874 | train_loss : 15533.21484375 | val_loss : 3199.014892578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 875 | train_loss : 5210.52978515625 | val_loss : 9958.306640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 876 | train_loss : 6324.921875 | val_loss : 10280.0673828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 877 | train_loss : 8469.50390625 | val_loss : 3532.516357421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 878 | train_loss : 2414.597412109375 | val_loss : 4116.00732421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 879 | train_loss : 3536.73779296875 | val_loss : 7141.35888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 880 | train_loss : 5538.70751953125 | val_loss : 4278.521484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 881 | train_loss : 5403.78759765625 | val_loss : 10083.91796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 882 | train_loss : 6895.20458984375 | val_loss : 2666.90869140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 883 | train_loss : 5401.9306640625 | val_loss : 11078.794921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 884 | train_loss : 7135.7568359375 | val_loss : 5605.392578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 885 | train_loss : 5265.244140625 | val_loss : 9544.21484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 886 | train_loss : 7138.888671875 | val_loss : 5566.21875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 887 | train_loss : 5999.3837890625 | val_loss : 20018.8671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 888 | train_loss : 13603.146484375 | val_loss : 3487.751220703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 889 | train_loss : 4234.48388671875 | val_loss : 7081.01513671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 890 | train_loss : 4295.17041015625 | val_loss : 6354.951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 891 | train_loss : 4900.51953125 | val_loss : 3317.746337890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 892 | train_loss : 2256.99609375 | val_loss : 2461.05615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 893 | train_loss : 3165.97119140625 | val_loss : 7946.521484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 894 | train_loss : 5491.31103515625 | val_loss : 3183.936279296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 895 | train_loss : 3785.697509765625 | val_loss : 4381.50244140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 896 | train_loss : 3432.2705078125 | val_loss : 4512.84619140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 897 | train_loss : 3938.060302734375 | val_loss : 6280.6962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 898 | train_loss : 4520.505859375 | val_loss : 4178.68115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 899 | train_loss : 3122.52001953125 | val_loss : 4738.1748046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 900 | train_loss : 3773.0185546875 | val_loss : 4375.107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 901 | train_loss : 3686.081298828125 | val_loss : 7601.84228515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 902 | train_loss : 5895.2880859375 | val_loss : 4951.52001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 903 | train_loss : 4784.00927734375 | val_loss : 17956.802734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 904 | train_loss : 11370.5126953125 | val_loss : 2637.688720703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 905 | train_loss : 3065.572265625 | val_loss : 7190.34130859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 906 | train_loss : 5052.64404296875 | val_loss : 16015.1396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 907 | train_loss : 9532.7802734375 | val_loss : 2966.646240234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 908 | train_loss : 2870.362548828125 | val_loss : 4946.205078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 909 | train_loss : 3305.804931640625 | val_loss : 4780.3662109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 910 | train_loss : 4686.2548828125 | val_loss : 8402.9375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 911 | train_loss : 5579.60986328125 | val_loss : 5589.732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 912 | train_loss : 10480.9921875 | val_loss : 13822.7998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 913 | train_loss : 10285.6240234375 | val_loss : 6389.55126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 914 | train_loss : 10883.208984375 | val_loss : 8498.048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 915 | train_loss : 5754.361328125 | val_loss : 2979.09619140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 916 | train_loss : 3392.468017578125 | val_loss : 8668.9345703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 917 | train_loss : 6116.03759765625 | val_loss : 4869.302734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 918 | train_loss : 4701.24072265625 | val_loss : 5803.82763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 919 | train_loss : 6079.5048828125 | val_loss : 6742.05859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 920 | train_loss : 6256.443359375 | val_loss : 18646.408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 921 | train_loss : 12089.5908203125 | val_loss : 3164.87255859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 922 | train_loss : 5618.83056640625 | val_loss : 7341.21240234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 923 | train_loss : 5603.64453125 | val_loss : 5760.4736328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 924 | train_loss : 5560.05126953125 | val_loss : 3842.389892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 925 | train_loss : 3090.52099609375 | val_loss : 4370.45263671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 926 | train_loss : 3756.03369140625 | val_loss : 3494.05615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 927 | train_loss : 2383.184814453125 | val_loss : 4455.228515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 928 | train_loss : 5100.37109375 | val_loss : 4403.87109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 929 | train_loss : 3288.85595703125 | val_loss : 4600.43359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 930 | train_loss : 5058.66162109375 | val_loss : 7196.14111328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 931 | train_loss : 4518.87939453125 | val_loss : 7080.27392578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 932 | train_loss : 8454.7119140625 | val_loss : 13196.9990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 933 | train_loss : 8167.64208984375 | val_loss : 4002.199951171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 934 | train_loss : 7911.74560546875 | val_loss : 7302.80126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 935 | train_loss : 4092.847412109375 | val_loss : 1522.2886962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 936 | train_loss : 3559.77490234375 | val_loss : 7212.84130859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 937 | train_loss : 4774.20263671875 | val_loss : 8530.15234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 938 | train_loss : 7425.96630859375 | val_loss : 4725.17626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 939 | train_loss : 2749.23681640625 | val_loss : 2726.1923828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 940 | train_loss : 3038.2548828125 | val_loss : 6524.25732421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 941 | train_loss : 4724.6298828125 | val_loss : 4335.4375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 942 | train_loss : 3881.67333984375 | val_loss : 6235.865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 943 | train_loss : 3982.5888671875 | val_loss : 4969.04736328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 944 | train_loss : 4771.5556640625 | val_loss : 12383.8662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 945 | train_loss : 8590.1865234375 | val_loss : 3509.824951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 946 | train_loss : 4340.37890625 | val_loss : 6799.75634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 947 | train_loss : 4640.20751953125 | val_loss : 3225.679931640625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 948 | train_loss : 3138.60791015625 | val_loss : 3513.288818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 949 | train_loss : 2287.414794921875 | val_loss : 3335.57373046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 950 | train_loss : 2973.906982421875 | val_loss : 6294.728515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 951 | train_loss : 5053.529296875 | val_loss : 5703.87890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 952 | train_loss : 5789.54736328125 | val_loss : 20976.29296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 953 | train_loss : 13712.7041015625 | val_loss : 2629.965087890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 954 | train_loss : 4064.573486328125 | val_loss : 7566.32763671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 955 | train_loss : 4984.9482421875 | val_loss : 13766.892578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 956 | train_loss : 8563.6474609375 | val_loss : 1839.3087158203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 957 | train_loss : 3389.485107421875 | val_loss : 5517.60107421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 958 | train_loss : 3415.920654296875 | val_loss : 3878.527587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 959 | train_loss : 5040.7080078125 | val_loss : 11376.1240234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 960 | train_loss : 6458.9375 | val_loss : 2875.1611328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 961 | train_loss : 4249.37646484375 | val_loss : 4460.73486328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 962 | train_loss : 3535.124755859375 | val_loss : 6953.103515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 963 | train_loss : 6211.02392578125 | val_loss : 5235.98876953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 964 | train_loss : 3459.86181640625 | val_loss : 4514.38623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 965 | train_loss : 5651.97314453125 | val_loss : 7383.79638671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 966 | train_loss : 5596.552734375 | val_loss : 4646.34619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 967 | train_loss : 3928.0107421875 | val_loss : 10615.10546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 968 | train_loss : 7851.61376953125 | val_loss : 5462.4111328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 969 | train_loss : 8594.298828125 | val_loss : 7590.21142578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 970 | train_loss : 5703.00927734375 | val_loss : 6789.138671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 971 | train_loss : 6936.64013671875 | val_loss : 7869.89501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 972 | train_loss : 4746.443359375 | val_loss : 1815.0262451171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 973 | train_loss : 5359.361328125 | val_loss : 5284.85498046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 974 | train_loss : 3407.43408203125 | val_loss : 2558.3212890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 975 | train_loss : 6172.3564453125 | val_loss : 4971.59130859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 976 | train_loss : 3405.6923828125 | val_loss : 4330.48486328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 977 | train_loss : 6440.31982421875 | val_loss : 5341.66015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 978 | train_loss : 4803.482421875 | val_loss : 5103.99267578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 979 | train_loss : 4911.7099609375 | val_loss : 7008.72119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 980 | train_loss : 6984.74365234375 | val_loss : 4465.20361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 981 | train_loss : 7615.6611328125 | val_loss : 15758.0810546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 982 | train_loss : 11241.8701171875 | val_loss : 6035.89892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 983 | train_loss : 5156.7080078125 | val_loss : 7044.3349609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 984 | train_loss : 5688.75439453125 | val_loss : 1162.06494140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 985 | train_loss : 1148.89599609375 | val_loss : 2229.03125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 986 | train_loss : 1555.296142578125 | val_loss : 3291.802490234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 987 | train_loss : 3427.26806640625 | val_loss : 10861.013671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 988 | train_loss : 9398.701171875 | val_loss : 3549.652587890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 989 | train_loss : 3088.10302734375 | val_loss : 9792.337890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 990 | train_loss : 8270.4521484375 | val_loss : 6851.02001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 991 | train_loss : 4981.677734375 | val_loss : 7029.88134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 992 | train_loss : 5774.02734375 | val_loss : 3922.94384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 993 | train_loss : 3462.642822265625 | val_loss : 11135.705078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 994 | train_loss : 10094.193359375 | val_loss : 3605.2099609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 995 | train_loss : 4188.43701171875 | val_loss : 6155.7685546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 996 | train_loss : 6145.3095703125 | val_loss : 5319.61767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 997 | train_loss : 4152.8798828125 | val_loss : 16097.326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 998 | train_loss : 12278.6220703125 | val_loss : 2879.30126953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 999 | train_loss : 3385.949462890625 | val_loss : 5660.06103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1000 | train_loss : 3930.224365234375 | val_loss : 8720.1416015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1001 | train_loss : 6839.494140625 | val_loss : 2598.9111328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1002 | train_loss : 2176.1474609375 | val_loss : 7218.9912109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1003 | train_loss : 4561.81201171875 | val_loss : 3505.169921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1004 | train_loss : 3325.81689453125 | val_loss : 6583.7373046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1005 | train_loss : 4571.1064453125 | val_loss : 4861.06494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1006 | train_loss : 4970.05126953125 | val_loss : 7599.87890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1007 | train_loss : 4935.3134765625 | val_loss : 3224.764892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1008 | train_loss : 2824.922607421875 | val_loss : 8385.45703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1009 | train_loss : 4841.76123046875 | val_loss : 4042.54541015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1010 | train_loss : 3749.580322265625 | val_loss : 4954.68359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1011 | train_loss : 4404.0927734375 | val_loss : 4571.22998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1012 | train_loss : 5271.322265625 | val_loss : 10037.9501953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1013 | train_loss : 7824.07763671875 | val_loss : 5139.201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1014 | train_loss : 3843.2802734375 | val_loss : 2972.827392578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1015 | train_loss : 2174.010009765625 | val_loss : 3567.695068359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1016 | train_loss : 3877.77978515625 | val_loss : 4930.66015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1017 | train_loss : 3625.995849609375 | val_loss : 7245.4501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1018 | train_loss : 5742.27392578125 | val_loss : 5389.3212890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1019 | train_loss : 3528.227294921875 | val_loss : 8026.9814453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1020 | train_loss : 6034.22802734375 | val_loss : 5652.6748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1021 | train_loss : 4301.86767578125 | val_loss : 14241.8623046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1022 | train_loss : 10389.8349609375 | val_loss : 4758.04736328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1023 | train_loss : 4025.4482421875 | val_loss : 3997.71630859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1024 | train_loss : 1894.8265380859375 | val_loss : 2809.5400390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1025 | train_loss : 1973.7449951171875 | val_loss : 4113.81494140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1026 | train_loss : 2395.8984375 | val_loss : 3941.003662109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1027 | train_loss : 3284.914306640625 | val_loss : 2833.376220703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1028 | train_loss : 2151.387939453125 | val_loss : 5437.8388671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1029 | train_loss : 4014.813720703125 | val_loss : 3249.669921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1030 | train_loss : 2766.64501953125 | val_loss : 3945.916259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1031 | train_loss : 4007.356201171875 | val_loss : 5151.63232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1032 | train_loss : 4952.205078125 | val_loss : 3511.402587890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1033 | train_loss : 4874.7939453125 | val_loss : 6214.0224609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1034 | train_loss : 5516.4931640625 | val_loss : 19638.984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1035 | train_loss : 13904.6611328125 | val_loss : 5690.1025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1036 | train_loss : 5986.447265625 | val_loss : 6269.333984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1037 | train_loss : 6705.80615234375 | val_loss : 7756.50244140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1038 | train_loss : 7439.65234375 | val_loss : 6372.33642578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1039 | train_loss : 7134.46826171875 | val_loss : 17526.83203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1040 | train_loss : 12225.9326171875 | val_loss : 3229.3974609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1041 | train_loss : 4822.79443359375 | val_loss : 6280.76513671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1042 | train_loss : 4137.4765625 | val_loss : 3437.9951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1043 | train_loss : 3726.92626953125 | val_loss : 3476.766357421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1044 | train_loss : 2727.1318359375 | val_loss : 2296.242431640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1045 | train_loss : 3066.11083984375 | val_loss : 7702.60888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1046 | train_loss : 5021.77734375 | val_loss : 2914.811279296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1047 | train_loss : 5621.43603515625 | val_loss : 8779.8671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1048 | train_loss : 5345.75830078125 | val_loss : 4174.35888671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1049 | train_loss : 4256.61279296875 | val_loss : 4683.853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1050 | train_loss : 3747.65185546875 | val_loss : 4079.851318359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1051 | train_loss : 4090.431884765625 | val_loss : 4643.9248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1052 | train_loss : 4368.9638671875 | val_loss : 5561.52001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1053 | train_loss : 4402.4814453125 | val_loss : 17213.283203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1054 | train_loss : 10276.482421875 | val_loss : 1821.8212890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1055 | train_loss : 2557.995849609375 | val_loss : 6140.33251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1056 | train_loss : 4420.37060546875 | val_loss : 8497.0400390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1057 | train_loss : 6867.84130859375 | val_loss : 2505.378662109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1058 | train_loss : 1308.20263671875 | val_loss : 3136.735107421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1059 | train_loss : 2214.65087890625 | val_loss : 3523.6474609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1060 | train_loss : 2729.62060546875 | val_loss : 3945.514892578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1061 | train_loss : 2751.205078125 | val_loss : 2504.8837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1062 | train_loss : 3207.0458984375 | val_loss : 5545.07861328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1063 | train_loss : 4084.827392578125 | val_loss : 4744.072265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1064 | train_loss : 4284.9482421875 | val_loss : 4197.25732421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1065 | train_loss : 2864.179931640625 | val_loss : 7436.0224609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1066 | train_loss : 5792.9912109375 | val_loss : 5247.416015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1067 | train_loss : 3949.360595703125 | val_loss : 8415.7314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1068 | train_loss : 6242.5751953125 | val_loss : 3378.736328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1069 | train_loss : 2665.414306640625 | val_loss : 3375.11376953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1070 | train_loss : 3702.053466796875 | val_loss : 6006.15234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1071 | train_loss : 4864.4755859375 | val_loss : 15541.978515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1072 | train_loss : 10293.025390625 | val_loss : 2629.925048828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1073 | train_loss : 3099.813720703125 | val_loss : 4997.6201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1074 | train_loss : 3475.41552734375 | val_loss : 6955.44140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1075 | train_loss : 5547.53759765625 | val_loss : 4264.115234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1076 | train_loss : 2984.766357421875 | val_loss : 4889.8486328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1077 | train_loss : 3211.82666015625 | val_loss : 2399.72509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1078 | train_loss : 2672.046875 | val_loss : 7750.6201171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1079 | train_loss : 4058.902587890625 | val_loss : 4389.87744140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1080 | train_loss : 5281.79638671875 | val_loss : 8172.1337890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1081 | train_loss : 4769.52392578125 | val_loss : 3871.686279296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1082 | train_loss : 7935.62451171875 | val_loss : 3647.409912109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1083 | train_loss : 2969.59619140625 | val_loss : 3817.26123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1084 | train_loss : 5398.52392578125 | val_loss : 6420.88623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1085 | train_loss : 4722.2001953125 | val_loss : 8006.2900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1086 | train_loss : 7609.38134765625 | val_loss : 6144.39990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1087 | train_loss : 4242.8974609375 | val_loss : 9938.6962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1088 | train_loss : 9245.96484375 | val_loss : 5210.5361328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1089 | train_loss : 3727.78125 | val_loss : 1867.3900146484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1090 | train_loss : 5064.3056640625 | val_loss : 8870.400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1091 | train_loss : 5978.2314453125 | val_loss : 2336.5625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1092 | train_loss : 5642.6826171875 | val_loss : 5530.47998046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1093 | train_loss : 3188.024658203125 | val_loss : 2800.277587890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1094 | train_loss : 4702.318359375 | val_loss : 6326.33740234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1095 | train_loss : 4228.154296875 | val_loss : 3217.625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1096 | train_loss : 2944.328857421875 | val_loss : 3791.68115234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1097 | train_loss : 2557.9560546875 | val_loss : 2633.57373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1098 | train_loss : 2041.4716796875 | val_loss : 4837.44140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1099 | train_loss : 3642.427490234375 | val_loss : 2802.827392578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1100 | train_loss : 1954.7269287109375 | val_loss : 4036.5361328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1101 | train_loss : 4663.30615234375 | val_loss : 5087.7001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1102 | train_loss : 4240.43115234375 | val_loss : 14909.5341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1103 | train_loss : 10114.0625 | val_loss : 2469.961181640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1104 | train_loss : 3281.692138671875 | val_loss : 4621.4189453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1105 | train_loss : 4884.24609375 | val_loss : 4093.885009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1106 | train_loss : 4267.4580078125 | val_loss : 4846.3486328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1107 | train_loss : 4099.861328125 | val_loss : 8226.625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1108 | train_loss : 6735.4267578125 | val_loss : 3661.90869140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1109 | train_loss : 3212.663818359375 | val_loss : 8644.2001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1110 | train_loss : 7977.72021484375 | val_loss : 4381.8662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1111 | train_loss : 3993.676025390625 | val_loss : 10527.8291015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1112 | train_loss : 7126.07421875 | val_loss : 2660.965087890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1113 | train_loss : 1992.5980224609375 | val_loss : 3256.186279296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1114 | train_loss : 2343.21533203125 | val_loss : 5012.80859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1115 | train_loss : 3633.85693359375 | val_loss : 8442.71484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1116 | train_loss : 5829.544921875 | val_loss : 3845.155029296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1117 | train_loss : 2954.425048828125 | val_loss : 4189.71875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1118 | train_loss : 3321.699462890625 | val_loss : 4664.93603515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1119 | train_loss : 3464.514892578125 | val_loss : 2581.742431640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1120 | train_loss : 2931.216796875 | val_loss : 5506.2001953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1121 | train_loss : 4364.6494140625 | val_loss : 14641.494140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1122 | train_loss : 9825.6728515625 | val_loss : 2793.893798828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1123 | train_loss : 2811.059326171875 | val_loss : 4598.9775390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1124 | train_loss : 2652.826171875 | val_loss : 13347.5263671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1125 | train_loss : 8923.0556640625 | val_loss : 2381.3349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1126 | train_loss : 2258.543212890625 | val_loss : 4045.1826171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1127 | train_loss : 3294.40966796875 | val_loss : 3968.898681640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1128 | train_loss : 3846.421630859375 | val_loss : 6948.9375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1129 | train_loss : 4097.560546875 | val_loss : 2224.271240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1130 | train_loss : 3059.1435546875 | val_loss : 4352.0185546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1131 | train_loss : 2553.3701171875 | val_loss : 3723.71630859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1132 | train_loss : 3516.798095703125 | val_loss : 5648.94873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1133 | train_loss : 3869.35693359375 | val_loss : 2528.969970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1134 | train_loss : 2209.581787109375 | val_loss : 3952.702392578125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1135 | train_loss : 2510.61181640625 | val_loss : 4137.35009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1136 | train_loss : 3610.068115234375 | val_loss : 3840.11865234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1137 | train_loss : 2793.001220703125 | val_loss : 2716.523681640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1138 | train_loss : 1818.056884765625 | val_loss : 3280.171142578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1139 | train_loss : 2376.5595703125 | val_loss : 2824.2451171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1140 | train_loss : 2197.478515625 | val_loss : 4075.217529296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1141 | train_loss : 3065.38623046875 | val_loss : 2587.726318359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1142 | train_loss : 2105.531494140625 | val_loss : 3674.0361328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1143 | train_loss : 3291.44287109375 | val_loss : 2863.5888671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1144 | train_loss : 2259.145263671875 | val_loss : 3282.052490234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1145 | train_loss : 3349.574462890625 | val_loss : 3418.72998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1146 | train_loss : 2310.10205078125 | val_loss : 6697.3935546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1147 | train_loss : 7168.9970703125 | val_loss : 5411.7275390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1148 | train_loss : 4457.94775390625 | val_loss : 7962.20751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1149 | train_loss : 7590.6826171875 | val_loss : 4417.0537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1150 | train_loss : 3098.07666015625 | val_loss : 2392.6787109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1151 | train_loss : 4460.81298828125 | val_loss : 5314.3173828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1152 | train_loss : 4021.73681640625 | val_loss : 2835.03125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1153 | train_loss : 5908.208984375 | val_loss : 7785.85498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1154 | train_loss : 5605.04052734375 | val_loss : 3106.677490234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1155 | train_loss : 5781.3798828125 | val_loss : 7711.1611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1156 | train_loss : 5349.91455078125 | val_loss : 3224.1298828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1157 | train_loss : 6358.35693359375 | val_loss : 6829.49755859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1158 | train_loss : 5035.728515625 | val_loss : 8801.9912109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1159 | train_loss : 8543.6943359375 | val_loss : 6738.18115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1160 | train_loss : 4568.5517578125 | val_loss : 4682.65478515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1161 | train_loss : 3779.412841796875 | val_loss : 11354.775390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1162 | train_loss : 7311.38134765625 | val_loss : 2086.648681640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1163 | train_loss : 1848.069580078125 | val_loss : 4580.24609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1164 | train_loss : 2920.375732421875 | val_loss : 3754.132568359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1165 | train_loss : 3015.488525390625 | val_loss : 2383.851318359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1166 | train_loss : 2012.7828369140625 | val_loss : 3616.89990234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1167 | train_loss : 2551.056640625 | val_loss : 6214.79736328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1168 | train_loss : 4971.048828125 | val_loss : 4993.0087890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1169 | train_loss : 3861.552490234375 | val_loss : 7345.7373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1170 | train_loss : 6502.12060546875 | val_loss : 4382.6337890625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1171 | train_loss : 3201.050048828125 | val_loss : 4206.62255859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1172 | train_loss : 3897.57373046875 | val_loss : 3680.246337890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1173 | train_loss : 2730.512451171875 | val_loss : 14308.1650390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1174 | train_loss : 8816.7412109375 | val_loss : 2653.89501953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1175 | train_loss : 3112.29150390625 | val_loss : 5582.72509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1176 | train_loss : 4017.2236328125 | val_loss : 11671.5888671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1177 | train_loss : 8111.20556640625 | val_loss : 2693.3076171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1178 | train_loss : 2388.456787109375 | val_loss : 3809.143798828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1179 | train_loss : 3346.09716796875 | val_loss : 4013.8076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1180 | train_loss : 3671.516357421875 | val_loss : 3438.4375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1181 | train_loss : 3721.050048828125 | val_loss : 6383.74853515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1182 | train_loss : 5302.60009765625 | val_loss : 2434.74365234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1183 | train_loss : 2774.665283203125 | val_loss : 4898.74609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1184 | train_loss : 3527.24462890625 | val_loss : 3580.074951171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1185 | train_loss : 2690.518798828125 | val_loss : 2561.608642578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1186 | train_loss : 1637.802978515625 | val_loss : 3102.08740234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1187 | train_loss : 2168.1708984375 | val_loss : 21748.5078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1188 | train_loss : 22131.125 | val_loss : 11297.478515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1189 | train_loss : 21881.130859375 | val_loss : 23615.630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1190 | train_loss : 23439.03515625 | val_loss : 4900.72021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1191 | train_loss : 9054.947265625 | val_loss : 7480.48388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1192 | train_loss : 4361.7568359375 | val_loss : 1499.3612060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1193 | train_loss : 5521.75390625 | val_loss : 2174.486328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1194 | train_loss : 1784.3984375 | val_loss : 3034.5712890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1195 | train_loss : 2485.84130859375 | val_loss : 3749.33740234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1196 | train_loss : 2780.20849609375 | val_loss : 2408.5400390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1197 | train_loss : 2512.607177734375 | val_loss : 3607.268798828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1198 | train_loss : 2628.971923828125 | val_loss : 2698.168701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1199 | train_loss : 2195.4306640625 | val_loss : 2438.987548828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1200 | train_loss : 1915.7191162109375 | val_loss : 2696.18994140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1201 | train_loss : 2235.9228515625 | val_loss : 2951.51123046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1202 | train_loss : 2522.9130859375 | val_loss : 2478.467529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1203 | train_loss : 1956.8017578125 | val_loss : 3093.9462890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1204 | train_loss : 2745.546875 | val_loss : 2304.5263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1205 | train_loss : 2840.852294921875 | val_loss : 4689.18359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1206 | train_loss : 3963.79833984375 | val_loss : 14891.861328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1207 | train_loss : 8879.291015625 | val_loss : 3750.71630859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1208 | train_loss : 2912.53369140625 | val_loss : 3047.41748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1209 | train_loss : 2026.830322265625 | val_loss : 3094.24365234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1210 | train_loss : 2281.493896484375 | val_loss : 2860.26123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1211 | train_loss : 1609.5096435546875 | val_loss : 2508.03759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1212 | train_loss : 2403.968505859375 | val_loss : 2830.594970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1213 | train_loss : 2065.2216796875 | val_loss : 2854.28125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1214 | train_loss : 2945.14599609375 | val_loss : 4507.0888671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1215 | train_loss : 2830.077392578125 | val_loss : 2621.043701171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1216 | train_loss : 2952.484130859375 | val_loss : 5556.9638671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1217 | train_loss : 4301.55126953125 | val_loss : 4451.71875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1218 | train_loss : 6382.20361328125 | val_loss : 16699.98046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1219 | train_loss : 11780.3095703125 | val_loss : 2238.56005859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1220 | train_loss : 2855.265869140625 | val_loss : 4548.36767578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1221 | train_loss : 2542.71826171875 | val_loss : 4089.103759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1222 | train_loss : 4298.6474609375 | val_loss : 3320.385009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1223 | train_loss : 1891.4532470703125 | val_loss : 1747.478759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1224 | train_loss : 3601.641845703125 | val_loss : 5021.03759765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1225 | train_loss : 3533.3017578125 | val_loss : 13226.2314453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1226 | train_loss : 9613.232421875 | val_loss : 3885.873779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1227 | train_loss : 2766.4814453125 | val_loss : 3781.916259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1228 | train_loss : 4022.296142578125 | val_loss : 4027.804931640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1229 | train_loss : 2476.331787109375 | val_loss : 2206.638671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1230 | train_loss : 2517.689697265625 | val_loss : 3753.33740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1231 | train_loss : 2839.314697265625 | val_loss : 3862.195068359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1232 | train_loss : 3501.389404296875 | val_loss : 5246.02392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1233 | train_loss : 4293.4033203125 | val_loss : 4361.701171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1234 | train_loss : 3832.349609375 | val_loss : 14580.2333984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1235 | train_loss : 9429.8740234375 | val_loss : 2665.375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1236 | train_loss : 2944.501220703125 | val_loss : 4346.50244140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1237 | train_loss : 2211.375732421875 | val_loss : 5364.46875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1238 | train_loss : 4772.92333984375 | val_loss : 3678.81884765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1239 | train_loss : 2431.812255859375 | val_loss : 3296.066162109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1240 | train_loss : 2550.76025390625 | val_loss : 3748.396240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1241 | train_loss : 2519.098388671875 | val_loss : 3979.923828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1242 | train_loss : 2915.207763671875 | val_loss : 3240.607421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1243 | train_loss : 2155.714599609375 | val_loss : 2801.27001953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1244 | train_loss : 1956.619384765625 | val_loss : 2920.9775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1245 | train_loss : 3120.6298828125 | val_loss : 5368.21630859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1246 | train_loss : 3550.320068359375 | val_loss : 3294.39501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1247 | train_loss : 3583.301513671875 | val_loss : 3078.844970703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1248 | train_loss : 2162.117431640625 | val_loss : 2539.168701171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1249 | train_loss : 3527.5712890625 | val_loss : 3322.610107421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1250 | train_loss : 2653.2099609375 | val_loss : 3110.56494140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1251 | train_loss : 3141.0869140625 | val_loss : 3790.826171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1252 | train_loss : 2645.913818359375 | val_loss : 6056.5361328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1253 | train_loss : 5329.39306640625 | val_loss : 2773.578857421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1254 | train_loss : 2086.46826171875 | val_loss : 4361.6123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1255 | train_loss : 4485.97265625 | val_loss : 3684.304931640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1256 | train_loss : 2810.894287109375 | val_loss : 11393.61328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1257 | train_loss : 7215.236328125 | val_loss : 4075.6513671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1258 | train_loss : 3024.669921875 | val_loss : 3220.86865234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1259 | train_loss : 3713.691162109375 | val_loss : 3464.74365234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1260 | train_loss : 2332.019287109375 | val_loss : 10010.9140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1261 | train_loss : 6987.48828125 | val_loss : 2606.79248046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1262 | train_loss : 1916.430419921875 | val_loss : 3354.313720703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1263 | train_loss : 1700.9888916015625 | val_loss : 2699.739990234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1264 | train_loss : 2038.1298828125 | val_loss : 2955.56494140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1265 | train_loss : 2046.63330078125 | val_loss : 3550.206298828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1266 | train_loss : 3007.34228515625 | val_loss : 3298.763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1267 | train_loss : 3386.44384765625 | val_loss : 4654.83642578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1268 | train_loss : 3687.5361328125 | val_loss : 14459.2998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1269 | train_loss : 9918.53125 | val_loss : 2052.81884765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1270 | train_loss : 2975.267578125 | val_loss : 6662.19384765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1271 | train_loss : 3967.605224609375 | val_loss : 2047.5150146484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1272 | train_loss : 3409.438232421875 | val_loss : 5245.30859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1273 | train_loss : 3672.556884765625 | val_loss : 5492.27392578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1274 | train_loss : 6142.09326171875 | val_loss : 4768.3388671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1275 | train_loss : 3652.489990234375 | val_loss : 3897.4111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1276 | train_loss : 4389.40625 | val_loss : 5818.38623046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1277 | train_loss : 3597.046875 | val_loss : 2824.199951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1278 | train_loss : 3830.664306640625 | val_loss : 4659.60986328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1279 | train_loss : 3514.186279296875 | val_loss : 2198.239990234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1280 | train_loss : 3819.50634765625 | val_loss : 7725.2001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1281 | train_loss : 4601.83544921875 | val_loss : 2277.705078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1282 | train_loss : 4209.78271484375 | val_loss : 4980.9423828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1283 | train_loss : 4007.824462890625 | val_loss : 2992.396240234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1284 | train_loss : 2530.7255859375 | val_loss : 2805.862548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1285 | train_loss : 2659.245361328125 | val_loss : 2606.62255859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1286 | train_loss : 2649.18212890625 | val_loss : 5540.419921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1287 | train_loss : 4677.0380859375 | val_loss : 4378.43017578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1288 | train_loss : 3772.300048828125 | val_loss : 13318.04296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1289 | train_loss : 9111.8701171875 | val_loss : 1846.9237060546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1290 | train_loss : 2221.6640625 | val_loss : 3475.20751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1291 | train_loss : 2378.85986328125 | val_loss : 4864.65380859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1292 | train_loss : 4953.25390625 | val_loss : 3152.702392578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1293 | train_loss : 2193.2861328125 | val_loss : 3160.679931640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1294 | train_loss : 3282.42431640625 | val_loss : 4428.43359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1295 | train_loss : 3133.93994140625 | val_loss : 2706.97509765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1296 | train_loss : 2856.0068359375 | val_loss : 2756.251220703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1297 | train_loss : 3294.91943359375 | val_loss : 3559.253662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1298 | train_loss : 3289.50927734375 | val_loss : 13223.8583984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1299 | train_loss : 8967.59765625 | val_loss : 2673.711181640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1300 | train_loss : 2405.19287109375 | val_loss : 2804.98876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1301 | train_loss : 1615.217529296875 | val_loss : 1891.6212158203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1302 | train_loss : 2118.60546875 | val_loss : 3984.983642578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1303 | train_loss : 2355.62939453125 | val_loss : 10096.775390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1304 | train_loss : 7146.4013671875 | val_loss : 1932.958740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1305 | train_loss : 1457.583251953125 | val_loss : 2491.422607421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1306 | train_loss : 1831.4525146484375 | val_loss : 2974.9736328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1307 | train_loss : 2309.52978515625 | val_loss : 4233.4599609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1308 | train_loss : 2630.98193359375 | val_loss : 2934.14990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1309 | train_loss : 2836.1376953125 | val_loss : 3656.387451171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1310 | train_loss : 2746.261474609375 | val_loss : 2912.038818359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1311 | train_loss : 2035.8673095703125 | val_loss : 3096.498779296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1312 | train_loss : 2076.45703125 | val_loss : 2056.683837890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1313 | train_loss : 1618.1629638671875 | val_loss : 2788.195068359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1314 | train_loss : 2013.290283203125 | val_loss : 2258.35498046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1315 | train_loss : 3043.8837890625 | val_loss : 3745.47509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1316 | train_loss : 2530.875732421875 | val_loss : 12214.4384765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1317 | train_loss : 8384.884765625 | val_loss : 2652.611328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1318 | train_loss : 2028.7718505859375 | val_loss : 3034.489990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1319 | train_loss : 3402.48291015625 | val_loss : 3267.580078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1320 | train_loss : 2439.42138671875 | val_loss : 14815.1171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1321 | train_loss : 9411.4482421875 | val_loss : 2223.97509765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1322 | train_loss : 1786.2010498046875 | val_loss : 3199.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1323 | train_loss : 1884.4224853515625 | val_loss : 2529.6875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1324 | train_loss : 1958.8516845703125 | val_loss : 3184.280029296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1325 | train_loss : 2542.82568359375 | val_loss : 3612.925048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1326 | train_loss : 2303.334716796875 | val_loss : 2819.719970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1327 | train_loss : 3308.540283203125 | val_loss : 3897.38623046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1328 | train_loss : 2787.485107421875 | val_loss : 2813.632568359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1329 | train_loss : 2882.90771484375 | val_loss : 3002.183837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1330 | train_loss : 2194.376953125 | val_loss : 7346.603515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1331 | train_loss : 5902.5126953125 | val_loss : 3494.784912109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1332 | train_loss : 2429.814453125 | val_loss : 5039.2998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1333 | train_loss : 4644.42919921875 | val_loss : 2667.15869140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1334 | train_loss : 1856.173583984375 | val_loss : 2659.657470703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1335 | train_loss : 1602.5699462890625 | val_loss : 2555.6474609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1336 | train_loss : 2200.352294921875 | val_loss : 2558.18505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1337 | train_loss : 1981.088134765625 | val_loss : 2106.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1338 | train_loss : 3563.41943359375 | val_loss : 3936.996337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1339 | train_loss : 2943.436279296875 | val_loss : 10456.5595703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1340 | train_loss : 7702.52734375 | val_loss : 2850.9599609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1341 | train_loss : 3153.5400390625 | val_loss : 2626.52490234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1342 | train_loss : 2612.501220703125 | val_loss : 3485.09130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1343 | train_loss : 2878.023193359375 | val_loss : 2659.3037109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1344 | train_loss : 1821.4151611328125 | val_loss : 2468.1787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1345 | train_loss : 1970.36376953125 | val_loss : 2941.703857421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1346 | train_loss : 1888.5465087890625 | val_loss : 2202.117431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1347 | train_loss : 1954.43603515625 | val_loss : 2911.513671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1348 | train_loss : 2203.3076171875 | val_loss : 2367.438720703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1349 | train_loss : 1640.8310546875 | val_loss : 2346.68505859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1350 | train_loss : 1780.588623046875 | val_loss : 2184.972412109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1351 | train_loss : 1691.7479248046875 | val_loss : 2338.843505859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1352 | train_loss : 1657.7945556640625 | val_loss : 2236.967529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1353 | train_loss : 1815.978271484375 | val_loss : 2397.983642578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1354 | train_loss : 1679.97607421875 | val_loss : 1948.56494140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1355 | train_loss : 1759.6148681640625 | val_loss : 2441.177490234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1356 | train_loss : 1666.4410400390625 | val_loss : 2217.11376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1357 | train_loss : 2331.2451171875 | val_loss : 3064.672607421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1358 | train_loss : 2072.544921875 | val_loss : 5227.7451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1359 | train_loss : 4538.4443359375 | val_loss : 2488.35009765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1360 | train_loss : 1731.3895263671875 | val_loss : 2273.347412109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1361 | train_loss : 1878.79833984375 | val_loss : 3589.12744140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1362 | train_loss : 2623.925537109375 | val_loss : 14597.1171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1363 | train_loss : 8905.7998046875 | val_loss : 1405.3675537109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1364 | train_loss : 2193.9501953125 | val_loss : 6291.72265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1365 | train_loss : 3743.81494140625 | val_loss : 2952.748779296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1366 | train_loss : 3735.5361328125 | val_loss : 3229.0224609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1367 | train_loss : 2720.683837890625 | val_loss : 1931.92626953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1368 | train_loss : 2524.380126953125 | val_loss : 3151.467529296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1369 | train_loss : 2018.1278076171875 | val_loss : 1965.166259765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1370 | train_loss : 1656.0855712890625 | val_loss : 2828.1201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1371 | train_loss : 2759.445556640625 | val_loss : 3391.4287109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1372 | train_loss : 2992.117431640625 | val_loss : 14322.7060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1373 | train_loss : 9169.9453125 | val_loss : 1347.6636962890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1374 | train_loss : 2018.032470703125 | val_loss : 3727.027587890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1375 | train_loss : 1773.4837646484375 | val_loss : 3599.171142578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1376 | train_loss : 3798.153076171875 | val_loss : 2551.72119140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1377 | train_loss : 1647.170654296875 | val_loss : 3738.33251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1378 | train_loss : 3276.429931640625 | val_loss : 3277.813720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1379 | train_loss : 2815.43115234375 | val_loss : 2979.201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1380 | train_loss : 3621.9296875 | val_loss : 5163.14501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1381 | train_loss : 4421.71240234375 | val_loss : 1362.1312255859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1382 | train_loss : 1880.98828125 | val_loss : 2217.09130859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1383 | train_loss : 1558.0238037109375 | val_loss : 3574.90380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1384 | train_loss : 4258.5439453125 | val_loss : 4381.11767578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1385 | train_loss : 4223.74609375 | val_loss : 13900.451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1386 | train_loss : 11073.927734375 | val_loss : 6355.17236328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1387 | train_loss : 6756.08642578125 | val_loss : 9782.8095703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1388 | train_loss : 11752.9912109375 | val_loss : 9970.1416015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1389 | train_loss : 9223.7177734375 | val_loss : 8661.94921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1390 | train_loss : 11948.4072265625 | val_loss : 8963.9228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1391 | train_loss : 8926.2177734375 | val_loss : 6416.1611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1392 | train_loss : 9555.79296875 | val_loss : 5403.37353515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1393 | train_loss : 4057.64501953125 | val_loss : 2437.538818359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1394 | train_loss : 4483.9443359375 | val_loss : 4179.1611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1395 | train_loss : 3307.64990234375 | val_loss : 3568.82373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1396 | train_loss : 2482.28515625 | val_loss : 3574.516357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1397 | train_loss : 3611.8134765625 | val_loss : 3196.07373046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1398 | train_loss : 2671.357421875 | val_loss : 11556.31640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1399 | train_loss : 7825.12451171875 | val_loss : 1888.4962158203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1400 | train_loss : 2258.507080078125 | val_loss : 2977.26123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1401 | train_loss : 1933.5491943359375 | val_loss : 2004.4012451171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1402 | train_loss : 2329.65576171875 | val_loss : 2891.282470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1403 | train_loss : 1727.7557373046875 | val_loss : 1740.6424560546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1404 | train_loss : 2867.547607421875 | val_loss : 2914.472412109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1405 | train_loss : 1604.483154296875 | val_loss : 4387.6162109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1406 | train_loss : 4692.6220703125 | val_loss : 2126.93505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1407 | train_loss : 1645.518798828125 | val_loss : 2383.203857421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1408 | train_loss : 2018.098876953125 | val_loss : 2949.37255859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1409 | train_loss : 3126.593505859375 | val_loss : 3915.8662109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1410 | train_loss : 2978.034912109375 | val_loss : 3074.81005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1411 | train_loss : 2721.734619140625 | val_loss : 3007.7099609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1412 | train_loss : 2263.21728515625 | val_loss : 2664.49365234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1413 | train_loss : 2792.449951171875 | val_loss : 3534.6611328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1414 | train_loss : 2574.580078125 | val_loss : 1883.98876953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1415 | train_loss : 1842.7261962890625 | val_loss : 2010.77001953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1416 | train_loss : 1846.84423828125 | val_loss : 2145.628662109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1417 | train_loss : 1729.2064208984375 | val_loss : 2041.1337890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1418 | train_loss : 1748.677978515625 | val_loss : 2045.989990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1419 | train_loss : 1860.6845703125 | val_loss : 2360.97998046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1420 | train_loss : 2124.8857421875 | val_loss : 2272.81494140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1421 | train_loss : 2413.86083984375 | val_loss : 3355.945068359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1422 | train_loss : 2721.945556640625 | val_loss : 1370.93505859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1423 | train_loss : 2002.755126953125 | val_loss : 3080.552490234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1424 | train_loss : 2353.291748046875 | val_loss : 9241.16015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1425 | train_loss : 6387.45361328125 | val_loss : 3337.206298828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1426 | train_loss : 2255.01318359375 | val_loss : 4692.31005859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1427 | train_loss : 4378.57568359375 | val_loss : 2246.53759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1428 | train_loss : 2073.675048828125 | val_loss : 4629.607421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1429 | train_loss : 5113.0712890625 | val_loss : 2624.547607421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1430 | train_loss : 2629.77490234375 | val_loss : 12965.146484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1431 | train_loss : 9148.98046875 | val_loss : 1373.4000244140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1432 | train_loss : 2531.124267578125 | val_loss : 3238.983642578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1433 | train_loss : 2070.4169921875 | val_loss : 2768.231201171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1434 | train_loss : 2320.051025390625 | val_loss : 4370.75390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1435 | train_loss : 3722.248046875 | val_loss : 4023.72509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1436 | train_loss : 2964.0283203125 | val_loss : 12244.7470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1437 | train_loss : 8586.791015625 | val_loss : 1341.5849609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1438 | train_loss : 2329.590576171875 | val_loss : 3490.296142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1439 | train_loss : 2540.232666015625 | val_loss : 2875.24365234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1440 | train_loss : 2225.66748046875 | val_loss : 2114.137451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1441 | train_loss : 1350.924072265625 | val_loss : 2211.385009765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1442 | train_loss : 1462.5413818359375 | val_loss : 2448.058837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1443 | train_loss : 1647.20654296875 | val_loss : 2352.6962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1444 | train_loss : 1905.0189208984375 | val_loss : 2504.2236328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1445 | train_loss : 1785.2584228515625 | val_loss : 2066.74365234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1446 | train_loss : 1963.635498046875 | val_loss : 2544.72509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1447 | train_loss : 2065.13623046875 | val_loss : 1564.449951171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1448 | train_loss : 2611.521484375 | val_loss : 5127.95263671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1449 | train_loss : 3635.105712890625 | val_loss : 1681.157470703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1450 | train_loss : 4098.4208984375 | val_loss : 3995.260009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1451 | train_loss : 3364.050048828125 | val_loss : 1742.64501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1452 | train_loss : 2397.404296875 | val_loss : 3490.061279296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1453 | train_loss : 3600.41748046875 | val_loss : 1277.6912841796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1454 | train_loss : 2289.554931640625 | val_loss : 4610.29736328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1455 | train_loss : 3136.037109375 | val_loss : 2893.217529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1456 | train_loss : 2608.6513671875 | val_loss : 11558.3466796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1457 | train_loss : 7257.61376953125 | val_loss : 1535.938720703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1458 | train_loss : 1843.5775146484375 | val_loss : 1936.35498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1459 | train_loss : 1782.03173828125 | val_loss : 1302.7125244140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1460 | train_loss : 1447.653076171875 | val_loss : 2180.891357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1461 | train_loss : 1483.013916015625 | val_loss : 1433.54248046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1462 | train_loss : 2206.70751953125 | val_loss : 2027.489990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1463 | train_loss : 1721.41748046875 | val_loss : 1019.0999755859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1464 | train_loss : 2317.6875 | val_loss : 3984.18994140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1465 | train_loss : 2912.787841796875 | val_loss : 2672.6298828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1466 | train_loss : 4000.29052734375 | val_loss : 3631.43115234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1467 | train_loss : 3090.416259765625 | val_loss : 8681.162109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1468 | train_loss : 6828.259765625 | val_loss : 3685.0625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1469 | train_loss : 3240.3818359375 | val_loss : 2476.8125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1470 | train_loss : 2770.9755859375 | val_loss : 1371.458740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1471 | train_loss : 1949.6231689453125 | val_loss : 1424.57373046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1472 | train_loss : 1681.6441650390625 | val_loss : 2020.864990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1473 | train_loss : 2030.337158203125 | val_loss : 3491.326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1474 | train_loss : 2559.9599609375 | val_loss : 5190.58251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1475 | train_loss : 4602.98193359375 | val_loss : 2837.38134765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1476 | train_loss : 2281.44677734375 | val_loss : 7778.7763671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1477 | train_loss : 5903.9599609375 | val_loss : 2152.72509765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1478 | train_loss : 1384.8304443359375 | val_loss : 2376.486328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1479 | train_loss : 1516.690185546875 | val_loss : 2847.205078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1480 | train_loss : 2207.255859375 | val_loss : 2162.1201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1481 | train_loss : 2341.82421875 | val_loss : 2707.3974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1482 | train_loss : 2258.600830078125 | val_loss : 12709.052734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1483 | train_loss : 7915.24853515625 | val_loss : 1363.58251953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1484 | train_loss : 1575.2376708984375 | val_loss : 3052.532470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1485 | train_loss : 1879.09375 | val_loss : 2280.8486328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1486 | train_loss : 1555.4515380859375 | val_loss : 2654.33740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1487 | train_loss : 2376.341796875 | val_loss : 2217.330078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1488 | train_loss : 1365.369873046875 | val_loss : 2433.68115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1489 | train_loss : 3013.498779296875 | val_loss : 2171.892578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1490 | train_loss : 1553.8414306640625 | val_loss : 2239.3662109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1491 | train_loss : 2291.29541015625 | val_loss : 2825.860107421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1492 | train_loss : 1843.16162109375 | val_loss : 12525.73046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1493 | train_loss : 7866.79931640625 | val_loss : 2163.8076171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1494 | train_loss : 1467.1337890625 | val_loss : 2884.66748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1495 | train_loss : 2415.416259765625 | val_loss : 2077.9638671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1496 | train_loss : 1440.794677734375 | val_loss : 2698.77001953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1497 | train_loss : 2277.78759765625 | val_loss : 2127.86376953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1498 | train_loss : 1533.8828125 | val_loss : 2832.8837890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1499 | train_loss : 2218.999267578125 | val_loss : 1686.3162841796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1500 | train_loss : 1297.657958984375 | val_loss : 2628.46875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1501 | train_loss : 1826.2769775390625 | val_loss : 1596.3387451171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1502 | train_loss : 1172.2691650390625 | val_loss : 2808.780029296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1503 | train_loss : 2152.4287109375 | val_loss : 880.8787231445312 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1504 | train_loss : 1503.787353515625 | val_loss : 3340.6162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1505 | train_loss : 2759.808837890625 | val_loss : 11557.03125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1506 | train_loss : 7919.3310546875 | val_loss : 1347.541259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1507 | train_loss : 1975.295654296875 | val_loss : 3012.282470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1508 | train_loss : 2319.40771484375 | val_loss : 11977.4248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1509 | train_loss : 7260.2763671875 | val_loss : 3109.702392578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1510 | train_loss : 2482.975830078125 | val_loss : 2783.9638671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1511 | train_loss : 2554.9580078125 | val_loss : 2813.847412109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1512 | train_loss : 2297.61962890625 | val_loss : 2571.38134765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1513 | train_loss : 3017.44091796875 | val_loss : 2266.316162109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1514 | train_loss : 1318.2423095703125 | val_loss : 4713.8349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1515 | train_loss : 3855.645263671875 | val_loss : 2593.797607421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1516 | train_loss : 1592.3900146484375 | val_loss : 3040.933837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1517 | train_loss : 1829.67724609375 | val_loss : 2021.2550048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1518 | train_loss : 2071.3251953125 | val_loss : 4317.72021484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1519 | train_loss : 3204.3857421875 | val_loss : 1994.9849853515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1520 | train_loss : 1861.00634765625 | val_loss : 2503.715087890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1521 | train_loss : 2064.7470703125 | val_loss : 1841.53125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1522 | train_loss : 2066.43603515625 | val_loss : 2716.40869140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1523 | train_loss : 2228.036376953125 | val_loss : 1660.498779296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1524 | train_loss : 2347.730712890625 | val_loss : 3543.172607421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1525 | train_loss : 2976.5048828125 | val_loss : 2584.456298828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1526 | train_loss : 5354.865234375 | val_loss : 6665.3837890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1527 | train_loss : 5679.8642578125 | val_loss : 2408.7275390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1528 | train_loss : 4021.672607421875 | val_loss : 2932.503662109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1529 | train_loss : 2017.37109375 | val_loss : 736.686279296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1530 | train_loss : 2607.374267578125 | val_loss : 2976.83251953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1531 | train_loss : 2393.419921875 | val_loss : 1596.4300537109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1532 | train_loss : 2727.93310546875 | val_loss : 2745.902587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1533 | train_loss : 2812.719482421875 | val_loss : 834.98876953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1534 | train_loss : 1924.6114501953125 | val_loss : 2752.24755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1535 | train_loss : 2821.1484375 | val_loss : 2414.94873046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1536 | train_loss : 2863.094970703125 | val_loss : 5694.9638671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1537 | train_loss : 5185.79736328125 | val_loss : 2964.84375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1538 | train_loss : 2871.105712890625 | val_loss : 12361.8740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1539 | train_loss : 7952.50146484375 | val_loss : 1316.9324951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1540 | train_loss : 2063.89990234375 | val_loss : 3199.958740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1541 | train_loss : 2360.5595703125 | val_loss : 1673.4737548828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1542 | train_loss : 1915.8994140625 | val_loss : 2012.1700439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1543 | train_loss : 1761.684814453125 | val_loss : 1522.67626953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1544 | train_loss : 2396.72802734375 | val_loss : 2912.2587890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1545 | train_loss : 2693.280029296875 | val_loss : 2021.3924560546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1546 | train_loss : 1648.3843994140625 | val_loss : 2340.985107421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1547 | train_loss : 1943.1668701171875 | val_loss : 2174.927490234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1548 | train_loss : 2037.99609375 | val_loss : 11724.150390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1549 | train_loss : 7096.18603515625 | val_loss : 1301.5050048828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1550 | train_loss : 1491.1090087890625 | val_loss : 2250.007568359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1551 | train_loss : 1209.4276123046875 | val_loss : 1625.6800537109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1552 | train_loss : 1289.3441162109375 | val_loss : 2460.583740234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1553 | train_loss : 1516.4566650390625 | val_loss : 1585.1387939453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1554 | train_loss : 1417.3631591796875 | val_loss : 1771.5687255859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1555 | train_loss : 1684.4034423828125 | val_loss : 1634.8924560546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1556 | train_loss : 1361.4776611328125 | val_loss : 2690.208740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1557 | train_loss : 2042.829345703125 | val_loss : 2454.9326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1558 | train_loss : 1624.11865234375 | val_loss : 3293.1875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1559 | train_loss : 4794.63916015625 | val_loss : 2889.237548828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1560 | train_loss : 2291.8720703125 | val_loss : 5197.43359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1561 | train_loss : 5155.95751953125 | val_loss : 2012.0675048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1562 | train_loss : 1345.4237060546875 | val_loss : 2506.043701171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1563 | train_loss : 2820.804931640625 | val_loss : 2372.705078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1564 | train_loss : 2282.350830078125 | val_loss : 12187.0966796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1565 | train_loss : 8322.6484375 | val_loss : 1341.9749755859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1566 | train_loss : 1631.6199951171875 | val_loss : 3307.2099609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1567 | train_loss : 1891.02978515625 | val_loss : 3495.264892578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1568 | train_loss : 3603.438232421875 | val_loss : 2753.56494140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1569 | train_loss : 1696.3375244140625 | val_loss : 1817.9825439453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1570 | train_loss : 1614.4681396484375 | val_loss : 2169.0263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1571 | train_loss : 1424.16455078125 | val_loss : 1435.268798828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1572 | train_loss : 1099.7969970703125 | val_loss : 2223.128662109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1573 | train_loss : 1735.94921875 | val_loss : 1968.26123046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1574 | train_loss : 1665.27294921875 | val_loss : 1854.260009765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1575 | train_loss : 1509.43994140625 | val_loss : 2047.092529296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1576 | train_loss : 1717.728759765625 | val_loss : 2161.391357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1577 | train_loss : 1639.1162109375 | val_loss : 1685.1837158203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1578 | train_loss : 1920.8751220703125 | val_loss : 2084.929931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1579 | train_loss : 1304.603759765625 | val_loss : 492.7025146484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1580 | train_loss : 1848.825439453125 | val_loss : 3165.25 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1581 | train_loss : 2283.348388671875 | val_loss : 10482.732421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1582 | train_loss : 6569.25732421875 | val_loss : 1816.2774658203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1583 | train_loss : 1372.501708984375 | val_loss : 2074.017578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1584 | train_loss : 1747.4910888671875 | val_loss : 4076.441162109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1585 | train_loss : 4309.0751953125 | val_loss : 2616.268798828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1586 | train_loss : 2067.13037109375 | val_loss : 3216.0888671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1587 | train_loss : 2798.6357421875 | val_loss : 1466.563720703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1588 | train_loss : 1228.68310546875 | val_loss : 2119.0224609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1589 | train_loss : 984.0070190429688 | val_loss : 1697.7724609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1590 | train_loss : 1484.579833984375 | val_loss : 2637.58251953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1591 | train_loss : 1700.77978515625 | val_loss : 1371.541259765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1592 | train_loss : 1941.3079833984375 | val_loss : 2955.646240234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1593 | train_loss : 1972.0238037109375 | val_loss : 1331.9112548828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1594 | train_loss : 2109.97021484375 | val_loss : 1979.42626953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1595 | train_loss : 1828.595458984375 | val_loss : 4659.21728515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1596 | train_loss : 4594.36376953125 | val_loss : 1395.7862548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1597 | train_loss : 1898.444091796875 | val_loss : 2846.80126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1598 | train_loss : 2797.314697265625 | val_loss : 2062.1513671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1599 | train_loss : 1559.5411376953125 | val_loss : 700.3574829101562 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 1600 | train_loss : 2297.54052734375 | val_loss : 3218.989990234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 8 | epoch : 1 | train_loss : 1439920.375 | val_loss : 483768.40625 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 2 | train_loss : 577092.875 | val_loss : 605095.4375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 3 | train_loss : 657896.875 | val_loss : 491960.96875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 4 | train_loss : 498535.96875 | val_loss : 525139.8125 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 5 | train_loss : 531377.1875 | val_loss : 705908.3125 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 6 | train_loss : 593856.5625 | val_loss : 360598.0 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 7 | train_loss : 333483.90625 | val_loss : 313882.3125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 8 | train_loss : 381651.59375 | val_loss : 228323.984375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 9 | train_loss : 314537.5625 | val_loss : 310501.3125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 10 | train_loss : 334077.6875 | val_loss : 348686.46875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 11 | train_loss : 315972.375 | val_loss : 305319.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 12 | train_loss : 296238.65625 | val_loss : 235330.640625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 13 | train_loss : 305765.0625 | val_loss : 335600.8125 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 14 | train_loss : 346179.75 | val_loss : 348407.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 15 | train_loss : 319048.25 | val_loss : 194047.453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 16 | train_loss : 215463.125 | val_loss : 208381.9375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 17 | train_loss : 201057.8125 | val_loss : 228519.71875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 18 | train_loss : 257548.421875 | val_loss : 270332.5625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 19 | train_loss : 303351.625 | val_loss : 228040.265625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 20 | train_loss : 284220.75 | val_loss : 340597.59375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 21 | train_loss : 281101.0 | val_loss : 265465.59375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 22 | train_loss : 220580.546875 | val_loss : 227821.375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 23 | train_loss : 243438.09375 | val_loss : 171473.921875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 24 | train_loss : 192792.5 | val_loss : 166330.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 25 | train_loss : 189726.359375 | val_loss : 213216.1875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 26 | train_loss : 201555.625 | val_loss : 192237.546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 27 | train_loss : 148141.53125 | val_loss : 210900.765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 28 | train_loss : 198076.1875 | val_loss : 199534.453125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 29 | train_loss : 234523.3125 | val_loss : 170254.453125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 30 | train_loss : 183187.71875 | val_loss : 234255.765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 31 | train_loss : 214897.578125 | val_loss : 277720.40625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 32 | train_loss : 235429.640625 | val_loss : 264047.6875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 33 | train_loss : 247175.5625 | val_loss : 176150.1875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 34 | train_loss : 189412.546875 | val_loss : 130491.5234375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 35 | train_loss : 129498.2578125 | val_loss : 174899.3125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 36 | train_loss : 216385.9375 | val_loss : 274136.1875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 37 | train_loss : 226454.90625 | val_loss : 176206.953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 38 | train_loss : 199149.90625 | val_loss : 213402.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 39 | train_loss : 210024.28125 | val_loss : 217152.21875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 40 | train_loss : 227566.09375 | val_loss : 158468.9375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 41 | train_loss : 154564.3125 | val_loss : 153545.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 42 | train_loss : 137566.859375 | val_loss : 100481.9609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 43 | train_loss : 85727.8671875 | val_loss : 147467.90625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 44 | train_loss : 116432.34375 | val_loss : 210215.71875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 45 | train_loss : 174348.515625 | val_loss : 154525.421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 46 | train_loss : 204003.546875 | val_loss : 177266.34375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 47 | train_loss : 144210.734375 | val_loss : 194840.953125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 48 | train_loss : 189488.6875 | val_loss : 262816.28125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 49 | train_loss : 216821.765625 | val_loss : 90495.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 50 | train_loss : 114695.2890625 | val_loss : 89053.609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 51 | train_loss : 113405.9921875 | val_loss : 109606.7734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 52 | train_loss : 91739.4921875 | val_loss : 87503.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 53 | train_loss : 99016.1328125 | val_loss : 99639.859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 54 | train_loss : 98169.296875 | val_loss : 98675.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 55 | train_loss : 103319.40625 | val_loss : 145873.703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 56 | train_loss : 152382.328125 | val_loss : 89614.21875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 57 | train_loss : 90345.1328125 | val_loss : 156799.5625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 58 | train_loss : 158312.484375 | val_loss : 132107.28125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 59 | train_loss : 173262.4375 | val_loss : 113960.7265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 60 | train_loss : 157882.203125 | val_loss : 210119.8125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 61 | train_loss : 187709.359375 | val_loss : 219562.84375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 62 | train_loss : 178549.953125 | val_loss : 141203.40625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 63 | train_loss : 158985.9375 | val_loss : 111077.9296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 64 | train_loss : 148283.796875 | val_loss : 129186.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 65 | train_loss : 163544.015625 | val_loss : 126899.21875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 66 | train_loss : 132225.359375 | val_loss : 99989.8984375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 67 | train_loss : 94358.40625 | val_loss : 48815.0703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 68 | train_loss : 86400.7109375 | val_loss : 146849.484375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 69 | train_loss : 138402.546875 | val_loss : 104430.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 70 | train_loss : 149464.953125 | val_loss : 63104.40625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 71 | train_loss : 63616.99609375 | val_loss : 126909.71875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 72 | train_loss : 111192.203125 | val_loss : 53176.78125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 73 | train_loss : 55436.94140625 | val_loss : 80122.2578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 74 | train_loss : 101626.046875 | val_loss : 90765.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 75 | train_loss : 149804.859375 | val_loss : 102728.8828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 76 | train_loss : 164766.5625 | val_loss : 143307.0 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 77 | train_loss : 180483.875 | val_loss : 107180.8203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 78 | train_loss : 114308.78125 | val_loss : 138372.515625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 79 | train_loss : 109864.390625 | val_loss : 133271.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 80 | train_loss : 125135.71875 | val_loss : 56136.05078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 81 | train_loss : 98939.4375 | val_loss : 145306.765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 82 | train_loss : 116821.5390625 | val_loss : 93763.5234375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 83 | train_loss : 128330.75 | val_loss : 80558.3203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 84 | train_loss : 126524.4296875 | val_loss : 110709.25 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 85 | train_loss : 104390.15625 | val_loss : 153566.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 86 | train_loss : 134760.71875 | val_loss : 75957.9296875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 87 | train_loss : 71333.515625 | val_loss : 88131.7890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 88 | train_loss : 102910.546875 | val_loss : 65692.2578125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 89 | train_loss : 89659.25 | val_loss : 79351.4921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 90 | train_loss : 81484.2734375 | val_loss : 142194.515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 91 | train_loss : 119381.0078125 | val_loss : 123446.28125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 92 | train_loss : 92731.453125 | val_loss : 93198.84375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 93 | train_loss : 136787.25 | val_loss : 105287.2421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 94 | train_loss : 115860.71875 | val_loss : 90332.34375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 95 | train_loss : 126812.03125 | val_loss : 145482.6875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 96 | train_loss : 120989.8828125 | val_loss : 80160.6328125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 97 | train_loss : 68740.09375 | val_loss : 29772.10546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 98 | train_loss : 58693.125 | val_loss : 56028.5703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 99 | train_loss : 62983.64453125 | val_loss : 94019.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 100 | train_loss : 83067.0390625 | val_loss : 60371.375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 101 | train_loss : 92219.46875 | val_loss : 74233.6171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 102 | train_loss : 83009.15625 | val_loss : 174501.234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 103 | train_loss : 102671.0 | val_loss : 108121.546875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 104 | train_loss : 83639.921875 | val_loss : 108760.578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 105 | train_loss : 98479.9765625 | val_loss : 33282.19140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 106 | train_loss : 58816.1953125 | val_loss : 92014.703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 107 | train_loss : 60827.69921875 | val_loss : 88477.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 108 | train_loss : 97359.75 | val_loss : 56232.66015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 109 | train_loss : 105861.0703125 | val_loss : 61370.734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 110 | train_loss : 61062.3203125 | val_loss : 43022.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 111 | train_loss : 59090.96484375 | val_loss : 144488.40625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 112 | train_loss : 94482.109375 | val_loss : 118189.859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 113 | train_loss : 106630.59375 | val_loss : 48543.3203125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 114 | train_loss : 71362.09375 | val_loss : 44051.8984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 115 | train_loss : 77377.703125 | val_loss : 72803.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 116 | train_loss : 78239.1015625 | val_loss : 77126.3203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 117 | train_loss : 66323.3984375 | val_loss : 75920.609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 118 | train_loss : 100264.6484375 | val_loss : 49526.875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 119 | train_loss : 69563.921875 | val_loss : 48172.75 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 120 | train_loss : 67012.1484375 | val_loss : 118444.578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 121 | train_loss : 82738.671875 | val_loss : 66268.1875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 122 | train_loss : 59407.59375 | val_loss : 27421.3359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 123 | train_loss : 42730.5 | val_loss : 111987.28125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 124 | train_loss : 84305.078125 | val_loss : 59066.515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 125 | train_loss : 83401.3515625 | val_loss : 55600.12890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 126 | train_loss : 68788.46875 | val_loss : 95201.1796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 127 | train_loss : 77704.359375 | val_loss : 110422.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 128 | train_loss : 81114.453125 | val_loss : 85048.640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 129 | train_loss : 114871.0703125 | val_loss : 99881.859375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 130 | train_loss : 105747.8984375 | val_loss : 81839.6015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 131 | train_loss : 84022.078125 | val_loss : 116757.0703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 132 | train_loss : 104368.3984375 | val_loss : 70410.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 133 | train_loss : 60347.1015625 | val_loss : 20847.05078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 134 | train_loss : 61351.99609375 | val_loss : 77710.515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 135 | train_loss : 73762.1015625 | val_loss : 32311.65234375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 136 | train_loss : 58742.85546875 | val_loss : 61316.74609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 137 | train_loss : 49136.7734375 | val_loss : 78963.5859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 138 | train_loss : 68527.7421875 | val_loss : 92480.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 139 | train_loss : 77310.453125 | val_loss : 37424.34375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 140 | train_loss : 52724.6015625 | val_loss : 49376.28125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 141 | train_loss : 39987.42578125 | val_loss : 47387.2734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 142 | train_loss : 76067.8984375 | val_loss : 39250.75 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 143 | train_loss : 67488.71875 | val_loss : 68485.3984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 144 | train_loss : 69611.6484375 | val_loss : 84762.2578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 145 | train_loss : 81791.1015625 | val_loss : 75940.9453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 146 | train_loss : 55354.30078125 | val_loss : 45578.23046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 147 | train_loss : 47341.50390625 | val_loss : 37007.96875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 148 | train_loss : 59508.91015625 | val_loss : 72402.1015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 149 | train_loss : 75928.3125 | val_loss : 85022.953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 150 | train_loss : 71908.2265625 | val_loss : 60787.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 151 | train_loss : 84608.546875 | val_loss : 89166.09375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 152 | train_loss : 85782.953125 | val_loss : 59968.015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 153 | train_loss : 68576.5703125 | val_loss : 63188.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 154 | train_loss : 64336.625 | val_loss : 29915.171875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 155 | train_loss : 43881.78125 | val_loss : 57294.87109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 156 | train_loss : 53519.3984375 | val_loss : 117111.671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 157 | train_loss : 103331.2421875 | val_loss : 61892.4609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 158 | train_loss : 62114.5546875 | val_loss : 45803.23828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 159 | train_loss : 66927.5234375 | val_loss : 92826.296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 160 | train_loss : 81723.28125 | val_loss : 39373.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 161 | train_loss : 34312.92578125 | val_loss : 43995.80859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 162 | train_loss : 57958.8515625 | val_loss : 39557.94921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 163 | train_loss : 57443.4609375 | val_loss : 96955.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 164 | train_loss : 113091.703125 | val_loss : 60535.2109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 165 | train_loss : 67877.78125 | val_loss : 53564.1953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 166 | train_loss : 44830.87109375 | val_loss : 46886.96484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 167 | train_loss : 53184.5703125 | val_loss : 58749.0859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 168 | train_loss : 65565.703125 | val_loss : 68780.3515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 169 | train_loss : 59372.7734375 | val_loss : 72640.9921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 170 | train_loss : 74609.9921875 | val_loss : 64260.99609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 171 | train_loss : 60312.921875 | val_loss : 75466.4921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 172 | train_loss : 57894.75 | val_loss : 50361.00390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 173 | train_loss : 49839.234375 | val_loss : 30669.2421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 174 | train_loss : 64302.8515625 | val_loss : 41741.59765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 175 | train_loss : 76607.421875 | val_loss : 43938.08984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 176 | train_loss : 69409.1328125 | val_loss : 47179.36328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 177 | train_loss : 55797.35546875 | val_loss : 36062.76171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 178 | train_loss : 43641.421875 | val_loss : 49599.0546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 179 | train_loss : 50198.99609375 | val_loss : 43266.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 180 | train_loss : 53036.92578125 | val_loss : 69142.7421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 181 | train_loss : 66398.7890625 | val_loss : 63362.57421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 182 | train_loss : 53586.8515625 | val_loss : 111702.6171875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 183 | train_loss : 97133.109375 | val_loss : 46230.94140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 184 | train_loss : 70042.640625 | val_loss : 96457.796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 185 | train_loss : 79418.40625 | val_loss : 29221.259765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 186 | train_loss : 49770.6640625 | val_loss : 37464.3359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 187 | train_loss : 37845.7109375 | val_loss : 35892.9453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 188 | train_loss : 48104.921875 | val_loss : 40084.92578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 189 | train_loss : 38619.71875 | val_loss : 57019.01171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 190 | train_loss : 44815.4296875 | val_loss : 46860.35546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 191 | train_loss : 59341.26171875 | val_loss : 37197.6484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 192 | train_loss : 47121.375 | val_loss : 36475.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 193 | train_loss : 35425.46484375 | val_loss : 35146.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 194 | train_loss : 41249.453125 | val_loss : 101938.28125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 195 | train_loss : 85372.0 | val_loss : 50507.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 196 | train_loss : 73868.0859375 | val_loss : 41143.8828125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 197 | train_loss : 53215.53125 | val_loss : 62220.94921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 198 | train_loss : 46095.18359375 | val_loss : 81488.515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 199 | train_loss : 69326.8984375 | val_loss : 27066.953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 200 | train_loss : 53387.9140625 | val_loss : 66025.6875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 201 | train_loss : 59675.43359375 | val_loss : 37727.140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 202 | train_loss : 55244.28515625 | val_loss : 69142.7734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 203 | train_loss : 48728.921875 | val_loss : 52039.58984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 204 | train_loss : 46719.609375 | val_loss : 76768.328125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 205 | train_loss : 56780.875 | val_loss : 41569.328125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 206 | train_loss : 49866.05078125 | val_loss : 27173.814453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 207 | train_loss : 54756.00390625 | val_loss : 51353.4453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 208 | train_loss : 64284.92578125 | val_loss : 22199.595703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 209 | train_loss : 46248.43359375 | val_loss : 61260.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 210 | train_loss : 54336.32421875 | val_loss : 57919.83984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 211 | train_loss : 69964.078125 | val_loss : 66054.703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 212 | train_loss : 65835.59375 | val_loss : 55428.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 213 | train_loss : 56230.0390625 | val_loss : 37676.12890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 214 | train_loss : 46115.12890625 | val_loss : 50553.94140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 215 | train_loss : 46835.3046875 | val_loss : 51921.06640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 216 | train_loss : 47109.3515625 | val_loss : 30632.95703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 217 | train_loss : 54592.171875 | val_loss : 59687.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 218 | train_loss : 55066.12890625 | val_loss : 32256.3671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 219 | train_loss : 43521.515625 | val_loss : 77206.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 220 | train_loss : 49890.03515625 | val_loss : 36808.99609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 221 | train_loss : 37110.2265625 | val_loss : 42650.26953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 222 | train_loss : 29715.158203125 | val_loss : 21202.072265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 223 | train_loss : 22605.580078125 | val_loss : 40238.6015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 224 | train_loss : 38306.3359375 | val_loss : 48723.56640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 225 | train_loss : 36721.4140625 | val_loss : 16904.064453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 226 | train_loss : 46496.96484375 | val_loss : 58333.7734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 227 | train_loss : 59024.46484375 | val_loss : 49181.8203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 228 | train_loss : 58323.51953125 | val_loss : 74023.953125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 229 | train_loss : 56193.84375 | val_loss : 23460.455078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 230 | train_loss : 39571.046875 | val_loss : 28829.2578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 231 | train_loss : 28962.7265625 | val_loss : 38301.6484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 232 | train_loss : 28202.05078125 | val_loss : 34975.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 233 | train_loss : 41525.32421875 | val_loss : 36369.3828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 234 | train_loss : 39246.2265625 | val_loss : 59983.9453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 235 | train_loss : 49335.83984375 | val_loss : 39126.73046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 236 | train_loss : 34381.0078125 | val_loss : 24010.294921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 237 | train_loss : 34808.41796875 | val_loss : 47652.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 238 | train_loss : 35776.640625 | val_loss : 45585.9609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 239 | train_loss : 49419.1640625 | val_loss : 59408.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 240 | train_loss : 46735.23046875 | val_loss : 22404.734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 241 | train_loss : 40163.71484375 | val_loss : 29391.79296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 242 | train_loss : 44540.48046875 | val_loss : 30600.59765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 243 | train_loss : 33918.76953125 | val_loss : 62419.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 244 | train_loss : 47237.19140625 | val_loss : 23047.607421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 245 | train_loss : 30963.806640625 | val_loss : 73531.1328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 246 | train_loss : 60731.9296875 | val_loss : 23108.927734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 247 | train_loss : 39792.8984375 | val_loss : 32328.10546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 248 | train_loss : 36351.0390625 | val_loss : 28941.28515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 249 | train_loss : 38658.921875 | val_loss : 61471.75 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 250 | train_loss : 43235.984375 | val_loss : 34575.0859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 251 | train_loss : 44907.80078125 | val_loss : 26785.82421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 252 | train_loss : 31596.0703125 | val_loss : 21737.4921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 253 | train_loss : 22324.53515625 | val_loss : 37741.34765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 254 | train_loss : 29826.1953125 | val_loss : 16933.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 255 | train_loss : 28471.037109375 | val_loss : 32143.08984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 256 | train_loss : 32089.419921875 | val_loss : 40887.00390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 257 | train_loss : 39006.53515625 | val_loss : 18794.6875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 258 | train_loss : 29670.080078125 | val_loss : 36653.2890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 259 | train_loss : 33515.92578125 | val_loss : 36182.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 260 | train_loss : 37231.19140625 | val_loss : 44450.5703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 261 | train_loss : 43143.828125 | val_loss : 37471.078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 262 | train_loss : 40051.796875 | val_loss : 37477.3359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 263 | train_loss : 38821.84375 | val_loss : 48886.8203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 264 | train_loss : 39637.32421875 | val_loss : 22133.619140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 265 | train_loss : 18801.63671875 | val_loss : 15313.9423828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 266 | train_loss : 26541.5703125 | val_loss : 46949.328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 267 | train_loss : 37811.8671875 | val_loss : 40207.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 268 | train_loss : 43272.25 | val_loss : 82553.8515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 269 | train_loss : 61611.3203125 | val_loss : 37037.56640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 270 | train_loss : 54490.875 | val_loss : 55732.828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 271 | train_loss : 50551.9765625 | val_loss : 33677.1171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 272 | train_loss : 34467.48046875 | val_loss : 47156.2109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 273 | train_loss : 39476.40625 | val_loss : 30947.275390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 274 | train_loss : 35779.21484375 | val_loss : 14451.77734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 275 | train_loss : 42086.81640625 | val_loss : 27477.697265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 276 | train_loss : 36340.4765625 | val_loss : 22811.453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 277 | train_loss : 42207.66015625 | val_loss : 52372.7734375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 278 | train_loss : 37370.046875 | val_loss : 23482.455078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 279 | train_loss : 19579.951171875 | val_loss : 26048.4609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 280 | train_loss : 36760.26171875 | val_loss : 28555.505859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 281 | train_loss : 34310.2734375 | val_loss : 30012.42578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 282 | train_loss : 28516.580078125 | val_loss : 19134.984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 283 | train_loss : 22329.77734375 | val_loss : 17352.939453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 284 | train_loss : 18373.685546875 | val_loss : 31766.384765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 285 | train_loss : 35378.43359375 | val_loss : 60066.23046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 286 | train_loss : 44037.86328125 | val_loss : 34233.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 287 | train_loss : 43361.31640625 | val_loss : 79598.53125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 288 | train_loss : 64907.17578125 | val_loss : 29347.876953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 289 | train_loss : 33569.05078125 | val_loss : 30685.09765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 290 | train_loss : 37814.921875 | val_loss : 53095.0234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 291 | train_loss : 44079.0390625 | val_loss : 38405.890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 292 | train_loss : 43799.36328125 | val_loss : 23077.044921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 293 | train_loss : 31451.130859375 | val_loss : 40716.15234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 294 | train_loss : 35583.03515625 | val_loss : 26638.912109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 295 | train_loss : 29294.435546875 | val_loss : 19161.509765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 296 | train_loss : 31726.982421875 | val_loss : 35202.83984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 297 | train_loss : 31465.3125 | val_loss : 28817.947265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 298 | train_loss : 35769.99609375 | val_loss : 54260.65625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 299 | train_loss : 45595.48828125 | val_loss : 56293.96875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 300 | train_loss : 56888.4453125 | val_loss : 39186.60546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 301 | train_loss : 33902.4921875 | val_loss : 31899.205078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 302 | train_loss : 34541.8046875 | val_loss : 51972.55859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 303 | train_loss : 37087.7265625 | val_loss : 17025.216796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 304 | train_loss : 26288.390625 | val_loss : 23921.474609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 305 | train_loss : 22106.982421875 | val_loss : 40340.60546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 306 | train_loss : 29058.421875 | val_loss : 35444.2265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 307 | train_loss : 33829.109375 | val_loss : 53502.30859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 308 | train_loss : 42003.80859375 | val_loss : 28978.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 309 | train_loss : 36650.42578125 | val_loss : 31920.30078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 310 | train_loss : 35102.05078125 | val_loss : 42310.12890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 311 | train_loss : 31688.83984375 | val_loss : 28968.095703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 312 | train_loss : 26526.16015625 | val_loss : 31012.681640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 313 | train_loss : 24092.734375 | val_loss : 25896.634765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 314 | train_loss : 36534.46875 | val_loss : 53691.69140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 315 | train_loss : 41822.640625 | val_loss : 37178.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 316 | train_loss : 30815.970703125 | val_loss : 50510.46875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 317 | train_loss : 44565.15625 | val_loss : 27108.9765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 318 | train_loss : 42853.6796875 | val_loss : 62290.5390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 319 | train_loss : 46272.9453125 | val_loss : 32639.65234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 320 | train_loss : 37287.921875 | val_loss : 59419.62890625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 321 | train_loss : 46546.80859375 | val_loss : 34494.25 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 322 | train_loss : 40521.09375 | val_loss : 46711.859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 323 | train_loss : 37624.59375 | val_loss : 47029.69140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 324 | train_loss : 33437.921875 | val_loss : 13337.6748046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 325 | train_loss : 12001.75 | val_loss : 21164.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 326 | train_loss : 24928.568359375 | val_loss : 17536.63671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 327 | train_loss : 31258.2265625 | val_loss : 77121.625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 328 | train_loss : 101889.5 | val_loss : 66106.703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 329 | train_loss : 40416.6328125 | val_loss : 23654.72265625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 330 | train_loss : 27606.685546875 | val_loss : 17508.841796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 331 | train_loss : 39859.875 | val_loss : 30249.552734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 332 | train_loss : 40214.9765625 | val_loss : 20536.810546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 333 | train_loss : 21767.9375 | val_loss : 13738.392578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 334 | train_loss : 15788.5576171875 | val_loss : 34870.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 335 | train_loss : 26503.212890625 | val_loss : 35424.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 336 | train_loss : 28793.724609375 | val_loss : 19838.33984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 337 | train_loss : 25466.7890625 | val_loss : 21931.740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 338 | train_loss : 29133.158203125 | val_loss : 43625.9140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 339 | train_loss : 28659.052734375 | val_loss : 16899.3046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 340 | train_loss : 24991.96484375 | val_loss : 21652.845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 341 | train_loss : 21054.345703125 | val_loss : 44904.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 342 | train_loss : 31958.099609375 | val_loss : 33483.40625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 343 | train_loss : 33286.46484375 | val_loss : 55259.05859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 344 | train_loss : 36872.46875 | val_loss : 33093.4609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 345 | train_loss : 36433.1484375 | val_loss : 66902.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 346 | train_loss : 43735.32421875 | val_loss : 20688.32421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 347 | train_loss : 20393.5234375 | val_loss : 35556.62109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 348 | train_loss : 30398.40234375 | val_loss : 114581.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 349 | train_loss : 154838.859375 | val_loss : 59955.4296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 350 | train_loss : 66763.765625 | val_loss : 63971.80078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 351 | train_loss : 71085.5625 | val_loss : 62269.73046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 352 | train_loss : 63319.24609375 | val_loss : 37834.06640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 353 | train_loss : 51142.0 | val_loss : 51394.109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 354 | train_loss : 53022.9765625 | val_loss : 27116.029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 355 | train_loss : 42596.15625 | val_loss : 35425.296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 356 | train_loss : 23634.642578125 | val_loss : 23229.32421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 357 | train_loss : 25861.08203125 | val_loss : 46451.5 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 358 | train_loss : 40822.3828125 | val_loss : 21898.22265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 359 | train_loss : 32028.580078125 | val_loss : 20292.23046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 360 | train_loss : 20719.669921875 | val_loss : 35009.48828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 361 | train_loss : 27300.373046875 | val_loss : 27151.98046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 362 | train_loss : 24518.953125 | val_loss : 26076.01953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 363 | train_loss : 46271.25 | val_loss : 40728.38671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 364 | train_loss : 40886.93359375 | val_loss : 23347.490234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 365 | train_loss : 24627.11328125 | val_loss : 43509.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 366 | train_loss : 26526.119140625 | val_loss : 34705.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 367 | train_loss : 38656.63671875 | val_loss : 32757.400390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 368 | train_loss : 30585.375 | val_loss : 18261.740234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 369 | train_loss : 26093.4296875 | val_loss : 44239.375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 370 | train_loss : 31246.279296875 | val_loss : 26133.740234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 371 | train_loss : 28694.404296875 | val_loss : 31818.529296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 372 | train_loss : 25371.01953125 | val_loss : 11547.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 373 | train_loss : 16761.287109375 | val_loss : 27190.296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 374 | train_loss : 23934.39453125 | val_loss : 20281.845703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 375 | train_loss : 17878.318359375 | val_loss : 16536.05078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 376 | train_loss : 22629.994140625 | val_loss : 14511.8095703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 377 | train_loss : 16236.6640625 | val_loss : 29899.017578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 378 | train_loss : 21267.10546875 | val_loss : 27206.203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 379 | train_loss : 37767.2421875 | val_loss : 34793.37890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 380 | train_loss : 28031.453125 | val_loss : 27625.814453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 381 | train_loss : 26216.078125 | val_loss : 25962.63671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 382 | train_loss : 19945.791015625 | val_loss : 14289.1328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 383 | train_loss : 23146.78515625 | val_loss : 21668.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 384 | train_loss : 21553.455078125 | val_loss : 30793.69921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 385 | train_loss : 24064.5546875 | val_loss : 17388.2421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 386 | train_loss : 19089.751953125 | val_loss : 30229.6796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 387 | train_loss : 23097.107421875 | val_loss : 19798.58984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 388 | train_loss : 25493.8984375 | val_loss : 27586.099609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 389 | train_loss : 19475.078125 | val_loss : 7863.49267578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 390 | train_loss : 11443.9677734375 | val_loss : 39620.32421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 391 | train_loss : 29719.009765625 | val_loss : 11685.787109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 392 | train_loss : 19523.67578125 | val_loss : 19625.974609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 393 | train_loss : 21050.33984375 | val_loss : 35644.6640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 394 | train_loss : 27378.193359375 | val_loss : 13500.0078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 395 | train_loss : 20128.298828125 | val_loss : 13231.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 396 | train_loss : 13099.6787109375 | val_loss : 26686.802734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 397 | train_loss : 14695.6201171875 | val_loss : 21452.556640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 398 | train_loss : 23874.32421875 | val_loss : 31273.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 399 | train_loss : 27814.9609375 | val_loss : 19970.48046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 400 | train_loss : 20067.6796875 | val_loss : 24912.6328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 401 | train_loss : 15186.2548828125 | val_loss : 20210.154296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 402 | train_loss : 22892.98046875 | val_loss : 28337.66015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 403 | train_loss : 23669.287109375 | val_loss : 34538.41015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 404 | train_loss : 25687.609375 | val_loss : 22030.962890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 405 | train_loss : 20278.24609375 | val_loss : 13307.8798828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 406 | train_loss : 10824.1845703125 | val_loss : 17477.623046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 407 | train_loss : 25378.751953125 | val_loss : 28676.1875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 408 | train_loss : 21100.595703125 | val_loss : 8815.705078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 409 | train_loss : 13638.0625 | val_loss : 41069.83984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 410 | train_loss : 26258.841796875 | val_loss : 18499.1328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 411 | train_loss : 22316.3203125 | val_loss : 35366.4140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 412 | train_loss : 25828.494140625 | val_loss : 37156.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 413 | train_loss : 40750.93359375 | val_loss : 44866.296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 414 | train_loss : 34157.7890625 | val_loss : 23743.150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 415 | train_loss : 24272.505859375 | val_loss : 39892.1171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 416 | train_loss : 25701.921875 | val_loss : 17548.357421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 417 | train_loss : 12590.3349609375 | val_loss : 15671.16015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 418 | train_loss : 25115.544921875 | val_loss : 33937.13671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 419 | train_loss : 28928.97265625 | val_loss : 19788.865234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 420 | train_loss : 21182.619140625 | val_loss : 18524.9296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 421 | train_loss : 23591.86328125 | val_loss : 39911.7265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 422 | train_loss : 27051.650390625 | val_loss : 36972.78125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 423 | train_loss : 30788.22265625 | val_loss : 31456.033203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 424 | train_loss : 24699.169921875 | val_loss : 16344.4072265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 425 | train_loss : 25947.470703125 | val_loss : 9232.3974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 426 | train_loss : 15543.212890625 | val_loss : 51489.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 427 | train_loss : 32599.2265625 | val_loss : 35028.71484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 428 | train_loss : 29191.79296875 | val_loss : 17159.337890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 429 | train_loss : 21621.3671875 | val_loss : 35883.7265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 430 | train_loss : 26042.85546875 | val_loss : 21022.099609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 431 | train_loss : 26589.14453125 | val_loss : 46370.26953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 432 | train_loss : 30567.630859375 | val_loss : 27825.205078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 433 | train_loss : 22775.7578125 | val_loss : 14156.53515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 434 | train_loss : 29238.470703125 | val_loss : 21226.591796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 435 | train_loss : 25849.234375 | val_loss : 28706.8046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 436 | train_loss : 30530.0 | val_loss : 22328.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 437 | train_loss : 20763.34765625 | val_loss : 8675.2978515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 438 | train_loss : 25855.275390625 | val_loss : 32412.134765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 439 | train_loss : 29290.755859375 | val_loss : 21154.29296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 440 | train_loss : 25597.76953125 | val_loss : 21365.10546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 441 | train_loss : 15619.7451171875 | val_loss : 16533.099609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 442 | train_loss : 22945.11328125 | val_loss : 34253.03515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 443 | train_loss : 25960.408203125 | val_loss : 29362.046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 444 | train_loss : 30159.685546875 | val_loss : 28454.154296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 445 | train_loss : 20175.146484375 | val_loss : 9975.8203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 446 | train_loss : 15474.7978515625 | val_loss : 16086.4912109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 447 | train_loss : 12648.068359375 | val_loss : 11704.2548828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 448 | train_loss : 10031.869140625 | val_loss : 17023.037109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 449 | train_loss : 24264.0078125 | val_loss : 15848.013671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 450 | train_loss : 12979.3349609375 | val_loss : 21773.8828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 451 | train_loss : 15755.650390625 | val_loss : 9083.8828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 452 | train_loss : 21469.068359375 | val_loss : 24522.2265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 453 | train_loss : 18279.6953125 | val_loss : 12158.1435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 454 | train_loss : 16215.72265625 | val_loss : 48124.75 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 455 | train_loss : 33839.01953125 | val_loss : 28035.310546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 456 | train_loss : 32841.22265625 | val_loss : 27728.41796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 457 | train_loss : 30164.97265625 | val_loss : 31592.193359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 458 | train_loss : 28004.880859375 | val_loss : 44456.08984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 459 | train_loss : 35049.37890625 | val_loss : 17633.23046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 460 | train_loss : 19206.962890625 | val_loss : 19797.00390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 461 | train_loss : 19775.97265625 | val_loss : 27303.162109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 462 | train_loss : 23643.6640625 | val_loss : 36840.76953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 463 | train_loss : 27222.849609375 | val_loss : 19031.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 464 | train_loss : 18123.859375 | val_loss : 17638.7265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 465 | train_loss : 19814.833984375 | val_loss : 19228.73828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 466 | train_loss : 16172.6435546875 | val_loss : 33651.5859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 467 | train_loss : 27328.990234375 | val_loss : 23558.98046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 468 | train_loss : 25297.078125 | val_loss : 19901.16796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 469 | train_loss : 26643.154296875 | val_loss : 32866.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 470 | train_loss : 23881.2890625 | val_loss : 9665.6123046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 471 | train_loss : 20680.140625 | val_loss : 25216.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 472 | train_loss : 20929.5 | val_loss : 19937.232421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 473 | train_loss : 21556.0078125 | val_loss : 12139.068359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 474 | train_loss : 16809.23828125 | val_loss : 22281.130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 475 | train_loss : 19086.88671875 | val_loss : 144205.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 476 | train_loss : 143908.109375 | val_loss : 56364.12890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 477 | train_loss : 39495.87109375 | val_loss : 24535.8046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 478 | train_loss : 29970.83984375 | val_loss : 25299.560546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 479 | train_loss : 28056.431640625 | val_loss : 21927.939453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 480 | train_loss : 16560.2421875 | val_loss : 31387.818359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 481 | train_loss : 24720.154296875 | val_loss : 20269.369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 482 | train_loss : 23749.716796875 | val_loss : 18021.953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 483 | train_loss : 26829.3125 | val_loss : 14975.6298828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 484 | train_loss : 14344.4365234375 | val_loss : 12679.2724609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 485 | train_loss : 15164.068359375 | val_loss : 12082.916015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 486 | train_loss : 15553.322265625 | val_loss : 26711.51171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 487 | train_loss : 23547.837890625 | val_loss : 13986.0712890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 488 | train_loss : 18936.595703125 | val_loss : 13690.5546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 489 | train_loss : 21217.794921875 | val_loss : 33624.08203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 490 | train_loss : 21530.4375 | val_loss : 73256.7421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 491 | train_loss : 67665.5 | val_loss : 51478.578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 492 | train_loss : 43944.67578125 | val_loss : 37812.3125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 493 | train_loss : 30100.08984375 | val_loss : 21192.53515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 494 | train_loss : 29589.6171875 | val_loss : 40485.37890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 495 | train_loss : 28869.578125 | val_loss : 26289.17578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 496 | train_loss : 28368.732421875 | val_loss : 17184.2578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 497 | train_loss : 18884.669921875 | val_loss : 31392.037109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 498 | train_loss : 23532.9453125 | val_loss : 16876.337890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 499 | train_loss : 23278.517578125 | val_loss : 37047.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 500 | train_loss : 22598.6484375 | val_loss : 7882.68017578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 501 | train_loss : 9835.322265625 | val_loss : 4702.3388671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 502 | train_loss : 15776.19921875 | val_loss : 22954.60546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 503 | train_loss : 20360.6875 | val_loss : 20577.54296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 504 | train_loss : 20995.9765625 | val_loss : 17357.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 505 | train_loss : 16792.79296875 | val_loss : 15622.2587890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 506 | train_loss : 14402.619140625 | val_loss : 21806.064453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 507 | train_loss : 16304.1123046875 | val_loss : 11826.419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 508 | train_loss : 17365.873046875 | val_loss : 12506.1259765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 509 | train_loss : 17403.427734375 | val_loss : 24388.2578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 510 | train_loss : 13813.9951171875 | val_loss : 18046.580078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 511 | train_loss : 19871.189453125 | val_loss : 40689.90625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 512 | train_loss : 34211.8359375 | val_loss : 20374.3046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 513 | train_loss : 29069.662109375 | val_loss : 32663.990234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 514 | train_loss : 23073.5078125 | val_loss : 10956.58984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 515 | train_loss : 9636.162109375 | val_loss : 4224.728515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 516 | train_loss : 12145.4072265625 | val_loss : 15851.693359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 517 | train_loss : 13260.119140625 | val_loss : 22951.08984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 518 | train_loss : 17915.7421875 | val_loss : 6493.12890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 519 | train_loss : 12279.298828125 | val_loss : 22670.171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 520 | train_loss : 14565.6015625 | val_loss : 17928.38671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 521 | train_loss : 20693.09765625 | val_loss : 20933.546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 522 | train_loss : 15601.6962890625 | val_loss : 12902.412109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 523 | train_loss : 22864.7734375 | val_loss : 22159.7890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 524 | train_loss : 19716.931640625 | val_loss : 18149.533203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 525 | train_loss : 18003.04296875 | val_loss : 9839.0849609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 526 | train_loss : 10609.76953125 | val_loss : 15422.46484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 527 | train_loss : 14458.52734375 | val_loss : 18829.841796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 528 | train_loss : 19553.822265625 | val_loss : 23499.0703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 529 | train_loss : 18929.0859375 | val_loss : 9476.326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 530 | train_loss : 12609.9287109375 | val_loss : 7065.40771484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 531 | train_loss : 8661.6787109375 | val_loss : 21682.314453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 532 | train_loss : 17966.76171875 | val_loss : 18161.623046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 533 | train_loss : 26122.36328125 | val_loss : 38139.58984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 534 | train_loss : 27668.5 | val_loss : 30589.623046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 535 | train_loss : 23156.98828125 | val_loss : 17169.6953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 536 | train_loss : 17433.912109375 | val_loss : 10734.6923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 537 | train_loss : 12171.6103515625 | val_loss : 14630.6640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 538 | train_loss : 11198.7900390625 | val_loss : 22603.58984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 539 | train_loss : 17235.666015625 | val_loss : 9995.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 540 | train_loss : 19102.76171875 | val_loss : 18915.345703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 541 | train_loss : 15555.80859375 | val_loss : 14813.6865234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 542 | train_loss : 13418.8447265625 | val_loss : 24890.98046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 543 | train_loss : 17993.283203125 | val_loss : 14493.8876953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 544 | train_loss : 16003.73828125 | val_loss : 39813.40234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 545 | train_loss : 27368.033203125 | val_loss : 17797.60546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 546 | train_loss : 23074.818359375 | val_loss : 35123.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 547 | train_loss : 20909.474609375 | val_loss : 16412.927734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 548 | train_loss : 16661.9296875 | val_loss : 16760.466796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 549 | train_loss : 20237.474609375 | val_loss : 12978.68359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 550 | train_loss : 13080.6474609375 | val_loss : 11920.759765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 551 | train_loss : 13770.4296875 | val_loss : 21024.599609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 552 | train_loss : 17680.20703125 | val_loss : 12089.951171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 553 | train_loss : 18701.283203125 | val_loss : 26269.70703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 554 | train_loss : 17596.98046875 | val_loss : 20252.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 555 | train_loss : 16041.7587890625 | val_loss : 18380.978515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 556 | train_loss : 25945.654296875 | val_loss : 15668.2236328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 557 | train_loss : 17726.5703125 | val_loss : 15698.8154296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 558 | train_loss : 10875.4970703125 | val_loss : 6375.7001953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 559 | train_loss : 8879.8115234375 | val_loss : 26365.505859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 560 | train_loss : 16350.107421875 | val_loss : 9337.8310546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 561 | train_loss : 11406.0283203125 | val_loss : 30836.240234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 562 | train_loss : 22020.375 | val_loss : 7699.81396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 563 | train_loss : 11745.048828125 | val_loss : 11556.8525390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 564 | train_loss : 10489.6787109375 | val_loss : 14518.263671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 565 | train_loss : 15131.43359375 | val_loss : 10953.205078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 566 | train_loss : 10574.70703125 | val_loss : 12639.05859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 567 | train_loss : 14406.3974609375 | val_loss : 12793.869140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 568 | train_loss : 14625.2841796875 | val_loss : 15141.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 569 | train_loss : 10299.978515625 | val_loss : 16971.439453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 570 | train_loss : 11463.29296875 | val_loss : 10822.771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 571 | train_loss : 14336.837890625 | val_loss : 23685.775390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 572 | train_loss : 16045.4833984375 | val_loss : 5879.40478515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 573 | train_loss : 6184.52294921875 | val_loss : 26107.09765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 574 | train_loss : 17604.134765625 | val_loss : 24500.95703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 575 | train_loss : 19840.1171875 | val_loss : 7770.24267578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 576 | train_loss : 16014.9765625 | val_loss : 6729.7138671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 577 | train_loss : 13424.580078125 | val_loss : 55384.9609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 578 | train_loss : 39945.7890625 | val_loss : 30690.9375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 579 | train_loss : 29938.2734375 | val_loss : 9888.8466796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 580 | train_loss : 15236.47265625 | val_loss : 27635.21484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 581 | train_loss : 20213.4609375 | val_loss : 24464.66015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 582 | train_loss : 19269.185546875 | val_loss : 21819.4140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 583 | train_loss : 18785.13671875 | val_loss : 8778.982421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 584 | train_loss : 20262.51953125 | val_loss : 27523.634765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 585 | train_loss : 23649.9765625 | val_loss : 20773.751953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 586 | train_loss : 24369.3125 | val_loss : 17351.55078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 587 | train_loss : 16466.4765625 | val_loss : 21727.44921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 588 | train_loss : 14422.2763671875 | val_loss : 14699.826171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 589 | train_loss : 14088.2060546875 | val_loss : 19363.421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 590 | train_loss : 12763.39453125 | val_loss : 14299.1064453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 591 | train_loss : 9095.0771484375 | val_loss : 11250.4697265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 592 | train_loss : 17846.232421875 | val_loss : 23130.376953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 593 | train_loss : 18613.052734375 | val_loss : 18278.865234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 594 | train_loss : 16983.466796875 | val_loss : 21220.900390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 595 | train_loss : 16968.837890625 | val_loss : 10413.4560546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 596 | train_loss : 13155.0302734375 | val_loss : 10211.3134765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 597 | train_loss : 9978.4287109375 | val_loss : 8196.91015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 598 | train_loss : 7978.9931640625 | val_loss : 11421.2314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 599 | train_loss : 18027.953125 | val_loss : 26189.0859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 600 | train_loss : 19162.546875 | val_loss : 12416.7158203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 601 | train_loss : 11491.67578125 | val_loss : 23898.98046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 602 | train_loss : 17516.734375 | val_loss : 15486.677734375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 603 | train_loss : 23433.47265625 | val_loss : 35211.75390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 604 | train_loss : 19271.4765625 | val_loss : 21295.828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 605 | train_loss : 15832.17578125 | val_loss : 23999.373046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 606 | train_loss : 20013.4296875 | val_loss : 7966.3564453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 607 | train_loss : 12270.755859375 | val_loss : 10990.4384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 608 | train_loss : 8854.681640625 | val_loss : 16733.08203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 609 | train_loss : 14617.462890625 | val_loss : 12600.71484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 610 | train_loss : 12797.6552734375 | val_loss : 7547.61767578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 611 | train_loss : 7186.05615234375 | val_loss : 19110.783203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 612 | train_loss : 10619.8662109375 | val_loss : 14625.7802734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 613 | train_loss : 17946.203125 | val_loss : 15077.4296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 614 | train_loss : 13705.2099609375 | val_loss : 10311.697265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 615 | train_loss : 10204.8935546875 | val_loss : 22775.703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 616 | train_loss : 13690.0888671875 | val_loss : 8090.1435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 617 | train_loss : 9730.25 | val_loss : 18633.33203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 618 | train_loss : 15079.677734375 | val_loss : 12718.3583984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 619 | train_loss : 18068.48828125 | val_loss : 23154.009765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 620 | train_loss : 16056.5751953125 | val_loss : 17069.60546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 621 | train_loss : 16122.263671875 | val_loss : 12999.6513671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 622 | train_loss : 13487.322265625 | val_loss : 9495.4853515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 623 | train_loss : 14816.9814453125 | val_loss : 450041.03125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 624 | train_loss : 283020.3125 | val_loss : 146953.546875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 625 | train_loss : 151246.6875 | val_loss : 105412.3125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 626 | train_loss : 122589.8203125 | val_loss : 74324.3515625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 627 | train_loss : 86555.9921875 | val_loss : 77308.328125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 628 | train_loss : 69738.609375 | val_loss : 40189.37109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 629 | train_loss : 45444.33984375 | val_loss : 34619.5859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 630 | train_loss : 34269.60546875 | val_loss : 24131.57421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 631 | train_loss : 30107.6015625 | val_loss : 27749.57421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 632 | train_loss : 24024.517578125 | val_loss : 15422.599609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 633 | train_loss : 13512.728515625 | val_loss : 13760.892578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 634 | train_loss : 13464.1220703125 | val_loss : 31284.83203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 635 | train_loss : 34273.48046875 | val_loss : 27376.0859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 636 | train_loss : 20426.08203125 | val_loss : 10862.7138671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 637 | train_loss : 15581.91796875 | val_loss : 24170.283203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 638 | train_loss : 20831.349609375 | val_loss : 18184.056640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 639 | train_loss : 22067.45703125 | val_loss : 27410.904296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 640 | train_loss : 20882.111328125 | val_loss : 37880.91796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 641 | train_loss : 35274.32421875 | val_loss : 15353.607421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 642 | train_loss : 27615.625 | val_loss : 10330.9287109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 643 | train_loss : 13107.7490234375 | val_loss : 10630.58984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 644 | train_loss : 14143.4912109375 | val_loss : 19189.806640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 645 | train_loss : 15345.0771484375 | val_loss : 6912.47265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 646 | train_loss : 8474.1015625 | val_loss : 8851.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 647 | train_loss : 8885.8212890625 | val_loss : 17567.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 648 | train_loss : 11132.60546875 | val_loss : 16207.9775390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 649 | train_loss : 14699.603515625 | val_loss : 4627.8623046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 650 | train_loss : 13544.52734375 | val_loss : 10286.201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 651 | train_loss : 11125.5166015625 | val_loss : 33318.5703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 652 | train_loss : 35980.48046875 | val_loss : 12635.58203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 653 | train_loss : 19542.724609375 | val_loss : 5678.39013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 654 | train_loss : 14441.9462890625 | val_loss : 18186.404296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 655 | train_loss : 12232.92578125 | val_loss : 8419.2939453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 656 | train_loss : 8578.576171875 | val_loss : 8770.833984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 657 | train_loss : 12063.9326171875 | val_loss : 11370.416015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 658 | train_loss : 9601.9873046875 | val_loss : 7955.1650390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 659 | train_loss : 7592.52978515625 | val_loss : 5298.59619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 660 | train_loss : 8616.37890625 | val_loss : 7850.25146484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 661 | train_loss : 6220.1455078125 | val_loss : 8796.1240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 662 | train_loss : 7562.6181640625 | val_loss : 9081.7626953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 663 | train_loss : 11701.4990234375 | val_loss : 19281.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 664 | train_loss : 14068.03125 | val_loss : 11410.2529296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 665 | train_loss : 16693.068359375 | val_loss : 22737.734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 666 | train_loss : 14534.5478515625 | val_loss : 19089.001953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 667 | train_loss : 20744.7265625 | val_loss : 30010.650390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 668 | train_loss : 21395.443359375 | val_loss : 13857.65625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 669 | train_loss : 16168.6611328125 | val_loss : 22238.259765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 670 | train_loss : 17191.07421875 | val_loss : 6447.09228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 671 | train_loss : 10877.93359375 | val_loss : 8627.62890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 672 | train_loss : 7584.35888671875 | val_loss : 5669.0224609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 673 | train_loss : 6960.9462890625 | val_loss : 10424.65234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 674 | train_loss : 8204.7685546875 | val_loss : 8866.5322265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 675 | train_loss : 10167.724609375 | val_loss : 7767.955078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 676 | train_loss : 10744.43359375 | val_loss : 10851.5849609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 677 | train_loss : 10459.1591796875 | val_loss : 10307.48828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 678 | train_loss : 14344.7734375 | val_loss : 21620.310546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 679 | train_loss : 12596.669921875 | val_loss : 13586.40625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 680 | train_loss : 8962.7275390625 | val_loss : 6005.81396484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 681 | train_loss : 9905.95703125 | val_loss : 8339.74609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 682 | train_loss : 8401.0673828125 | val_loss : 10291.259765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 683 | train_loss : 8225.7890625 | val_loss : 5417.21240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 684 | train_loss : 11349.943359375 | val_loss : 8294.607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 685 | train_loss : 9347.7724609375 | val_loss : 10876.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 686 | train_loss : 10343.5927734375 | val_loss : 6741.3251953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 687 | train_loss : 12470.455078125 | val_loss : 24572.052734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 688 | train_loss : 17310.994140625 | val_loss : 12989.0478515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 689 | train_loss : 16242.552734375 | val_loss : 18068.087890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 690 | train_loss : 16689.533203125 | val_loss : 6432.5576171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 691 | train_loss : 13458.9599609375 | val_loss : 12697.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 692 | train_loss : 9330.8740234375 | val_loss : 8180.544921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 693 | train_loss : 8627.06640625 | val_loss : 5239.28369140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 694 | train_loss : 9586.3447265625 | val_loss : 5600.4736328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 695 | train_loss : 6815.22509765625 | val_loss : 8435.8271484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 696 | train_loss : 7783.22607421875 | val_loss : 4701.13232421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 697 | train_loss : 6878.37548828125 | val_loss : 17413.26953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 698 | train_loss : 12034.486328125 | val_loss : 5061.60888671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 699 | train_loss : 8575.1962890625 | val_loss : 16473.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 700 | train_loss : 12270.7841796875 | val_loss : 9285.7626953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 701 | train_loss : 15294.5546875 | val_loss : 22289.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 702 | train_loss : 16685.875 | val_loss : 8574.4287109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 703 | train_loss : 12030.48046875 | val_loss : 21564.142578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 704 | train_loss : 13852.6220703125 | val_loss : 11089.990234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 705 | train_loss : 14579.0322265625 | val_loss : 13283.92578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 706 | train_loss : 11185.0234375 | val_loss : 13821.3623046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 707 | train_loss : 13901.2470703125 | val_loss : 5419.40478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 708 | train_loss : 8534.75 | val_loss : 36350.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 709 | train_loss : 24910.30078125 | val_loss : 15926.857421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 710 | train_loss : 21692.13671875 | val_loss : 7044.99755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 711 | train_loss : 8849.9150390625 | val_loss : 11086.3603515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 712 | train_loss : 7737.68017578125 | val_loss : 6323.3076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 713 | train_loss : 10108.1455078125 | val_loss : 8160.28271484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 714 | train_loss : 9733.8359375 | val_loss : 16829.99609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 715 | train_loss : 10728.451171875 | val_loss : 4374.43505859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 716 | train_loss : 10102.5791015625 | val_loss : 15555.5029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 717 | train_loss : 12127.0986328125 | val_loss : 7357.37353515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 718 | train_loss : 8511.626953125 | val_loss : 16666.24609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 719 | train_loss : 10360.4609375 | val_loss : 7506.33251953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 720 | train_loss : 13832.634765625 | val_loss : 16326.888671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 721 | train_loss : 12681.9208984375 | val_loss : 12297.263671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 722 | train_loss : 12386.66015625 | val_loss : 7527.982421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 723 | train_loss : 6436.4287109375 | val_loss : 3993.99365234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 724 | train_loss : 11899.14453125 | val_loss : 15639.6650390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 725 | train_loss : 12208.9501953125 | val_loss : 9955.4736328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 726 | train_loss : 11840.0009765625 | val_loss : 7157.18994140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 727 | train_loss : 7807.32763671875 | val_loss : 7152.3037109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 728 | train_loss : 9140.353515625 | val_loss : 8842.6787109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 729 | train_loss : 7639.72998046875 | val_loss : 5915.43603515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 730 | train_loss : 11196.8896484375 | val_loss : 22851.533203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 731 | train_loss : 13696.3447265625 | val_loss : 17543.595703125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 732 | train_loss : 13690.8759765625 | val_loss : 8203.4970703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 733 | train_loss : 14468.3603515625 | val_loss : 7658.4462890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 734 | train_loss : 10755.6689453125 | val_loss : 7976.49853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 735 | train_loss : 6173.8662109375 | val_loss : 4625.52978515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 736 | train_loss : 8507.6865234375 | val_loss : 15898.5888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 737 | train_loss : 9646.607421875 | val_loss : 5985.19140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 738 | train_loss : 7994.24951171875 | val_loss : 4605.1201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 739 | train_loss : 7731.45361328125 | val_loss : 5171.77392578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 740 | train_loss : 5677.193359375 | val_loss : 5048.35107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 741 | train_loss : 7610.04736328125 | val_loss : 14667.861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 742 | train_loss : 11564.0908203125 | val_loss : 5764.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 743 | train_loss : 9706.828125 | val_loss : 13413.1328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 744 | train_loss : 12370.5986328125 | val_loss : 13383.3984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 745 | train_loss : 13818.9609375 | val_loss : 8487.42578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 746 | train_loss : 13143.0986328125 | val_loss : 16720.60546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 747 | train_loss : 12166.6552734375 | val_loss : 18187.00390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 748 | train_loss : 12802.7666015625 | val_loss : 6348.85498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 749 | train_loss : 13889.9052734375 | val_loss : 6553.833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 750 | train_loss : 9867.337890625 | val_loss : 6379.2763671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 751 | train_loss : 5418.36669921875 | val_loss : 4789.65234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 752 | train_loss : 8417.5732421875 | val_loss : 14629.0009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 753 | train_loss : 9094.1513671875 | val_loss : 6286.37255859375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 754 | train_loss : 8157.48291015625 | val_loss : 7975.96240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 755 | train_loss : 6729.09619140625 | val_loss : 3677.820068359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 756 | train_loss : 10713.2734375 | val_loss : 13049.6708984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 757 | train_loss : 11411.05078125 | val_loss : 11499.8974609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 758 | train_loss : 11889.9541015625 | val_loss : 4013.93994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 759 | train_loss : 7104.72705078125 | val_loss : 9302.2314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 760 | train_loss : 8274.3134765625 | val_loss : 4369.103515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 761 | train_loss : 7866.81396484375 | val_loss : 12834.1162109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 762 | train_loss : 9177.8740234375 | val_loss : 14934.0771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 763 | train_loss : 10845.7470703125 | val_loss : 4543.42138671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 764 | train_loss : 7222.9814453125 | val_loss : 5323.927734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 765 | train_loss : 5705.77490234375 | val_loss : 4825.60888671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 766 | train_loss : 5343.85009765625 | val_loss : 2816.419921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 767 | train_loss : 5564.125 | val_loss : 7498.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 768 | train_loss : 6235.47509765625 | val_loss : 5327.013671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 769 | train_loss : 6778.83935546875 | val_loss : 16426.38671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 770 | train_loss : 10890.8466796875 | val_loss : 16341.06640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 771 | train_loss : 12386.5283203125 | val_loss : 9644.2724609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 772 | train_loss : 10237.30859375 | val_loss : 5712.57763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 773 | train_loss : 9180.4208984375 | val_loss : 14694.3486328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 774 | train_loss : 10268.986328125 | val_loss : 4349.25634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 775 | train_loss : 8344.8095703125 | val_loss : 9463.0908203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 776 | train_loss : 8997.09765625 | val_loss : 6689.84130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 777 | train_loss : 8257.255859375 | val_loss : 12182.306640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 778 | train_loss : 8762.2734375 | val_loss : 6760.419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 779 | train_loss : 11466.755859375 | val_loss : 9293.0810546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 780 | train_loss : 8961.025390625 | val_loss : 10114.6396484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 781 | train_loss : 9468.8017578125 | val_loss : 5067.9775390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 782 | train_loss : 7790.025390625 | val_loss : 4458.87646484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 783 | train_loss : 6864.55517578125 | val_loss : 8681.25390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 784 | train_loss : 8608.9677734375 | val_loss : 7318.388671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 785 | train_loss : 10097.39453125 | val_loss : 19785.16796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 786 | train_loss : 11507.1484375 | val_loss : 9318.1416015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 787 | train_loss : 9770.5654296875 | val_loss : 14356.6962890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 788 | train_loss : 12140.2373046875 | val_loss : 7430.08642578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 789 | train_loss : 9884.20703125 | val_loss : 18921.85546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 790 | train_loss : 12266.4609375 | val_loss : 5152.00732421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 791 | train_loss : 9440.4091796875 | val_loss : 13086.19921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 792 | train_loss : 9200.1064453125 | val_loss : 8770.388671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 793 | train_loss : 8482.5830078125 | val_loss : 11693.087890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 794 | train_loss : 7785.04052734375 | val_loss : 5578.267578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 795 | train_loss : 9778.01953125 | val_loss : 7250.21728515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 796 | train_loss : 7670.98388671875 | val_loss : 7524.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 797 | train_loss : 7141.93017578125 | val_loss : 4975.25732421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 798 | train_loss : 11357.8408203125 | val_loss : 13134.97265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 799 | train_loss : 10900.14453125 | val_loss : 10690.4677734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 800 | train_loss : 11510.62890625 | val_loss : 5267.61865234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 801 | train_loss : 8544.908203125 | val_loss : 13983.7236328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 802 | train_loss : 8801.693359375 | val_loss : 5672.67138671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 803 | train_loss : 9531.7666015625 | val_loss : 12234.6845703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 804 | train_loss : 10649.75390625 | val_loss : 5744.4462890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 805 | train_loss : 8790.806640625 | val_loss : 15273.0322265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 806 | train_loss : 11188.6748046875 | val_loss : 7546.826171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 807 | train_loss : 10854.1416015625 | val_loss : 16574.603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 808 | train_loss : 11131.3427734375 | val_loss : 4445.31640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 809 | train_loss : 8039.4462890625 | val_loss : 14597.142578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 810 | train_loss : 9290.177734375 | val_loss : 3143.847412109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 811 | train_loss : 6736.91357421875 | val_loss : 10450.8388671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 812 | train_loss : 7770.111328125 | val_loss : 5888.72607421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 813 | train_loss : 7757.29736328125 | val_loss : 11772.3251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 814 | train_loss : 7650.52294921875 | val_loss : 1821.666259765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 815 | train_loss : 8701.3798828125 | val_loss : 8818.6689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 816 | train_loss : 7398.2626953125 | val_loss : 5918.8486328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 817 | train_loss : 6385.5283203125 | val_loss : 3721.46630859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 818 | train_loss : 6669.78564453125 | val_loss : 2887.248779296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 819 | train_loss : 4435.60498046875 | val_loss : 4683.22021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 820 | train_loss : 5013.01806640625 | val_loss : 5354.3037109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 821 | train_loss : 5925.27490234375 | val_loss : 7367.802734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 822 | train_loss : 5862.27490234375 | val_loss : 4754.2724609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 823 | train_loss : 5290.49853515625 | val_loss : 7527.49267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 824 | train_loss : 6080.09423828125 | val_loss : 2477.7587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 825 | train_loss : 9199.3291015625 | val_loss : 15916.6259765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 826 | train_loss : 12745.1064453125 | val_loss : 11931.37890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 827 | train_loss : 12469.9462890625 | val_loss : 6346.23876953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 828 | train_loss : 12198.7236328125 | val_loss : 10550.61328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 829 | train_loss : 8243.6259765625 | val_loss : 6268.22265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 830 | train_loss : 8366.9677734375 | val_loss : 18210.8046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 831 | train_loss : 9594.04296875 | val_loss : 12838.0478515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 832 | train_loss : 11756.3427734375 | val_loss : 13419.85546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 833 | train_loss : 10213.3134765625 | val_loss : 5178.19140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 834 | train_loss : 6659.73486328125 | val_loss : 7547.6962890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 835 | train_loss : 7869.48046875 | val_loss : 4107.65234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 836 | train_loss : 9711.9296875 | val_loss : 5243.9873046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 837 | train_loss : 6989.943359375 | val_loss : 10814.017578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 838 | train_loss : 10526.09375 | val_loss : 5387.5361328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 839 | train_loss : 10276.185546875 | val_loss : 14955.076171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 840 | train_loss : 10285.591796875 | val_loss : 8058.6435546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 841 | train_loss : 9156.146484375 | val_loss : 15059.8095703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 842 | train_loss : 12124.59765625 | val_loss : 7751.41357421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 843 | train_loss : 11409.1591796875 | val_loss : 43103.08984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 844 | train_loss : 38791.34375 | val_loss : 14550.0009765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 845 | train_loss : 15168.58984375 | val_loss : 6081.052734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 846 | train_loss : 10705.2509765625 | val_loss : 7103.625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 847 | train_loss : 9154.13671875 | val_loss : 10681.318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 848 | train_loss : 8339.47265625 | val_loss : 6718.10986328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 849 | train_loss : 7578.958984375 | val_loss : 9247.7353515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 850 | train_loss : 7064.64208984375 | val_loss : 7509.77880859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 851 | train_loss : 7809.69384765625 | val_loss : 7433.87890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 852 | train_loss : 6019.33984375 | val_loss : 4308.3974609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 853 | train_loss : 6719.46630859375 | val_loss : 15718.130859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 854 | train_loss : 11350.7373046875 | val_loss : 3104.31005859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 855 | train_loss : 6674.75634765625 | val_loss : 11313.57421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 856 | train_loss : 9571.40234375 | val_loss : 5567.13232421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 857 | train_loss : 10471.16015625 | val_loss : 15536.380859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 858 | train_loss : 10977.666015625 | val_loss : 6643.677734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 859 | train_loss : 8046.70947265625 | val_loss : 8372.3603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 860 | train_loss : 7931.01611328125 | val_loss : 32646.966796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 861 | train_loss : 35013.30078125 | val_loss : 29026.470703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 862 | train_loss : 23608.58984375 | val_loss : 14790.25390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 863 | train_loss : 16579.8125 | val_loss : 22882.515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 864 | train_loss : 16458.62890625 | val_loss : 11078.2001953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 865 | train_loss : 14430.302734375 | val_loss : 18537.76171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 866 | train_loss : 12237.431640625 | val_loss : 11490.01171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 867 | train_loss : 8077.5712890625 | val_loss : 7237.830078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 868 | train_loss : 6870.49365234375 | val_loss : 2360.836181640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 869 | train_loss : 7992.31494140625 | val_loss : 28005.75 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 870 | train_loss : 23062.85546875 | val_loss : 19690.42578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 871 | train_loss : 21202.560546875 | val_loss : 7831.455078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 872 | train_loss : 15422.2236328125 | val_loss : 6846.642578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 873 | train_loss : 7167.95556640625 | val_loss : 6050.34619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 874 | train_loss : 6976.94482421875 | val_loss : 13844.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 875 | train_loss : 9703.6796875 | val_loss : 5434.9013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 876 | train_loss : 8052.79052734375 | val_loss : 6969.33642578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 877 | train_loss : 7880.3154296875 | val_loss : 6578.55859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 878 | train_loss : 5951.91748046875 | val_loss : 3628.97998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 879 | train_loss : 7026.31640625 | val_loss : 11436.2822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 880 | train_loss : 7980.58984375 | val_loss : 4311.46142578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 881 | train_loss : 5957.04443359375 | val_loss : 8766.7509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 882 | train_loss : 6740.2939453125 | val_loss : 5134.4150390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 883 | train_loss : 8741.01171875 | val_loss : 10937.2021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 884 | train_loss : 9503.2880859375 | val_loss : 7442.72021484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 885 | train_loss : 8600.3876953125 | val_loss : 8617.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 886 | train_loss : 7396.64892578125 | val_loss : 7228.19140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 887 | train_loss : 8178.53857421875 | val_loss : 4600.0087890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 888 | train_loss : 6541.9443359375 | val_loss : 4060.385009765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 889 | train_loss : 5305.99609375 | val_loss : 10550.431640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 890 | train_loss : 7368.88134765625 | val_loss : 3388.764892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 891 | train_loss : 8703.2724609375 | val_loss : 10675.5146484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 892 | train_loss : 8928.0048828125 | val_loss : 12908.880859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 893 | train_loss : 12035.6103515625 | val_loss : 7403.08740234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 894 | train_loss : 11515.52734375 | val_loss : 13262.728515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 895 | train_loss : 11633.8095703125 | val_loss : 16031.5947265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 896 | train_loss : 9633.2880859375 | val_loss : 2661.675048828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 897 | train_loss : 4868.07421875 | val_loss : 5969.888671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 898 | train_loss : 6869.51806640625 | val_loss : 3063.22998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 899 | train_loss : 7420.00146484375 | val_loss : 6910.7939453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 900 | train_loss : 5698.97509765625 | val_loss : 6259.666015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 901 | train_loss : 7133.70166015625 | val_loss : 3039.4462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 902 | train_loss : 7589.693359375 | val_loss : 4069.078857421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 903 | train_loss : 5346.669921875 | val_loss : 5442.28125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 904 | train_loss : 6030.7294921875 | val_loss : 7603.81396484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 905 | train_loss : 7675.39111328125 | val_loss : 5052.96240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 906 | train_loss : 8185.04052734375 | val_loss : 11729.169921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 907 | train_loss : 9018.9287109375 | val_loss : 13312.6484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 908 | train_loss : 8760.2666015625 | val_loss : 3160.717529296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 909 | train_loss : 6146.79931640625 | val_loss : 5594.7275390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 910 | train_loss : 5834.64697265625 | val_loss : 3345.092529296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 911 | train_loss : 4398.29931640625 | val_loss : 3238.0673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 912 | train_loss : 6473.47509765625 | val_loss : 10224.28515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 913 | train_loss : 7120.92626953125 | val_loss : 4590.2412109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 914 | train_loss : 4926.03369140625 | val_loss : 7984.92236328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 915 | train_loss : 6906.4951171875 | val_loss : 2647.489990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 916 | train_loss : 4022.318359375 | val_loss : 6875.0 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 917 | train_loss : 7127.201171875 | val_loss : 4984.15771484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 918 | train_loss : 7219.50048828125 | val_loss : 9391.44921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 919 | train_loss : 5743.7685546875 | val_loss : 8734.537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 920 | train_loss : 5674.232421875 | val_loss : 4666.47265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 921 | train_loss : 8141.70703125 | val_loss : 10300.83984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 922 | train_loss : 8406.4677734375 | val_loss : 8819.40234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 923 | train_loss : 9383.7177734375 | val_loss : 10609.4052734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 924 | train_loss : 8747.12109375 | val_loss : 3523.219970703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 925 | train_loss : 7154.42626953125 | val_loss : 6947.150390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 926 | train_loss : 7896.21240234375 | val_loss : 6723.666015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 927 | train_loss : 6541.2861328125 | val_loss : 4686.439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 928 | train_loss : 7380.93310546875 | val_loss : 6761.21142578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 929 | train_loss : 6373.595703125 | val_loss : 5547.08203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 930 | train_loss : 8245.3779296875 | val_loss : 8586.8525390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 931 | train_loss : 8377.705078125 | val_loss : 6348.40478515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 932 | train_loss : 8011.27294921875 | val_loss : 13617.697265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 933 | train_loss : 8224.548828125 | val_loss : 10151.8095703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 934 | train_loss : 9087.271484375 | val_loss : 5088.3564453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 935 | train_loss : 5679.51513671875 | val_loss : 3521.16064453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 936 | train_loss : 5819.22314453125 | val_loss : 27348.212890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 937 | train_loss : 19038.328125 | val_loss : 10082.447265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 938 | train_loss : 12655.7763671875 | val_loss : 4433.7099609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 939 | train_loss : 5419.24853515625 | val_loss : 4007.738037109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 940 | train_loss : 4080.434326171875 | val_loss : 2926.188720703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 941 | train_loss : 5428.935546875 | val_loss : 12930.568359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 942 | train_loss : 9316.34375 | val_loss : 4759.5 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 943 | train_loss : 6108.65673828125 | val_loss : 12534.7021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 944 | train_loss : 8249.1416015625 | val_loss : 3730.166259765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 945 | train_loss : 7969.060546875 | val_loss : 11103.65234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 946 | train_loss : 8808.2587890625 | val_loss : 8636.517578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 947 | train_loss : 9587.072265625 | val_loss : 12056.927734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 948 | train_loss : 8553.916015625 | val_loss : 6752.79736328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 949 | train_loss : 9564.8046875 | val_loss : 8597.7548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 950 | train_loss : 8428.16796875 | val_loss : 10121.71875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 951 | train_loss : 8952.5869140625 | val_loss : 4703.93505859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 952 | train_loss : 8276.701171875 | val_loss : 5416.5888671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 953 | train_loss : 6767.43115234375 | val_loss : 8620.1572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 954 | train_loss : 7326.63818359375 | val_loss : 4513.22119140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 955 | train_loss : 7106.65673828125 | val_loss : 11169.583984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 956 | train_loss : 7103.5244140625 | val_loss : 4439.5625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 957 | train_loss : 6297.712890625 | val_loss : 9410.2412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 958 | train_loss : 8589.255859375 | val_loss : 4719.78271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 959 | train_loss : 6505.083984375 | val_loss : 7310.146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 960 | train_loss : 4780.06201171875 | val_loss : 2361.82373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 961 | train_loss : 5959.4375 | val_loss : 11370.771484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 962 | train_loss : 7745.04638671875 | val_loss : 4655.3837890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 963 | train_loss : 6478.0537109375 | val_loss : 8354.287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 964 | train_loss : 6111.66552734375 | val_loss : 2179.775146484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 965 | train_loss : 6356.2587890625 | val_loss : 7362.75830078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 966 | train_loss : 6414.60205078125 | val_loss : 3376.199951171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 967 | train_loss : 4267.1982421875 | val_loss : 5297.20751953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 968 | train_loss : 5023.89111328125 | val_loss : 2338.482421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 969 | train_loss : 4702.208984375 | val_loss : 6642.62744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 970 | train_loss : 5859.58984375 | val_loss : 4587.99365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 971 | train_loss : 6423.28125 | val_loss : 73085.7578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 972 | train_loss : 58833.44140625 | val_loss : 10432.837890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 973 | train_loss : 9242.6298828125 | val_loss : 17285.91796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 974 | train_loss : 15863.02734375 | val_loss : 11216.525390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 975 | train_loss : 15219.05078125 | val_loss : 12027.29296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 976 | train_loss : 10141.4697265625 | val_loss : 11474.982421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 977 | train_loss : 12452.5849609375 | val_loss : 12841.240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 978 | train_loss : 12338.5712890625 | val_loss : 8544.412109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 979 | train_loss : 10221.298828125 | val_loss : 12681.576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 980 | train_loss : 9553.380859375 | val_loss : 3599.148193359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 981 | train_loss : 5817.3642578125 | val_loss : 6706.982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 982 | train_loss : 6351.20361328125 | val_loss : 4216.615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 983 | train_loss : 4804.1982421875 | val_loss : 4656.19482421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 984 | train_loss : 5161.08642578125 | val_loss : 2684.552490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 985 | train_loss : 7297.68505859375 | val_loss : 7417.9345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 986 | train_loss : 6504.3623046875 | val_loss : 4983.982421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 987 | train_loss : 5332.07373046875 | val_loss : 3458.30322265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 988 | train_loss : 6177.21484375 | val_loss : 3821.4638671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 989 | train_loss : 4083.211181640625 | val_loss : 3554.6767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 990 | train_loss : 4729.439453125 | val_loss : 9632.037109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 991 | train_loss : 6867.57958984375 | val_loss : 4041.232421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 992 | train_loss : 3842.289306640625 | val_loss : 2954.3125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 993 | train_loss : 3776.655517578125 | val_loss : 2790.205078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 994 | train_loss : 4780.15869140625 | val_loss : 3447.922607421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 995 | train_loss : 4279.83837890625 | val_loss : 3888.684326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 996 | train_loss : 2916.503662109375 | val_loss : 3566.771240234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 997 | train_loss : 4686.23388671875 | val_loss : 11598.1123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 998 | train_loss : 7574.94189453125 | val_loss : 2579.32373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 999 | train_loss : 4572.4111328125 | val_loss : 7240.9755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1000 | train_loss : 5727.56884765625 | val_loss : 2576.378662109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1001 | train_loss : 5453.0205078125 | val_loss : 7847.0712890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1002 | train_loss : 6600.59130859375 | val_loss : 3791.7763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1003 | train_loss : 4684.025390625 | val_loss : 6114.40576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1004 | train_loss : 5628.08984375 | val_loss : 12210.603515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1005 | train_loss : 7896.6337890625 | val_loss : 8640.798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1006 | train_loss : 8662.3583984375 | val_loss : 5296.58984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1007 | train_loss : 5058.9306640625 | val_loss : 4642.279296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1008 | train_loss : 4686.6845703125 | val_loss : 9568.1484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1009 | train_loss : 6147.919921875 | val_loss : 5139.25634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1010 | train_loss : 7054.75634765625 | val_loss : 4700.21142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1011 | train_loss : 5047.0576171875 | val_loss : 3827.5888671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1012 | train_loss : 3071.745849609375 | val_loss : 2911.8173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1013 | train_loss : 5495.154296875 | val_loss : 5699.06396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1014 | train_loss : 5458.8349609375 | val_loss : 11394.0771484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1015 | train_loss : 7340.33984375 | val_loss : 3782.50927734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1016 | train_loss : 5090.8291015625 | val_loss : 4578.8525390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1017 | train_loss : 4352.205078125 | val_loss : 3473.023681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1018 | train_loss : 3437.564697265625 | val_loss : 6464.27880859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1019 | train_loss : 6003.1943359375 | val_loss : 4425.00732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1020 | train_loss : 5939.52197265625 | val_loss : 4876.2587890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1021 | train_loss : 7315.51611328125 | val_loss : 15154.5537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1022 | train_loss : 11334.599609375 | val_loss : 6271.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1023 | train_loss : 8008.517578125 | val_loss : 12169.830078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1024 | train_loss : 7943.3037109375 | val_loss : 8073.57763671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1025 | train_loss : 8241.005859375 | val_loss : 11020.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1026 | train_loss : 7859.33935546875 | val_loss : 4697.35498046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1027 | train_loss : 6265.81884765625 | val_loss : 9514.837890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1028 | train_loss : 7070.4013671875 | val_loss : 4201.34130859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1029 | train_loss : 5489.34765625 | val_loss : 9490.900390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1030 | train_loss : 8705.533203125 | val_loss : 4575.84375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1031 | train_loss : 6738.353515625 | val_loss : 10664.79296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1032 | train_loss : 6298.36083984375 | val_loss : 3268.54248046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1033 | train_loss : 6091.16943359375 | val_loss : 10402.87109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1034 | train_loss : 8215.85546875 | val_loss : 5678.56982421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1035 | train_loss : 7366.767578125 | val_loss : 12717.81640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1036 | train_loss : 7892.009765625 | val_loss : 3716.1611328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1037 | train_loss : 5938.8408203125 | val_loss : 10082.7548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1038 | train_loss : 7372.95556640625 | val_loss : 4687.697265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1039 | train_loss : 6683.60888671875 | val_loss : 9389.76953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1040 | train_loss : 6298.47607421875 | val_loss : 3678.72998046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1041 | train_loss : 6047.6923828125 | val_loss : 7929.8076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1042 | train_loss : 6914.0361328125 | val_loss : 5851.81103515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1043 | train_loss : 6094.31494140625 | val_loss : 10165.416015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1044 | train_loss : 7362.548828125 | val_loss : 3402.771240234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1045 | train_loss : 7408.72021484375 | val_loss : 7177.53125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1046 | train_loss : 6865.572265625 | val_loss : 6710.07958984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1047 | train_loss : 5897.7412109375 | val_loss : 2946.4287109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1048 | train_loss : 5743.43017578125 | val_loss : 7758.134765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1049 | train_loss : 5712.93603515625 | val_loss : 3522.782470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1050 | train_loss : 3609.37939453125 | val_loss : 3174.9775390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1051 | train_loss : 6040.033203125 | val_loss : 7315.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1052 | train_loss : 5379.14013671875 | val_loss : 4881.48388671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1053 | train_loss : 6446.623046875 | val_loss : 9092.8623046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1054 | train_loss : 6525.55322265625 | val_loss : 3007.02685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1055 | train_loss : 5499.513671875 | val_loss : 5665.7724609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1056 | train_loss : 5066.95947265625 | val_loss : 2251.280029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1057 | train_loss : 3387.08056640625 | val_loss : 2615.71630859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1058 | train_loss : 4305.32666015625 | val_loss : 7685.72119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1059 | train_loss : 5098.828125 | val_loss : 3431.308837890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1060 | train_loss : 3085.05029296875 | val_loss : 9522.2763671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1061 | train_loss : 6118.03173828125 | val_loss : 4168.00390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1062 | train_loss : 5112.515625 | val_loss : 3767.572509765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1063 | train_loss : 4650.3876953125 | val_loss : 4490.83056640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1064 | train_loss : 3159.423828125 | val_loss : 2891.114990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1065 | train_loss : 5661.77734375 | val_loss : 8886.90234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1066 | train_loss : 5689.84130859375 | val_loss : 4023.60498046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1067 | train_loss : 5101.2099609375 | val_loss : 5317.48681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1068 | train_loss : 3936.5361328125 | val_loss : 1703.0262451171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1069 | train_loss : 5427.70947265625 | val_loss : 8281.3984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1070 | train_loss : 5493.62255859375 | val_loss : 5239.7294921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1071 | train_loss : 6273.47705078125 | val_loss : 2648.168701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1072 | train_loss : 2292.578369140625 | val_loss : 1242.5775146484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1073 | train_loss : 2724.12060546875 | val_loss : 5739.458984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1074 | train_loss : 4481.19189453125 | val_loss : 1441.37255859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1075 | train_loss : 5169.84619140625 | val_loss : 7434.6064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1076 | train_loss : 4361.08154296875 | val_loss : 3564.76123046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1077 | train_loss : 5765.76513671875 | val_loss : 8894.7724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1078 | train_loss : 7627.9150390625 | val_loss : 4615.302734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1079 | train_loss : 6881.04833984375 | val_loss : 7640.49365234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1080 | train_loss : 5441.2705078125 | val_loss : 9995.0302734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1081 | train_loss : 10047.0654296875 | val_loss : 6530.10986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1082 | train_loss : 7393.236328125 | val_loss : 3654.314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1083 | train_loss : 6134.7080078125 | val_loss : 9157.943359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1084 | train_loss : 7249.18994140625 | val_loss : 4512.58203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1085 | train_loss : 5889.95263671875 | val_loss : 5972.611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1086 | train_loss : 6786.5712890625 | val_loss : 4760.66064453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1087 | train_loss : 5350.61083984375 | val_loss : 6073.5751953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1088 | train_loss : 6049.32763671875 | val_loss : 3521.830078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1089 | train_loss : 6587.2548828125 | val_loss : 4272.96484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1090 | train_loss : 5435.68359375 | val_loss : 6749.33740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1091 | train_loss : 5890.54541015625 | val_loss : 3945.958740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1092 | train_loss : 7502.87451171875 | val_loss : 4487.5087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1093 | train_loss : 6259.47998046875 | val_loss : 6030.349609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1094 | train_loss : 4485.46142578125 | val_loss : 1943.19873046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1095 | train_loss : 3412.048828125 | val_loss : 7449.75390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1096 | train_loss : 5633.41064453125 | val_loss : 2671.5712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1097 | train_loss : 3423.43212890625 | val_loss : 8849.12890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1098 | train_loss : 5194.24169921875 | val_loss : 1485.60498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1099 | train_loss : 3059.73095703125 | val_loss : 4421.45263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1100 | train_loss : 3695.1044921875 | val_loss : 3673.086181640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1101 | train_loss : 4101.548828125 | val_loss : 5002.31396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1102 | train_loss : 4013.8017578125 | val_loss : 1643.02001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1103 | train_loss : 3887.176513671875 | val_loss : 6676.564453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1104 | train_loss : 4739.2607421875 | val_loss : 2703.64990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1105 | train_loss : 5209.119140625 | val_loss : 9189.755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1106 | train_loss : 5026.65576171875 | val_loss : 4920.3173828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1107 | train_loss : 6529.6513671875 | val_loss : 9015.7685546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1108 | train_loss : 7318.82373046875 | val_loss : 5514.0283203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1109 | train_loss : 7147.24072265625 | val_loss : 13447.423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1110 | train_loss : 8430.2822265625 | val_loss : 3371.239990234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1111 | train_loss : 6003.35986328125 | val_loss : 5978.87255859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1112 | train_loss : 5262.521484375 | val_loss : 2968.994384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1113 | train_loss : 4007.3017578125 | val_loss : 4691.31640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1114 | train_loss : 4861.42431640625 | val_loss : 7141.3681640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1115 | train_loss : 5850.482421875 | val_loss : 2427.985107421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1116 | train_loss : 4713.67333984375 | val_loss : 4271.94140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1117 | train_loss : 3522.1875 | val_loss : 3296.2275390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1118 | train_loss : 5038.73779296875 | val_loss : 8818.216796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1119 | train_loss : 6856.27734375 | val_loss : 2683.534912109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1120 | train_loss : 3879.812255859375 | val_loss : 2743.6875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1121 | train_loss : 4129.841796875 | val_loss : 16419.396484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1122 | train_loss : 14966.5712890625 | val_loss : 6882.66064453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1123 | train_loss : 8232.0791015625 | val_loss : 8643.974609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1124 | train_loss : 7855.69873046875 | val_loss : 2991.16259765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1125 | train_loss : 4415.9091796875 | val_loss : 9564.9931640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1126 | train_loss : 6335.513671875 | val_loss : 3553.132568359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1127 | train_loss : 4584.072265625 | val_loss : 8802.7353515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1128 | train_loss : 6070.8466796875 | val_loss : 6662.03857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1129 | train_loss : 7190.85107421875 | val_loss : 6742.28857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1130 | train_loss : 6290.86767578125 | val_loss : 4681.86376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1131 | train_loss : 5235.5693359375 | val_loss : 8630.068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1132 | train_loss : 5567.548828125 | val_loss : 4381.4013671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1133 | train_loss : 6469.3701171875 | val_loss : 6754.41943359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1134 | train_loss : 4858.72802734375 | val_loss : 3827.913818359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1135 | train_loss : 4862.2568359375 | val_loss : 9252.4658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1136 | train_loss : 5351.98486328125 | val_loss : 3451.0673828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1137 | train_loss : 6118.916015625 | val_loss : 6609.00244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1138 | train_loss : 4883.08447265625 | val_loss : 2904.04443359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1139 | train_loss : 4131.2607421875 | val_loss : 10229.119140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1140 | train_loss : 6348.24853515625 | val_loss : 2735.39501953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1141 | train_loss : 5102.98046875 | val_loss : 9261.4697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1142 | train_loss : 7333.31640625 | val_loss : 4156.32861328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1143 | train_loss : 6471.64697265625 | val_loss : 12280.6162109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1144 | train_loss : 6680.271484375 | val_loss : 4990.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1145 | train_loss : 5572.7685546875 | val_loss : 8360.04296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1146 | train_loss : 6898.05078125 | val_loss : 6386.77978515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1147 | train_loss : 7076.54833984375 | val_loss : 10360.1845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1148 | train_loss : 7199.07958984375 | val_loss : 3703.800048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1149 | train_loss : 6079.21728515625 | val_loss : 7836.64697265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1150 | train_loss : 7145.455078125 | val_loss : 4950.5380859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1151 | train_loss : 5887.1826171875 | val_loss : 8164.34765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1152 | train_loss : 5820.08642578125 | val_loss : 3755.293701171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1153 | train_loss : 6411.9814453125 | val_loss : 5965.8095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1154 | train_loss : 5714.07177734375 | val_loss : 3838.23193359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1155 | train_loss : 4816.64111328125 | val_loss : 8274.6416015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1156 | train_loss : 5339.17626953125 | val_loss : 3327.2919921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1157 | train_loss : 5928.1162109375 | val_loss : 5366.619140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1158 | train_loss : 4460.6806640625 | val_loss : 2154.523193359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1159 | train_loss : 3126.328125 | val_loss : 4875.78955078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1160 | train_loss : 4061.516845703125 | val_loss : 1838.949951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1161 | train_loss : 2962.603759765625 | val_loss : 6297.78173828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1162 | train_loss : 4302.82421875 | val_loss : 1955.0587158203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1163 | train_loss : 4226.5869140625 | val_loss : 7654.228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1164 | train_loss : 4448.91943359375 | val_loss : 3520.20751953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1165 | train_loss : 5525.6376953125 | val_loss : 7187.33544921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1166 | train_loss : 6254.10302734375 | val_loss : 4893.0849609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1167 | train_loss : 6045.96142578125 | val_loss : 9499.330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1168 | train_loss : 5839.5107421875 | val_loss : 5574.4970703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1169 | train_loss : 7194.63818359375 | val_loss : 6547.453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1170 | train_loss : 5265.431640625 | val_loss : 3230.590087890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1171 | train_loss : 4687.89453125 | val_loss : 6673.92041015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1172 | train_loss : 5066.18310546875 | val_loss : 1572.3443603515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1173 | train_loss : 4372.31201171875 | val_loss : 6578.46875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1174 | train_loss : 5114.6494140625 | val_loss : 2503.090087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1175 | train_loss : 4166.41796875 | val_loss : 7905.5341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1176 | train_loss : 5361.1787109375 | val_loss : 1523.416259765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1177 | train_loss : 3740.320556640625 | val_loss : 11103.6328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1178 | train_loss : 7397.5869140625 | val_loss : 3364.125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1179 | train_loss : 5063.33251953125 | val_loss : 8931.4873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1180 | train_loss : 5834.599609375 | val_loss : 2324.2587890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1181 | train_loss : 5412.49609375 | val_loss : 9487.5107421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1182 | train_loss : 7174.40380859375 | val_loss : 3418.871337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1183 | train_loss : 4589.1513671875 | val_loss : 7519.12109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1184 | train_loss : 6328.16943359375 | val_loss : 2632.0849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1185 | train_loss : 4513.66796875 | val_loss : 6880.845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1186 | train_loss : 5066.8544921875 | val_loss : 3678.804931640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1187 | train_loss : 4189.39208984375 | val_loss : 7761.380859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1188 | train_loss : 5712.837890625 | val_loss : 3857.244384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1189 | train_loss : 6077.83740234375 | val_loss : 6233.8017578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1190 | train_loss : 6853.6435546875 | val_loss : 5091.04248046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1191 | train_loss : 4821.26416015625 | val_loss : 4466.1044921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1192 | train_loss : 6503.349609375 | val_loss : 5408.12109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1193 | train_loss : 5120.18115234375 | val_loss : 4853.55517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1194 | train_loss : 4654.724609375 | val_loss : 1508.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1195 | train_loss : 4764.484375 | val_loss : 7260.640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1196 | train_loss : 4104.38232421875 | val_loss : 4344.0576171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1197 | train_loss : 3647.972412109375 | val_loss : 5381.453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1198 | train_loss : 3908.86865234375 | val_loss : 5748.20556640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1199 | train_loss : 6258.37548828125 | val_loss : 4179.08935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1200 | train_loss : 5368.37109375 | val_loss : 7472.67626953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1201 | train_loss : 5477.94482421875 | val_loss : 3588.544921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1202 | train_loss : 5361.2119140625 | val_loss : 4506.33544921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1203 | train_loss : 4987.63134765625 | val_loss : 5507.9326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1204 | train_loss : 3945.816650390625 | val_loss : 4270.83740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1205 | train_loss : 5340.57177734375 | val_loss : 4362.64892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1206 | train_loss : 6064.45166015625 | val_loss : 2620.39306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1207 | train_loss : 3582.427490234375 | val_loss : 80316.03125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1208 | train_loss : 60301.94140625 | val_loss : 22071.806640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1209 | train_loss : 27943.169921875 | val_loss : 19889.494140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1210 | train_loss : 18416.224609375 | val_loss : 18340.85546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1211 | train_loss : 18350.9296875 | val_loss : 16975.814453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1212 | train_loss : 16305.58984375 | val_loss : 8476.8369140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1213 | train_loss : 8809.9716796875 | val_loss : 9361.025390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1214 | train_loss : 7703.10693359375 | val_loss : 5475.35302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1215 | train_loss : 4480.0029296875 | val_loss : 2564.436767578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1216 | train_loss : 4674.06982421875 | val_loss : 2510.108642578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1217 | train_loss : 3818.292236328125 | val_loss : 3427.71435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1218 | train_loss : 3181.409423828125 | val_loss : 3344.362548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1219 | train_loss : 2607.268798828125 | val_loss : 4670.69580078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1220 | train_loss : 4710.33349609375 | val_loss : 2908.427490234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1221 | train_loss : 3140.1298828125 | val_loss : 8340.6171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1222 | train_loss : 4882.0048828125 | val_loss : 1922.1287841796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1223 | train_loss : 4375.57861328125 | val_loss : 7183.50048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1224 | train_loss : 5530.5341796875 | val_loss : 3184.076171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1225 | train_loss : 4417.005859375 | val_loss : 9298.1533203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1226 | train_loss : 6211.18017578125 | val_loss : 2945.867431640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1227 | train_loss : 3921.72802734375 | val_loss : 3714.1650390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1228 | train_loss : 3711.91552734375 | val_loss : 3370.142578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1229 | train_loss : 3732.46533203125 | val_loss : 4025.498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1230 | train_loss : 3724.524658203125 | val_loss : 2380.211181640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1231 | train_loss : 3204.56494140625 | val_loss : 5560.72314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1232 | train_loss : 4629.3916015625 | val_loss : 4584.39501953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1233 | train_loss : 4131.54248046875 | val_loss : 5007.37255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1234 | train_loss : 5220.95166015625 | val_loss : 3391.783203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1235 | train_loss : 4897.09326171875 | val_loss : 3719.08740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1236 | train_loss : 3858.203125 | val_loss : 2917.356201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1237 | train_loss : 3418.383056640625 | val_loss : 6038.24853515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1238 | train_loss : 5207.6103515625 | val_loss : 4408.298828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1239 | train_loss : 5350.4423828125 | val_loss : 3165.90185546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1240 | train_loss : 3081.6240234375 | val_loss : 5809.2919921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1241 | train_loss : 4783.33642578125 | val_loss : 8112.0537109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1242 | train_loss : 6024.96142578125 | val_loss : 5579.79541015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1243 | train_loss : 4097.45703125 | val_loss : 3789.2861328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1244 | train_loss : 5733.48486328125 | val_loss : 4664.65673828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1245 | train_loss : 4007.512451171875 | val_loss : 3461.36376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1246 | train_loss : 3427.74755859375 | val_loss : 3269.5732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1247 | train_loss : 3619.9638671875 | val_loss : 5427.68310546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1248 | train_loss : 4476.96875 | val_loss : 4065.983154296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1249 | train_loss : 3269.181884765625 | val_loss : 6421.03125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1250 | train_loss : 4498.36328125 | val_loss : 4600.99951171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1251 | train_loss : 3620.788818359375 | val_loss : 3945.624267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1252 | train_loss : 4554.30078125 | val_loss : 5035.9326171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1253 | train_loss : 5217.169921875 | val_loss : 5434.23046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1254 | train_loss : 4609.87744140625 | val_loss : 6381.51513671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1255 | train_loss : 3946.6494140625 | val_loss : 1753.7181396484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1256 | train_loss : 4418.42529296875 | val_loss : 10782.490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1257 | train_loss : 6851.88623046875 | val_loss : 2482.523681640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1258 | train_loss : 4301.767578125 | val_loss : 8978.8837890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1259 | train_loss : 6186.40869140625 | val_loss : 1434.3287353515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1260 | train_loss : 5357.87255859375 | val_loss : 11096.6953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1261 | train_loss : 7122.02490234375 | val_loss : 3551.539306640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1262 | train_loss : 5830.39697265625 | val_loss : 10417.40234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1263 | train_loss : 6376.818359375 | val_loss : 1352.677490234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1264 | train_loss : 5129.04931640625 | val_loss : 8196.2568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1265 | train_loss : 5741.7275390625 | val_loss : 4155.6044921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1266 | train_loss : 5259.5087890625 | val_loss : 6002.5341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1267 | train_loss : 4779.041015625 | val_loss : 4617.494140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1268 | train_loss : 3454.083984375 | val_loss : 5410.20166015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1269 | train_loss : 4951.59228515625 | val_loss : 4243.63134765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1270 | train_loss : 3664.875244140625 | val_loss : 3573.669921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1271 | train_loss : 3081.92822265625 | val_loss : 3834.608154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1272 | train_loss : 3199.90625 | val_loss : 2666.4287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1273 | train_loss : 2991.47021484375 | val_loss : 5096.06494140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1274 | train_loss : 3663.45947265625 | val_loss : 5259.458984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1275 | train_loss : 3895.806640625 | val_loss : 3537.8837890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1276 | train_loss : 2860.297607421875 | val_loss : 4739.81689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1277 | train_loss : 3578.3359375 | val_loss : 2297.90869140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1278 | train_loss : 4250.1513671875 | val_loss : 3972.143798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1279 | train_loss : 2585.09375 | val_loss : 2970.6494140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1280 | train_loss : 4243.37939453125 | val_loss : 6450.22998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1281 | train_loss : 5123.09228515625 | val_loss : 4567.29736328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1282 | train_loss : 3754.92333984375 | val_loss : 5765.875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1283 | train_loss : 5153.82177734375 | val_loss : 7710.24560546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1284 | train_loss : 7059.8701171875 | val_loss : 5801.6962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1285 | train_loss : 4547.76318359375 | val_loss : 3178.999267578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1286 | train_loss : 5058.5205078125 | val_loss : 5961.291015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1287 | train_loss : 3799.732177734375 | val_loss : 570.41064453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1288 | train_loss : 2927.76123046875 | val_loss : 4765.38134765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1289 | train_loss : 2985.166259765625 | val_loss : 1147.1968994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1290 | train_loss : 3874.711181640625 | val_loss : 6676.18310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1291 | train_loss : 3427.360595703125 | val_loss : 1228.7293701171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1292 | train_loss : 3381.4833984375 | val_loss : 7258.2529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1293 | train_loss : 4766.64697265625 | val_loss : 3061.371337890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1294 | train_loss : 3801.595703125 | val_loss : 7468.953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1295 | train_loss : 4354.7763671875 | val_loss : 1620.4337158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1296 | train_loss : 2651.746826171875 | val_loss : 4950.01513671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1297 | train_loss : 4109.158203125 | val_loss : 2546.9755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1298 | train_loss : 3632.891357421875 | val_loss : 6050.60205078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1299 | train_loss : 4920.8671875 | val_loss : 1995.25439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1300 | train_loss : 4077.297607421875 | val_loss : 5420.771484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1301 | train_loss : 4243.10693359375 | val_loss : 3752.16259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1302 | train_loss : 5888.73828125 | val_loss : 1896.93994140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1303 | train_loss : 2544.855224609375 | val_loss : 2587.590087890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1304 | train_loss : 2401.39599609375 | val_loss : 2151.3349609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1305 | train_loss : 3073.684326171875 | val_loss : 2837.69384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1306 | train_loss : 3768.32177734375 | val_loss : 5227.98486328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1307 | train_loss : 4176.09326171875 | val_loss : 5061.994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1308 | train_loss : 3792.268798828125 | val_loss : 2391.4619140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1309 | train_loss : 3712.567138671875 | val_loss : 8024.59619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1310 | train_loss : 4871.248046875 | val_loss : 1435.4962158203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1311 | train_loss : 2860.867919921875 | val_loss : 6237.21923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1312 | train_loss : 4755.86669921875 | val_loss : 3571.84619140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1313 | train_loss : 5442.32177734375 | val_loss : 7788.2451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1314 | train_loss : 5776.05517578125 | val_loss : 3975.27197265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1315 | train_loss : 4320.10107421875 | val_loss : 8083.9248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1316 | train_loss : 6076.54736328125 | val_loss : 2523.438232421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1317 | train_loss : 4661.78271484375 | val_loss : 7337.72314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1318 | train_loss : 5460.84375 | val_loss : 3835.782470703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1319 | train_loss : 5207.03369140625 | val_loss : 7495.22119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1320 | train_loss : 4527.55029296875 | val_loss : 2070.793212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1321 | train_loss : 4062.879150390625 | val_loss : 4831.63134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1322 | train_loss : 4240.32958984375 | val_loss : 3028.0888671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1323 | train_loss : 3610.640625 | val_loss : 5444.921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1324 | train_loss : 3786.765625 | val_loss : 1643.5068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1325 | train_loss : 4363.06103515625 | val_loss : 3666.7861328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1326 | train_loss : 3299.0224609375 | val_loss : 4663.49072265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1327 | train_loss : 3147.7138671875 | val_loss : 3690.112548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1328 | train_loss : 5700.5263671875 | val_loss : 3684.688232421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1329 | train_loss : 4238.7001953125 | val_loss : 6898.36572265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1330 | train_loss : 6301.74609375 | val_loss : 3322.382568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1331 | train_loss : 4498.06103515625 | val_loss : 8184.435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1332 | train_loss : 5818.25146484375 | val_loss : 2512.4150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1333 | train_loss : 4007.93603515625 | val_loss : 4889.3193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1334 | train_loss : 3979.738037109375 | val_loss : 1624.802490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1335 | train_loss : 3304.360107421875 | val_loss : 7620.0830078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1336 | train_loss : 4627.77783203125 | val_loss : 1271.31689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1337 | train_loss : 2476.332763671875 | val_loss : 3898.06884765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1338 | train_loss : 3001.8798828125 | val_loss : 2103.585693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1339 | train_loss : 3386.6025390625 | val_loss : 6570.50048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1340 | train_loss : 3657.705322265625 | val_loss : 2709.094482421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1341 | train_loss : 3254.512451171875 | val_loss : 6838.70458984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1342 | train_loss : 4608.72119140625 | val_loss : 2449.3017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1343 | train_loss : 3777.041015625 | val_loss : 4973.40185546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1344 | train_loss : 5134.6279296875 | val_loss : 5195.7861328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1345 | train_loss : 5502.40625 | val_loss : 9101.162109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1346 | train_loss : 8772.240234375 | val_loss : 5941.56689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1347 | train_loss : 6037.95947265625 | val_loss : 5516.3955078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1348 | train_loss : 4430.29638671875 | val_loss : 4001.217529296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1349 | train_loss : 3422.20166015625 | val_loss : 5143.48193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1350 | train_loss : 4217.16015625 | val_loss : 5018.4658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1351 | train_loss : 3905.966796875 | val_loss : 6383.86083984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1352 | train_loss : 4526.560546875 | val_loss : 3761.05810546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1353 | train_loss : 4534.33349609375 | val_loss : 4224.3837890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1354 | train_loss : 3941.705078125 | val_loss : 4395.3720703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1355 | train_loss : 3912.773193359375 | val_loss : 2384.461181640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1356 | train_loss : 4111.40234375 | val_loss : 92512.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1357 | train_loss : 70988.8125 | val_loss : 13392.041015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1358 | train_loss : 11162.5341796875 | val_loss : 18495.33203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1359 | train_loss : 13019.275390625 | val_loss : 14411.4970703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1360 | train_loss : 9984.849609375 | val_loss : 9396.1826171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1361 | train_loss : 11669.1484375 | val_loss : 7051.64306640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1362 | train_loss : 8127.89892578125 | val_loss : 3624.08935546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1363 | train_loss : 4000.99658203125 | val_loss : 4227.06884765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1364 | train_loss : 3251.1513671875 | val_loss : 3138.438232421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1365 | train_loss : 3772.491943359375 | val_loss : 3324.77001953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1366 | train_loss : 3539.013671875 | val_loss : 4735.53955078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1367 | train_loss : 3621.58447265625 | val_loss : 2391.9599609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1368 | train_loss : 3869.251953125 | val_loss : 3701.3798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1369 | train_loss : 3633.896240234375 | val_loss : 1340.2718505859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1370 | train_loss : 3297.719970703125 | val_loss : 5041.609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1371 | train_loss : 4394.46142578125 | val_loss : 1769.8199462890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1372 | train_loss : 2744.43115234375 | val_loss : 2745.3076171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1373 | train_loss : 3549.90380859375 | val_loss : 2467.3525390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1374 | train_loss : 2620.845947265625 | val_loss : 2612.463134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1375 | train_loss : 2578.2236328125 | val_loss : 6049.4033203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1376 | train_loss : 3642.614013671875 | val_loss : 3198.15625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1377 | train_loss : 2206.440673828125 | val_loss : 5497.330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1378 | train_loss : 3457.042724609375 | val_loss : 2295.616943359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1379 | train_loss : 4118.099609375 | val_loss : 6237.6904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1380 | train_loss : 4340.27099609375 | val_loss : 4400.58642578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1381 | train_loss : 4418.47021484375 | val_loss : 7035.47998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1382 | train_loss : 5290.615234375 | val_loss : 2236.273193359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1383 | train_loss : 3151.6923828125 | val_loss : 5075.908203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1384 | train_loss : 4756.02197265625 | val_loss : 2577.031982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1385 | train_loss : 3215.706298828125 | val_loss : 5156.45166015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1386 | train_loss : 4083.138671875 | val_loss : 1248.06005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1387 | train_loss : 2733.78759765625 | val_loss : 6686.123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1388 | train_loss : 4031.607421875 | val_loss : 1945.3363037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1389 | train_loss : 2136.71630859375 | val_loss : 4207.66015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1390 | train_loss : 2942.570556640625 | val_loss : 1556.0899658203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1391 | train_loss : 2813.966552734375 | val_loss : 5822.63671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1392 | train_loss : 3927.4248046875 | val_loss : 4072.543701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1393 | train_loss : 3300.101318359375 | val_loss : 7307.69189453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1394 | train_loss : 5199.162109375 | val_loss : 2566.091796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1395 | train_loss : 4258.99462890625 | val_loss : 4906.69921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1396 | train_loss : 5746.99951171875 | val_loss : 4059.614990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1397 | train_loss : 3464.342529296875 | val_loss : 3823.003173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1398 | train_loss : 4133.4482421875 | val_loss : 5978.88916015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1399 | train_loss : 4339.90673828125 | val_loss : 3104.99365234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1400 | train_loss : 4697.06494140625 | val_loss : 7295.16015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1401 | train_loss : 5513.66015625 | val_loss : 8031.16015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1402 | train_loss : 5913.21923828125 | val_loss : 4150.96826171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1403 | train_loss : 3024.923828125 | val_loss : 2797.81689453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1404 | train_loss : 3766.532470703125 | val_loss : 2893.54931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1405 | train_loss : 2250.702392578125 | val_loss : 4540.18994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1406 | train_loss : 2955.9306640625 | val_loss : 658.2193603515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1407 | train_loss : 2140.78125 | val_loss : 3606.833740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1408 | train_loss : 2829.666259765625 | val_loss : 3248.640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1409 | train_loss : 3743.4072265625 | val_loss : 6103.72265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1410 | train_loss : 3552.28662109375 | val_loss : 2135.77197265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1411 | train_loss : 3862.406005859375 | val_loss : 5120.0048828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1412 | train_loss : 4130.349609375 | val_loss : 2884.77001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1413 | train_loss : 3405.20068359375 | val_loss : 3110.91748046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1414 | train_loss : 2868.84619140625 | val_loss : 5335.7587890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1415 | train_loss : 3734.28125 | val_loss : 2611.239990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1416 | train_loss : 4400.97021484375 | val_loss : 3361.655517578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1417 | train_loss : 3253.976806640625 | val_loss : 3286.451171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1418 | train_loss : 3423.6064453125 | val_loss : 5960.72998046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1419 | train_loss : 5051.142578125 | val_loss : 3758.59375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1420 | train_loss : 5499.79638671875 | val_loss : 3277.068115234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1421 | train_loss : 5259.662109375 | val_loss : 7777.36376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1422 | train_loss : 6798.8408203125 | val_loss : 3772.813232421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1423 | train_loss : 3973.250732421875 | val_loss : 3222.642578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1424 | train_loss : 4061.811279296875 | val_loss : 4186.5419921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1425 | train_loss : 5066.79296875 | val_loss : 6687.09130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1426 | train_loss : 5088.34228515625 | val_loss : 1843.842529296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1427 | train_loss : 2925.851806640625 | val_loss : 7062.2431640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1428 | train_loss : 4424.44921875 | val_loss : 2454.50439453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1429 | train_loss : 2286.334716796875 | val_loss : 4018.56689453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1430 | train_loss : 2940.341796875 | val_loss : 961.4693603515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1431 | train_loss : 3051.12060546875 | val_loss : 4970.4189453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1432 | train_loss : 2814.850830078125 | val_loss : 1702.998779296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1433 | train_loss : 3031.824951171875 | val_loss : 7078.43017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1434 | train_loss : 3739.73583984375 | val_loss : 2260.498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1435 | train_loss : 3604.054931640625 | val_loss : 4433.208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1436 | train_loss : 4181.24951171875 | val_loss : 3706.6630859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1437 | train_loss : 3348.99560546875 | val_loss : 3009.527587890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1438 | train_loss : 3100.363037109375 | val_loss : 5429.03271484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1439 | train_loss : 4404.671875 | val_loss : 3086.97314453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1440 | train_loss : 5587.853515625 | val_loss : 3300.830078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1441 | train_loss : 3982.5087890625 | val_loss : 6570.54931640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1442 | train_loss : 5704.74267578125 | val_loss : 2038.3643798828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1443 | train_loss : 3222.59375 | val_loss : 6573.81005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1444 | train_loss : 4946.8076171875 | val_loss : 1074.0799560546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1445 | train_loss : 2919.56494140625 | val_loss : 5986.20166015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1446 | train_loss : 3822.313720703125 | val_loss : 3187.445556640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1447 | train_loss : 3985.4111328125 | val_loss : 4394.3505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1448 | train_loss : 3524.81884765625 | val_loss : 1144.8587646484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1449 | train_loss : 2054.3349609375 | val_loss : 2325.038818359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1450 | train_loss : 2320.54052734375 | val_loss : 3695.576904296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1451 | train_loss : 3670.071533203125 | val_loss : 3193.4267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1452 | train_loss : 4533.17822265625 | val_loss : 6193.2763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1453 | train_loss : 4936.0341796875 | val_loss : 8436.0126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1454 | train_loss : 6792.3623046875 | val_loss : 2603.74755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1455 | train_loss : 3500.262451171875 | val_loss : 4190.177734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1456 | train_loss : 3738.856201171875 | val_loss : 1676.815673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1457 | train_loss : 4082.95751953125 | val_loss : 5279.5966796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1458 | train_loss : 3888.049072265625 | val_loss : 3854.681884765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1459 | train_loss : 4636.08056640625 | val_loss : 4700.197265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1460 | train_loss : 3870.06591796875 | val_loss : 4665.484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1461 | train_loss : 4997.072265625 | val_loss : 4068.98193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1462 | train_loss : 4483.7900390625 | val_loss : 4445.7119140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1463 | train_loss : 5319.02978515625 | val_loss : 9624.400390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1464 | train_loss : 7369.64013671875 | val_loss : 4068.08447265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1465 | train_loss : 4721.84765625 | val_loss : 7276.9951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1466 | train_loss : 5093.26611328125 | val_loss : 2043.22998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1467 | train_loss : 2966.6337890625 | val_loss : 3026.123779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1468 | train_loss : 2974.23876953125 | val_loss : 2798.50439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1469 | train_loss : 2361.988037109375 | val_loss : 4759.34765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1470 | train_loss : 3057.533203125 | val_loss : 1195.2874755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1471 | train_loss : 3057.116943359375 | val_loss : 5216.0107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1472 | train_loss : 2889.70849609375 | val_loss : 2066.80126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1473 | train_loss : 2029.3433837890625 | val_loss : 4979.3955078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1474 | train_loss : 3528.79150390625 | val_loss : 1705.04931640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1475 | train_loss : 3512.4736328125 | val_loss : 7003.333984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1476 | train_loss : 3975.466796875 | val_loss : 7065.53564453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1477 | train_loss : 5224.923828125 | val_loss : 1408.95751953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1478 | train_loss : 4041.4775390625 | val_loss : 4664.2392578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1479 | train_loss : 3786.578125 | val_loss : 1910.21875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1480 | train_loss : 2578.21728515625 | val_loss : 3962.701171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1481 | train_loss : 3655.661865234375 | val_loss : 3434.10302734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1482 | train_loss : 3930.964111328125 | val_loss : 2881.86865234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1483 | train_loss : 2683.62744140625 | val_loss : 1982.4112548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1484 | train_loss : 2621.500244140625 | val_loss : 2913.893798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1485 | train_loss : 3268.586181640625 | val_loss : 2296.418212890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1486 | train_loss : 3077.387451171875 | val_loss : 3219.407470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1487 | train_loss : 2102.192626953125 | val_loss : 2853.072509765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1488 | train_loss : 2833.22314453125 | val_loss : 2830.496337890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1489 | train_loss : 2502.48583984375 | val_loss : 2477.11376953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1490 | train_loss : 3735.625244140625 | val_loss : 3614.86181640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1491 | train_loss : 3206.664306640625 | val_loss : 5043.4931640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1492 | train_loss : 3897.111572265625 | val_loss : 7342.56982421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1493 | train_loss : 4225.00048828125 | val_loss : 400.7637634277344 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1494 | train_loss : 3986.471923828125 | val_loss : 6527.95361328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1495 | train_loss : 4110.05419921875 | val_loss : 1275.463134765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1496 | train_loss : 3003.5595703125 | val_loss : 7603.80126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1497 | train_loss : 5783.48046875 | val_loss : 1987.391845703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1498 | train_loss : 4313.712890625 | val_loss : 5530.57080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1499 | train_loss : 4035.404052734375 | val_loss : 5221.07568359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1500 | train_loss : 5181.89794921875 | val_loss : 4551.1298828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1501 | train_loss : 4664.42822265625 | val_loss : 3952.735595703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1502 | train_loss : 4882.369140625 | val_loss : 5517.92333984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1503 | train_loss : 4244.15625 | val_loss : 4449.54833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1504 | train_loss : 3689.90625 | val_loss : 5095.72509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1505 | train_loss : 4971.92919921875 | val_loss : 2014.824951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1506 | train_loss : 3636.023681640625 | val_loss : 3611.065673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1507 | train_loss : 2656.79931640625 | val_loss : 347.78375244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1508 | train_loss : 3283.601806640625 | val_loss : 3343.489990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1509 | train_loss : 1847.2772216796875 | val_loss : 1546.9212646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1510 | train_loss : 2422.0634765625 | val_loss : 6106.603515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1511 | train_loss : 3508.04541015625 | val_loss : 3230.416259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1512 | train_loss : 2799.9462890625 | val_loss : 2231.514404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1513 | train_loss : 2809.691162109375 | val_loss : 5600.53369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1514 | train_loss : 3639.220703125 | val_loss : 4345.025390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1515 | train_loss : 4965.0849609375 | val_loss : 2918.25634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1516 | train_loss : 4023.0859375 | val_loss : 3802.548095703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1517 | train_loss : 3164.390869140625 | val_loss : 2922.304931640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1518 | train_loss : 4102.53369140625 | val_loss : 5301.1806640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1519 | train_loss : 3961.313720703125 | val_loss : 3484.09619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1520 | train_loss : 4290.337890625 | val_loss : 2981.64501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1521 | train_loss : 3253.137451171875 | val_loss : 3191.0556640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1522 | train_loss : 3600.796142578125 | val_loss : 5510.82421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1523 | train_loss : 4068.7353515625 | val_loss : 1947.1812744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1524 | train_loss : 3909.669677734375 | val_loss : 4046.357421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1525 | train_loss : 3457.742431640625 | val_loss : 3497.353759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1526 | train_loss : 3131.33056640625 | val_loss : 1344.8612060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1527 | train_loss : 3550.981201171875 | val_loss : 5580.28173828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1528 | train_loss : 3832.81494140625 | val_loss : 805.0800170898438 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1529 | train_loss : 2121.4013671875 | val_loss : 2613.719970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1530 | train_loss : 2487.133544921875 | val_loss : 2001.6005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1531 | train_loss : 1495.4130859375 | val_loss : 3799.056884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1532 | train_loss : 2273.769775390625 | val_loss : 2180.289306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1533 | train_loss : 2912.197509765625 | val_loss : 4036.590576171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1534 | train_loss : 3339.129150390625 | val_loss : 2864.318115234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1535 | train_loss : 2759.28271484375 | val_loss : 2890.690673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1536 | train_loss : 2474.955322265625 | val_loss : 3431.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1537 | train_loss : 3040.75146484375 | val_loss : 2790.909912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1538 | train_loss : 4043.7236328125 | val_loss : 7038.77392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1539 | train_loss : 4238.0341796875 | val_loss : 7400.4873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1540 | train_loss : 5516.56103515625 | val_loss : 1759.7874755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1541 | train_loss : 2226.80810546875 | val_loss : 2410.01806640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1542 | train_loss : 2345.294677734375 | val_loss : 1548.74755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1543 | train_loss : 3125.125732421875 | val_loss : 3819.80322265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1544 | train_loss : 2848.04931640625 | val_loss : 3521.181884765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1545 | train_loss : 3087.54931640625 | val_loss : 2954.29931640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1546 | train_loss : 2611.323486328125 | val_loss : 4893.7568359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1547 | train_loss : 3386.7939453125 | val_loss : 3108.625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1548 | train_loss : 3390.298095703125 | val_loss : 2095.17431640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1549 | train_loss : 2180.261474609375 | val_loss : 1499.2449951171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1550 | train_loss : 1360.2593994140625 | val_loss : 3044.453857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1551 | train_loss : 1855.4593505859375 | val_loss : 1266.3900146484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1552 | train_loss : 3148.28564453125 | val_loss : 3354.838134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1553 | train_loss : 1972.678466796875 | val_loss : 3758.264892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1554 | train_loss : 3354.1591796875 | val_loss : 5650.0419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1555 | train_loss : 4321.21728515625 | val_loss : 3222.570068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1556 | train_loss : 4577.17138671875 | val_loss : 3668.986328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1557 | train_loss : 2983.423095703125 | val_loss : 3653.364990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1558 | train_loss : 3211.3017578125 | val_loss : 1893.03369140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1559 | train_loss : 3660.564453125 | val_loss : 6661.9794921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1560 | train_loss : 3927.008056640625 | val_loss : 2064.77001953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1561 | train_loss : 2879.13818359375 | val_loss : 8215.1572265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1562 | train_loss : 6233.357421875 | val_loss : 4806.64453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1563 | train_loss : 6190.11328125 | val_loss : 5485.611328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1564 | train_loss : 4063.203857421875 | val_loss : 3122.346923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1565 | train_loss : 2814.629638671875 | val_loss : 2529.158203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1566 | train_loss : 4119.42529296875 | val_loss : 5272.77490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1567 | train_loss : 3641.50341796875 | val_loss : 1808.0294189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1568 | train_loss : 3491.9248046875 | val_loss : 3071.032470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1569 | train_loss : 1947.5693359375 | val_loss : 5056.30419921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1570 | train_loss : 3213.601318359375 | val_loss : 3794.5625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1571 | train_loss : 4047.1904296875 | val_loss : 2071.438232421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1572 | train_loss : 2435.10595703125 | val_loss : 1859.8074951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1573 | train_loss : 1991.0775146484375 | val_loss : 2313.088134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1574 | train_loss : 2214.5654296875 | val_loss : 2499.60302734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1575 | train_loss : 3071.25439453125 | val_loss : 1849.8349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1576 | train_loss : 3073.179443359375 | val_loss : 3091.89306640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1577 | train_loss : 2799.902099609375 | val_loss : 3866.764404296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1578 | train_loss : 3500.522216796875 | val_loss : 1382.7850341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1579 | train_loss : 2793.739990234375 | val_loss : 6750.72802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1580 | train_loss : 4186.794921875 | val_loss : 2855.34814453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1581 | train_loss : 3397.23193359375 | val_loss : 7431.578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1582 | train_loss : 4943.041015625 | val_loss : 2674.4599609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1583 | train_loss : 3178.324462890625 | val_loss : 6175.8017578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1584 | train_loss : 5037.07763671875 | val_loss : 3456.5693359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1585 | train_loss : 4539.61669921875 | val_loss : 8670.6904296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1586 | train_loss : 5376.37255859375 | val_loss : 1840.4881591796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1587 | train_loss : 3549.5048828125 | val_loss : 4849.52978515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1588 | train_loss : 3591.517822265625 | val_loss : 1493.76318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1589 | train_loss : 2293.392822265625 | val_loss : 5109.98388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1590 | train_loss : 3200.8076171875 | val_loss : 2508.983154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1591 | train_loss : 2243.244384765625 | val_loss : 2154.314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1592 | train_loss : 2873.1474609375 | val_loss : 4645.66455078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1593 | train_loss : 2577.3447265625 | val_loss : 2136.97509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1594 | train_loss : 2388.2529296875 | val_loss : 2665.07373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1595 | train_loss : 2675.17626953125 | val_loss : 2283.280517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1596 | train_loss : 2969.239990234375 | val_loss : 5606.6044921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1597 | train_loss : 3388.38427734375 | val_loss : 2140.7236328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1598 | train_loss : 3962.5087890625 | val_loss : 3914.90625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1599 | train_loss : 3162.676513671875 | val_loss : 4352.0498046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 1600 | train_loss : 3583.0205078125 | val_loss : 4315.34912109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 9 | epoch : 1 | train_loss : 1531264.375 | val_loss : 595521.125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 2 | train_loss : 700736.9375 | val_loss : 462599.59375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 3 | train_loss : 514069.90625 | val_loss : 380077.6875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 4 | train_loss : 420224.28125 | val_loss : 531859.6875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 5 | train_loss : 548439.25 | val_loss : 595421.75 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 6 | train_loss : 511922.15625 | val_loss : 591713.8125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 7 | train_loss : 541243.25 | val_loss : 717541.625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 8 | train_loss : 654457.875 | val_loss : 462260.875 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 9 | train_loss : 455250.4375 | val_loss : 339177.96875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 10 | train_loss : 318424.28125 | val_loss : 428651.6875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 11 | train_loss : 377116.96875 | val_loss : 186276.0625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 12 | train_loss : 150323.625 | val_loss : 176223.28125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 13 | train_loss : 170403.65625 | val_loss : 111133.0625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 14 | train_loss : 163291.28125 | val_loss : 198888.046875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 15 | train_loss : 233726.28125 | val_loss : 141307.8125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 16 | train_loss : 224316.0625 | val_loss : 241409.953125 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 17 | train_loss : 247303.1875 | val_loss : 289786.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 18 | train_loss : 283745.125 | val_loss : 302988.34375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 19 | train_loss : 306776.90625 | val_loss : 160177.875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 20 | train_loss : 149827.546875 | val_loss : 156782.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 21 | train_loss : 146877.625 | val_loss : 72599.734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 22 | train_loss : 116884.09375 | val_loss : 130582.7578125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 23 | train_loss : 98889.03125 | val_loss : 215891.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 24 | train_loss : 150287.03125 | val_loss : 191623.0625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 25 | train_loss : 134929.0625 | val_loss : 168386.625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 26 | train_loss : 168492.421875 | val_loss : 216956.4375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 27 | train_loss : 219454.984375 | val_loss : 219068.0625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 28 | train_loss : 194694.59375 | val_loss : 204898.796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 29 | train_loss : 161256.078125 | val_loss : 250574.265625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 30 | train_loss : 218943.71875 | val_loss : 238716.546875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 31 | train_loss : 207261.015625 | val_loss : 169430.125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 32 | train_loss : 200017.6875 | val_loss : 107110.1015625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 33 | train_loss : 167182.234375 | val_loss : 222587.34375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 34 | train_loss : 175175.234375 | val_loss : 283334.34375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 35 | train_loss : 203960.296875 | val_loss : 216442.40625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 36 | train_loss : 177993.578125 | val_loss : 182690.875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 37 | train_loss : 158013.65625 | val_loss : 198971.203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 38 | train_loss : 148091.078125 | val_loss : 284662.40625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 39 | train_loss : 218354.921875 | val_loss : 275044.15625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 40 | train_loss : 203222.734375 | val_loss : 227740.796875 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 41 | train_loss : 186464.265625 | val_loss : 223682.515625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 42 | train_loss : 214706.359375 | val_loss : 136953.71875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 43 | train_loss : 124020.5 | val_loss : 134951.375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 44 | train_loss : 137354.875 | val_loss : 68525.2734375 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 45 | train_loss : 84806.2578125 | val_loss : 113829.6171875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 46 | train_loss : 109290.0234375 | val_loss : 93751.9765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 47 | train_loss : 88449.78125 | val_loss : 122758.453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 48 | train_loss : 93244.0703125 | val_loss : 99776.171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 49 | train_loss : 83027.90625 | val_loss : 102907.9765625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 50 | train_loss : 113139.1015625 | val_loss : 123940.4375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 51 | train_loss : 145817.984375 | val_loss : 100555.6484375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 52 | train_loss : 111783.5703125 | val_loss : 142940.8125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 53 | train_loss : 98874.3828125 | val_loss : 111196.15625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 54 | train_loss : 106639.3671875 | val_loss : 105794.40625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 55 | train_loss : 111385.53125 | val_loss : 129364.859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 56 | train_loss : 119078.9765625 | val_loss : 74221.53125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 57 | train_loss : 70072.6640625 | val_loss : 94199.859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 58 | train_loss : 99555.8515625 | val_loss : 92012.2734375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 59 | train_loss : 100162.25 | val_loss : 119499.140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 60 | train_loss : 91816.1015625 | val_loss : 149274.09375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 61 | train_loss : 120951.7578125 | val_loss : 125546.84375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 62 | train_loss : 101012.0234375 | val_loss : 179686.5625 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 63 | train_loss : 154299.515625 | val_loss : 217993.15625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 64 | train_loss : 186181.640625 | val_loss : 200776.8125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 65 | train_loss : 208835.0 | val_loss : 202447.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 66 | train_loss : 224659.0 | val_loss : 143827.546875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 67 | train_loss : 185368.921875 | val_loss : 129571.578125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 68 | train_loss : 112829.09375 | val_loss : 152401.328125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 69 | train_loss : 137799.890625 | val_loss : 109467.2265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 70 | train_loss : 89701.3515625 | val_loss : 109853.359375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 71 | train_loss : 90355.5078125 | val_loss : 64540.99609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 72 | train_loss : 79670.7890625 | val_loss : 80158.34375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 73 | train_loss : 88213.4296875 | val_loss : 125789.5234375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 74 | train_loss : 110140.6171875 | val_loss : 84602.4296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 75 | train_loss : 78795.3203125 | val_loss : 98463.859375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 76 | train_loss : 93028.9765625 | val_loss : 107669.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 77 | train_loss : 117419.4375 | val_loss : 167229.421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 78 | train_loss : 151999.84375 | val_loss : 105576.2109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 79 | train_loss : 101552.578125 | val_loss : 101014.8984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 80 | train_loss : 86429.6875 | val_loss : 85629.15625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 81 | train_loss : 61602.75 | val_loss : 122990.3125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 82 | train_loss : 106189.3125 | val_loss : 123206.1875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 83 | train_loss : 118823.6015625 | val_loss : 95876.5078125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 84 | train_loss : 67979.9296875 | val_loss : 55624.71484375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 85 | train_loss : 45586.1015625 | val_loss : 119060.5390625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 86 | train_loss : 111358.359375 | val_loss : 136850.15625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 87 | train_loss : 119238.203125 | val_loss : 91167.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 88 | train_loss : 87696.078125 | val_loss : 129543.921875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 89 | train_loss : 100340.96875 | val_loss : 124601.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 90 | train_loss : 98209.6171875 | val_loss : 60252.859375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 91 | train_loss : 65955.25 | val_loss : 77877.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 92 | train_loss : 92778.0 | val_loss : 45326.73046875 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 93 | train_loss : 69364.5546875 | val_loss : 66899.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 94 | train_loss : 77541.4921875 | val_loss : 94367.4609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 95 | train_loss : 58997.5 | val_loss : 76342.4609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 96 | train_loss : 68581.4453125 | val_loss : 91889.0390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 97 | train_loss : 78086.8671875 | val_loss : 69316.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 98 | train_loss : 56283.328125 | val_loss : 87924.1171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 99 | train_loss : 81288.640625 | val_loss : 57824.2890625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 100 | train_loss : 62593.87890625 | val_loss : 88370.4296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 101 | train_loss : 118830.15625 | val_loss : 80251.7421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 102 | train_loss : 75108.7734375 | val_loss : 90106.203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 103 | train_loss : 75975.21875 | val_loss : 116661.7421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 104 | train_loss : 89339.4765625 | val_loss : 98018.171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 105 | train_loss : 89483.4921875 | val_loss : 68357.5859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 106 | train_loss : 61018.44921875 | val_loss : 74932.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 107 | train_loss : 73529.3203125 | val_loss : 72832.703125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 108 | train_loss : 80981.7734375 | val_loss : 72593.796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 109 | train_loss : 77243.5234375 | val_loss : 93376.6796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 110 | train_loss : 70113.53125 | val_loss : 79692.890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 111 | train_loss : 63635.0859375 | val_loss : 94347.8203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 112 | train_loss : 93169.9765625 | val_loss : 130404.6015625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 113 | train_loss : 119064.1796875 | val_loss : 103078.4765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 114 | train_loss : 97592.9375 | val_loss : 94072.3828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 115 | train_loss : 91704.609375 | val_loss : 95505.4921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 116 | train_loss : 69802.0546875 | val_loss : 143687.03125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 117 | train_loss : 105545.953125 | val_loss : 53739.80859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 118 | train_loss : 34435.6484375 | val_loss : 53986.99609375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 119 | train_loss : 65656.890625 | val_loss : 90934.7578125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 120 | train_loss : 95032.921875 | val_loss : 107915.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 121 | train_loss : 107164.71875 | val_loss : 169500.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 122 | train_loss : 125057.03125 | val_loss : 160161.28125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 123 | train_loss : 127959.1015625 | val_loss : 61149.23046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 124 | train_loss : 60502.62890625 | val_loss : 62377.3359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 125 | train_loss : 67660.953125 | val_loss : 89045.4375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 126 | train_loss : 84025.3671875 | val_loss : 100493.8828125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 127 | train_loss : 95520.6484375 | val_loss : 134885.734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 128 | train_loss : 87431.8125 | val_loss : 142882.0625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 129 | train_loss : 98852.9765625 | val_loss : 107961.0390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 130 | train_loss : 83745.171875 | val_loss : 115419.8984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 131 | train_loss : 87078.359375 | val_loss : 120517.2734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 132 | train_loss : 97162.609375 | val_loss : 68620.2421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 133 | train_loss : 52906.53515625 | val_loss : 104717.3984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 134 | train_loss : 113065.2578125 | val_loss : 44455.3984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 135 | train_loss : 53924.203125 | val_loss : 100186.71875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 136 | train_loss : 77882.09375 | val_loss : 87628.21875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 137 | train_loss : 78552.046875 | val_loss : 39883.80078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 138 | train_loss : 32341.349609375 | val_loss : 77315.8515625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 139 | train_loss : 64109.43359375 | val_loss : 115389.8203125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 140 | train_loss : 114879.3515625 | val_loss : 100754.75 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 141 | train_loss : 84698.0625 | val_loss : 119863.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 142 | train_loss : 116739.6328125 | val_loss : 103580.859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 143 | train_loss : 91345.828125 | val_loss : 93623.546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 144 | train_loss : 98339.7890625 | val_loss : 100603.8984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 145 | train_loss : 74774.6796875 | val_loss : 85942.9609375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 146 | train_loss : 62664.83984375 | val_loss : 55891.30078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 147 | train_loss : 52013.42578125 | val_loss : 50638.7890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 148 | train_loss : 53013.03125 | val_loss : 45237.390625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 149 | train_loss : 55589.21484375 | val_loss : 55567.08984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 150 | train_loss : 67241.9765625 | val_loss : 41959.19140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 151 | train_loss : 37392.125 | val_loss : 65368.41015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 152 | train_loss : 39531.171875 | val_loss : 74656.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 153 | train_loss : 66416.3125 | val_loss : 94615.0234375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 154 | train_loss : 80226.1484375 | val_loss : 48851.51953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 155 | train_loss : 43868.69921875 | val_loss : 50648.46484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 156 | train_loss : 43654.37890625 | val_loss : 81638.140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 157 | train_loss : 76054.328125 | val_loss : 55832.84375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 158 | train_loss : 57241.2734375 | val_loss : 71438.296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 159 | train_loss : 65534.32421875 | val_loss : 39399.69140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 160 | train_loss : 41451.703125 | val_loss : 75628.328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 161 | train_loss : 56016.53125 | val_loss : 66849.6015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 162 | train_loss : 62224.265625 | val_loss : 83910.0234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 163 | train_loss : 78519.1796875 | val_loss : 20656.248046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 164 | train_loss : 14055.0361328125 | val_loss : 51608.0390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 165 | train_loss : 37103.0703125 | val_loss : 44052.85546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 166 | train_loss : 44327.26171875 | val_loss : 51724.56640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 167 | train_loss : 41367.484375 | val_loss : 64068.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 168 | train_loss : 63881.8984375 | val_loss : 86437.4296875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 169 | train_loss : 67471.703125 | val_loss : 64333.23046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 170 | train_loss : 59389.51953125 | val_loss : 76195.953125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 171 | train_loss : 62631.4140625 | val_loss : 72400.6484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 172 | train_loss : 57684.07421875 | val_loss : 62983.26171875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 173 | train_loss : 48686.25390625 | val_loss : 56830.93359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 174 | train_loss : 65365.7734375 | val_loss : 76032.4765625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 175 | train_loss : 68890.8671875 | val_loss : 97337.5390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 176 | train_loss : 96367.140625 | val_loss : 102231.3828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 177 | train_loss : 76593.4453125 | val_loss : 84323.890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 178 | train_loss : 80944.28125 | val_loss : 57670.01171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 179 | train_loss : 61991.41015625 | val_loss : 48625.0 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 180 | train_loss : 49093.171875 | val_loss : 77830.828125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 181 | train_loss : 86296.96875 | val_loss : 104500.2421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 182 | train_loss : 79404.6171875 | val_loss : 65517.8515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 183 | train_loss : 71605.171875 | val_loss : 64064.71484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 184 | train_loss : 68012.6953125 | val_loss : 77151.984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 185 | train_loss : 50049.36328125 | val_loss : 79323.4375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 186 | train_loss : 64754.48828125 | val_loss : 68476.5390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 187 | train_loss : 57528.36328125 | val_loss : 33469.640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 188 | train_loss : 29290.77734375 | val_loss : 41235.11328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 189 | train_loss : 42732.890625 | val_loss : 68851.3203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 190 | train_loss : 57110.5859375 | val_loss : 67472.328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 191 | train_loss : 50171.21484375 | val_loss : 30197.94921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 192 | train_loss : 27970.7109375 | val_loss : 45018.890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 193 | train_loss : 37138.40625 | val_loss : 36576.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 194 | train_loss : 37983.03125 | val_loss : 57371.46875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 195 | train_loss : 60794.6953125 | val_loss : 23515.439453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 196 | train_loss : 20025.552734375 | val_loss : 60160.48046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 197 | train_loss : 46726.4453125 | val_loss : 71333.28125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 198 | train_loss : 66385.0078125 | val_loss : 68361.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 199 | train_loss : 54468.6796875 | val_loss : 66507.2734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 200 | train_loss : 64414.48046875 | val_loss : 70930.171875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 201 | train_loss : 51381.65625 | val_loss : 71086.390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 202 | train_loss : 66960.203125 | val_loss : 57599.62109375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 203 | train_loss : 46997.5546875 | val_loss : 47597.359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 204 | train_loss : 29925.767578125 | val_loss : 61182.0234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 205 | train_loss : 50876.94140625 | val_loss : 39829.12109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 206 | train_loss : 36272.046875 | val_loss : 39699.84375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 207 | train_loss : 40230.546875 | val_loss : 28398.919921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 208 | train_loss : 35448.921875 | val_loss : 52685.046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 209 | train_loss : 30518.490234375 | val_loss : 54837.0703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 210 | train_loss : 39796.2890625 | val_loss : 49240.0859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 211 | train_loss : 44555.8984375 | val_loss : 65173.98828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 212 | train_loss : 60869.6484375 | val_loss : 52085.6796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 213 | train_loss : 36660.24609375 | val_loss : 28805.58984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 214 | train_loss : 31194.267578125 | val_loss : 41768.43359375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 215 | train_loss : 37538.76171875 | val_loss : 41842.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 216 | train_loss : 42007.453125 | val_loss : 62276.0703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 217 | train_loss : 40620.7890625 | val_loss : 40883.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 218 | train_loss : 36747.3671875 | val_loss : 40382.359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 219 | train_loss : 40548.984375 | val_loss : 38543.03515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 220 | train_loss : 43382.515625 | val_loss : 71419.3515625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 221 | train_loss : 52799.35546875 | val_loss : 83135.90625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 222 | train_loss : 75080.78125 | val_loss : 81048.765625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 223 | train_loss : 71010.7890625 | val_loss : 37420.91796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 224 | train_loss : 32524.744140625 | val_loss : 160113.796875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 225 | train_loss : 128109.0625 | val_loss : 90099.28125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 226 | train_loss : 87465.40625 | val_loss : 134043.34375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 227 | train_loss : 112881.7734375 | val_loss : 89888.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 228 | train_loss : 52154.6015625 | val_loss : 73061.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 229 | train_loss : 58386.4765625 | val_loss : 54439.2890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 230 | train_loss : 41556.9921875 | val_loss : 56404.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 231 | train_loss : 55676.94921875 | val_loss : 37240.23828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 232 | train_loss : 31492.654296875 | val_loss : 38073.5859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 233 | train_loss : 36090.421875 | val_loss : 56999.64453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 234 | train_loss : 43895.76171875 | val_loss : 56732.2890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 235 | train_loss : 53486.09375 | val_loss : 58296.39453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 236 | train_loss : 50124.82421875 | val_loss : 53669.00390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 237 | train_loss : 54930.19921875 | val_loss : 48484.91015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 238 | train_loss : 37081.9453125 | val_loss : 54910.12890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 239 | train_loss : 45880.23828125 | val_loss : 27240.04296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 240 | train_loss : 25950.44921875 | val_loss : 45851.171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 241 | train_loss : 34347.80078125 | val_loss : 49480.23828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 242 | train_loss : 41404.625 | val_loss : 57421.93359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 243 | train_loss : 56433.21875 | val_loss : 60194.46875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 244 | train_loss : 43315.00390625 | val_loss : 45193.62109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 245 | train_loss : 42607.5546875 | val_loss : 63421.0 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 246 | train_loss : 48300.60546875 | val_loss : 55437.5234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 247 | train_loss : 46236.18359375 | val_loss : 45453.13671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 248 | train_loss : 33722.9921875 | val_loss : 39362.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 249 | train_loss : 35500.609375 | val_loss : 54717.84375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 250 | train_loss : 37661.171875 | val_loss : 63785.1484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 251 | train_loss : 53736.2890625 | val_loss : 22889.802734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 252 | train_loss : 23166.029296875 | val_loss : 38785.71875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 253 | train_loss : 21691.328125 | val_loss : 28979.3828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 254 | train_loss : 20689.912109375 | val_loss : 31064.21484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 255 | train_loss : 26381.3515625 | val_loss : 39296.359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 256 | train_loss : 33680.8359375 | val_loss : 50118.92578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 257 | train_loss : 31934.13671875 | val_loss : 45861.35546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 258 | train_loss : 29211.98828125 | val_loss : 49529.80859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 259 | train_loss : 47966.1640625 | val_loss : 53087.0234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 260 | train_loss : 50541.44921875 | val_loss : 45935.3984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 261 | train_loss : 37151.9453125 | val_loss : 41130.46875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 262 | train_loss : 38767.9609375 | val_loss : 48846.6796875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 263 | train_loss : 38087.453125 | val_loss : 43205.0 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 264 | train_loss : 34320.5390625 | val_loss : 27202.77734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 265 | train_loss : 23952.8515625 | val_loss : 37821.328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 266 | train_loss : 32799.89453125 | val_loss : 29482.580078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 267 | train_loss : 35701.0 | val_loss : 44944.51171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 268 | train_loss : 28628.654296875 | val_loss : 28229.3046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 269 | train_loss : 25481.720703125 | val_loss : 52119.89453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 270 | train_loss : 43283.93359375 | val_loss : 41154.65234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 271 | train_loss : 39960.7109375 | val_loss : 57363.16015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 272 | train_loss : 44468.07421875 | val_loss : 63246.50390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 273 | train_loss : 58538.5390625 | val_loss : 66937.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 274 | train_loss : 54348.91015625 | val_loss : 31589.02734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 275 | train_loss : 31039.5546875 | val_loss : 45230.109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 276 | train_loss : 33553.5234375 | val_loss : 29715.41796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 277 | train_loss : 25217.099609375 | val_loss : 19894.703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 278 | train_loss : 17954.638671875 | val_loss : 35645.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 279 | train_loss : 29193.0078125 | val_loss : 49657.96875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 280 | train_loss : 36142.76171875 | val_loss : 50943.625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 281 | train_loss : 47885.5 | val_loss : 40863.44140625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 282 | train_loss : 32667.4296875 | val_loss : 42800.91015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 283 | train_loss : 43556.7109375 | val_loss : 52888.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 284 | train_loss : 35719.359375 | val_loss : 51866.875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 285 | train_loss : 48630.8984375 | val_loss : 39960.86328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 286 | train_loss : 35894.51171875 | val_loss : 44231.4296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 287 | train_loss : 40039.94921875 | val_loss : 35506.640625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 288 | train_loss : 23058.134765625 | val_loss : 25133.3515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 289 | train_loss : 28922.318359375 | val_loss : 50542.8203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 290 | train_loss : 36888.62109375 | val_loss : 38413.82421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 291 | train_loss : 34421.20703125 | val_loss : 36753.828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 292 | train_loss : 27704.015625 | val_loss : 35096.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 293 | train_loss : 32402.994140625 | val_loss : 35550.8984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 294 | train_loss : 29083.474609375 | val_loss : 20641.755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 295 | train_loss : 26280.29296875 | val_loss : 51346.609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 296 | train_loss : 41580.875 | val_loss : 45910.109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 297 | train_loss : 43206.96484375 | val_loss : 36141.05859375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 298 | train_loss : 26605.3359375 | val_loss : 21002.390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 299 | train_loss : 21525.716796875 | val_loss : 48177.890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 300 | train_loss : 30791.6796875 | val_loss : 35486.45703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 301 | train_loss : 29456.740234375 | val_loss : 35989.01171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 302 | train_loss : 31843.380859375 | val_loss : 34838.8984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 303 | train_loss : 38004.23828125 | val_loss : 54350.38671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 304 | train_loss : 39320.4140625 | val_loss : 43134.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 305 | train_loss : 37032.30859375 | val_loss : 50058.171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 306 | train_loss : 40373.69140625 | val_loss : 39222.6015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 307 | train_loss : 40022.921875 | val_loss : 34791.01171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 308 | train_loss : 25205.572265625 | val_loss : 29861.0234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 309 | train_loss : 28330.10546875 | val_loss : 46287.1953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 310 | train_loss : 30165.302734375 | val_loss : 49776.1796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 311 | train_loss : 40206.671875 | val_loss : 42644.05859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 312 | train_loss : 33678.421875 | val_loss : 42230.0703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 313 | train_loss : 43518.546875 | val_loss : 60957.23828125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 314 | train_loss : 40135.4140625 | val_loss : 35159.2890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 315 | train_loss : 27012.029296875 | val_loss : 29405.21484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 316 | train_loss : 27227.498046875 | val_loss : 23556.4609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 317 | train_loss : 28665.037109375 | val_loss : 59694.37890625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 318 | train_loss : 43657.1953125 | val_loss : 80264.75 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 319 | train_loss : 85446.7734375 | val_loss : 49301.8203125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 320 | train_loss : 40442.484375 | val_loss : 22067.216796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 321 | train_loss : 23803.849609375 | val_loss : 52816.5390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 322 | train_loss : 34727.703125 | val_loss : 36947.08984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 323 | train_loss : 34297.4609375 | val_loss : 20252.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 324 | train_loss : 17073.205078125 | val_loss : 21988.08203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 325 | train_loss : 21570.564453125 | val_loss : 38855.30859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 326 | train_loss : 23132.158203125 | val_loss : 36701.9296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 327 | train_loss : 29041.78515625 | val_loss : 32840.6875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 328 | train_loss : 30535.421875 | val_loss : 18920.712890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 329 | train_loss : 26750.865234375 | val_loss : 45175.43359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 330 | train_loss : 26350.5859375 | val_loss : 34828.390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 331 | train_loss : 22168.1015625 | val_loss : 28390.96484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 332 | train_loss : 19808.02734375 | val_loss : 20931.283203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 333 | train_loss : 19244.8515625 | val_loss : 27746.869140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 334 | train_loss : 20374.703125 | val_loss : 16850.08984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 335 | train_loss : 13329.23046875 | val_loss : 30525.115234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 336 | train_loss : 17649.818359375 | val_loss : 26441.0078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 337 | train_loss : 18991.1875 | val_loss : 31338.3125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 338 | train_loss : 26156.072265625 | val_loss : 42213.76171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 339 | train_loss : 41190.0546875 | val_loss : 14529.29296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 340 | train_loss : 13450.5576171875 | val_loss : 27309.4609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 341 | train_loss : 25681.630859375 | val_loss : 39471.84765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 342 | train_loss : 28194.802734375 | val_loss : 35126.05078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 343 | train_loss : 34249.37890625 | val_loss : 34981.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 344 | train_loss : 22896.259765625 | val_loss : 15814.7177734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 345 | train_loss : 13223.4345703125 | val_loss : 16158.2529296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 346 | train_loss : 21354.86328125 | val_loss : 44579.78125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 347 | train_loss : 33798.9140625 | val_loss : 22275.51953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 348 | train_loss : 17087.966796875 | val_loss : 19784.185546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 349 | train_loss : 15598.1728515625 | val_loss : 41169.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 350 | train_loss : 27899.4609375 | val_loss : 23545.904296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 351 | train_loss : 22403.5625 | val_loss : 43162.8046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 352 | train_loss : 32793.62890625 | val_loss : 11330.0478515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 353 | train_loss : 12198.29296875 | val_loss : 16898.23046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 354 | train_loss : 15311.482421875 | val_loss : 42838.9296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 355 | train_loss : 38427.765625 | val_loss : 50095.76953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 356 | train_loss : 49244.046875 | val_loss : 29486.796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 357 | train_loss : 24305.0703125 | val_loss : 20323.755859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 358 | train_loss : 16850.4375 | val_loss : 41994.26171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 359 | train_loss : 29431.587890625 | val_loss : 38481.45703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 360 | train_loss : 29121.775390625 | val_loss : 42212.6953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 361 | train_loss : 37265.4765625 | val_loss : 43487.21484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 362 | train_loss : 38805.3984375 | val_loss : 23854.998046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 363 | train_loss : 17886.619140625 | val_loss : 16303.9326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 364 | train_loss : 16286.9638671875 | val_loss : 40059.16015625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 365 | train_loss : 25502.884765625 | val_loss : 34013.79296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 366 | train_loss : 24274.9609375 | val_loss : 36428.0 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 367 | train_loss : 29062.27734375 | val_loss : 32407.537109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 368 | train_loss : 33828.78125 | val_loss : 30853.759765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 369 | train_loss : 18341.51953125 | val_loss : 22574.337890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 370 | train_loss : 23372.07421875 | val_loss : 24835.73828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 371 | train_loss : 21232.044921875 | val_loss : 26372.546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 372 | train_loss : 19645.83984375 | val_loss : 26133.587890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 373 | train_loss : 21866.123046875 | val_loss : 32839.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 374 | train_loss : 28943.654296875 | val_loss : 43190.62890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 375 | train_loss : 36602.59375 | val_loss : 13420.3251953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 376 | train_loss : 18711.76953125 | val_loss : 29072.98828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 377 | train_loss : 16326.91796875 | val_loss : 25573.6875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 378 | train_loss : 19194.583984375 | val_loss : 37414.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 379 | train_loss : 28785.087890625 | val_loss : 36846.34375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 380 | train_loss : 35871.38671875 | val_loss : 18146.365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 381 | train_loss : 12678.0908203125 | val_loss : 25012.23828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 382 | train_loss : 22216.36328125 | val_loss : 137453.46875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 383 | train_loss : 102259.6484375 | val_loss : 60848.62890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 384 | train_loss : 58858.203125 | val_loss : 31324.029296875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 385 | train_loss : 27534.244140625 | val_loss : 17867.822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 386 | train_loss : 21288.9375 | val_loss : 38892.62890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 387 | train_loss : 21580.05078125 | val_loss : 37933.86328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 388 | train_loss : 25957.22265625 | val_loss : 23127.037109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 389 | train_loss : 20826.55078125 | val_loss : 25742.76953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 390 | train_loss : 24204.609375 | val_loss : 29227.03515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 391 | train_loss : 18011.45703125 | val_loss : 22320.41015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 392 | train_loss : 16691.4375 | val_loss : 27721.2578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 393 | train_loss : 19246.681640625 | val_loss : 30111.740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 394 | train_loss : 28753.3203125 | val_loss : 17050.591796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 395 | train_loss : 13413.5712890625 | val_loss : 20083.03515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 396 | train_loss : 29515.412109375 | val_loss : 78438.34375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 397 | train_loss : 43793.6953125 | val_loss : 57340.140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 398 | train_loss : 33500.171875 | val_loss : 47888.890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 399 | train_loss : 32568.8203125 | val_loss : 43851.50390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 400 | train_loss : 31254.720703125 | val_loss : 30066.705078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 401 | train_loss : 19797.701171875 | val_loss : 31026.376953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 402 | train_loss : 30542.16015625 | val_loss : 15421.83203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 403 | train_loss : 16612.337890625 | val_loss : 20848.6171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 404 | train_loss : 16620.013671875 | val_loss : 24261.7734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 405 | train_loss : 18516.275390625 | val_loss : 27341.060546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 406 | train_loss : 26663.48046875 | val_loss : 14573.212890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 407 | train_loss : 11786.3515625 | val_loss : 10406.5400390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 408 | train_loss : 11071.09765625 | val_loss : 33058.0625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 409 | train_loss : 25464.3359375 | val_loss : 34242.0234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 410 | train_loss : 32486.650390625 | val_loss : 20741.939453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 411 | train_loss : 22128.740234375 | val_loss : 28164.560546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 412 | train_loss : 21356.875 | val_loss : 16601.8046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 413 | train_loss : 15472.8203125 | val_loss : 30773.5390625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 414 | train_loss : 19544.29296875 | val_loss : 26472.3125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 415 | train_loss : 19870.82421875 | val_loss : 32391.330078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 416 | train_loss : 24948.904296875 | val_loss : 26007.822265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 417 | train_loss : 26695.107421875 | val_loss : 26557.85546875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 418 | train_loss : 19468.4921875 | val_loss : 18993.90234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 419 | train_loss : 16764.53515625 | val_loss : 32597.86328125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 420 | train_loss : 21944.498046875 | val_loss : 22790.619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 421 | train_loss : 21256.61328125 | val_loss : 17868.556640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 422 | train_loss : 13948.4150390625 | val_loss : 19048.48046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 423 | train_loss : 21217.65234375 | val_loss : 34786.2421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 424 | train_loss : 25314.275390625 | val_loss : 29093.193359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 425 | train_loss : 25806.158203125 | val_loss : 25101.248046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 426 | train_loss : 18474.294921875 | val_loss : 15083.125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 427 | train_loss : 14351.9072265625 | val_loss : 11969.5751953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 428 | train_loss : 9768.9169921875 | val_loss : 13849.33984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 429 | train_loss : 12955.2490234375 | val_loss : 32656.66796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 430 | train_loss : 20603.578125 | val_loss : 17395.849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 431 | train_loss : 15593.4873046875 | val_loss : 15302.177734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 432 | train_loss : 11144.3388671875 | val_loss : 29419.9140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 433 | train_loss : 25881.3203125 | val_loss : 18100.439453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 434 | train_loss : 13572.0810546875 | val_loss : 9851.009765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 435 | train_loss : 9436.677734375 | val_loss : 17613.642578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 436 | train_loss : 13265.3974609375 | val_loss : 26206.10546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 437 | train_loss : 21867.0078125 | val_loss : 24999.32421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 438 | train_loss : 22112.734375 | val_loss : 33349.62109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 439 | train_loss : 30131.662109375 | val_loss : 25112.697265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 440 | train_loss : 18904.5234375 | val_loss : 27355.67578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 441 | train_loss : 21178.484375 | val_loss : 24937.267578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 442 | train_loss : 26880.3671875 | val_loss : 24825.564453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 443 | train_loss : 22545.490234375 | val_loss : 28861.490234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 444 | train_loss : 24170.369140625 | val_loss : 35942.1875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 445 | train_loss : 38079.859375 | val_loss : 26119.3515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 446 | train_loss : 24239.087890625 | val_loss : 22760.21484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 447 | train_loss : 17815.828125 | val_loss : 22122.697265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 448 | train_loss : 18162.12109375 | val_loss : 31422.775390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 449 | train_loss : 21087.634765625 | val_loss : 25835.69921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 450 | train_loss : 20773.39453125 | val_loss : 18597.7109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 451 | train_loss : 20858.423828125 | val_loss : 16775.69921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 452 | train_loss : 15429.1376953125 | val_loss : 8022.892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 453 | train_loss : 8421.0126953125 | val_loss : 25679.009765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 454 | train_loss : 16027.23046875 | val_loss : 22839.4296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 455 | train_loss : 19970.30859375 | val_loss : 24547.65234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 456 | train_loss : 21189.6171875 | val_loss : 20067.982421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 457 | train_loss : 21106.54296875 | val_loss : 8148.75732421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 458 | train_loss : 11316.6259765625 | val_loss : 20517.427734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 459 | train_loss : 20347.001953125 | val_loss : 27707.2890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 460 | train_loss : 21591.8671875 | val_loss : 29341.8359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 461 | train_loss : 23441.369140625 | val_loss : 19266.150390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 462 | train_loss : 14636.0224609375 | val_loss : 19751.474609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 463 | train_loss : 18271.978515625 | val_loss : 22381.16015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 464 | train_loss : 15743.6162109375 | val_loss : 13464.14453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 465 | train_loss : 9763.8515625 | val_loss : 17423.115234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 466 | train_loss : 13016.2900390625 | val_loss : 15572.60546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 467 | train_loss : 14455.91015625 | val_loss : 16667.568359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 468 | train_loss : 13739.0751953125 | val_loss : 15015.76953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 469 | train_loss : 13103.54296875 | val_loss : 19984.51953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 470 | train_loss : 13247.5302734375 | val_loss : 18275.388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 471 | train_loss : 14994.169921875 | val_loss : 36624.58984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 472 | train_loss : 27861.57421875 | val_loss : 27103.654296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 473 | train_loss : 25501.779296875 | val_loss : 19407.630859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 474 | train_loss : 13946.8720703125 | val_loss : 14954.857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 475 | train_loss : 14043.00390625 | val_loss : 23520.453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 476 | train_loss : 14781.8603515625 | val_loss : 18703.0234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 477 | train_loss : 14955.4375 | val_loss : 17819.8046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 478 | train_loss : 13474.630859375 | val_loss : 23529.943359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 479 | train_loss : 22144.794921875 | val_loss : 14692.1728515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 480 | train_loss : 12013.9248046875 | val_loss : 22002.04296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 481 | train_loss : 20073.236328125 | val_loss : 19704.181640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 482 | train_loss : 18168.13671875 | val_loss : 15737.4453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 483 | train_loss : 13729.2275390625 | val_loss : 13174.6923828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 484 | train_loss : 13501.9365234375 | val_loss : 23180.935546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 485 | train_loss : 22775.943359375 | val_loss : 17070.892578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 486 | train_loss : 16278.4853515625 | val_loss : 23673.955078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 487 | train_loss : 20367.404296875 | val_loss : 16418.22265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 488 | train_loss : 20613.833984375 | val_loss : 22410.462890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 489 | train_loss : 18853.984375 | val_loss : 13773.7373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 490 | train_loss : 12689.84375 | val_loss : 17330.748046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 491 | train_loss : 14263.5712890625 | val_loss : 20783.794921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 492 | train_loss : 15911.4501953125 | val_loss : 21559.623046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 493 | train_loss : 20015.98046875 | val_loss : 14623.111328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 494 | train_loss : 12742.8095703125 | val_loss : 18568.87109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 495 | train_loss : 15167.7724609375 | val_loss : 18243.474609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 496 | train_loss : 12411.3388671875 | val_loss : 17732.146484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 497 | train_loss : 13166.2041015625 | val_loss : 20860.849609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 498 | train_loss : 13942.9375 | val_loss : 11697.927734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 499 | train_loss : 9972.423828125 | val_loss : 30698.0390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 500 | train_loss : 20641.025390625 | val_loss : 26901.119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 501 | train_loss : 23668.546875 | val_loss : 21625.4140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 502 | train_loss : 15894.4599609375 | val_loss : 12330.81640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 503 | train_loss : 10299.12109375 | val_loss : 20940.755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 504 | train_loss : 13595.8212890625 | val_loss : 11785.009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 505 | train_loss : 9339.2509765625 | val_loss : 17168.806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 506 | train_loss : 11116.12109375 | val_loss : 17407.884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 507 | train_loss : 15075.7939453125 | val_loss : 19270.966796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 508 | train_loss : 14493.013671875 | val_loss : 13708.1826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 509 | train_loss : 12998.94921875 | val_loss : 14133.1279296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 510 | train_loss : 9866.130859375 | val_loss : 20777.630859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 511 | train_loss : 19091.908203125 | val_loss : 23717.435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 512 | train_loss : 19557.232421875 | val_loss : 22506.349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 513 | train_loss : 17873.57421875 | val_loss : 16056.44921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 514 | train_loss : 11215.3984375 | val_loss : 14796.775390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 515 | train_loss : 14424.3349609375 | val_loss : 19304.87890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 516 | train_loss : 13070.78515625 | val_loss : 16707.998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 517 | train_loss : 12866.5146484375 | val_loss : 17255.26953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 518 | train_loss : 12249.4609375 | val_loss : 11574.66015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 519 | train_loss : 10974.99609375 | val_loss : 30300.767578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 520 | train_loss : 19988.888671875 | val_loss : 24860.91015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 521 | train_loss : 21295.11328125 | val_loss : 25264.876953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 522 | train_loss : 19177.0703125 | val_loss : 13739.9990234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 523 | train_loss : 13811.3837890625 | val_loss : 14932.1796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 524 | train_loss : 13255.6962890625 | val_loss : 16210.986328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 525 | train_loss : 14009.45703125 | val_loss : 20874.2734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 526 | train_loss : 13309.79296875 | val_loss : 17653.5859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 527 | train_loss : 12978.6025390625 | val_loss : 20555.2421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 528 | train_loss : 16481.82421875 | val_loss : 24568.33984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 529 | train_loss : 24492.560546875 | val_loss : 32318.830078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 530 | train_loss : 24018.517578125 | val_loss : 38429.80078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 531 | train_loss : 32539.998046875 | val_loss : 14654.4345703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 532 | train_loss : 19236.13671875 | val_loss : 17825.23046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 533 | train_loss : 10972.9248046875 | val_loss : 9236.5478515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 534 | train_loss : 9022.0751953125 | val_loss : 10688.4873046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 535 | train_loss : 7819.04736328125 | val_loss : 18130.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 536 | train_loss : 15179.80078125 | val_loss : 20015.2421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 537 | train_loss : 14601.3466796875 | val_loss : 14854.0 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 538 | train_loss : 15751.1611328125 | val_loss : 27407.685546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 539 | train_loss : 21350.60546875 | val_loss : 22740.474609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 540 | train_loss : 19278.73046875 | val_loss : 16550.841796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 541 | train_loss : 11362.0927734375 | val_loss : 18524.560546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 542 | train_loss : 15894.021484375 | val_loss : 16771.390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 543 | train_loss : 12820.1953125 | val_loss : 16558.880859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 544 | train_loss : 13911.58984375 | val_loss : 20999.939453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 545 | train_loss : 13767.4970703125 | val_loss : 15800.43359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 546 | train_loss : 13532.0478515625 | val_loss : 17504.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 547 | train_loss : 11936.4765625 | val_loss : 9622.2314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 548 | train_loss : 9758.9521484375 | val_loss : 26469.607421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 549 | train_loss : 17755.822265625 | val_loss : 22583.119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 550 | train_loss : 19911.091796875 | val_loss : 11879.7197265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 551 | train_loss : 10289.0361328125 | val_loss : 13953.755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 552 | train_loss : 10648.6845703125 | val_loss : 20013.037109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 553 | train_loss : 12385.865234375 | val_loss : 14527.037109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 554 | train_loss : 11842.447265625 | val_loss : 16695.712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 555 | train_loss : 10926.58203125 | val_loss : 11941.8154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 556 | train_loss : 9797.3173828125 | val_loss : 26051.51171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 557 | train_loss : 17112.44921875 | val_loss : 19202.650390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 558 | train_loss : 16168.736328125 | val_loss : 22624.130859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 559 | train_loss : 18889.51953125 | val_loss : 24152.685546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 560 | train_loss : 21095.5546875 | val_loss : 16156.044921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 561 | train_loss : 20138.048828125 | val_loss : 19548.314453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 562 | train_loss : 13713.80859375 | val_loss : 20667.966796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 563 | train_loss : 22678.453125 | val_loss : 23018.828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 564 | train_loss : 19049.068359375 | val_loss : 13891.087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 565 | train_loss : 12808.50390625 | val_loss : 21398.845703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 566 | train_loss : 18237.810546875 | val_loss : 28635.5078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 567 | train_loss : 25252.47265625 | val_loss : 20741.095703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 568 | train_loss : 20211.712890625 | val_loss : 9562.474609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 569 | train_loss : 14126.16796875 | val_loss : 19774.72265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 570 | train_loss : 12698.076171875 | val_loss : 12717.419921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 571 | train_loss : 10341.791015625 | val_loss : 16136.9052734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 572 | train_loss : 12561.25 | val_loss : 14846.08984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 573 | train_loss : 17580.189453125 | val_loss : 18717.197265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 574 | train_loss : 15707.6591796875 | val_loss : 9447.07421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 575 | train_loss : 13289.611328125 | val_loss : 15816.6376953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 576 | train_loss : 13208.8251953125 | val_loss : 12143.0576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 577 | train_loss : 10527.8564453125 | val_loss : 9548.013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 578 | train_loss : 8606.9033203125 | val_loss : 20667.36328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 579 | train_loss : 12667.2197265625 | val_loss : 18285.193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 580 | train_loss : 14020.83984375 | val_loss : 15151.99609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 581 | train_loss : 11206.826171875 | val_loss : 10383.259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 582 | train_loss : 9327.7119140625 | val_loss : 27179.693359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 583 | train_loss : 16767.962890625 | val_loss : 22489.66796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 584 | train_loss : 18192.060546875 | val_loss : 12248.572265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 585 | train_loss : 13701.244140625 | val_loss : 21689.0625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 586 | train_loss : 15095.708984375 | val_loss : 11054.62890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 587 | train_loss : 10575.2099609375 | val_loss : 6353.2236328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 588 | train_loss : 5206.19482421875 | val_loss : 6388.6787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 589 | train_loss : 7116.07373046875 | val_loss : 14316.568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 590 | train_loss : 8237.3017578125 | val_loss : 14619.93359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 591 | train_loss : 12475.87890625 | val_loss : 17758.107421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 592 | train_loss : 13481.1376953125 | val_loss : 18627.58984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 593 | train_loss : 16320.5263671875 | val_loss : 19839.94921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 594 | train_loss : 13039.3076171875 | val_loss : 14616.42578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 595 | train_loss : 12657.2841796875 | val_loss : 20743.873046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 596 | train_loss : 13402.822265625 | val_loss : 10607.337890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 597 | train_loss : 9105.833984375 | val_loss : 22578.748046875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 598 | train_loss : 14433.025390625 | val_loss : 16348.8974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 599 | train_loss : 14141.21484375 | val_loss : 17694.25390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 600 | train_loss : 11421.322265625 | val_loss : 13666.8515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 601 | train_loss : 11917.10546875 | val_loss : 18515.759765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 602 | train_loss : 13006.048828125 | val_loss : 17372.796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 603 | train_loss : 13865.875 | val_loss : 21295.224609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 604 | train_loss : 15193.5458984375 | val_loss : 18400.251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 605 | train_loss : 17897.33203125 | val_loss : 22455.140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 606 | train_loss : 17174.82421875 | val_loss : 13181.6572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 607 | train_loss : 11060.951171875 | val_loss : 17493.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 608 | train_loss : 12050.1533203125 | val_loss : 21205.505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 609 | train_loss : 20046.580078125 | val_loss : 14918.138671875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 610 | train_loss : 11282.068359375 | val_loss : 16417.765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 611 | train_loss : 19253.3828125 | val_loss : 18911.06640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 612 | train_loss : 17546.93359375 | val_loss : 16801.904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 613 | train_loss : 13914.1875 | val_loss : 27488.751953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 614 | train_loss : 18346.6640625 | val_loss : 25567.08203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 615 | train_loss : 22788.669921875 | val_loss : 11860.5751953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 616 | train_loss : 10232.1640625 | val_loss : 9667.990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 617 | train_loss : 10535.275390625 | val_loss : 27595.685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 618 | train_loss : 18478.751953125 | val_loss : 19014.267578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 619 | train_loss : 17241.3671875 | val_loss : 14139.572265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 620 | train_loss : 17750.51953125 | val_loss : 20794.271484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 621 | train_loss : 16883.46484375 | val_loss : 14100.9658203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 622 | train_loss : 17758.92578125 | val_loss : 13003.8525390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 623 | train_loss : 11651.46875 | val_loss : 18318.95703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 624 | train_loss : 15115.857421875 | val_loss : 23355.8046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 625 | train_loss : 22794.251953125 | val_loss : 11865.6728515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 626 | train_loss : 10398.5078125 | val_loss : 13489.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 627 | train_loss : 10276.677734375 | val_loss : 16964.587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 628 | train_loss : 11994.611328125 | val_loss : 9522.1884765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 629 | train_loss : 8763.005859375 | val_loss : 18260.71875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 630 | train_loss : 11424.91015625 | val_loss : 14027.5166015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 631 | train_loss : 10958.95703125 | val_loss : 20227.201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 632 | train_loss : 13708.9375 | val_loss : 13196.2978515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 633 | train_loss : 12299.9736328125 | val_loss : 8737.1875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 634 | train_loss : 8205.6416015625 | val_loss : 9547.9072265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 635 | train_loss : 8215.7431640625 | val_loss : 17909.091796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 636 | train_loss : 11887.302734375 | val_loss : 17245.244140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 637 | train_loss : 15193.791015625 | val_loss : 10797.3388671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 638 | train_loss : 8551.443359375 | val_loss : 14697.46484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 639 | train_loss : 12031.7626953125 | val_loss : 24595.08984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 640 | train_loss : 15864.083984375 | val_loss : 19499.193359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 641 | train_loss : 15763.861328125 | val_loss : 21977.90234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 642 | train_loss : 18341.216796875 | val_loss : 17367.49609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 643 | train_loss : 15759.7470703125 | val_loss : 19386.00390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 644 | train_loss : 13381.875 | val_loss : 12378.0322265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 645 | train_loss : 10675.77734375 | val_loss : 16604.7109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 646 | train_loss : 10842.1396484375 | val_loss : 16870.9375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 647 | train_loss : 14175.6748046875 | val_loss : 12306.5078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 648 | train_loss : 10008.181640625 | val_loss : 15656.3046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 649 | train_loss : 12912.8037109375 | val_loss : 17111.80078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 650 | train_loss : 21097.46484375 | val_loss : 18466.060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 651 | train_loss : 15782.2529296875 | val_loss : 11572.8759765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 652 | train_loss : 10475.474609375 | val_loss : 14160.9521484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 653 | train_loss : 12142.568359375 | val_loss : 5392.69140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 654 | train_loss : 5601.73291015625 | val_loss : 11567.9404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 655 | train_loss : 8665.193359375 | val_loss : 13999.6787109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 656 | train_loss : 10015.794921875 | val_loss : 7241.06494140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 657 | train_loss : 6849.458984375 | val_loss : 24761.392578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 658 | train_loss : 14976.353515625 | val_loss : 16447.650390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 659 | train_loss : 13183.21875 | val_loss : 6061.990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 660 | train_loss : 11121.375 | val_loss : 15416.12109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 661 | train_loss : 10467.5478515625 | val_loss : 9116.09765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 662 | train_loss : 10473.0791015625 | val_loss : 8573.7509765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 663 | train_loss : 6776.38134765625 | val_loss : 7019.4013671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 664 | train_loss : 9571.5751953125 | val_loss : 16646.92578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 665 | train_loss : 14037.33203125 | val_loss : 11331.6845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 666 | train_loss : 12155.0263671875 | val_loss : 10671.2666015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 667 | train_loss : 8970.8896484375 | val_loss : 7980.8037109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 668 | train_loss : 11552.142578125 | val_loss : 17324.91796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 669 | train_loss : 13276.66015625 | val_loss : 8324.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 670 | train_loss : 8179.4169921875 | val_loss : 7831.8525390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 671 | train_loss : 7521.63916015625 | val_loss : 8957.353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 672 | train_loss : 7171.25634765625 | val_loss : 12816.3271484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 673 | train_loss : 10988.2109375 | val_loss : 12430.1396484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 674 | train_loss : 11163.869140625 | val_loss : 16768.89453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 675 | train_loss : 12653.8310546875 | val_loss : 20288.841796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 676 | train_loss : 12898.0302734375 | val_loss : 10268.5078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 677 | train_loss : 8329.9775390625 | val_loss : 16817.095703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 678 | train_loss : 12042.7353515625 | val_loss : 16869.140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 679 | train_loss : 14699.986328125 | val_loss : 17477.28125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 680 | train_loss : 14011.64453125 | val_loss : 18287.8125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 681 | train_loss : 15342.2763671875 | val_loss : 13214.8759765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 682 | train_loss : 8275.9697265625 | val_loss : 11048.6064453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 683 | train_loss : 8238.2490234375 | val_loss : 15546.1435546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 684 | train_loss : 9900.2021484375 | val_loss : 9309.3740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 685 | train_loss : 7335.29638671875 | val_loss : 17324.3671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 686 | train_loss : 11579.0576171875 | val_loss : 15892.6923828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 687 | train_loss : 13069.162109375 | val_loss : 12416.9384765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 688 | train_loss : 8748.74609375 | val_loss : 11440.6708984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 689 | train_loss : 13440.9375 | val_loss : 13238.3154296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 690 | train_loss : 8947.552734375 | val_loss : 11713.33203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 691 | train_loss : 9078.005859375 | val_loss : 12857.0966796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 692 | train_loss : 9022.486328125 | val_loss : 6256.18017578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 693 | train_loss : 6389.53515625 | val_loss : 18190.908203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 694 | train_loss : 12259.5537109375 | val_loss : 14272.2685546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 695 | train_loss : 13018.3251953125 | val_loss : 17485.279296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 696 | train_loss : 13014.986328125 | val_loss : 16041.44921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 697 | train_loss : 14157.2021484375 | val_loss : 12604.2158203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 698 | train_loss : 8618.4072265625 | val_loss : 12450.630859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 699 | train_loss : 10154.583984375 | val_loss : 14281.84375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 700 | train_loss : 9005.072265625 | val_loss : 8451.8447265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 701 | train_loss : 7914.98046875 | val_loss : 15063.330078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 702 | train_loss : 10131.8330078125 | val_loss : 7682.46875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 703 | train_loss : 5773.99560546875 | val_loss : 17089.12890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 704 | train_loss : 11062.6328125 | val_loss : 14156.7373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 705 | train_loss : 11348.037109375 | val_loss : 11788.474609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 706 | train_loss : 8346.23046875 | val_loss : 14346.51171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 707 | train_loss : 12114.263671875 | val_loss : 11449.2646484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 708 | train_loss : 7936.74267578125 | val_loss : 11908.271484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 709 | train_loss : 10601.89453125 | val_loss : 16376.7978515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 710 | train_loss : 11881.6123046875 | val_loss : 63416.9140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 711 | train_loss : 62541.80078125 | val_loss : 41044.95703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 712 | train_loss : 31962.671875 | val_loss : 23792.15234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 713 | train_loss : 18784.1796875 | val_loss : 20043.21875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 714 | train_loss : 17894.98046875 | val_loss : 7496.6611328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 715 | train_loss : 7050.3251953125 | val_loss : 6895.40380859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 716 | train_loss : 4690.373046875 | val_loss : 9937.8935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 717 | train_loss : 7920.123046875 | val_loss : 18076.076171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 718 | train_loss : 11627.6953125 | val_loss : 15067.47265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 719 | train_loss : 13298.705078125 | val_loss : 10980.5478515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 720 | train_loss : 9820.1826171875 | val_loss : 10272.3740234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 721 | train_loss : 7932.81103515625 | val_loss : 11317.7060546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 722 | train_loss : 11250.482421875 | val_loss : 14643.048828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 723 | train_loss : 11330.7998046875 | val_loss : 11214.6025390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 724 | train_loss : 13360.4248046875 | val_loss : 13540.634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 725 | train_loss : 11029.49609375 | val_loss : 13369.8359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 726 | train_loss : 10647.64453125 | val_loss : 14887.72265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 727 | train_loss : 12948.6162109375 | val_loss : 11405.357421875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 728 | train_loss : 8252.0244140625 | val_loss : 9935.4697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 729 | train_loss : 8935.1533203125 | val_loss : 18629.46484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 730 | train_loss : 11513.6396484375 | val_loss : 11732.6083984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 731 | train_loss : 9110.291015625 | val_loss : 14639.6953125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 732 | train_loss : 10852.5927734375 | val_loss : 12700.5048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 733 | train_loss : 11236.6123046875 | val_loss : 16898.91796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 734 | train_loss : 11586.7353515625 | val_loss : 13215.7578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 735 | train_loss : 11343.67578125 | val_loss : 12798.8388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 736 | train_loss : 8001.11328125 | val_loss : 8077.83740234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 737 | train_loss : 7281.234375 | val_loss : 8883.91015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 738 | train_loss : 5742.11767578125 | val_loss : 10863.224609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 739 | train_loss : 9136.287109375 | val_loss : 28113.2421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 740 | train_loss : 18110.849609375 | val_loss : 21689.515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 741 | train_loss : 17314.33984375 | val_loss : 12408.0537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 742 | train_loss : 12040.5126953125 | val_loss : 18919.568359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 743 | train_loss : 13535.9287109375 | val_loss : 10413.0771484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 744 | train_loss : 12143.544921875 | val_loss : 14189.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 745 | train_loss : 13427.6162109375 | val_loss : 15457.8447265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 746 | train_loss : 9986.2490234375 | val_loss : 15380.9150390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 747 | train_loss : 12874.8388671875 | val_loss : 12250.7001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 748 | train_loss : 8029.47265625 | val_loss : 8513.0341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 749 | train_loss : 7268.662109375 | val_loss : 18096.689453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 750 | train_loss : 10855.3701171875 | val_loss : 13277.9013671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 751 | train_loss : 11097.513671875 | val_loss : 7094.62353515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 752 | train_loss : 8525.20703125 | val_loss : 8509.5263671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 753 | train_loss : 7361.39990234375 | val_loss : 12343.3837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 754 | train_loss : 9614.763671875 | val_loss : 9541.490234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 755 | train_loss : 9163.1591796875 | val_loss : 12505.6728515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 756 | train_loss : 10214.375 | val_loss : 12066.85546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 757 | train_loss : 10612.5458984375 | val_loss : 13730.8125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 758 | train_loss : 10565.294921875 | val_loss : 12449.5546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 759 | train_loss : 12721.2666015625 | val_loss : 12497.2109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 760 | train_loss : 9525.869140625 | val_loss : 9153.869140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 761 | train_loss : 8828.6123046875 | val_loss : 16865.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 762 | train_loss : 11004.2265625 | val_loss : 12576.916015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 763 | train_loss : 11055.4365234375 | val_loss : 7400.52001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 764 | train_loss : 11669.291015625 | val_loss : 10543.900390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 765 | train_loss : 6650.60693359375 | val_loss : 6401.44873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 766 | train_loss : 6535.296875 | val_loss : 5365.7685546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 767 | train_loss : 5165.89794921875 | val_loss : 5454.9814453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 768 | train_loss : 5054.9873046875 | val_loss : 6045.31494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 769 | train_loss : 5607.15380859375 | val_loss : 11452.1650390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 770 | train_loss : 10750.455078125 | val_loss : 19407.392578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 771 | train_loss : 13946.5302734375 | val_loss : 12223.267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 772 | train_loss : 9751.068359375 | val_loss : 10947.6513671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 773 | train_loss : 8772.0888671875 | val_loss : 13597.423828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 774 | train_loss : 11496.611328125 | val_loss : 7795.486328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 775 | train_loss : 5969.91796875 | val_loss : 9797.3662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 776 | train_loss : 11074.302734375 | val_loss : 20788.201171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 777 | train_loss : 15515.7060546875 | val_loss : 21682.78515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 778 | train_loss : 18326.099609375 | val_loss : 8827.9697265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 779 | train_loss : 7550.958984375 | val_loss : 11345.4638671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 780 | train_loss : 9656.45703125 | val_loss : 8735.94140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 781 | train_loss : 7276.68017578125 | val_loss : 8541.9921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 782 | train_loss : 7792.283203125 | val_loss : 234159.765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 783 | train_loss : 223610.78125 | val_loss : 36554.7890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 784 | train_loss : 33719.6328125 | val_loss : 15449.24609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 785 | train_loss : 19385.3828125 | val_loss : 27629.185546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 786 | train_loss : 18707.42578125 | val_loss : 17505.751953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 787 | train_loss : 11355.349609375 | val_loss : 9049.0576171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 788 | train_loss : 7986.1201171875 | val_loss : 7407.79736328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 789 | train_loss : 6689.87109375 | val_loss : 13277.2802734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 790 | train_loss : 9607.21484375 | val_loss : 10901.865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 791 | train_loss : 8673.5380859375 | val_loss : 9928.6171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 792 | train_loss : 6723.07373046875 | val_loss : 11654.3828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 793 | train_loss : 8300.4521484375 | val_loss : 11315.33203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 794 | train_loss : 7907.1982421875 | val_loss : 7362.794921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 795 | train_loss : 6242.68017578125 | val_loss : 12590.853515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 796 | train_loss : 8185.8798828125 | val_loss : 11349.072265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 797 | train_loss : 8321.53515625 | val_loss : 9731.853515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 798 | train_loss : 7322.8173828125 | val_loss : 4884.19482421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 799 | train_loss : 5315.24072265625 | val_loss : 18657.3671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 800 | train_loss : 11381.322265625 | val_loss : 10719.1796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 801 | train_loss : 8641.2109375 | val_loss : 11689.1298828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 802 | train_loss : 8813.240234375 | val_loss : 14497.3037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 803 | train_loss : 11444.6025390625 | val_loss : 9838.744140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 804 | train_loss : 6925.48828125 | val_loss : 7865.77490234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 805 | train_loss : 7629.98046875 | val_loss : 17531.83203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 806 | train_loss : 12198.0302734375 | val_loss : 12310.8037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 807 | train_loss : 10601.5986328125 | val_loss : 12098.40234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 808 | train_loss : 8108.888671875 | val_loss : 14077.1728515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 809 | train_loss : 11211.5576171875 | val_loss : 10895.0712890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 810 | train_loss : 8270.44921875 | val_loss : 12605.724609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 811 | train_loss : 13017.5625 | val_loss : 14956.9091796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 812 | train_loss : 9832.6708984375 | val_loss : 12916.9833984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 813 | train_loss : 11999.228515625 | val_loss : 10065.375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 814 | train_loss : 9669.5703125 | val_loss : 11892.9521484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 815 | train_loss : 9812.5771484375 | val_loss : 11438.099609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 816 | train_loss : 8716.3271484375 | val_loss : 11202.5615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 817 | train_loss : 9268.4765625 | val_loss : 12687.3046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 818 | train_loss : 8279.4951171875 | val_loss : 10603.4833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 819 | train_loss : 8775.12890625 | val_loss : 13305.0302734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 820 | train_loss : 9267.2197265625 | val_loss : 11101.4326171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 821 | train_loss : 10574.3701171875 | val_loss : 9585.8935546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 822 | train_loss : 8477.9716796875 | val_loss : 11149.794921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 823 | train_loss : 11191.33984375 | val_loss : 7770.357421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 824 | train_loss : 11920.8388671875 | val_loss : 8705.8134765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 825 | train_loss : 7250.99267578125 | val_loss : 8596.7099609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 826 | train_loss : 6679.4716796875 | val_loss : 7562.2236328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 827 | train_loss : 7055.06982421875 | val_loss : 13164.6201171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 828 | train_loss : 8191.74267578125 | val_loss : 8561.7666015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 829 | train_loss : 7644.294921875 | val_loss : 11250.30078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 830 | train_loss : 7231.7939453125 | val_loss : 9671.3779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 831 | train_loss : 8294.333984375 | val_loss : 10922.48046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 832 | train_loss : 7199.09375 | val_loss : 7158.31396484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 833 | train_loss : 6042.63134765625 | val_loss : 11779.8427734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 834 | train_loss : 8136.2900390625 | val_loss : 10214.7236328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 835 | train_loss : 8438.4296875 | val_loss : 13228.423828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 836 | train_loss : 9485.193359375 | val_loss : 11957.0859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 837 | train_loss : 10213.212890625 | val_loss : 11816.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 838 | train_loss : 8289.3828125 | val_loss : 7597.73876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 839 | train_loss : 6520.8076171875 | val_loss : 13588.26953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 840 | train_loss : 9070.7890625 | val_loss : 10547.7333984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 841 | train_loss : 9558.4111328125 | val_loss : 10435.4384765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 842 | train_loss : 7319.28369140625 | val_loss : 9917.6064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 843 | train_loss : 8109.32958984375 | val_loss : 16162.77734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 844 | train_loss : 10274.9697265625 | val_loss : 8092.0361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 845 | train_loss : 7084.9375 | val_loss : 11776.16796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 846 | train_loss : 7899.50048828125 | val_loss : 15647.0908203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 847 | train_loss : 13356.521484375 | val_loss : 9215.396484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 848 | train_loss : 9703.603515625 | val_loss : 7012.56494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 849 | train_loss : 5930.955078125 | val_loss : 3137.30126953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 850 | train_loss : 4982.6962890625 | val_loss : 8730.6123046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 851 | train_loss : 6823.45703125 | val_loss : 9612.76953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 852 | train_loss : 10520.048828125 | val_loss : 8610.5986328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 853 | train_loss : 8670.521484375 | val_loss : 19149.712890625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 854 | train_loss : 24500.16015625 | val_loss : 19147.046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 855 | train_loss : 17883.67578125 | val_loss : 6772.14013671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 856 | train_loss : 7990.271484375 | val_loss : 4748.1513671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 857 | train_loss : 4774.3505859375 | val_loss : 6888.6435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 858 | train_loss : 7803.8251953125 | val_loss : 9466.8798828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 859 | train_loss : 9002.0361328125 | val_loss : 9765.0615234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 860 | train_loss : 7517.8154296875 | val_loss : 6754.3798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 861 | train_loss : 6200.6904296875 | val_loss : 15595.2197265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 862 | train_loss : 9817.642578125 | val_loss : 9794.2978515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 863 | train_loss : 8206.2822265625 | val_loss : 16078.4013671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 864 | train_loss : 11497.115234375 | val_loss : 14018.45703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 865 | train_loss : 11643.1533203125 | val_loss : 10711.5849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 866 | train_loss : 8348.7880859375 | val_loss : 9395.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 867 | train_loss : 6601.4482421875 | val_loss : 9296.611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 868 | train_loss : 5534.240234375 | val_loss : 8769.5595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 869 | train_loss : 6780.33642578125 | val_loss : 11489.7734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 870 | train_loss : 7192.2744140625 | val_loss : 10849.69921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 871 | train_loss : 9594.6865234375 | val_loss : 9674.576171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 872 | train_loss : 5569.2724609375 | val_loss : 7463.70263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 873 | train_loss : 5944.701171875 | val_loss : 14372.2001953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 874 | train_loss : 8301.0810546875 | val_loss : 7935.423828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 875 | train_loss : 5847.43505859375 | val_loss : 12962.880859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 876 | train_loss : 8693.5771484375 | val_loss : 11441.8134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 877 | train_loss : 10347.279296875 | val_loss : 9745.1689453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 878 | train_loss : 7075.45947265625 | val_loss : 9767.1064453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 879 | train_loss : 8458.599609375 | val_loss : 15717.67578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 880 | train_loss : 9748.130859375 | val_loss : 9729.8486328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 881 | train_loss : 7884.53759765625 | val_loss : 10904.7333984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 882 | train_loss : 6557.69140625 | val_loss : 10784.8486328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 883 | train_loss : 8286.3994140625 | val_loss : 9332.58203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 884 | train_loss : 6829.25390625 | val_loss : 6545.9912109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 885 | train_loss : 5418.06494140625 | val_loss : 11454.888671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 886 | train_loss : 7654.06494140625 | val_loss : 7641.08984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 887 | train_loss : 5680.44921875 | val_loss : 7231.267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 888 | train_loss : 5087.01416015625 | val_loss : 6649.513671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 889 | train_loss : 5392.02978515625 | val_loss : 7498.75 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 890 | train_loss : 5754.16064453125 | val_loss : 6955.5673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 891 | train_loss : 6729.66064453125 | val_loss : 65627.4765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 892 | train_loss : 60010.1953125 | val_loss : 22404.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 893 | train_loss : 29225.265625 | val_loss : 25179.71484375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 894 | train_loss : 28152.310546875 | val_loss : 15483.2763671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 895 | train_loss : 16321.580078125 | val_loss : 17158.80859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 896 | train_loss : 12896.9814453125 | val_loss : 9179.9248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 897 | train_loss : 6829.27978515625 | val_loss : 6879.9814453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 898 | train_loss : 4536.248046875 | val_loss : 6244.39501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 899 | train_loss : 5215.646484375 | val_loss : 375664.09375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 900 | train_loss : 274711.3125 | val_loss : 203230.3125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 901 | train_loss : 172639.140625 | val_loss : 84006.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 902 | train_loss : 98487.90625 | val_loss : 25625.162109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 903 | train_loss : 37468.18359375 | val_loss : 13687.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 904 | train_loss : 16502.71484375 | val_loss : 12619.39453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 905 | train_loss : 7601.83251953125 | val_loss : 5913.4501953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 906 | train_loss : 4903.67333984375 | val_loss : 8353.2958984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 907 | train_loss : 6703.4931640625 | val_loss : 9374.017578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 908 | train_loss : 10370.33203125 | val_loss : 9952.1875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 909 | train_loss : 8365.998046875 | val_loss : 10212.322265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 910 | train_loss : 9899.384765625 | val_loss : 12127.40234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 911 | train_loss : 9635.1806640625 | val_loss : 6816.98876953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 912 | train_loss : 8121.951171875 | val_loss : 8751.8623046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 913 | train_loss : 6884.46484375 | val_loss : 7939.103515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 914 | train_loss : 6863.28369140625 | val_loss : 5871.72607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 915 | train_loss : 5024.2431640625 | val_loss : 6673.4150390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 916 | train_loss : 5385.455078125 | val_loss : 9255.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 917 | train_loss : 7366.3349609375 | val_loss : 5461.55859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 918 | train_loss : 4981.95263671875 | val_loss : 8625.205078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 919 | train_loss : 8315.853515625 | val_loss : 30848.650390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 920 | train_loss : 30994.251953125 | val_loss : 11346.1611328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 921 | train_loss : 18603.8671875 | val_loss : 25167.232421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 922 | train_loss : 18457.994140625 | val_loss : 23423.564453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 923 | train_loss : 17649.330078125 | val_loss : 9872.71875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 924 | train_loss : 9608.0927734375 | val_loss : 8702.5654296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 925 | train_loss : 8347.1435546875 | val_loss : 11434.76171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 926 | train_loss : 10358.2578125 | val_loss : 7537.166015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 927 | train_loss : 5820.05615234375 | val_loss : 6449.9775390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 928 | train_loss : 5640.99609375 | val_loss : 14130.5703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 929 | train_loss : 9475.419921875 | val_loss : 6278.84228515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 930 | train_loss : 5444.458984375 | val_loss : 10361.68359375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 931 | train_loss : 7385.5087890625 | val_loss : 9073.3623046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 932 | train_loss : 8107.5439453125 | val_loss : 10388.4521484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 933 | train_loss : 8781.4921875 | val_loss : 8849.080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 934 | train_loss : 8294.0537109375 | val_loss : 12378.1650390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 935 | train_loss : 8132.59375 | val_loss : 7626.60107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 936 | train_loss : 5851.64208984375 | val_loss : 5278.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 937 | train_loss : 4114.416015625 | val_loss : 7156.97998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 938 | train_loss : 5494.32177734375 | val_loss : 7311.791015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 939 | train_loss : 5840.23583984375 | val_loss : 5650.5673828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 940 | train_loss : 5453.2548828125 | val_loss : 9259.5048828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 941 | train_loss : 6233.72607421875 | val_loss : 7123.84619140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 942 | train_loss : 5716.33056640625 | val_loss : 6948.1064453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 943 | train_loss : 5196.38916015625 | val_loss : 6024.64892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 944 | train_loss : 6252.34130859375 | val_loss : 9943.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 945 | train_loss : 6631.076171875 | val_loss : 5671.67138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 946 | train_loss : 4597.56005859375 | val_loss : 6766.1435546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 947 | train_loss : 4667.673828125 | val_loss : 6630.0595703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 948 | train_loss : 5454.29052734375 | val_loss : 8915.8876953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 949 | train_loss : 5952.92578125 | val_loss : 4393.50634765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 950 | train_loss : 3618.423095703125 | val_loss : 6513.615234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 951 | train_loss : 4724.73193359375 | val_loss : 6864.69482421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 952 | train_loss : 5341.3935546875 | val_loss : 5175.36376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 953 | train_loss : 4226.94970703125 | val_loss : 4911.78857421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 954 | train_loss : 3679.956298828125 | val_loss : 5996.33251953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 955 | train_loss : 4758.86767578125 | val_loss : 5793.1337890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 956 | train_loss : 4609.10400390625 | val_loss : 5696.8212890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 957 | train_loss : 5181.87744140625 | val_loss : 7750.89111328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 958 | train_loss : 6593.57763671875 | val_loss : 5611.56103515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 959 | train_loss : 5900.18994140625 | val_loss : 9585.146484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 960 | train_loss : 7944.66748046875 | val_loss : 5955.228515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 961 | train_loss : 11743.548828125 | val_loss : 12187.888671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 962 | train_loss : 8241.666015625 | val_loss : 4558.6337890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 963 | train_loss : 5198.70361328125 | val_loss : 6373.09228515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 964 | train_loss : 6130.80126953125 | val_loss : 5778.00634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 965 | train_loss : 4505.4775390625 | val_loss : 5853.353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 966 | train_loss : 4994.31005859375 | val_loss : 11946.79296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 967 | train_loss : 7806.228515625 | val_loss : 8507.7099609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 968 | train_loss : 7062.98388671875 | val_loss : 9024.291015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 969 | train_loss : 6943.0029296875 | val_loss : 8052.03271484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 970 | train_loss : 6669.625 | val_loss : 10327.7802734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 971 | train_loss : 7489.33251953125 | val_loss : 8594.8046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 972 | train_loss : 7145.60009765625 | val_loss : 7167.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 973 | train_loss : 4696.55419921875 | val_loss : 4596.00244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 974 | train_loss : 3972.030517578125 | val_loss : 8482.583984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 975 | train_loss : 5273.28173828125 | val_loss : 6526.625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 976 | train_loss : 5694.56494140625 | val_loss : 13360.6787109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 977 | train_loss : 8718.21484375 | val_loss : 68078.7109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 978 | train_loss : 66546.2421875 | val_loss : 35665.1640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 979 | train_loss : 33164.31640625 | val_loss : 8300.072265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 980 | train_loss : 14162.78125 | val_loss : 13313.6259765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 981 | train_loss : 12330.12109375 | val_loss : 10515.701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 982 | train_loss : 9005.376953125 | val_loss : 4964.83740234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 983 | train_loss : 5209.62890625 | val_loss : 3977.43115234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 984 | train_loss : 3623.52099609375 | val_loss : 6500.92236328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 985 | train_loss : 5360.90771484375 | val_loss : 11810.8447265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 986 | train_loss : 8545.28515625 | val_loss : 7638.830078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 987 | train_loss : 6262.64208984375 | val_loss : 10785.86328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 988 | train_loss : 7643.001953125 | val_loss : 9978.2861328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 989 | train_loss : 8559.8623046875 | val_loss : 10358.8974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 990 | train_loss : 7079.86767578125 | val_loss : 6907.51123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 991 | train_loss : 6060.07861328125 | val_loss : 8883.75390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 992 | train_loss : 5901.8837890625 | val_loss : 10437.4326171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 993 | train_loss : 8728.359375 | val_loss : 8224.318359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 994 | train_loss : 5777.67236328125 | val_loss : 6982.91259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 995 | train_loss : 5726.0732421875 | val_loss : 10415.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 996 | train_loss : 6638.572265625 | val_loss : 8161.18896484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 997 | train_loss : 6513.54296875 | val_loss : 10367.16015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 998 | train_loss : 7501.88916015625 | val_loss : 9164.27734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 999 | train_loss : 7954.3525390625 | val_loss : 10233.4765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1000 | train_loss : 6917.9462890625 | val_loss : 6515.8525390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1001 | train_loss : 5472.35107421875 | val_loss : 11120.5615234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1002 | train_loss : 7387.8076171875 | val_loss : 9076.6376953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1003 | train_loss : 7977.18115234375 | val_loss : 10446.919921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1004 | train_loss : 7175.12939453125 | val_loss : 7376.47509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1005 | train_loss : 6577.53369140625 | val_loss : 12192.1884765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1006 | train_loss : 7588.4951171875 | val_loss : 6544.96630859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1007 | train_loss : 5394.51171875 | val_loss : 9092.830078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1008 | train_loss : 5625.7099609375 | val_loss : 8444.2099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1009 | train_loss : 6930.25390625 | val_loss : 35737.38671875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1010 | train_loss : 29952.58984375 | val_loss : 17869.888671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1011 | train_loss : 18632.921875 | val_loss : 13897.44140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1012 | train_loss : 11753.2861328125 | val_loss : 9403.0771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1013 | train_loss : 14051.576171875 | val_loss : 8460.646484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1014 | train_loss : 6586.47607421875 | val_loss : 4326.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1015 | train_loss : 4837.2001953125 | val_loss : 5424.74365234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1016 | train_loss : 3955.791259765625 | val_loss : 5904.92138671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1017 | train_loss : 5226.14697265625 | val_loss : 5182.37646484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1018 | train_loss : 3769.83740234375 | val_loss : 5678.9375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1019 | train_loss : 4537.45361328125 | val_loss : 6527.205078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1020 | train_loss : 4765.32275390625 | val_loss : 5686.96630859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1021 | train_loss : 4449.10791015625 | val_loss : 5771.857421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1022 | train_loss : 4225.90234375 | val_loss : 6887.875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1023 | train_loss : 5318.5 | val_loss : 5679.1748046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1024 | train_loss : 4163.80615234375 | val_loss : 5917.62353515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1025 | train_loss : 4267.9697265625 | val_loss : 6369.76123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1026 | train_loss : 4920.07373046875 | val_loss : 6856.013671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1027 | train_loss : 4704.03076171875 | val_loss : 5167.353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1028 | train_loss : 4478.2939453125 | val_loss : 9522.513671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1029 | train_loss : 5946.197265625 | val_loss : 5072.66357421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1030 | train_loss : 3931.93310546875 | val_loss : 6227.61865234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1031 | train_loss : 4417.40283203125 | val_loss : 5628.47119140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1032 | train_loss : 4970.462890625 | val_loss : 8268.35546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1033 | train_loss : 5256.376953125 | val_loss : 5108.40380859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1034 | train_loss : 4146.05712890625 | val_loss : 7180.87646484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1035 | train_loss : 5106.97802734375 | val_loss : 5321.68896484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1036 | train_loss : 4026.0673828125 | val_loss : 6353.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1037 | train_loss : 4348.3740234375 | val_loss : 6358.82373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1038 | train_loss : 4726.4248046875 | val_loss : 6373.32373046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1039 | train_loss : 4677.8544921875 | val_loss : 6160.78857421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1040 | train_loss : 4832.248046875 | val_loss : 5973.46728515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1041 | train_loss : 4390.4501953125 | val_loss : 6944.0361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1042 | train_loss : 5526.94189453125 | val_loss : 6798.32763671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1043 | train_loss : 5397.548828125 | val_loss : 8700.974609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1044 | train_loss : 7613.10986328125 | val_loss : 5177.34326171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1045 | train_loss : 6274.05419921875 | val_loss : 8393.6513671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1046 | train_loss : 7960.28125 | val_loss : 3804.449951171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1047 | train_loss : 8199.7177734375 | val_loss : 10940.78125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1048 | train_loss : 8639.935546875 | val_loss : 3486.2763671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1049 | train_loss : 5546.6220703125 | val_loss : 7625.06005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1050 | train_loss : 6361.11376953125 | val_loss : 7385.798828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1051 | train_loss : 5881.8154296875 | val_loss : 8405.568359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1052 | train_loss : 6848.34130859375 | val_loss : 6080.365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1053 | train_loss : 4172.5576171875 | val_loss : 3796.648681640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1054 | train_loss : 4124.22509765625 | val_loss : 12930.84765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1055 | train_loss : 9463.609375 | val_loss : 11264.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1056 | train_loss : 9773.986328125 | val_loss : 10445.6689453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1057 | train_loss : 7485.443359375 | val_loss : 11148.5283203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1058 | train_loss : 8453.7373046875 | val_loss : 8501.5673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1059 | train_loss : 6526.3681640625 | val_loss : 7848.7099609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1060 | train_loss : 7633.3935546875 | val_loss : 14895.4111328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1061 | train_loss : 9896.306640625 | val_loss : 8336.71875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1062 | train_loss : 7318.08251953125 | val_loss : 8096.44384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1063 | train_loss : 5927.23291015625 | val_loss : 8615.669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1064 | train_loss : 7053.74267578125 | val_loss : 6738.87646484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1065 | train_loss : 4495.4931640625 | val_loss : 5467.884765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1066 | train_loss : 3849.51416015625 | val_loss : 7262.39013671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1067 | train_loss : 4557.134765625 | val_loss : 9125.044921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1068 | train_loss : 7524.1962890625 | val_loss : 7801.37353515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1069 | train_loss : 5069.12451171875 | val_loss : 6551.3173828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1070 | train_loss : 5956.521484375 | val_loss : 10374.8671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1071 | train_loss : 8821.931640625 | val_loss : 12709.1376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1072 | train_loss : 11695.4990234375 | val_loss : 5121.9560546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1073 | train_loss : 8862.291015625 | val_loss : 8101.142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1074 | train_loss : 5189.79150390625 | val_loss : 4296.146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1075 | train_loss : 3903.996337890625 | val_loss : 5312.81884765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1076 | train_loss : 4721.39697265625 | val_loss : 8670.8466796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1077 | train_loss : 5462.07958984375 | val_loss : 5730.94384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1078 | train_loss : 4910.65625 | val_loss : 9225.5654296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1079 | train_loss : 5693.171875 | val_loss : 6508.09228515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1080 | train_loss : 5281.75 | val_loss : 9294.919921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1081 | train_loss : 5704.3505859375 | val_loss : 6633.0986328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1082 | train_loss : 5190.54638671875 | val_loss : 9534.728515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1083 | train_loss : 6598.10986328125 | val_loss : 8740.912109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1084 | train_loss : 7395.62646484375 | val_loss : 6194.771484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1085 | train_loss : 3847.051025390625 | val_loss : 5824.22314453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1086 | train_loss : 4936.1611328125 | val_loss : 10291.59375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1087 | train_loss : 6432.0361328125 | val_loss : 6148.0439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1088 | train_loss : 4867.43310546875 | val_loss : 7186.853515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1089 | train_loss : 5025.986328125 | val_loss : 7472.53857421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1090 | train_loss : 6490.3779296875 | val_loss : 5738.28759765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1091 | train_loss : 7231.69482421875 | val_loss : 8711.0234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1092 | train_loss : 7155.125 | val_loss : 5216.732421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1093 | train_loss : 5994.3193359375 | val_loss : 7287.36767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1094 | train_loss : 6382.69384765625 | val_loss : 7960.40234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1095 | train_loss : 6264.88623046875 | val_loss : 6399.3876953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1096 | train_loss : 5854.56640625 | val_loss : 8568.5498046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1097 | train_loss : 5386.732421875 | val_loss : 6762.9462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1098 | train_loss : 6110.38427734375 | val_loss : 9634.103515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1099 | train_loss : 5910.8525390625 | val_loss : 5532.43603515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1100 | train_loss : 4685.85205078125 | val_loss : 7916.7001953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1101 | train_loss : 4431.95751953125 | val_loss : 6373.46240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1102 | train_loss : 5933.55419921875 | val_loss : 9944.705078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1103 | train_loss : 6050.6611328125 | val_loss : 5456.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1104 | train_loss : 5471.2001953125 | val_loss : 10685.4814453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1105 | train_loss : 6247.57080078125 | val_loss : 7241.6611328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1106 | train_loss : 6172.91748046875 | val_loss : 10315.0087890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1107 | train_loss : 5760.5537109375 | val_loss : 7017.2451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1108 | train_loss : 5402.35009765625 | val_loss : 11356.8134765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1109 | train_loss : 8183.89501953125 | val_loss : 8216.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1110 | train_loss : 6710.025390625 | val_loss : 7555.89111328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1111 | train_loss : 8959.5810546875 | val_loss : 11193.6328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1112 | train_loss : 10819.068359375 | val_loss : 6628.89013671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1113 | train_loss : 5407.92333984375 | val_loss : 5868.01318359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1114 | train_loss : 4412.7216796875 | val_loss : 7251.423828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1115 | train_loss : 4614.59130859375 | val_loss : 4868.42626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1116 | train_loss : 3429.378173828125 | val_loss : 5008.92626953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1117 | train_loss : 3873.4619140625 | val_loss : 5528.19384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1118 | train_loss : 3775.638671875 | val_loss : 3314.853759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1119 | train_loss : 3030.40380859375 | val_loss : 5588.98388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1120 | train_loss : 4170.54248046875 | val_loss : 5187.18603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1121 | train_loss : 4025.909423828125 | val_loss : 4760.4111328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1122 | train_loss : 3536.070068359375 | val_loss : 4872.6298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1123 | train_loss : 3519.8212890625 | val_loss : 6312.3349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1124 | train_loss : 4842.41552734375 | val_loss : 6996.41259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1125 | train_loss : 4974.158203125 | val_loss : 5818.25146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1126 | train_loss : 4690.8935546875 | val_loss : 7311.68603515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1127 | train_loss : 5218.35498046875 | val_loss : 6360.701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1128 | train_loss : 4781.2919921875 | val_loss : 5896.68896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1129 | train_loss : 4697.10791015625 | val_loss : 5727.146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1130 | train_loss : 4450.76025390625 | val_loss : 6188.49267578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1131 | train_loss : 4539.8056640625 | val_loss : 5573.1611328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1132 | train_loss : 4449.9462890625 | val_loss : 6155.35009765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1133 | train_loss : 4881.78125 | val_loss : 5844.68896484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1134 | train_loss : 4637.869140625 | val_loss : 5856.15869140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1135 | train_loss : 4608.0458984375 | val_loss : 6330.17626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1136 | train_loss : 4803.091796875 | val_loss : 6209.22607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1137 | train_loss : 4711.8310546875 | val_loss : 6604.57861328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1138 | train_loss : 5068.56982421875 | val_loss : 6273.44873046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1139 | train_loss : 5407.666015625 | val_loss : 7330.65478515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1140 | train_loss : 6409.5498046875 | val_loss : 5524.82763671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1141 | train_loss : 4679.37890625 | val_loss : 6793.53369140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1142 | train_loss : 5028.51611328125 | val_loss : 5497.02392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1143 | train_loss : 4319.259765625 | val_loss : 6396.5126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1144 | train_loss : 4735.47314453125 | val_loss : 6811.3876953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1145 | train_loss : 5799.95947265625 | val_loss : 7725.10888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1146 | train_loss : 6368.19482421875 | val_loss : 5102.19482421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1147 | train_loss : 4107.75634765625 | val_loss : 5381.197265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1148 | train_loss : 4019.550048828125 | val_loss : 4812.50732421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1149 | train_loss : 3645.197265625 | val_loss : 4323.37353515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1150 | train_loss : 3530.945556640625 | val_loss : 6645.3623046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1151 | train_loss : 4268.20751953125 | val_loss : 5908.13623046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1152 | train_loss : 4622.7783203125 | val_loss : 4379.6826171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1153 | train_loss : 3437.626220703125 | val_loss : 6536.384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1154 | train_loss : 4422.95556640625 | val_loss : 3777.18115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1155 | train_loss : 5020.53955078125 | val_loss : 5048.291015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1156 | train_loss : 4390.0830078125 | val_loss : 6108.76513671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1157 | train_loss : 5690.931640625 | val_loss : 8380.9677734375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1158 | train_loss : 7121.10302734375 | val_loss : 4867.71630859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1159 | train_loss : 9380.21875 | val_loss : 7795.3310546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1160 | train_loss : 6252.443359375 | val_loss : 6609.740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1161 | train_loss : 6304.98486328125 | val_loss : 8382.349609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1162 | train_loss : 7117.2763671875 | val_loss : 4399.06396484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1163 | train_loss : 3496.750732421875 | val_loss : 6002.67919921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1164 | train_loss : 4804.06005859375 | val_loss : 7399.80615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1165 | train_loss : 4793.16162109375 | val_loss : 4339.947265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1166 | train_loss : 3407.275634765625 | val_loss : 7305.521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1167 | train_loss : 4819.8427734375 | val_loss : 4365.43359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1168 | train_loss : 3329.40380859375 | val_loss : 5935.38232421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1169 | train_loss : 3733.31689453125 | val_loss : 6003.87646484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1170 | train_loss : 4305.8740234375 | val_loss : 5781.97509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1171 | train_loss : 4034.61279296875 | val_loss : 4729.7119140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1172 | train_loss : 3423.157470703125 | val_loss : 6140.31103515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1173 | train_loss : 4330.310546875 | val_loss : 7440.142578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1174 | train_loss : 6700.93359375 | val_loss : 5902.021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1175 | train_loss : 4320.50390625 | val_loss : 5753.767578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1176 | train_loss : 4834.42431640625 | val_loss : 11089.23828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1177 | train_loss : 7251.9951171875 | val_loss : 8519.9541015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1178 | train_loss : 8058.572265625 | val_loss : 4628.38232421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1179 | train_loss : 3926.68994140625 | val_loss : 6482.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1180 | train_loss : 5534.216796875 | val_loss : 7695.5400390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1181 | train_loss : 7284.447265625 | val_loss : 7470.021484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1182 | train_loss : 7155.634765625 | val_loss : 7339.93505859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1183 | train_loss : 5968.60693359375 | val_loss : 7029.3017578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1184 | train_loss : 6633.7607421875 | val_loss : 6122.94580078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1185 | train_loss : 4108.2529296875 | val_loss : 5669.18505859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1186 | train_loss : 4202.07958984375 | val_loss : 7322.9111328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1187 | train_loss : 5336.5341796875 | val_loss : 8488.548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1188 | train_loss : 6731.02197265625 | val_loss : 4284.177734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1189 | train_loss : 2987.286865234375 | val_loss : 6036.3779296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1190 | train_loss : 4262.34228515625 | val_loss : 6285.87646484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1191 | train_loss : 4470.89306640625 | val_loss : 5334.1376953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1192 | train_loss : 4003.77880859375 | val_loss : 7146.18896484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1193 | train_loss : 4370.46142578125 | val_loss : 5677.9443359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1194 | train_loss : 4064.764892578125 | val_loss : 5006.77001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1195 | train_loss : 3133.879638671875 | val_loss : 4340.021484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1196 | train_loss : 3085.82568359375 | val_loss : 5080.79443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1197 | train_loss : 3556.519775390625 | val_loss : 4785.353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1198 | train_loss : 3448.985107421875 | val_loss : 5123.7216796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1199 | train_loss : 3851.29541015625 | val_loss : 5111.744140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1200 | train_loss : 3771.495849609375 | val_loss : 4767.86328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1201 | train_loss : 3776.69873046875 | val_loss : 5158.3125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1202 | train_loss : 4161.740234375 | val_loss : 4472.4775390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1203 | train_loss : 4016.023681640625 | val_loss : 4078.485595703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1204 | train_loss : 4598.60205078125 | val_loss : 3276.695556640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1205 | train_loss : 4375.24609375 | val_loss : 5319.25390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1206 | train_loss : 4740.7216796875 | val_loss : 3835.755615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1207 | train_loss : 3540.40869140625 | val_loss : 3026.813232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1208 | train_loss : 3797.48291015625 | val_loss : 3284.923095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1209 | train_loss : 3062.45166015625 | val_loss : 7203.8388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1210 | train_loss : 4470.8017578125 | val_loss : 6754.1201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1211 | train_loss : 6006.97607421875 | val_loss : 4641.20361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1212 | train_loss : 4909.8056640625 | val_loss : 8397.0751953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1213 | train_loss : 7739.80419921875 | val_loss : 5554.4580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1214 | train_loss : 4640.58935546875 | val_loss : 5452.701171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1215 | train_loss : 5143.74560546875 | val_loss : 7076.30810546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1216 | train_loss : 4496.62255859375 | val_loss : 7019.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1217 | train_loss : 6420.79052734375 | val_loss : 6376.908203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1218 | train_loss : 4521.841796875 | val_loss : 6476.19189453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1219 | train_loss : 5714.8505859375 | val_loss : 4867.20361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1220 | train_loss : 3014.5693359375 | val_loss : 4281.919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1221 | train_loss : 3821.233642578125 | val_loss : 10535.0947265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1222 | train_loss : 6764.12060546875 | val_loss : 8696.9208984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1223 | train_loss : 8296.3291015625 | val_loss : 3855.244384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1224 | train_loss : 3863.69091796875 | val_loss : 4773.79931640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1225 | train_loss : 4320.40576171875 | val_loss : 7183.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1226 | train_loss : 4314.12548828125 | val_loss : 4665.029296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1227 | train_loss : 4148.66015625 | val_loss : 9022.9033203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1228 | train_loss : 6551.43359375 | val_loss : 9072.5166015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1229 | train_loss : 8055.8349609375 | val_loss : 4404.34228515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1230 | train_loss : 3358.661865234375 | val_loss : 4887.25048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1231 | train_loss : 4110.0830078125 | val_loss : 7494.833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1232 | train_loss : 5729.02490234375 | val_loss : 7729.111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1233 | train_loss : 6768.4287109375 | val_loss : 4302.953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1234 | train_loss : 2982.375244140625 | val_loss : 5634.16015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1235 | train_loss : 4907.06103515625 | val_loss : 4722.8017578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1236 | train_loss : 5905.2373046875 | val_loss : 6695.91748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1237 | train_loss : 5536.11328125 | val_loss : 5532.76171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1238 | train_loss : 6990.14697265625 | val_loss : 7313.62744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1239 | train_loss : 7225.42919921875 | val_loss : 5984.96435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1240 | train_loss : 4370.32958984375 | val_loss : 5085.26416015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1241 | train_loss : 5287.6357421875 | val_loss : 9326.0361328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1242 | train_loss : 5225.98876953125 | val_loss : 4312.9482421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1243 | train_loss : 3839.248046875 | val_loss : 9230.2890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1244 | train_loss : 5285.419921875 | val_loss : 6494.064453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1245 | train_loss : 6022.84375 | val_loss : 7132.96435546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1246 | train_loss : 5107.88134765625 | val_loss : 6249.28759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1247 | train_loss : 5690.39794921875 | val_loss : 6983.82666015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1248 | train_loss : 4577.65234375 | val_loss : 5096.439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1249 | train_loss : 4454.21240234375 | val_loss : 6587.50732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1250 | train_loss : 4915.34765625 | val_loss : 6560.46142578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1251 | train_loss : 5829.95361328125 | val_loss : 6028.31396484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1252 | train_loss : 3874.862548828125 | val_loss : 4197.302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1253 | train_loss : 3576.6513671875 | val_loss : 7249.203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1254 | train_loss : 4000.282470703125 | val_loss : 3980.1162109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1255 | train_loss : 3544.360107421875 | val_loss : 5870.796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1256 | train_loss : 4028.468017578125 | val_loss : 4288.33984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1257 | train_loss : 4210.607421875 | val_loss : 7409.90771484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1258 | train_loss : 4289.31298828125 | val_loss : 4774.79296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1259 | train_loss : 4248.89306640625 | val_loss : 7789.16552734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1260 | train_loss : 5006.36572265625 | val_loss : 7166.64794921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1261 | train_loss : 6699.9912109375 | val_loss : 5540.80810546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1262 | train_loss : 3567.32373046875 | val_loss : 4672.35693359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1263 | train_loss : 4222.12646484375 | val_loss : 5427.04443359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1264 | train_loss : 8274.99609375 | val_loss : 7432.9091796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1265 | train_loss : 5921.68017578125 | val_loss : 5579.5625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1266 | train_loss : 6156.7783203125 | val_loss : 6865.80419921875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1267 | train_loss : 6382.5 | val_loss : 4044.242431640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1268 | train_loss : 3058.082275390625 | val_loss : 3971.4375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1269 | train_loss : 4102.0185546875 | val_loss : 9497.5654296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1270 | train_loss : 5444.85498046875 | val_loss : 4044.918701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1271 | train_loss : 3528.9111328125 | val_loss : 7392.9091796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1272 | train_loss : 4963.19580078125 | val_loss : 6018.4873046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1273 | train_loss : 5363.41015625 | val_loss : 5880.34814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1274 | train_loss : 4041.796630859375 | val_loss : 6657.52294921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1275 | train_loss : 5672.845703125 | val_loss : 6927.55078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1276 | train_loss : 4595.10693359375 | val_loss : 4031.13818359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1277 | train_loss : 3548.0 | val_loss : 6560.38916015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1278 | train_loss : 3677.042236328125 | val_loss : 5088.84619140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1279 | train_loss : 4140.67919921875 | val_loss : 4990.22119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1280 | train_loss : 2809.034912109375 | val_loss : 3076.58447265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1281 | train_loss : 2649.70654296875 | val_loss : 7138.9794921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1282 | train_loss : 4445.755859375 | val_loss : 4770.5205078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1283 | train_loss : 3930.78125 | val_loss : 5680.0185546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1284 | train_loss : 3761.934326171875 | val_loss : 7952.52734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1285 | train_loss : 6708.27392578125 | val_loss : 2845.987548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1286 | train_loss : 3160.73291015625 | val_loss : 3914.525634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1287 | train_loss : 3875.27685546875 | val_loss : 4742.25634765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1288 | train_loss : 4226.39013671875 | val_loss : 5299.2080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1289 | train_loss : 3456.863037109375 | val_loss : 3978.34619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1290 | train_loss : 5968.71630859375 | val_loss : 10225.6796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1291 | train_loss : 5801.00048828125 | val_loss : 2740.119384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1292 | train_loss : 2716.969970703125 | val_loss : 3816.25439453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1293 | train_loss : 2510.141845703125 | val_loss : 2739.215576171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1294 | train_loss : 2701.469970703125 | val_loss : 7093.76318359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1295 | train_loss : 4411.58251953125 | val_loss : 2126.746826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1296 | train_loss : 2390.5009765625 | val_loss : 4973.71044921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1297 | train_loss : 3228.456298828125 | val_loss : 3533.599365234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1298 | train_loss : 3665.508056640625 | val_loss : 3647.93994140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1299 | train_loss : 2841.195556640625 | val_loss : 2802.925537109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1300 | train_loss : 2657.0166015625 | val_loss : 5233.06689453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1301 | train_loss : 3396.20849609375 | val_loss : 3903.7861328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1302 | train_loss : 3786.3681640625 | val_loss : 9702.8134765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1303 | train_loss : 6168.19140625 | val_loss : 9519.0498046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1304 | train_loss : 8936.4638671875 | val_loss : 3770.56005859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1305 | train_loss : 4783.83203125 | val_loss : 5322.42822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1306 | train_loss : 3801.3603515625 | val_loss : 3841.887451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1307 | train_loss : 3913.802490234375 | val_loss : 7359.47119140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1308 | train_loss : 6554.2861328125 | val_loss : 4501.7705078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1309 | train_loss : 3186.697509765625 | val_loss : 6485.51953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1310 | train_loss : 6623.005859375 | val_loss : 4683.14306640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1311 | train_loss : 3441.47119140625 | val_loss : 6498.50927734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1312 | train_loss : 5454.1982421875 | val_loss : 10289.4228515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1313 | train_loss : 6062.126953125 | val_loss : 6405.8173828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1314 | train_loss : 6229.18798828125 | val_loss : 4233.34228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1315 | train_loss : 3085.448974609375 | val_loss : 4411.90478515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1316 | train_loss : 3690.941162109375 | val_loss : 8339.25390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1317 | train_loss : 4848.2197265625 | val_loss : 6417.07177734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1318 | train_loss : 5573.294921875 | val_loss : 6171.98388671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1319 | train_loss : 3768.576171875 | val_loss : 2900.947509765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1320 | train_loss : 2973.402587890625 | val_loss : 6535.07958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1321 | train_loss : 3420.743408203125 | val_loss : 3641.836181640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1322 | train_loss : 3656.45556640625 | val_loss : 10112.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1323 | train_loss : 5170.0654296875 | val_loss : 4243.3037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1324 | train_loss : 3659.804443359375 | val_loss : 5324.0224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1325 | train_loss : 5449.89892578125 | val_loss : 8148.30517578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1326 | train_loss : 7794.833984375 | val_loss : 4184.00048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1327 | train_loss : 5139.94189453125 | val_loss : 9067.5947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1328 | train_loss : 6616.10693359375 | val_loss : 3689.887451171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1329 | train_loss : 4966.669921875 | val_loss : 6794.32421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1330 | train_loss : 3752.853515625 | val_loss : 3320.27685546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1331 | train_loss : 2743.818359375 | val_loss : 2853.73193359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1332 | train_loss : 2910.280029296875 | val_loss : 5532.23388671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1333 | train_loss : 2925.66650390625 | val_loss : 2939.2724609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1334 | train_loss : 2581.800048828125 | val_loss : 5709.60107421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1335 | train_loss : 3489.242919921875 | val_loss : 3128.491943359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1336 | train_loss : 2506.656982421875 | val_loss : 5754.52392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1337 | train_loss : 4030.933837890625 | val_loss : 8108.876953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1338 | train_loss : 7366.0263671875 | val_loss : 3053.344970703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1339 | train_loss : 2854.236328125 | val_loss : 4857.234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1340 | train_loss : 3563.0419921875 | val_loss : 5466.84521484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1341 | train_loss : 4492.19580078125 | val_loss : 6598.22314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1342 | train_loss : 5395.57080078125 | val_loss : 3957.0517578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1343 | train_loss : 3353.37255859375 | val_loss : 5312.9111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1344 | train_loss : 4062.03125 | val_loss : 6156.2685546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1345 | train_loss : 4114.20361328125 | val_loss : 6947.4970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1346 | train_loss : 5930.31396484375 | val_loss : 6156.6005859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1347 | train_loss : 3715.49365234375 | val_loss : 2548.126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1348 | train_loss : 3001.889404296875 | val_loss : 6706.12109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1349 | train_loss : 3279.656982421875 | val_loss : 4069.472412109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1350 | train_loss : 3568.310546875 | val_loss : 8221.7509765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1351 | train_loss : 4539.31689453125 | val_loss : 3671.1005859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1352 | train_loss : 3160.464599609375 | val_loss : 4164.09521484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1353 | train_loss : 3711.17333984375 | val_loss : 10259.826171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1354 | train_loss : 8686.654296875 | val_loss : 4144.62109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1355 | train_loss : 5114.3486328125 | val_loss : 10354.2421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1356 | train_loss : 9215.3720703125 | val_loss : 6855.6435546875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1357 | train_loss : 10181.1376953125 | val_loss : 11820.4365234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1358 | train_loss : 8379.265625 | val_loss : 3263.2119140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1359 | train_loss : 5229.0595703125 | val_loss : 8491.9453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1360 | train_loss : 6486.4462890625 | val_loss : 2704.286865234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1361 | train_loss : 3326.9287109375 | val_loss : 5015.85791015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1362 | train_loss : 3018.2587890625 | val_loss : 3044.253662109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1363 | train_loss : 3585.48876953125 | val_loss : 6322.3935546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1364 | train_loss : 3676.166259765625 | val_loss : 2379.304443359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1365 | train_loss : 2992.5166015625 | val_loss : 6545.44189453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1366 | train_loss : 4160.01416015625 | val_loss : 2081.795654296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1367 | train_loss : 2491.24755859375 | val_loss : 4079.876220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1368 | train_loss : 2094.445068359375 | val_loss : 1892.3131103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1369 | train_loss : 2683.844482421875 | val_loss : 6592.75439453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1370 | train_loss : 3550.19384765625 | val_loss : 1353.3756103515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1371 | train_loss : 2301.940185546875 | val_loss : 6869.45166015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1372 | train_loss : 3681.185302734375 | val_loss : 1840.2493896484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1373 | train_loss : 3007.1796875 | val_loss : 7893.65576171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1374 | train_loss : 3991.30908203125 | val_loss : 1582.987548828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1375 | train_loss : 2932.806884765625 | val_loss : 8848.521484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1376 | train_loss : 4065.765869140625 | val_loss : 3036.269287109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1377 | train_loss : 2696.226806640625 | val_loss : 6488.830078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1378 | train_loss : 6127.03125 | val_loss : 7125.9033203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1379 | train_loss : 6293.67138671875 | val_loss : 3245.87060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1380 | train_loss : 2879.39208984375 | val_loss : 7662.9287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1381 | train_loss : 6117.63916015625 | val_loss : 3227.39306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1382 | train_loss : 4083.8505859375 | val_loss : 9358.896484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1383 | train_loss : 7618.33251953125 | val_loss : 3118.45556640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1384 | train_loss : 4691.23583984375 | val_loss : 6470.80615234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1385 | train_loss : 4934.591796875 | val_loss : 3659.76318359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1386 | train_loss : 3304.228515625 | val_loss : 3680.10498046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1387 | train_loss : 2488.94677734375 | val_loss : 2579.217529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1388 | train_loss : 2220.805419921875 | val_loss : 2485.054931640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1389 | train_loss : 2560.6064453125 | val_loss : 2707.8701171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1390 | train_loss : 2636.09130859375 | val_loss : 3292.82373046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1391 | train_loss : 2190.40576171875 | val_loss : 3149.941162109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1392 | train_loss : 2912.134033203125 | val_loss : 4734.86865234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1393 | train_loss : 2908.779052734375 | val_loss : 5279.20068359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1394 | train_loss : 4342.93701171875 | val_loss : 5705.16357421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1395 | train_loss : 3798.0205078125 | val_loss : 10364.1005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1396 | train_loss : 8841.326171875 | val_loss : 2704.246337890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1397 | train_loss : 3095.632568359375 | val_loss : 8141.69140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1398 | train_loss : 6247.98828125 | val_loss : 3409.085693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1399 | train_loss : 5042.3125 | val_loss : 9492.59765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1400 | train_loss : 7766.1337890625 | val_loss : 4240.39990234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1401 | train_loss : 5661.81640625 | val_loss : 8796.251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1402 | train_loss : 6321.6875 | val_loss : 2899.773193359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1403 | train_loss : 3225.953125 | val_loss : 4391.9306640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1404 | train_loss : 3230.486328125 | val_loss : 2869.8388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1405 | train_loss : 3162.90478515625 | val_loss : 3491.3798828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1406 | train_loss : 2681.062255859375 | val_loss : 1207.2293701171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1407 | train_loss : 2065.18994140625 | val_loss : 6591.4248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1408 | train_loss : 3539.335205078125 | val_loss : 1799.4136962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1409 | train_loss : 2901.0595703125 | val_loss : 8975.55078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1410 | train_loss : 4212.7705078125 | val_loss : 2348.00927734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1411 | train_loss : 2312.36279296875 | val_loss : 5039.748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1412 | train_loss : 3613.04443359375 | val_loss : 6074.919921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1413 | train_loss : 5804.9306640625 | val_loss : 4477.8095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1414 | train_loss : 2813.478515625 | val_loss : 3134.387451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1415 | train_loss : 3227.691162109375 | val_loss : 4723.16552734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1416 | train_loss : 2421.7685546875 | val_loss : 7551.3310546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1417 | train_loss : 6969.181640625 | val_loss : 3707.241943359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1418 | train_loss : 2890.332275390625 | val_loss : 1730.5244140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1419 | train_loss : 1514.31201171875 | val_loss : 2699.005615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1420 | train_loss : 1317.9732666015625 | val_loss : 1310.1356201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1421 | train_loss : 1826.068603515625 | val_loss : 6585.31396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1422 | train_loss : 3295.35791015625 | val_loss : 1593.1468505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1423 | train_loss : 2561.0498046875 | val_loss : 9194.791015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1424 | train_loss : 4647.81396484375 | val_loss : 12158.7578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1425 | train_loss : 9789.50390625 | val_loss : 1450.2593994140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1426 | train_loss : 1745.4066162109375 | val_loss : 4947.978515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1427 | train_loss : 2978.62744140625 | val_loss : 1752.3087158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1428 | train_loss : 2148.386962890625 | val_loss : 10685.5146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1429 | train_loss : 7709.23388671875 | val_loss : 2649.34130859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1430 | train_loss : 2777.453125 | val_loss : 7272.5732421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1431 | train_loss : 5502.9013671875 | val_loss : 3196.84375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1432 | train_loss : 3187.711669921875 | val_loss : 3693.619384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1433 | train_loss : 2790.5703125 | val_loss : 2161.126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1434 | train_loss : 2763.68603515625 | val_loss : 5479.8818359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1435 | train_loss : 3464.9306640625 | val_loss : 2064.780517578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1436 | train_loss : 2864.99072265625 | val_loss : 5292.099609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1437 | train_loss : 3771.293701171875 | val_loss : 2072.10009765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1438 | train_loss : 3643.769775390625 | val_loss : 7248.453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1439 | train_loss : 4778.69970703125 | val_loss : 3820.6787109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1440 | train_loss : 5410.572265625 | val_loss : 9346.4052734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1441 | train_loss : 5403.49755859375 | val_loss : 1404.1187744140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1442 | train_loss : 2512.45947265625 | val_loss : 5341.2431640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1443 | train_loss : 3012.822509765625 | val_loss : 2929.488037109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1444 | train_loss : 2640.387451171875 | val_loss : 4578.23388671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1445 | train_loss : 3495.375 | val_loss : 8436.521484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1446 | train_loss : 7984.79541015625 | val_loss : 3582.05615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1447 | train_loss : 2822.99755859375 | val_loss : 6806.62939453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1448 | train_loss : 6023.47265625 | val_loss : 2696.976318359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1449 | train_loss : 2518.38525390625 | val_loss : 6318.03564453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1450 | train_loss : 3942.006591796875 | val_loss : 2632.03125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1451 | train_loss : 3438.350830078125 | val_loss : 5214.9013671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1452 | train_loss : 3422.07373046875 | val_loss : 2466.81005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1453 | train_loss : 2060.857421875 | val_loss : 3171.38134765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1454 | train_loss : 1919.90380859375 | val_loss : 3069.548095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1455 | train_loss : 2588.8671875 | val_loss : 3951.234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1456 | train_loss : 2307.68994140625 | val_loss : 2735.0107421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1457 | train_loss : 1952.0159912109375 | val_loss : 3550.061767578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1458 | train_loss : 2262.52978515625 | val_loss : 1614.6800537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1459 | train_loss : 1530.3046875 | val_loss : 3926.14306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1460 | train_loss : 2125.88916015625 | val_loss : 3779.566162109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1461 | train_loss : 2875.19775390625 | val_loss : 3105.889404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1462 | train_loss : 3245.0205078125 | val_loss : 8651.6689453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1463 | train_loss : 7967.55322265625 | val_loss : 3276.103759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1464 | train_loss : 4093.0087890625 | val_loss : 10005.9443359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1465 | train_loss : 7508.39892578125 | val_loss : 3228.802490234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1466 | train_loss : 3598.44189453125 | val_loss : 9888.4208984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1467 | train_loss : 7609.79541015625 | val_loss : 2791.783203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1468 | train_loss : 2945.01025390625 | val_loss : 5695.0517578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1469 | train_loss : 5708.0439453125 | val_loss : 1860.6925048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1470 | train_loss : 2164.22119140625 | val_loss : 2879.617431640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1471 | train_loss : 2265.4052734375 | val_loss : 2496.150634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1472 | train_loss : 2941.448974609375 | val_loss : 5667.935546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1473 | train_loss : 3573.709716796875 | val_loss : 1574.978759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1474 | train_loss : 2801.82958984375 | val_loss : 7166.3310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1475 | train_loss : 3631.739990234375 | val_loss : 1073.9918212890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1476 | train_loss : 1869.0543212890625 | val_loss : 5163.05517578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1477 | train_loss : 2623.702392578125 | val_loss : 1123.9012451171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1478 | train_loss : 1858.30615234375 | val_loss : 4805.42138671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1479 | train_loss : 2140.03369140625 | val_loss : 1897.1494140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1480 | train_loss : 2167.757568359375 | val_loss : 5561.31103515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1481 | train_loss : 2966.96435546875 | val_loss : 609.3056030273438 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1482 | train_loss : 1094.9476318359375 | val_loss : 2988.30810546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1483 | train_loss : 1505.2615966796875 | val_loss : 1941.5218505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1484 | train_loss : 1965.3045654296875 | val_loss : 1805.81005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1485 | train_loss : 1433.1181640625 | val_loss : 909.2962646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1486 | train_loss : 962.0547485351562 | val_loss : 2847.4130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1487 | train_loss : 1927.5699462890625 | val_loss : 1169.29248046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1488 | train_loss : 1097.1058349609375 | val_loss : 2171.447509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1489 | train_loss : 1119.62841796875 | val_loss : 2714.88818359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1490 | train_loss : 2586.064453125 | val_loss : 5229.6474609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1491 | train_loss : 5101.103515625 | val_loss : 7098.8974609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1492 | train_loss : 8302.61328125 | val_loss : 3016.788818359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1493 | train_loss : 2437.980712890625 | val_loss : 1527.20751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1494 | train_loss : 1500.4185791015625 | val_loss : 1798.1712646484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1495 | train_loss : 2294.9228515625 | val_loss : 7106.1220703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1496 | train_loss : 4694.8291015625 | val_loss : 8818.7353515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1497 | train_loss : 9027.7021484375 | val_loss : 2840.7412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1498 | train_loss : 2904.01123046875 | val_loss : 5688.6943359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1499 | train_loss : 3330.605224609375 | val_loss : 3465.6943359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1500 | train_loss : 4728.005859375 | val_loss : 6138.35693359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1501 | train_loss : 3621.6962890625 | val_loss : 7150.423828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1502 | train_loss : 7143.3486328125 | val_loss : 2641.24072265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1503 | train_loss : 2612.65380859375 | val_loss : 4097.7412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1504 | train_loss : 3015.248046875 | val_loss : 778.4606323242188 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1505 | train_loss : 1382.2403564453125 | val_loss : 3817.456298828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1506 | train_loss : 1985.4144287109375 | val_loss : 2534.10693359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1507 | train_loss : 2004.574951171875 | val_loss : 1432.690673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1508 | train_loss : 1223.1881103515625 | val_loss : 2072.516845703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1509 | train_loss : 1540.3292236328125 | val_loss : 2469.6044921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1510 | train_loss : 1788.6751708984375 | val_loss : 4988.01513671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1511 | train_loss : 3875.5419921875 | val_loss : 2922.90380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1512 | train_loss : 3322.6025390625 | val_loss : 7575.77734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1513 | train_loss : 6722.63623046875 | val_loss : 1722.793701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1514 | train_loss : 1691.9449462890625 | val_loss : 2814.7900390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1515 | train_loss : 2089.114013671875 | val_loss : 1407.9462890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1516 | train_loss : 1646.9805908203125 | val_loss : 1977.599365234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1517 | train_loss : 1665.1895751953125 | val_loss : 1312.989990234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1518 | train_loss : 1714.302490234375 | val_loss : 2497.05810546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1519 | train_loss : 2138.247314453125 | val_loss : 1419.1580810546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1520 | train_loss : 1807.9534912109375 | val_loss : 3935.83447265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1521 | train_loss : 2526.839599609375 | val_loss : 1027.13818359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1522 | train_loss : 1643.6722412109375 | val_loss : 6193.8388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1523 | train_loss : 2931.85693359375 | val_loss : 2039.786865234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1524 | train_loss : 2482.65966796875 | val_loss : 7283.626953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1525 | train_loss : 4280.74169921875 | val_loss : 8290.57421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1526 | train_loss : 7687.14208984375 | val_loss : 2316.04052734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1527 | train_loss : 1845.061279296875 | val_loss : 2456.003173828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1528 | train_loss : 1556.3046875 | val_loss : 1626.6912841796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1529 | train_loss : 1269.720947265625 | val_loss : 3592.0576171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1530 | train_loss : 2187.64501953125 | val_loss : 2358.414306640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1531 | train_loss : 1840.2562255859375 | val_loss : 5004.548828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1532 | train_loss : 4295.08642578125 | val_loss : 7298.0205078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1533 | train_loss : 6453.01611328125 | val_loss : 1721.57568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1534 | train_loss : 1974.7744140625 | val_loss : 7818.7060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1535 | train_loss : 6734.42138671875 | val_loss : 2282.072509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1536 | train_loss : 2840.00439453125 | val_loss : 8860.814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1537 | train_loss : 6290.1806640625 | val_loss : 2223.922607421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1538 | train_loss : 2866.803955078125 | val_loss : 4750.00244140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1539 | train_loss : 3050.39208984375 | val_loss : 1109.9481201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1540 | train_loss : 1874.58837890625 | val_loss : 3485.663818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1541 | train_loss : 2289.583740234375 | val_loss : 1012.1643676757812 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1542 | train_loss : 1373.4571533203125 | val_loss : 2347.452392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1543 | train_loss : 1946.7862548828125 | val_loss : 1144.0462646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1544 | train_loss : 1545.0732421875 | val_loss : 1725.45556640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1545 | train_loss : 1481.2025146484375 | val_loss : 1659.2349853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1546 | train_loss : 1781.58056640625 | val_loss : 1924.5137939453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1547 | train_loss : 1879.2784423828125 | val_loss : 2193.589599609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1548 | train_loss : 1787.3265380859375 | val_loss : 2277.389892578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1549 | train_loss : 2524.22900390625 | val_loss : 4371.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1550 | train_loss : 3158.6875 | val_loss : 8814.8818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1551 | train_loss : 8401.9677734375 | val_loss : 2198.1044921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1552 | train_loss : 2510.681640625 | val_loss : 6731.390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1553 | train_loss : 5715.02685546875 | val_loss : 2318.11865234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1554 | train_loss : 4118.62890625 | val_loss : 8983.2666015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1555 | train_loss : 5456.41455078125 | val_loss : 2454.851806640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1556 | train_loss : 3710.19287109375 | val_loss : 4481.7158203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1557 | train_loss : 5426.3388671875 | val_loss : 8081.45556640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1558 | train_loss : 7265.6611328125 | val_loss : 2396.63623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1559 | train_loss : 1931.0841064453125 | val_loss : 3120.679443359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1560 | train_loss : 2767.280029296875 | val_loss : 1754.423095703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1561 | train_loss : 1296.153564453125 | val_loss : 1551.7593994140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1562 | train_loss : 1686.504638671875 | val_loss : 3013.514404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1563 | train_loss : 2518.1005859375 | val_loss : 570.8031005859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1564 | train_loss : 893.4483032226562 | val_loss : 1202.0919189453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1565 | train_loss : 1305.3343505859375 | val_loss : 3128.121826171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1566 | train_loss : 2108.52490234375 | val_loss : 2565.893798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1567 | train_loss : 2639.476318359375 | val_loss : 2730.3857421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1568 | train_loss : 1790.2349853515625 | val_loss : 3814.612548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1569 | train_loss : 3079.25927734375 | val_loss : 4340.19580078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1570 | train_loss : 4581.26611328125 | val_loss : 6441.68994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1571 | train_loss : 6258.2451171875 | val_loss : 2570.07373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1572 | train_loss : 2021.532470703125 | val_loss : 2615.413818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1573 | train_loss : 2382.314697265625 | val_loss : 1071.4080810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1574 | train_loss : 1165.3480224609375 | val_loss : 2509.3662109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1575 | train_loss : 1931.0855712890625 | val_loss : 1660.434326171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1576 | train_loss : 1672.5240478515625 | val_loss : 989.7650146484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1577 | train_loss : 765.7767944335938 | val_loss : 2056.4375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1578 | train_loss : 1685.0540771484375 | val_loss : 2632.476318359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1579 | train_loss : 2358.876953125 | val_loss : 546.5968627929688 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1580 | train_loss : 785.9346923828125 | val_loss : 1244.358154296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1581 | train_loss : 1175.33935546875 | val_loss : 3974.32373046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1582 | train_loss : 3789.831787109375 | val_loss : 8126.08056640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1583 | train_loss : 8257.4033203125 | val_loss : 1791.98193359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1584 | train_loss : 1722.6246337890625 | val_loss : 7695.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1585 | train_loss : 4190.814453125 | val_loss : 395.3237609863281 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1586 | train_loss : 814.4812622070312 | val_loss : 2557.171142578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1587 | train_loss : 1119.7044677734375 | val_loss : 2242.1455078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1588 | train_loss : 2186.509765625 | val_loss : 4806.826171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1589 | train_loss : 2874.10302734375 | val_loss : 7448.712890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1590 | train_loss : 7196.2705078125 | val_loss : 2956.512451171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1591 | train_loss : 2380.156494140625 | val_loss : 2442.3369140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1592 | train_loss : 2245.5341796875 | val_loss : 4455.59423828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1593 | train_loss : 3915.69677734375 | val_loss : 5056.255859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1594 | train_loss : 4085.51123046875 | val_loss : 6510.455078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1595 | train_loss : 5132.97509765625 | val_loss : 7060.16552734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1596 | train_loss : 5163.83544921875 | val_loss : 7890.283203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1597 | train_loss : 5616.103515625 | val_loss : 8247.10546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1598 | train_loss : 5153.81298828125 | val_loss : 5860.740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1599 | train_loss : 4085.2529296875 | val_loss : 5145.345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 1600 | train_loss : 3434.18505859375 | val_loss : 3489.248046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "Val Loss: 1417.2526, Test Accuracy: 0.748 ± 0.133, Average Duration per fold: 8.304 mins\n"
     ]
    }
   ],
   "source": [
    "loss_mean, acc_mean, models = cross_val(\n",
    "     dataset=H_10,\n",
    "    model=model_10,\n",
    "    folds=10,\n",
    "    epochs=1600,\n",
    "    lr=0.02,\n",
    "    device=device,\n",
    "    weight_decay=0.0005,\n",
    "    lr_decay_factor=0.5,\n",
    "    exp_factor=1,\n",
    "    lr_decay_step_size=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 5, 9, 5, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 7, 2, 2, 2, 2, 2, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,\n",
       "       0, 3, 0, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted, mask = voting(models, H_10, device=device)\n",
    "\n",
    "predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(y_true=lb.inverse_transform(H_10['MIDI'].y[mask].to('cpu')), y_pred=lb.inverse_transform(predicted),\n",
    "                                                cmap='bone', normalize='true')\n",
    "\n",
    "disp.ax_.set_title('SLAC Genre')\n",
    "disp.figure_.set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved at .\\slac\\models_10\\\n"
     ]
    }
   ],
   "source": [
    "save_models(models, '.\\\\slac\\\\models_10\\\\')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
