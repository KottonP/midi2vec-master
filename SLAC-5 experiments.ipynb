{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import winsound\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.optim import Adam, NAdam\n",
    "from torch.optim.lr_scheduler import OneCycleLR as OCR\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HGTConv, SAGEConv, GATConv, Linear, to_hetero\n",
    "from torch_geometric.nn import models as pyg_models\n",
    "from torch_geometric.sampler import HGTSampler\n",
    "from torch_geometric.loader import DataLoader, HGTLoader, NeighborLoader, NodeLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from UltilityFunctions import *\n",
    "\n",
    "\n",
    "# print(matplotlib.__version__)\n",
    "# print(nx.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 960\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLAC 5-Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading edgelists...\n",
      "- notes.edgelist\n",
      "- program.edgelist\n",
      "- tempo.edgelist\n",
      "- time.signature.edgelist\n",
      "Nodes: 93553\n",
      "Edges: 786635\n"
     ]
    }
   ],
   "source": [
    "# # Complete Dataset\n",
    "G = complete_graph(\".\\\\slac\\\\embeddings\\\\all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame((list(G.nodes)), columns=['name'])\n",
    "edges = pd.DataFrame(np.array(list(G.edges)), columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_cat_dict took 0.19 secs to run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['note_group', 'pitch', 'program', 'MIDI', 'duration', 'velocity', 'time_sig', 'tempo'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_categories = node_cat_dict(nodes)\n",
    "node_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "nodes_df_complete = pd.read_csv('.\\slac\\Contents of Slac\\\\nodes_complete.csv')\n",
    "edges_df_complete = pd.read_csv('.\\slac\\Contents of Slac\\edges_complete.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MIDI',\n",
       " 'duration',\n",
       " 'note_group',\n",
       " 'pitch',\n",
       " 'program',\n",
       " 'tempo',\n",
       " 'time_sig',\n",
       " 'velocity'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_types = set(nodes_df_complete['node_type'])\n",
    "node_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = [\"MIDI__has__tempo\",\n",
    "                   \"MIDI__in__time_sig\",\n",
    "                   \"MIDI__has__program\",\n",
    "                   \"MIDI__has__note_group\",\n",
    "                   \"note_group__has__velocity\",\n",
    "                   \"note_group__has__duration\",\n",
    "                   \"note_group__contains__pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = flatten_lol(node_categories.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(names_list, n_labels=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_nodes took 0.02 secs to run\n",
      "encode_nodes took 0.01 secs to run\n",
      "encode_nodes took 3.42 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n",
      "encode_nodes took 0.00 secs to run\n"
     ]
    }
   ],
   "source": [
    "input_node_dict = {node_type: {'x': encoder.\n",
    "                    encode_nodes(nodes_df_complete.\n",
    "                    loc[nodes_df_complete['node_type'] == node_type, ['name']])}\n",
    "                    for node_type in node_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_enc_to_idx = {node_type: {encoder.decode_value(node_enc.item()): i for i, node_enc in enumerate(input_node_dict[node_type]['x'])} for node_type in node_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_edge_dict = dict()\n",
    "for edge_type in edge_types:\n",
    "    node_type_s, node_type_t = edge_type.split('__')[0], edge_type.split('__')[2]\n",
    "\n",
    "    edge_df = edges_df_complete.loc[edges_df_complete['edge_type'] == edge_type, ['source', 'target']].copy()\n",
    "\n",
    "    edge_df['source'], edge_df['target'] = edge_df['source'].map(node_enc_to_idx[node_type_s]), edge_df['target'].map(node_enc_to_idx[node_type_t])\n",
    "\n",
    "    input_edge_dict[edge_type] = {'edge_index': torch.tensor(edge_df.values).T}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blues', 'Classical', 'Jazz', 'Rap', 'Rock'], dtype='<U9')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the label of each Midi.\n",
    "midi_val = nodes_df_complete.loc[nodes_df_complete['node_type'] == 'MIDI', ['name']].values\n",
    "midi_class_5 = [midi_type(s[0], 5) for s in midi_val]\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_5 = torch.from_numpy(lb.fit_transform(midi_class_5)) # .type(torch.LongTensor)\n",
    "\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_dict_5 = input_node_dict.copy()\n",
    "\n",
    "input_node_dict_5['MIDI']['y'] = y_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_5 = HeteroData(input_node_dict_5, **input_edge_dict)\n",
    "H_5 = T.ToUndirected()(H_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mduration\u001b[0m={ x=[570, 1] },\n",
      "  \u001b[1mMIDI\u001b[0m={\n",
      "    x=[250, 1],\n",
      "    y=[250]\n",
      "  },\n",
      "  \u001b[1mnote_group\u001b[0m={ x=[92484, 1] },\n",
      "  \u001b[1mtime_sig\u001b[0m={ x=[14, 1] },\n",
      "  \u001b[1mtempo\u001b[0m={ x=[23, 1] },\n",
      "  \u001b[1mpitch\u001b[0m={ x=[93, 1] },\n",
      "  \u001b[1mvelocity\u001b[0m={ x=[11, 1] },\n",
      "  \u001b[1mprogram\u001b[0m={ x=[108, 1] },\n",
      "  \u001b[1m(MIDI, has, tempo)\u001b[0m={ edge_index=[2, 250] },\n",
      "  \u001b[1m(MIDI, in, time_sig)\u001b[0m={ edge_index=[2, 239] },\n",
      "  \u001b[1m(MIDI, has, program)\u001b[0m={ edge_index=[2, 1392] },\n",
      "  \u001b[1m(MIDI, has, note_group)\u001b[0m={ edge_index=[2, 135160] },\n",
      "  \u001b[1m(note_group, has, velocity)\u001b[0m={ edge_index=[2, 118626] },\n",
      "  \u001b[1m(note_group, has, duration)\u001b[0m={ edge_index=[2, 92484] },\n",
      "  \u001b[1m(note_group, contains, pitch)\u001b[0m={ edge_index=[2, 438484] },\n",
      "  \u001b[1m(tempo, rev_has, MIDI)\u001b[0m={ edge_index=[2, 250] },\n",
      "  \u001b[1m(time_sig, rev_in, MIDI)\u001b[0m={ edge_index=[2, 239] },\n",
      "  \u001b[1m(program, rev_has, MIDI)\u001b[0m={ edge_index=[2, 1392] },\n",
      "  \u001b[1m(note_group, rev_has, MIDI)\u001b[0m={ edge_index=[2, 135160] },\n",
      "  \u001b[1m(velocity, rev_has, note_group)\u001b[0m={ edge_index=[2, 118626] },\n",
      "  \u001b[1m(duration, rev_has, note_group)\u001b[0m={ edge_index=[2, 92484] },\n",
      "  \u001b[1m(pitch, rev_contains, note_group)\u001b[0m={ edge_index=[2, 438484] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(H_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = pyg_models.GraphSAGE(in_channels=-1, hidden_channels=64, num_layers=2, out_channels=len(set(lb.classes_)))\n",
    "model_5 = to_hetero(model_5, H_5.metadata(), aggr='sum')\n",
    "\n",
    "# model_5 = torch_geometric.compile(model_5) # not supported in Windows\n",
    "# model_5.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfering dataset to device cuda\n",
      "Done\n",
      "________________________________________________________________________________\n",
      "Starting Cross Validation\n",
      "________________________________________________________________________________\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 0 | epoch : 1 | train_loss : 603066.4375 | val_loss : 620153.375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 2 | train_loss : 592824.5 | val_loss : 916911.9375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 3 | train_loss : 954321.8125 | val_loss : 1261466.75 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 4 | train_loss : 1173290.75 | val_loss : 1174253.625 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 5 | train_loss : 1202951.25 | val_loss : 283432.46875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 6 | train_loss : 268551.375 | val_loss : 252888.921875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 7 | train_loss : 324345.0625 | val_loss : 430380.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 8 | train_loss : 412313.0 | val_loss : 454004.6875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 9 | train_loss : 429827.1875 | val_loss : 379948.03125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 10 | train_loss : 367668.375 | val_loss : 499504.25 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 11 | train_loss : 421044.625 | val_loss : 341928.59375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 12 | train_loss : 323485.09375 | val_loss : 194309.0 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 13 | train_loss : 182621.703125 | val_loss : 176357.0625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 14 | train_loss : 127841.2890625 | val_loss : 170378.234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 15 | train_loss : 200313.796875 | val_loss : 258011.078125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 16 | train_loss : 247097.984375 | val_loss : 324180.46875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 17 | train_loss : 231022.71875 | val_loss : 316925.65625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 18 | train_loss : 285741.96875 | val_loss : 227759.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 19 | train_loss : 165643.859375 | val_loss : 141118.6875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 20 | train_loss : 157584.953125 | val_loss : 242640.09375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 21 | train_loss : 216171.953125 | val_loss : 252570.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 22 | train_loss : 184960.546875 | val_loss : 276104.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 23 | train_loss : 267736.96875 | val_loss : 104568.21875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 24 | train_loss : 116950.5078125 | val_loss : 229810.3125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 25 | train_loss : 185019.875 | val_loss : 223899.28125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 26 | train_loss : 196179.21875 | val_loss : 144313.125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 27 | train_loss : 131708.65625 | val_loss : 28345.4609375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 28 | train_loss : 45165.99609375 | val_loss : 272725.09375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 29 | train_loss : 197570.796875 | val_loss : 222184.484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 30 | train_loss : 213223.65625 | val_loss : 129387.4765625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 31 | train_loss : 153618.15625 | val_loss : 204852.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 32 | train_loss : 150243.875 | val_loss : 127445.859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 33 | train_loss : 135469.703125 | val_loss : 83437.5078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 34 | train_loss : 86510.8984375 | val_loss : 230242.859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 35 | train_loss : 184620.203125 | val_loss : 270260.1875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 36 | train_loss : 209107.765625 | val_loss : 193070.90625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 37 | train_loss : 171636.9375 | val_loss : 107590.3203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 38 | train_loss : 126045.0234375 | val_loss : 165053.6875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 39 | train_loss : 174334.546875 | val_loss : 203982.15625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 40 | train_loss : 167355.046875 | val_loss : 231514.8125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 41 | train_loss : 183935.421875 | val_loss : 191208.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 42 | train_loss : 197222.34375 | val_loss : 134707.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 43 | train_loss : 110069.6015625 | val_loss : 60854.73828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 44 | train_loss : 61544.796875 | val_loss : 50474.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 45 | train_loss : 51007.53515625 | val_loss : 97991.1328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 46 | train_loss : 90494.84375 | val_loss : 158071.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 47 | train_loss : 151778.34375 | val_loss : 14586.384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 48 | train_loss : 14643.9248046875 | val_loss : 18404.04296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 49 | train_loss : 20286.529296875 | val_loss : 64478.61328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 50 | train_loss : 51470.84375 | val_loss : 101754.421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 51 | train_loss : 88480.15625 | val_loss : 80270.328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 52 | train_loss : 70238.2578125 | val_loss : 149832.296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 53 | train_loss : 127252.8671875 | val_loss : 78342.296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 54 | train_loss : 58691.24609375 | val_loss : 116742.28125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 55 | train_loss : 135181.625 | val_loss : 212194.453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 56 | train_loss : 155094.3125 | val_loss : 172448.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 57 | train_loss : 154633.953125 | val_loss : 130757.3828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 58 | train_loss : 105681.671875 | val_loss : 118505.171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 59 | train_loss : 135022.546875 | val_loss : 138503.015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 60 | train_loss : 101898.96875 | val_loss : 170149.796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 61 | train_loss : 135395.015625 | val_loss : 93934.8828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 62 | train_loss : 111156.453125 | val_loss : 67558.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 63 | train_loss : 50568.5390625 | val_loss : 64787.0546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 64 | train_loss : 56710.171875 | val_loss : 139635.1875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 65 | train_loss : 169218.125 | val_loss : 207705.359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 66 | train_loss : 180908.90625 | val_loss : 61705.62109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 67 | train_loss : 56998.28515625 | val_loss : 153723.125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 68 | train_loss : 149865.296875 | val_loss : 37735.921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 69 | train_loss : 30398.056640625 | val_loss : 75442.1015625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 70 | train_loss : 88364.1484375 | val_loss : 166437.515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 71 | train_loss : 122122.921875 | val_loss : 93869.921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 72 | train_loss : 85093.5625 | val_loss : 96722.6171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 73 | train_loss : 84244.5625 | val_loss : 122819.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 74 | train_loss : 103211.140625 | val_loss : 82825.984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 75 | train_loss : 103934.296875 | val_loss : 54413.15625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 76 | train_loss : 49881.30078125 | val_loss : 46105.26171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 77 | train_loss : 40500.60546875 | val_loss : 65495.19921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 78 | train_loss : 72835.390625 | val_loss : 43946.359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 79 | train_loss : 43848.37109375 | val_loss : 78186.3671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 80 | train_loss : 69213.015625 | val_loss : 62328.23046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 81 | train_loss : 52442.7734375 | val_loss : 86553.4609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 82 | train_loss : 80360.796875 | val_loss : 111303.4765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 83 | train_loss : 113765.5390625 | val_loss : 45118.078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 84 | train_loss : 36450.08984375 | val_loss : 97095.140625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 85 | train_loss : 85816.1015625 | val_loss : 110305.3125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 86 | train_loss : 83205.3125 | val_loss : 29475.755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 87 | train_loss : 22560.130859375 | val_loss : 55564.68359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 88 | train_loss : 53713.41015625 | val_loss : 155196.734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 89 | train_loss : 122715.1015625 | val_loss : 132598.484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 90 | train_loss : 112019.8984375 | val_loss : 68321.6171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 91 | train_loss : 66266.421875 | val_loss : 127326.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 92 | train_loss : 129218.1171875 | val_loss : 74950.875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 93 | train_loss : 55078.14453125 | val_loss : 79387.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 94 | train_loss : 67878.3515625 | val_loss : 51375.796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 95 | train_loss : 58296.24609375 | val_loss : 57166.37109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 96 | train_loss : 46853.421875 | val_loss : 67269.96875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 97 | train_loss : 65828.140625 | val_loss : 94083.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 98 | train_loss : 81547.8984375 | val_loss : 75691.078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 99 | train_loss : 56448.99609375 | val_loss : 18581.375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 100 | train_loss : 22832.6484375 | val_loss : 100267.2421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 101 | train_loss : 75900.1171875 | val_loss : 106261.59375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 102 | train_loss : 107785.96875 | val_loss : 84677.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 103 | train_loss : 91012.28125 | val_loss : 131536.921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 104 | train_loss : 102198.4765625 | val_loss : 145609.90625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 105 | train_loss : 114752.2890625 | val_loss : 84188.296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 106 | train_loss : 89318.6484375 | val_loss : 28367.5859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 107 | train_loss : 29188.52734375 | val_loss : 71739.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 108 | train_loss : 56450.6015625 | val_loss : 84580.890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 109 | train_loss : 109103.5234375 | val_loss : 56153.703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 110 | train_loss : 55064.51953125 | val_loss : 37774.265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 111 | train_loss : 32790.3359375 | val_loss : 111126.5625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 112 | train_loss : 110374.34375 | val_loss : 44101.78125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 113 | train_loss : 32991.015625 | val_loss : 24741.822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 114 | train_loss : 27255.435546875 | val_loss : 135975.09375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 115 | train_loss : 109542.4296875 | val_loss : 117231.84375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 116 | train_loss : 107460.9921875 | val_loss : 34115.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 117 | train_loss : 35819.43359375 | val_loss : 71540.3125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 118 | train_loss : 50994.25390625 | val_loss : 17511.484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 119 | train_loss : 14427.51171875 | val_loss : 35318.75 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 120 | train_loss : 37167.05859375 | val_loss : 76025.359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 121 | train_loss : 61423.32421875 | val_loss : 83702.84375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 122 | train_loss : 77165.140625 | val_loss : 44509.12890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 123 | train_loss : 35525.42578125 | val_loss : 72962.921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 124 | train_loss : 73461.9921875 | val_loss : 53596.6015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 125 | train_loss : 42287.21875 | val_loss : 41149.171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 126 | train_loss : 41747.4375 | val_loss : 81881.8125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 127 | train_loss : 68786.7578125 | val_loss : 82081.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 128 | train_loss : 73012.9296875 | val_loss : 37310.4765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 129 | train_loss : 34211.1484375 | val_loss : 96518.65625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 130 | train_loss : 94927.3515625 | val_loss : 59265.53125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 131 | train_loss : 41651.74609375 | val_loss : 54634.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 132 | train_loss : 62282.546875 | val_loss : 75051.5 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 133 | train_loss : 54729.5234375 | val_loss : 36811.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 134 | train_loss : 48009.05859375 | val_loss : 83565.5234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 135 | train_loss : 65373.26171875 | val_loss : 76679.25 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 136 | train_loss : 86454.7890625 | val_loss : 37114.64453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 137 | train_loss : 33479.18359375 | val_loss : 45305.8359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 138 | train_loss : 38880.65625 | val_loss : 58037.87109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 139 | train_loss : 61979.37890625 | val_loss : 32221.38671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 140 | train_loss : 32958.75 | val_loss : 64026.078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 141 | train_loss : 55180.23828125 | val_loss : 31339.23046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 142 | train_loss : 27342.935546875 | val_loss : 30087.1328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 143 | train_loss : 27321.6953125 | val_loss : 74713.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 144 | train_loss : 78255.59375 | val_loss : 42789.3203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 145 | train_loss : 33421.84375 | val_loss : 20150.5546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 146 | train_loss : 26430.693359375 | val_loss : 91352.171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 147 | train_loss : 73597.140625 | val_loss : 81614.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 148 | train_loss : 80121.5390625 | val_loss : 43418.7890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 149 | train_loss : 46545.12890625 | val_loss : 110565.0234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 150 | train_loss : 80483.4140625 | val_loss : 78974.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 151 | train_loss : 59191.86328125 | val_loss : 89813.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 152 | train_loss : 78664.84375 | val_loss : 83237.9375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 153 | train_loss : 104931.90625 | val_loss : 100097.546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 154 | train_loss : 78336.0703125 | val_loss : 37734.87890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 155 | train_loss : 33932.734375 | val_loss : 43828.48828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 156 | train_loss : 38000.66796875 | val_loss : 51012.37109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 157 | train_loss : 44078.6640625 | val_loss : 49427.4296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 158 | train_loss : 64508.63671875 | val_loss : 23101.73828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 159 | train_loss : 24904.078125 | val_loss : 62327.98046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 160 | train_loss : 50450.0546875 | val_loss : 65929.046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 161 | train_loss : 61871.19921875 | val_loss : 37675.21875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 162 | train_loss : 32060.1171875 | val_loss : 62375.12109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 163 | train_loss : 64599.37890625 | val_loss : 41970.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 164 | train_loss : 34912.6953125 | val_loss : 43200.01953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 165 | train_loss : 46504.828125 | val_loss : 40905.83203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 166 | train_loss : 32474.216796875 | val_loss : 45374.8515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 167 | train_loss : 49731.98828125 | val_loss : 46459.19921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 168 | train_loss : 39791.15625 | val_loss : 45215.3203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 169 | train_loss : 46204.2265625 | val_loss : 41931.28125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 170 | train_loss : 36253.80859375 | val_loss : 64454.28125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 171 | train_loss : 66673.875 | val_loss : 29286.13671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 172 | train_loss : 24920.8984375 | val_loss : 46101.37109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 173 | train_loss : 37592.546875 | val_loss : 40206.43359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 174 | train_loss : 40199.40625 | val_loss : 41724.97265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 175 | train_loss : 34811.734375 | val_loss : 59899.23046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 176 | train_loss : 81784.90625 | val_loss : 45304.0859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 177 | train_loss : 40333.86328125 | val_loss : 26335.318359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 178 | train_loss : 22973.349609375 | val_loss : 60402.3203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 179 | train_loss : 65626.9375 | val_loss : 46023.03125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 180 | train_loss : 36585.828125 | val_loss : 31893.1171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 181 | train_loss : 31328.408203125 | val_loss : 65511.953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 182 | train_loss : 52539.63671875 | val_loss : 33132.93359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 183 | train_loss : 28289.28515625 | val_loss : 45814.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 184 | train_loss : 38684.34765625 | val_loss : 67424.21875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 185 | train_loss : 79208.109375 | val_loss : 63311.46875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 186 | train_loss : 53479.41015625 | val_loss : 59012.23828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 187 | train_loss : 54869.9140625 | val_loss : 35929.375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 188 | train_loss : 29662.22265625 | val_loss : 30597.337890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 189 | train_loss : 30489.490234375 | val_loss : 62990.796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 190 | train_loss : 49555.0234375 | val_loss : 13771.6396484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 191 | train_loss : 12218.6826171875 | val_loss : 13928.625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 192 | train_loss : 12260.1171875 | val_loss : 35723.09375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 193 | train_loss : 31588.17578125 | val_loss : 37308.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 194 | train_loss : 32156.36328125 | val_loss : 65986.5625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 195 | train_loss : 73196.46875 | val_loss : 50803.3515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 196 | train_loss : 35577.42578125 | val_loss : 52684.51171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 197 | train_loss : 44524.53125 | val_loss : 38062.55078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 198 | train_loss : 37834.234375 | val_loss : 24526.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 199 | train_loss : 20959.2265625 | val_loss : 44410.78515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 200 | train_loss : 57953.578125 | val_loss : 29293.578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 201 | train_loss : 20757.755859375 | val_loss : 27799.943359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 202 | train_loss : 25810.734375 | val_loss : 69386.3671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 203 | train_loss : 50106.7265625 | val_loss : 24099.169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 204 | train_loss : 15503.5322265625 | val_loss : 30463.005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 205 | train_loss : 25187.455078125 | val_loss : 41446.46875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 206 | train_loss : 40335.59765625 | val_loss : 22738.58984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 207 | train_loss : 20264.791015625 | val_loss : 36842.83203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 208 | train_loss : 30086.0625 | val_loss : 38710.4765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 209 | train_loss : 35016.1875 | val_loss : 60524.19140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 210 | train_loss : 47599.50390625 | val_loss : 13367.0224609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 211 | train_loss : 10976.900390625 | val_loss : 25239.2578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 212 | train_loss : 20697.013671875 | val_loss : 64172.7265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 213 | train_loss : 73270.1953125 | val_loss : 49817.12890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 214 | train_loss : 40559.77734375 | val_loss : 53509.03125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 215 | train_loss : 46819.10546875 | val_loss : 30318.98828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 216 | train_loss : 31489.755859375 | val_loss : 43909.12109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 217 | train_loss : 35681.66015625 | val_loss : 63739.75390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 218 | train_loss : 88297.6875 | val_loss : 55474.49609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 219 | train_loss : 46905.80078125 | val_loss : 19472.3515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 220 | train_loss : 18513.126953125 | val_loss : 26962.14453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 221 | train_loss : 18919.07421875 | val_loss : 28126.1015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 222 | train_loss : 23972.294921875 | val_loss : 46096.41015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 223 | train_loss : 48767.80078125 | val_loss : 44781.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 224 | train_loss : 35064.43359375 | val_loss : 47484.828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 225 | train_loss : 47070.42578125 | val_loss : 43500.203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 226 | train_loss : 33705.765625 | val_loss : 36163.4921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 227 | train_loss : 34510.05078125 | val_loss : 31831.6875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 228 | train_loss : 24741.96484375 | val_loss : 46657.25 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 229 | train_loss : 50995.4296875 | val_loss : 27475.23828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 230 | train_loss : 19766.6953125 | val_loss : 35941.88671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 231 | train_loss : 35204.9765625 | val_loss : 90895.6171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 232 | train_loss : 68940.8359375 | val_loss : 66214.3125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 233 | train_loss : 51078.3359375 | val_loss : 31944.953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 234 | train_loss : 29559.5859375 | val_loss : 38398.7890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 235 | train_loss : 29539.943359375 | val_loss : 18348.197265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 236 | train_loss : 19439.8828125 | val_loss : 34455.6171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 237 | train_loss : 28109.587890625 | val_loss : 19670.73828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 238 | train_loss : 23068.39453125 | val_loss : 44546.53125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 239 | train_loss : 36701.00390625 | val_loss : 52804.80859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 240 | train_loss : 51242.7890625 | val_loss : 10051.2802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 241 | train_loss : 11508.66796875 | val_loss : 37485.37890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 242 | train_loss : 28513.83984375 | val_loss : 42569.01171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 243 | train_loss : 62325.76171875 | val_loss : 30828.845703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 244 | train_loss : 29184.796875 | val_loss : 50614.73046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 245 | train_loss : 42913.87109375 | val_loss : 56056.2890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 246 | train_loss : 54877.44921875 | val_loss : 17985.2421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 247 | train_loss : 15387.74609375 | val_loss : 28542.078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 248 | train_loss : 31398.05078125 | val_loss : 51397.7890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 249 | train_loss : 42968.26953125 | val_loss : 50001.30078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 250 | train_loss : 46985.7734375 | val_loss : 12027.326171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 251 | train_loss : 11239.490234375 | val_loss : 25879.619140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 252 | train_loss : 18998.111328125 | val_loss : 55662.7109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 253 | train_loss : 48747.859375 | val_loss : 49360.390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 254 | train_loss : 58448.7109375 | val_loss : 38861.91796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 255 | train_loss : 25316.595703125 | val_loss : 38763.828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 256 | train_loss : 31195.4375 | val_loss : 34276.94140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 257 | train_loss : 31831.8828125 | val_loss : 25646.4609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 258 | train_loss : 20789.111328125 | val_loss : 30863.841796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 259 | train_loss : 32158.875 | val_loss : 20715.791015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 260 | train_loss : 15793.1513671875 | val_loss : 33003.515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 261 | train_loss : 41084.02734375 | val_loss : 35863.6328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 262 | train_loss : 26933.1640625 | val_loss : 8127.30517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 263 | train_loss : 11644.7939453125 | val_loss : 65415.359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 264 | train_loss : 48794.68359375 | val_loss : 62983.10546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 265 | train_loss : 65858.7265625 | val_loss : 45432.48046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 266 | train_loss : 48764.74609375 | val_loss : 94501.5078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 267 | train_loss : 75674.734375 | val_loss : 89371.71875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 268 | train_loss : 85017.7734375 | val_loss : 31849.775390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 269 | train_loss : 36739.57421875 | val_loss : 40164.15625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 270 | train_loss : 29056.88671875 | val_loss : 10192.322265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 271 | train_loss : 7718.41796875 | val_loss : 18202.890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 272 | train_loss : 13844.6171875 | val_loss : 41914.61328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 273 | train_loss : 43815.46875 | val_loss : 20411.083984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 274 | train_loss : 15620.197265625 | val_loss : 27527.248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 275 | train_loss : 32929.86328125 | val_loss : 46016.91015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 276 | train_loss : 37397.21875 | val_loss : 46358.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 277 | train_loss : 42930.0546875 | val_loss : 9418.2939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 278 | train_loss : 11405.4384765625 | val_loss : 15294.6064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 279 | train_loss : 14436.4658203125 | val_loss : 11856.9697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 280 | train_loss : 17407.685546875 | val_loss : 56512.5546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 281 | train_loss : 42857.4609375 | val_loss : 50904.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 282 | train_loss : 52268.94921875 | val_loss : 30216.82421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 283 | train_loss : 33004.55859375 | val_loss : 56596.53515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 284 | train_loss : 44681.30859375 | val_loss : 41494.09375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 285 | train_loss : 35707.5234375 | val_loss : 26975.154296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 286 | train_loss : 22219.453125 | val_loss : 33424.76953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 287 | train_loss : 33564.234375 | val_loss : 24646.1640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 288 | train_loss : 19553.5859375 | val_loss : 37930.578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 289 | train_loss : 40890.89453125 | val_loss : 25173.57421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 290 | train_loss : 21575.658203125 | val_loss : 29735.3828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 291 | train_loss : 33204.39453125 | val_loss : 31331.248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 292 | train_loss : 28288.55078125 | val_loss : 40367.44921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 293 | train_loss : 39801.4140625 | val_loss : 8913.7470703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 294 | train_loss : 7592.8173828125 | val_loss : 9919.4384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 295 | train_loss : 11269.28515625 | val_loss : 27579.109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 296 | train_loss : 23499.572265625 | val_loss : 41423.88671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 297 | train_loss : 44417.14453125 | val_loss : 12511.8564453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 298 | train_loss : 12864.7412109375 | val_loss : 52020.359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 299 | train_loss : 44108.1953125 | val_loss : 46987.48046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 300 | train_loss : 53256.046875 | val_loss : 90145.5078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 301 | train_loss : 69703.78125 | val_loss : 89546.2890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 302 | train_loss : 91918.7265625 | val_loss : 28204.857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 303 | train_loss : 39833.47265625 | val_loss : 19385.94921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 304 | train_loss : 17975.66015625 | val_loss : 26496.3046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 305 | train_loss : 42633.39453125 | val_loss : 20555.484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 306 | train_loss : 16422.275390625 | val_loss : 17771.720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 307 | train_loss : 23142.818359375 | val_loss : 47264.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 308 | train_loss : 35978.1015625 | val_loss : 44942.8203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 309 | train_loss : 43098.2890625 | val_loss : 9943.33203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 310 | train_loss : 14040.9248046875 | val_loss : 23137.26953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 311 | train_loss : 20767.75 | val_loss : 14672.41015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 312 | train_loss : 21122.359375 | val_loss : 38005.91796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 313 | train_loss : 27918.177734375 | val_loss : 39145.296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 314 | train_loss : 38216.35546875 | val_loss : 10256.8603515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 315 | train_loss : 10058.2861328125 | val_loss : 26243.935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 316 | train_loss : 19477.310546875 | val_loss : 22443.1640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 317 | train_loss : 22174.01171875 | val_loss : 25152.0703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 318 | train_loss : 21197.08203125 | val_loss : 18146.0390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 319 | train_loss : 16264.8212890625 | val_loss : 22399.142578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 320 | train_loss : 17521.212890625 | val_loss : 36447.8984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 321 | train_loss : 30873.248046875 | val_loss : 25416.8203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 322 | train_loss : 33200.609375 | val_loss : 10358.5361328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 323 | train_loss : 9341.5654296875 | val_loss : 5489.68505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 324 | train_loss : 5770.37744140625 | val_loss : 11319.037109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 325 | train_loss : 10130.9091796875 | val_loss : 11606.3359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 326 | train_loss : 16087.9599609375 | val_loss : 43877.62890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 327 | train_loss : 33875.15234375 | val_loss : 39087.33984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 328 | train_loss : 40865.86328125 | val_loss : 16957.783203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 329 | train_loss : 17697.205078125 | val_loss : 32845.1484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 330 | train_loss : 24637.369140625 | val_loss : 7825.5126953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 331 | train_loss : 5953.693359375 | val_loss : 17514.54296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 332 | train_loss : 14723.5888671875 | val_loss : 36539.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 333 | train_loss : 35609.2734375 | val_loss : 13333.8271484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 334 | train_loss : 8831.84765625 | val_loss : 26018.98046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 335 | train_loss : 26487.5625 | val_loss : 16744.01953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 336 | train_loss : 13696.048828125 | val_loss : 29083.6953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 337 | train_loss : 29878.46484375 | val_loss : 11743.4814453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 338 | train_loss : 9605.2734375 | val_loss : 18976.64453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 339 | train_loss : 20015.703125 | val_loss : 176468.90625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 340 | train_loss : 183120.796875 | val_loss : 117945.9609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 341 | train_loss : 102987.046875 | val_loss : 39049.87109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 342 | train_loss : 35562.15625 | val_loss : 55890.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 343 | train_loss : 43245.8203125 | val_loss : 40984.328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 344 | train_loss : 37140.87890625 | val_loss : 35837.9765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 345 | train_loss : 43654.1796875 | val_loss : 17806.294921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 346 | train_loss : 12555.3701171875 | val_loss : 15554.78125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 347 | train_loss : 12835.28515625 | val_loss : 12522.80859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 348 | train_loss : 8550.01953125 | val_loss : 17119.59765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 349 | train_loss : 11932.52734375 | val_loss : 49930.51953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 350 | train_loss : 53621.1953125 | val_loss : 53455.05078125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 351 | train_loss : 48489.10546875 | val_loss : 17998.537109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 352 | train_loss : 14535.7353515625 | val_loss : 84771.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 353 | train_loss : 71476.328125 | val_loss : 56189.07421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 354 | train_loss : 58829.26171875 | val_loss : 28612.794921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 355 | train_loss : 24979.234375 | val_loss : 11249.509765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 356 | train_loss : 11529.40234375 | val_loss : 12642.6591796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 357 | train_loss : 12971.35546875 | val_loss : 41107.81640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 358 | train_loss : 34726.4921875 | val_loss : 36403.90625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 359 | train_loss : 30913.068359375 | val_loss : 10128.15234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 360 | train_loss : 8055.53076171875 | val_loss : 14352.5849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 361 | train_loss : 13118.3037109375 | val_loss : 30858.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 362 | train_loss : 24645.802734375 | val_loss : 32686.072265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 363 | train_loss : 31612.267578125 | val_loss : 9655.736328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 364 | train_loss : 7643.705078125 | val_loss : 10720.3623046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 365 | train_loss : 7719.95556640625 | val_loss : 86312.40625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 366 | train_loss : 89600.4609375 | val_loss : 116701.1328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 367 | train_loss : 100047.5234375 | val_loss : 41653.203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 368 | train_loss : 37075.578125 | val_loss : 42967.51171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 369 | train_loss : 33151.10546875 | val_loss : 19718.33203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 370 | train_loss : 12538.0400390625 | val_loss : 22917.427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 371 | train_loss : 18498.1796875 | val_loss : 27356.6015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 372 | train_loss : 23331.8359375 | val_loss : 13749.85546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 373 | train_loss : 9973.64453125 | val_loss : 13519.7490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 374 | train_loss : 13186.8447265625 | val_loss : 25482.578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 375 | train_loss : 19937.623046875 | val_loss : 29701.83984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 376 | train_loss : 28533.25 | val_loss : 13920.974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 377 | train_loss : 10277.3369140625 | val_loss : 12138.517578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 378 | train_loss : 12296.8837890625 | val_loss : 20183.029296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 379 | train_loss : 16896.3671875 | val_loss : 25389.564453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 380 | train_loss : 25796.615234375 | val_loss : 10016.1826171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 381 | train_loss : 6322.09814453125 | val_loss : 5515.9150390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 382 | train_loss : 5440.5986328125 | val_loss : 21403.779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 383 | train_loss : 17697.552734375 | val_loss : 30431.470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 384 | train_loss : 28864.294921875 | val_loss : 8263.7041015625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 385 | train_loss : 6110.52685546875 | val_loss : 6712.625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 386 | train_loss : 6509.30517578125 | val_loss : 16832.212890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 387 | train_loss : 13768.2451171875 | val_loss : 28242.619140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 388 | train_loss : 25394.501953125 | val_loss : 10507.62890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 389 | train_loss : 7954.22021484375 | val_loss : 17966.630859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 390 | train_loss : 16025.5615234375 | val_loss : 18551.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 391 | train_loss : 14354.3974609375 | val_loss : 26871.3359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 392 | train_loss : 24513.30078125 | val_loss : 10312.3037109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 393 | train_loss : 7118.6064453125 | val_loss : 14971.45703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 394 | train_loss : 13067.0048828125 | val_loss : 22427.748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 395 | train_loss : 17611.376953125 | val_loss : 28148.16015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 396 | train_loss : 26719.447265625 | val_loss : 9367.2001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 397 | train_loss : 6030.95947265625 | val_loss : 7212.416015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 398 | train_loss : 6481.38623046875 | val_loss : 23613.427734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 399 | train_loss : 19824.765625 | val_loss : 31824.509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 400 | train_loss : 35130.0234375 | val_loss : 10068.142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 401 | train_loss : 10897.4599609375 | val_loss : 19224.763671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 402 | train_loss : 15620.9423828125 | val_loss : 25214.35546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 403 | train_loss : 25545.669921875 | val_loss : 8225.830078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 404 | train_loss : 4797.2861328125 | val_loss : 8831.482421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 405 | train_loss : 9884.9921875 | val_loss : 22427.39453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 406 | train_loss : 18928.0703125 | val_loss : 22868.380859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 407 | train_loss : 24518.001953125 | val_loss : 9447.3115234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 408 | train_loss : 5523.0869140625 | val_loss : 6112.54736328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 409 | train_loss : 7323.46044921875 | val_loss : 24281.568359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 410 | train_loss : 20349.81640625 | val_loss : 24687.890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 411 | train_loss : 26357.89453125 | val_loss : 9039.7578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 412 | train_loss : 4161.64697265625 | val_loss : 2707.628662109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 413 | train_loss : 3736.74365234375 | val_loss : 9114.9423828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 414 | train_loss : 5100.35302734375 | val_loss : 10493.7734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 415 | train_loss : 10921.9970703125 | val_loss : 20191.71875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 416 | train_loss : 16344.150390625 | val_loss : 22857.35546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 417 | train_loss : 23724.748046875 | val_loss : 10490.6923828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 418 | train_loss : 4752.71142578125 | val_loss : 6163.4736328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 419 | train_loss : 6787.8125 | val_loss : 16936.052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 420 | train_loss : 13464.82421875 | val_loss : 21892.4140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 421 | train_loss : 22737.439453125 | val_loss : 9812.7060546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 422 | train_loss : 6274.64990234375 | val_loss : 8218.0498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 423 | train_loss : 8956.3603515625 | val_loss : 22188.720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 424 | train_loss : 17137.88671875 | val_loss : 25103.7109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 425 | train_loss : 26408.455078125 | val_loss : 8882.8759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 426 | train_loss : 3739.913818359375 | val_loss : 3044.41259765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 427 | train_loss : 2843.300048828125 | val_loss : 9159.3271484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 428 | train_loss : 5055.99560546875 | val_loss : 13712.2373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 429 | train_loss : 10739.490234375 | val_loss : 24895.4296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 430 | train_loss : 20038.841796875 | val_loss : 27399.390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 431 | train_loss : 26113.77734375 | val_loss : 12845.1328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 432 | train_loss : 6432.1376953125 | val_loss : 13499.369140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 433 | train_loss : 10296.583984375 | val_loss : 20799.732421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 434 | train_loss : 16534.9609375 | val_loss : 33601.64453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 435 | train_loss : 35536.34765625 | val_loss : 12812.46875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 436 | train_loss : 8577.3046875 | val_loss : 11243.40625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 437 | train_loss : 10394.38671875 | val_loss : 14885.537109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 438 | train_loss : 12899.4150390625 | val_loss : 25284.412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 439 | train_loss : 23403.865234375 | val_loss : 11208.4326171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 440 | train_loss : 6880.27734375 | val_loss : 16192.59375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 441 | train_loss : 12780.3408203125 | val_loss : 18971.400390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 442 | train_loss : 14320.416015625 | val_loss : 21858.568359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 443 | train_loss : 17499.310546875 | val_loss : 13923.3876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 444 | train_loss : 10486.3779296875 | val_loss : 22295.318359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 445 | train_loss : 17580.818359375 | val_loss : 15424.607421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 446 | train_loss : 10774.494140625 | val_loss : 21161.35546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 447 | train_loss : 15778.2763671875 | val_loss : 15168.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 448 | train_loss : 10823.103515625 | val_loss : 20923.15625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 449 | train_loss : 14984.7548828125 | val_loss : 15531.96875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 450 | train_loss : 10766.0703125 | val_loss : 20586.568359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 451 | train_loss : 14091.103515625 | val_loss : 15478.7353515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 452 | train_loss : 10631.4375 | val_loss : 21311.0859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 453 | train_loss : 15733.5537109375 | val_loss : 14443.90234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 454 | train_loss : 8181.84130859375 | val_loss : 37370.21875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 455 | train_loss : 35957.359375 | val_loss : 31371.384765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 456 | train_loss : 21623.537109375 | val_loss : 24469.17578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 457 | train_loss : 19771.26171875 | val_loss : 15345.806640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 458 | train_loss : 8867.947265625 | val_loss : 22617.939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 459 | train_loss : 21618.98046875 | val_loss : 19662.0 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 460 | train_loss : 12640.958984375 | val_loss : 16376.6171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 461 | train_loss : 14578.77734375 | val_loss : 14079.8916015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 462 | train_loss : 8423.1005859375 | val_loss : 12016.0986328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 463 | train_loss : 10906.5166015625 | val_loss : 16895.890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 464 | train_loss : 12000.6015625 | val_loss : 17094.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 465 | train_loss : 15132.732421875 | val_loss : 15797.1796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 466 | train_loss : 9403.8076171875 | val_loss : 14489.7509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 467 | train_loss : 11241.826171875 | val_loss : 17188.931640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 468 | train_loss : 12589.87109375 | val_loss : 21039.4453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 469 | train_loss : 17767.0546875 | val_loss : 13164.3115234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 470 | train_loss : 7167.61328125 | val_loss : 11579.5263671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 471 | train_loss : 8238.607421875 | val_loss : 12637.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 472 | train_loss : 8222.681640625 | val_loss : 19512.701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 473 | train_loss : 13921.4990234375 | val_loss : 15778.5546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 474 | train_loss : 10633.263671875 | val_loss : 18905.626953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 475 | train_loss : 12777.57421875 | val_loss : 16221.9248046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 476 | train_loss : 11806.6533203125 | val_loss : 20964.822265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 477 | train_loss : 14399.4609375 | val_loss : 14267.05859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 478 | train_loss : 9780.865234375 | val_loss : 16162.68359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 479 | train_loss : 10576.763671875 | val_loss : 16997.224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 480 | train_loss : 10650.4560546875 | val_loss : 18586.431640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 481 | train_loss : 13372.642578125 | val_loss : 17332.591796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 482 | train_loss : 10020.2060546875 | val_loss : 15842.611328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 483 | train_loss : 11622.34765625 | val_loss : 16803.216796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 484 | train_loss : 10802.7578125 | val_loss : 13351.759765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 485 | train_loss : 12525.455078125 | val_loss : 16759.876953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 486 | train_loss : 9927.9404296875 | val_loss : 14281.857421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 487 | train_loss : 10694.24609375 | val_loss : 18083.748046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 488 | train_loss : 11622.5390625 | val_loss : 16025.5927734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 489 | train_loss : 13654.41796875 | val_loss : 13570.90625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 490 | train_loss : 7714.15380859375 | val_loss : 10904.4375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 491 | train_loss : 8238.46484375 | val_loss : 12871.9814453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 492 | train_loss : 7174.3857421875 | val_loss : 15568.79296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 493 | train_loss : 10295.9384765625 | val_loss : 14158.021484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 494 | train_loss : 10161.5322265625 | val_loss : 16892.189453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 495 | train_loss : 11821.4736328125 | val_loss : 15436.0712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 496 | train_loss : 9510.1884765625 | val_loss : 16886.94921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 497 | train_loss : 11137.5341796875 | val_loss : 13540.705078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 498 | train_loss : 9155.0595703125 | val_loss : 16850.232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 499 | train_loss : 11224.8525390625 | val_loss : 15095.9716796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 500 | train_loss : 9089.3759765625 | val_loss : 14720.7509765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 501 | train_loss : 9521.046875 | val_loss : 14526.4560546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 502 | train_loss : 8753.091796875 | val_loss : 15885.4560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 503 | train_loss : 10189.9892578125 | val_loss : 12897.755859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 504 | train_loss : 8106.029296875 | val_loss : 17236.7734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 505 | train_loss : 12074.3779296875 | val_loss : 15147.8212890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 506 | train_loss : 8175.35107421875 | val_loss : 15848.287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 507 | train_loss : 9858.447265625 | val_loss : 11905.0546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 508 | train_loss : 7438.69140625 | val_loss : 13896.9990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 509 | train_loss : 9273.12890625 | val_loss : 15313.1513671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 510 | train_loss : 8566.419921875 | val_loss : 11748.2822265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 511 | train_loss : 8365.7265625 | val_loss : 13146.7861328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 512 | train_loss : 6827.76171875 | val_loss : 10456.09765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 513 | train_loss : 7186.05126953125 | val_loss : 9834.806640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 514 | train_loss : 5960.24267578125 | val_loss : 9540.7646484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 515 | train_loss : 6684.12451171875 | val_loss : 11565.7861328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 516 | train_loss : 6738.5654296875 | val_loss : 13258.4033203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 517 | train_loss : 8536.41015625 | val_loss : 12046.775390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 518 | train_loss : 8430.337890625 | val_loss : 15684.8984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 519 | train_loss : 10986.4091796875 | val_loss : 14509.38671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 520 | train_loss : 8744.9833984375 | val_loss : 14665.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 521 | train_loss : 9660.5322265625 | val_loss : 14411.20703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 522 | train_loss : 9614.833984375 | val_loss : 13985.3466796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 523 | train_loss : 8990.95703125 | val_loss : 13210.724609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 524 | train_loss : 8161.82763671875 | val_loss : 16298.5166015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 525 | train_loss : 11012.6572265625 | val_loss : 13863.75 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 526 | train_loss : 8251.0537109375 | val_loss : 15681.14453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 527 | train_loss : 9738.1748046875 | val_loss : 12076.48046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 528 | train_loss : 7256.79443359375 | val_loss : 13943.7412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 529 | train_loss : 9041.9208984375 | val_loss : 14406.1845703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 530 | train_loss : 8242.44140625 | val_loss : 12172.8359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 531 | train_loss : 8285.634765625 | val_loss : 10903.412109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 532 | train_loss : 5738.63427734375 | val_loss : 11422.677734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 533 | train_loss : 8297.9296875 | val_loss : 13052.2841796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 534 | train_loss : 6502.06103515625 | val_loss : 10342.4423828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 535 | train_loss : 7107.326171875 | val_loss : 9179.7822265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 536 | train_loss : 5353.0576171875 | val_loss : 10581.6240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 537 | train_loss : 7240.5263671875 | val_loss : 10752.2587890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 538 | train_loss : 6112.046875 | val_loss : 13140.7802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 539 | train_loss : 9602.5029296875 | val_loss : 14650.4599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 540 | train_loss : 9448.884765625 | val_loss : 18076.8125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 541 | train_loss : 12346.6279296875 | val_loss : 13138.6435546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 542 | train_loss : 9832.986328125 | val_loss : 16404.521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 543 | train_loss : 11258.9453125 | val_loss : 15322.4228515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 544 | train_loss : 8912.3916015625 | val_loss : 14563.3427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 545 | train_loss : 9134.7568359375 | val_loss : 11905.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 546 | train_loss : 6836.55322265625 | val_loss : 11617.5537109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 547 | train_loss : 7718.92431640625 | val_loss : 12728.1201171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 548 | train_loss : 6652.4306640625 | val_loss : 9327.4951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 549 | train_loss : 7052.6806640625 | val_loss : 8481.7998046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 550 | train_loss : 4031.166259765625 | val_loss : 5948.611328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 551 | train_loss : 4195.9638671875 | val_loss : 10148.9462890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 552 | train_loss : 5680.732421875 | val_loss : 10496.8076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 553 | train_loss : 7483.58251953125 | val_loss : 12375.4091796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 554 | train_loss : 6596.20751953125 | val_loss : 11588.0576171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 555 | train_loss : 8114.24609375 | val_loss : 12229.83984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 556 | train_loss : 8053.7216796875 | val_loss : 12408.2587890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 557 | train_loss : 8421.2314453125 | val_loss : 13595.0009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 558 | train_loss : 9574.818359375 | val_loss : 15795.4365234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 559 | train_loss : 12028.419921875 | val_loss : 15213.138671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 560 | train_loss : 9003.5927734375 | val_loss : 12012.9775390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 561 | train_loss : 8188.2373046875 | val_loss : 12161.958984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 562 | train_loss : 7653.970703125 | val_loss : 13758.9150390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 563 | train_loss : 9363.7158203125 | val_loss : 14973.005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 564 | train_loss : 9286.9765625 | val_loss : 232823.71875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 565 | train_loss : 227770.703125 | val_loss : 27842.205078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 566 | train_loss : 23392.19921875 | val_loss : 61929.96484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 567 | train_loss : 55635.49609375 | val_loss : 28994.400390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 568 | train_loss : 28279.671875 | val_loss : 28692.015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 569 | train_loss : 33730.265625 | val_loss : 10087.076171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 570 | train_loss : 8350.224609375 | val_loss : 15762.2587890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 571 | train_loss : 10136.4384765625 | val_loss : 9989.34375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 572 | train_loss : 8199.796875 | val_loss : 14369.89453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 573 | train_loss : 8707.3876953125 | val_loss : 11264.47265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 574 | train_loss : 8574.91796875 | val_loss : 13539.8779296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 575 | train_loss : 7835.84619140625 | val_loss : 11409.3427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 576 | train_loss : 8679.9140625 | val_loss : 13552.3251953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 577 | train_loss : 7819.6318359375 | val_loss : 11109.7197265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 578 | train_loss : 9313.22265625 | val_loss : 13993.806640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 579 | train_loss : 8342.5126953125 | val_loss : 11499.72265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 580 | train_loss : 8469.8681640625 | val_loss : 12365.2470703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 581 | train_loss : 6600.09423828125 | val_loss : 7813.28271484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 582 | train_loss : 7251.95361328125 | val_loss : 11226.5927734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 583 | train_loss : 5619.64013671875 | val_loss : 6159.55517578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 584 | train_loss : 6104.703125 | val_loss : 10010.7646484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 585 | train_loss : 4909.71728515625 | val_loss : 4091.148681640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 586 | train_loss : 5240.60546875 | val_loss : 10236.47265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 587 | train_loss : 5573.11376953125 | val_loss : 4317.37890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 588 | train_loss : 4648.23291015625 | val_loss : 10138.0947265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 589 | train_loss : 5098.43359375 | val_loss : 4111.97119140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 590 | train_loss : 4814.3955078125 | val_loss : 9454.5146484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 591 | train_loss : 4804.353515625 | val_loss : 5605.97509765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 592 | train_loss : 6019.17041015625 | val_loss : 10677.900390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 593 | train_loss : 5913.9462890625 | val_loss : 7908.69873046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 594 | train_loss : 6659.1201171875 | val_loss : 12687.1337890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 595 | train_loss : 8018.384765625 | val_loss : 8944.1220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 596 | train_loss : 7841.84130859375 | val_loss : 13341.31640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 597 | train_loss : 8653.833984375 | val_loss : 8479.634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 598 | train_loss : 7252.8857421875 | val_loss : 13208.7841796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 599 | train_loss : 8360.330078125 | val_loss : 9238.11328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 600 | train_loss : 7685.38330078125 | val_loss : 13377.7041015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 601 | train_loss : 8356.9033203125 | val_loss : 7838.78515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 602 | train_loss : 6461.896484375 | val_loss : 9012.443359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 603 | train_loss : 4420.423828125 | val_loss : 4353.92236328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 604 | train_loss : 4454.2353515625 | val_loss : 9128.44921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 605 | train_loss : 4605.2216796875 | val_loss : 4506.47119140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 606 | train_loss : 4729.248046875 | val_loss : 9721.052734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 607 | train_loss : 5078.17041015625 | val_loss : 4233.7373046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 608 | train_loss : 4127.69140625 | val_loss : 9276.9951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 609 | train_loss : 4651.97705078125 | val_loss : 4151.1826171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 610 | train_loss : 4266.9287109375 | val_loss : 8751.177734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 611 | train_loss : 4353.3955078125 | val_loss : 3738.708740234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 612 | train_loss : 4266.9697265625 | val_loss : 8624.451171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 613 | train_loss : 4294.048828125 | val_loss : 3998.820068359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 614 | train_loss : 4552.3330078125 | val_loss : 9336.5810546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 615 | train_loss : 4856.59130859375 | val_loss : 5768.82861328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 616 | train_loss : 5708.88330078125 | val_loss : 12595.63671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 617 | train_loss : 8401.30859375 | val_loss : 9757.8291015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 618 | train_loss : 8720.18359375 | val_loss : 14110.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 619 | train_loss : 10070.93359375 | val_loss : 10522.5859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 620 | train_loss : 9484.87890625 | val_loss : 13987.150390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 621 | train_loss : 8983.525390625 | val_loss : 8490.7177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 622 | train_loss : 7697.57080078125 | val_loss : 14322.302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 623 | train_loss : 9253.974609375 | val_loss : 8507.7353515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 624 | train_loss : 6756.34130859375 | val_loss : 12416.767578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 625 | train_loss : 7182.9873046875 | val_loss : 7142.34375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 626 | train_loss : 6456.27001953125 | val_loss : 11680.494140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 627 | train_loss : 5832.150390625 | val_loss : 6807.263671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 628 | train_loss : 5541.32666015625 | val_loss : 9208.5146484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 629 | train_loss : 4159.92236328125 | val_loss : 4631.833984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 630 | train_loss : 4349.87548828125 | val_loss : 8857.708984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 631 | train_loss : 4249.611328125 | val_loss : 4080.3525390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 632 | train_loss : 4241.10546875 | val_loss : 9194.556640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 633 | train_loss : 4703.853515625 | val_loss : 4180.28857421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 634 | train_loss : 3801.654052734375 | val_loss : 8566.392578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 635 | train_loss : 4138.533203125 | val_loss : 3071.6201171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 636 | train_loss : 3480.125 | val_loss : 11650.4765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 637 | train_loss : 6605.34228515625 | val_loss : 9972.6904296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 638 | train_loss : 9424.2802734375 | val_loss : 14430.0791015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 639 | train_loss : 10278.9140625 | val_loss : 9349.8212890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 640 | train_loss : 7711.60302734375 | val_loss : 13644.1611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 641 | train_loss : 8540.0234375 | val_loss : 7799.02880859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 642 | train_loss : 6756.7548828125 | val_loss : 12560.541015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 643 | train_loss : 6839.01953125 | val_loss : 7876.427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 644 | train_loss : 7626.76611328125 | val_loss : 12915.6572265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 645 | train_loss : 7851.40234375 | val_loss : 8886.271484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 646 | train_loss : 10893.5263671875 | val_loss : 140563.84375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 647 | train_loss : 109294.8515625 | val_loss : 34541.8828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 648 | train_loss : 35544.5546875 | val_loss : 11858.2724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 649 | train_loss : 14588.10546875 | val_loss : 22647.009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 650 | train_loss : 13435.7470703125 | val_loss : 6998.97607421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 651 | train_loss : 4345.84814453125 | val_loss : 4304.0361328125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 652 | train_loss : 2521.1513671875 | val_loss : 5308.75390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 653 | train_loss : 3286.373046875 | val_loss : 3891.982421875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 654 | train_loss : 3014.97314453125 | val_loss : 4903.2626953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 655 | train_loss : 4082.719482421875 | val_loss : 4235.13134765625 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 656 | train_loss : 2212.25390625 | val_loss : 3237.40380859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 657 | train_loss : 2333.9345703125 | val_loss : 3029.626220703125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 658 | train_loss : 2633.7158203125 | val_loss : 5144.4814453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 659 | train_loss : 3535.73193359375 | val_loss : 3291.66748046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 660 | train_loss : 2379.53759765625 | val_loss : 3752.43994140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 661 | train_loss : 2795.78125 | val_loss : 1660.978759765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 662 | train_loss : 2508.353515625 | val_loss : 5322.78125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 663 | train_loss : 3132.33740234375 | val_loss : 2005.981201171875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 664 | train_loss : 2165.731201171875 | val_loss : 3924.9423828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 665 | train_loss : 2736.5400390625 | val_loss : 2388.108642578125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 666 | train_loss : 2576.7294921875 | val_loss : 4198.15234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 667 | train_loss : 3640.62060546875 | val_loss : 1400.31494140625 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 668 | train_loss : 1537.365478515625 | val_loss : 2620.570068359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 669 | train_loss : 1740.78125 | val_loss : 1958.248779296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 670 | train_loss : 2847.91845703125 | val_loss : 4641.28515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 671 | train_loss : 4062.822509765625 | val_loss : 1753.3912353515625 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 672 | train_loss : 1343.1884765625 | val_loss : 2226.84619140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 673 | train_loss : 1821.615478515625 | val_loss : 1193.0262451171875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 674 | train_loss : 2438.238525390625 | val_loss : 4415.5751953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 675 | train_loss : 3734.258056640625 | val_loss : 1213.262451171875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 676 | train_loss : 1369.327392578125 | val_loss : 2411.986328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 677 | train_loss : 1723.8865966796875 | val_loss : 553.1062622070312 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 678 | train_loss : 2268.833984375 | val_loss : 4130.02392578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 679 | train_loss : 3252.513671875 | val_loss : 1053.936279296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 680 | train_loss : 1707.600341796875 | val_loss : 2491.61865234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 681 | train_loss : 2066.7861328125 | val_loss : 907.4562377929688 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 682 | train_loss : 1979.5474853515625 | val_loss : 2887.389892578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 683 | train_loss : 2127.419189453125 | val_loss : 339.9725036621094 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 684 | train_loss : 2142.031005859375 | val_loss : 3575.66259765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 685 | train_loss : 2865.443115234375 | val_loss : 388.73126220703125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 686 | train_loss : 1460.4642333984375 | val_loss : 2522.79248046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 687 | train_loss : 1796.88720703125 | val_loss : 353.80999755859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 688 | train_loss : 1953.8399658203125 | val_loss : 3163.96630859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 689 | train_loss : 2272.274658203125 | val_loss : 350.1937561035156 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 690 | train_loss : 1849.7529296875 | val_loss : 3118.378662109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 691 | train_loss : 2218.32666015625 | val_loss : 345.5675048828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 692 | train_loss : 1898.9017333984375 | val_loss : 3071.282470703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 693 | train_loss : 2162.39453125 | val_loss : 345.1087646484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 694 | train_loss : 1946.8511962890625 | val_loss : 3439.242431640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 695 | train_loss : 2529.38623046875 | val_loss : 477.87750244140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 696 | train_loss : 1710.7220458984375 | val_loss : 3032.4462890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 697 | train_loss : 2345.38037109375 | val_loss : 485.4700012207031 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 698 | train_loss : 1735.7867431640625 | val_loss : 2997.75634765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 699 | train_loss : 2312.644775390625 | val_loss : 708.59375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 700 | train_loss : 1803.0712890625 | val_loss : 2967.947509765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 701 | train_loss : 2268.857666015625 | val_loss : 494.0975036621094 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 702 | train_loss : 1801.71630859375 | val_loss : 2926.108642578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 703 | train_loss : 2222.675537109375 | val_loss : 701.6012573242188 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 704 | train_loss : 1886.8978271484375 | val_loss : 2891.43994140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 705 | train_loss : 2168.482177734375 | val_loss : 703.8062744140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 706 | train_loss : 1935.775634765625 | val_loss : 2854.8037109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 707 | train_loss : 2110.616455078125 | val_loss : 700.3687744140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 708 | train_loss : 1993.5535888671875 | val_loss : 3592.59375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 709 | train_loss : 2941.887451171875 | val_loss : 960.2874755859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 710 | train_loss : 1542.3599853515625 | val_loss : 2822.476318359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 711 | train_loss : 2129.9755859375 | val_loss : 487.4100036621094 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 712 | train_loss : 1931.352783203125 | val_loss : 2757.2412109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 713 | train_loss : 2057.6435546875 | val_loss : 481.0799865722656 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 714 | train_loss : 2004.0992431640625 | val_loss : 3467.732421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 715 | train_loss : 2859.177490234375 | val_loss : 788.5399780273438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 716 | train_loss : 1391.39453125 | val_loss : 43712.4140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 717 | train_loss : 42448.4140625 | val_loss : 53743.74609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 718 | train_loss : 53662.85546875 | val_loss : 41632.98828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 719 | train_loss : 38551.37890625 | val_loss : 16896.974609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 720 | train_loss : 17681.42578125 | val_loss : 17472.53125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 721 | train_loss : 15998.732421875 | val_loss : 13061.01171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 722 | train_loss : 11425.6064453125 | val_loss : 13891.8525390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 723 | train_loss : 11855.138671875 | val_loss : 14061.4990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 724 | train_loss : 12183.599609375 | val_loss : 12975.0576171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 725 | train_loss : 10460.7626953125 | val_loss : 13044.5263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 726 | train_loss : 10663.16796875 | val_loss : 12464.0634765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 727 | train_loss : 9229.5576171875 | val_loss : 11544.1640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 728 | train_loss : 8300.6181640625 | val_loss : 10930.6435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 729 | train_loss : 7872.98486328125 | val_loss : 10347.4423828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 730 | train_loss : 6579.92431640625 | val_loss : 9524.193359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 731 | train_loss : 6736.328125 | val_loss : 7341.666015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 732 | train_loss : 4013.417724609375 | val_loss : 6656.06982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 733 | train_loss : 4532.841796875 | val_loss : 7423.64013671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 734 | train_loss : 4045.8330078125 | val_loss : 6073.9326171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 735 | train_loss : 3892.867431640625 | val_loss : 7911.7763671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 736 | train_loss : 4637.6943359375 | val_loss : 7376.08251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 737 | train_loss : 5080.70703125 | val_loss : 7068.72265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 738 | train_loss : 3916.66552734375 | val_loss : 6142.3212890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 739 | train_loss : 4129.88134765625 | val_loss : 8071.17138671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 740 | train_loss : 4253.08203125 | val_loss : 7066.392578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 741 | train_loss : 5117.064453125 | val_loss : 7612.7939453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 742 | train_loss : 4102.748046875 | val_loss : 5620.705078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 743 | train_loss : 3915.195556640625 | val_loss : 6871.84375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 744 | train_loss : 3399.001220703125 | val_loss : 5758.357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 745 | train_loss : 3965.624267578125 | val_loss : 6485.1162109375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 746 | train_loss : 3251.000732421875 | val_loss : 5303.93115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 747 | train_loss : 3623.39599609375 | val_loss : 5818.6123046875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 748 | train_loss : 2898.22314453125 | val_loss : 5535.93115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 749 | train_loss : 3924.283203125 | val_loss : 6112.21630859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 750 | train_loss : 3167.5224609375 | val_loss : 6054.13623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 751 | train_loss : 4235.21630859375 | val_loss : 6490.2001953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 752 | train_loss : 3529.18115234375 | val_loss : 7079.99755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 753 | train_loss : 5465.55078125 | val_loss : 9617.9599609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 754 | train_loss : 5921.78369140625 | val_loss : 8349.2734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 755 | train_loss : 6497.64697265625 | val_loss : 11764.3779296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 756 | train_loss : 7449.8974609375 | val_loss : 8286.77734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 757 | train_loss : 6450.32763671875 | val_loss : 11506.97265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 758 | train_loss : 8473.052734375 | val_loss : 10270.57421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 759 | train_loss : 7905.98388671875 | val_loss : 15401.6650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 760 | train_loss : 10956.2138671875 | val_loss : 11588.2890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 761 | train_loss : 8969.3359375 | val_loss : 12695.17578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 762 | train_loss : 7997.36767578125 | val_loss : 9321.166015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 763 | train_loss : 6442.82861328125 | val_loss : 11527.517578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 764 | train_loss : 7778.02001953125 | val_loss : 12295.744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 765 | train_loss : 10356.6728515625 | val_loss : 21646.9296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 766 | train_loss : 13543.51953125 | val_loss : 12913.005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 767 | train_loss : 12920.6953125 | val_loss : 10117.4375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 768 | train_loss : 3647.5712890625 | val_loss : 3838.5986328125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 769 | train_loss : 2155.492431640625 | val_loss : 2894.96875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 770 | train_loss : 2425.8447265625 | val_loss : 4139.30126953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 771 | train_loss : 2808.7158203125 | val_loss : 2869.736328125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 772 | train_loss : 1899.39501953125 | val_loss : 4304.388671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 773 | train_loss : 2122.71044921875 | val_loss : 2991.123779296875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 774 | train_loss : 1798.550048828125 | val_loss : 4050.177490234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 775 | train_loss : 2498.406005859375 | val_loss : 2191.757568359375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 776 | train_loss : 1845.788330078125 | val_loss : 4501.455078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 777 | train_loss : 2409.996826171875 | val_loss : 2178.29248046875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 778 | train_loss : 1662.6422119140625 | val_loss : 4398.5673828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 779 | train_loss : 2142.43115234375 | val_loss : 2255.06884765625 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 780 | train_loss : 1683.3582763671875 | val_loss : 3354.451171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 781 | train_loss : 2154.74853515625 | val_loss : 1412.3475341796875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 782 | train_loss : 1644.155029296875 | val_loss : 3529.94873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 783 | train_loss : 2032.7266845703125 | val_loss : 1400.9549560546875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 784 | train_loss : 1636.7906494140625 | val_loss : 3845.7412109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 785 | train_loss : 2362.320068359375 | val_loss : 949.552490234375 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 786 | train_loss : 1602.8470458984375 | val_loss : 2933.842529296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 787 | train_loss : 1945.43212890625 | val_loss : 813.82373046875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 788 | train_loss : 1461.137939453125 | val_loss : 2622.169921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 789 | train_loss : 1726.91455078125 | val_loss : 1358.21875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 790 | train_loss : 1772.1304931640625 | val_loss : 3200.955078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 791 | train_loss : 2415.371337890625 | val_loss : 1432.3299560546875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 792 | train_loss : 1486.246826171875 | val_loss : 3111.590087890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 793 | train_loss : 2415.14697265625 | val_loss : 543.91748046875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 794 | train_loss : 1417.6094970703125 | val_loss : 3063.07373046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 795 | train_loss : 2406.3779296875 | val_loss : 476.7724914550781 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 796 | train_loss : 1417.8609619140625 | val_loss : 3014.3388671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 797 | train_loss : 2388.376220703125 | val_loss : 392.2362365722656 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 798 | train_loss : 1274.4381103515625 | val_loss : 2230.441162109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 799 | train_loss : 1600.4989013671875 | val_loss : 367.1137390136719 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 0 | epoch : 800 | train_loss : 1782.2481689453125 | val_loss : 3343.267578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 1 | epoch : 1 | train_loss : 778723.1875 | val_loss : 586998.75 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 2 | train_loss : 565796.4375 | val_loss : 198021.484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 3 | train_loss : 199944.203125 | val_loss : 527465.625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 4 | train_loss : 487804.46875 | val_loss : 469346.25 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 5 | train_loss : 467625.71875 | val_loss : 420740.875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 6 | train_loss : 450663.3125 | val_loss : 284956.1875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 7 | train_loss : 265028.84375 | val_loss : 585194.3125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 8 | train_loss : 522185.4375 | val_loss : 387807.1875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 9 | train_loss : 391130.875 | val_loss : 309431.625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 10 | train_loss : 356299.25 | val_loss : 106255.453125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 11 | train_loss : 107148.34375 | val_loss : 323996.1875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 12 | train_loss : 325331.8125 | val_loss : 257444.984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 13 | train_loss : 237177.6875 | val_loss : 243432.6875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 14 | train_loss : 259088.078125 | val_loss : 221231.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 15 | train_loss : 277210.125 | val_loss : 138805.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 16 | train_loss : 140561.40625 | val_loss : 131387.8125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 17 | train_loss : 121029.1015625 | val_loss : 240680.453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 18 | train_loss : 253252.453125 | val_loss : 133517.0 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 19 | train_loss : 176037.265625 | val_loss : 246753.859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 20 | train_loss : 254423.9375 | val_loss : 72610.78125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 21 | train_loss : 80432.9375 | val_loss : 134310.28125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 22 | train_loss : 132501.765625 | val_loss : 179319.21875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 23 | train_loss : 203855.8125 | val_loss : 125121.96875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 24 | train_loss : 165680.3125 | val_loss : 230190.0625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 25 | train_loss : 242488.515625 | val_loss : 72201.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 26 | train_loss : 85859.578125 | val_loss : 115264.5234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 27 | train_loss : 116836.5234375 | val_loss : 162693.453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 28 | train_loss : 190979.59375 | val_loss : 97088.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 29 | train_loss : 114652.546875 | val_loss : 125931.1875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 30 | train_loss : 135882.15625 | val_loss : 127579.34375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 31 | train_loss : 137817.5625 | val_loss : 60287.53125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 32 | train_loss : 68332.2265625 | val_loss : 92093.203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 33 | train_loss : 142837.953125 | val_loss : 69159.1015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 34 | train_loss : 85115.703125 | val_loss : 110819.5390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 35 | train_loss : 125672.6171875 | val_loss : 146374.390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 36 | train_loss : 129131.5234375 | val_loss : 90919.96875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 37 | train_loss : 92254.9609375 | val_loss : 110992.8671875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 38 | train_loss : 126054.0625 | val_loss : 102072.703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 39 | train_loss : 149887.734375 | val_loss : 201733.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 40 | train_loss : 232183.515625 | val_loss : 89596.3203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 41 | train_loss : 104890.0234375 | val_loss : 106780.8984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 42 | train_loss : 113328.46875 | val_loss : 130589.1484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 43 | train_loss : 149277.265625 | val_loss : 45876.89453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 44 | train_loss : 57384.28125 | val_loss : 35345.55859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 45 | train_loss : 38450.37109375 | val_loss : 194965.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 46 | train_loss : 172474.28125 | val_loss : 137082.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 47 | train_loss : 132262.546875 | val_loss : 16718.853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 48 | train_loss : 23875.205078125 | val_loss : 76651.0703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 49 | train_loss : 92549.5390625 | val_loss : 159412.90625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 50 | train_loss : 143374.984375 | val_loss : 147094.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 51 | train_loss : 155548.484375 | val_loss : 70430.25 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 52 | train_loss : 88425.46875 | val_loss : 69986.3515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 53 | train_loss : 87340.59375 | val_loss : 138690.453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 54 | train_loss : 124734.6171875 | val_loss : 60695.23828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 55 | train_loss : 70070.734375 | val_loss : 87383.171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 56 | train_loss : 105887.4375 | val_loss : 116534.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 57 | train_loss : 131127.796875 | val_loss : 20841.453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 58 | train_loss : 29667.748046875 | val_loss : 116164.3671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 59 | train_loss : 134967.3125 | val_loss : 43567.3984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 60 | train_loss : 58722.3515625 | val_loss : 31416.03515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 61 | train_loss : 46032.73046875 | val_loss : 85143.9609375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 62 | train_loss : 84445.6875 | val_loss : 37459.59375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 63 | train_loss : 54552.6953125 | val_loss : 111894.2890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 64 | train_loss : 130982.5078125 | val_loss : 113820.53125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 65 | train_loss : 105171.4375 | val_loss : 13986.0224609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 66 | train_loss : 24111.912109375 | val_loss : 32338.17578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 67 | train_loss : 46480.86328125 | val_loss : 109682.78125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 68 | train_loss : 100855.1484375 | val_loss : 25293.380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 69 | train_loss : 32314.970703125 | val_loss : 59519.046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 70 | train_loss : 59913.1640625 | val_loss : 132237.21875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 71 | train_loss : 137522.65625 | val_loss : 106528.828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 72 | train_loss : 126109.3515625 | val_loss : 69078.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 73 | train_loss : 93479.09375 | val_loss : 110670.1484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 74 | train_loss : 101488.9375 | val_loss : 24739.2890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 75 | train_loss : 32693.158203125 | val_loss : 53625.62109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 76 | train_loss : 58605.11328125 | val_loss : 90865.8828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 77 | train_loss : 89346.5703125 | val_loss : 56320.484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 78 | train_loss : 70853.5546875 | val_loss : 81643.7734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 79 | train_loss : 107066.75 | val_loss : 111723.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 80 | train_loss : 111644.03125 | val_loss : 58143.80859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 81 | train_loss : 69615.34375 | val_loss : 117790.7109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 82 | train_loss : 138439.21875 | val_loss : 18487.556640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 83 | train_loss : 30083.060546875 | val_loss : 36546.421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 84 | train_loss : 51761.61328125 | val_loss : 108711.296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 85 | train_loss : 134838.453125 | val_loss : 118124.5234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 86 | train_loss : 117443.21875 | val_loss : 9844.82421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 87 | train_loss : 15665.9404296875 | val_loss : 33772.71875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 88 | train_loss : 37456.51171875 | val_loss : 187321.703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 89 | train_loss : 202507.046875 | val_loss : 114043.4296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 90 | train_loss : 121308.6015625 | val_loss : 27547.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 91 | train_loss : 37574.71875 | val_loss : 126444.6796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 92 | train_loss : 142586.796875 | val_loss : 38590.87109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 93 | train_loss : 46747.81640625 | val_loss : 37501.23046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 94 | train_loss : 47492.98828125 | val_loss : 53382.7890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 95 | train_loss : 58057.21484375 | val_loss : 46546.984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 96 | train_loss : 57245.05078125 | val_loss : 47392.73046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 97 | train_loss : 52087.26953125 | val_loss : 23449.2109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 98 | train_loss : 32356.126953125 | val_loss : 137894.703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 99 | train_loss : 122444.6796875 | val_loss : 88807.46875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 100 | train_loss : 85411.0078125 | val_loss : 18701.84765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 101 | train_loss : 23552.865234375 | val_loss : 60014.82421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 102 | train_loss : 78872.09375 | val_loss : 64685.3203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 103 | train_loss : 59127.75 | val_loss : 19950.5 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 104 | train_loss : 30923.056640625 | val_loss : 92490.1875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 105 | train_loss : 102192.59375 | val_loss : 46805.23828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 106 | train_loss : 64726.59375 | val_loss : 19120.068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 107 | train_loss : 25314.45703125 | val_loss : 25681.025390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 108 | train_loss : 37720.453125 | val_loss : 75427.078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 109 | train_loss : 90673.96875 | val_loss : 59855.58984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 110 | train_loss : 80110.375 | val_loss : 47125.16015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 111 | train_loss : 46647.38671875 | val_loss : 36306.44921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 112 | train_loss : 35669.19921875 | val_loss : 126416.859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 113 | train_loss : 121597.5078125 | val_loss : 120379.453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 114 | train_loss : 138176.0 | val_loss : 53509.2890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 115 | train_loss : 76857.40625 | val_loss : 87809.6015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 116 | train_loss : 80515.4765625 | val_loss : 37969.3984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 117 | train_loss : 47651.07421875 | val_loss : 27084.205078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 118 | train_loss : 32237.11328125 | val_loss : 43305.671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 119 | train_loss : 50462.44140625 | val_loss : 49734.6015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 120 | train_loss : 51402.73046875 | val_loss : 76943.671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 121 | train_loss : 71604.109375 | val_loss : 8309.60546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 122 | train_loss : 15986.1240234375 | val_loss : 29161.83984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 123 | train_loss : 30535.51953125 | val_loss : 122051.796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 124 | train_loss : 118864.546875 | val_loss : 89662.7109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 125 | train_loss : 100496.5703125 | val_loss : 37672.66015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 126 | train_loss : 44068.16015625 | val_loss : 111201.28125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 127 | train_loss : 99842.203125 | val_loss : 49685.41015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 128 | train_loss : 49605.515625 | val_loss : 21216.71484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 129 | train_loss : 22996.34765625 | val_loss : 50477.44921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 130 | train_loss : 47507.31640625 | val_loss : 14874.08984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 131 | train_loss : 25279.3125 | val_loss : 76319.296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 132 | train_loss : 79236.7265625 | val_loss : 41427.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 133 | train_loss : 57415.21875 | val_loss : 25042.140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 134 | train_loss : 28173.779296875 | val_loss : 89527.0 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 135 | train_loss : 104245.0 | val_loss : 80421.7109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 136 | train_loss : 72733.1953125 | val_loss : 42123.23828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 137 | train_loss : 53329.71484375 | val_loss : 86772.7421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 138 | train_loss : 88205.1484375 | val_loss : 27381.03515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 139 | train_loss : 40551.671875 | val_loss : 28012.310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 140 | train_loss : 29653.517578125 | val_loss : 70051.4296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 141 | train_loss : 87233.078125 | val_loss : 78801.9921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 142 | train_loss : 67494.1484375 | val_loss : 42816.80859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 143 | train_loss : 51982.875 | val_loss : 105223.421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 144 | train_loss : 114140.1484375 | val_loss : 11475.19140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 145 | train_loss : 17142.921875 | val_loss : 80849.1484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 146 | train_loss : 81964.5234375 | val_loss : 57214.51171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 147 | train_loss : 75904.7265625 | val_loss : 25515.6953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 148 | train_loss : 32819.19921875 | val_loss : 85296.0625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 149 | train_loss : 76709.8203125 | val_loss : 36084.24609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 150 | train_loss : 38559.69921875 | val_loss : 27129.669921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 151 | train_loss : 28537.072265625 | val_loss : 62059.9296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 152 | train_loss : 60911.390625 | val_loss : 44632.2890625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 153 | train_loss : 59984.0234375 | val_loss : 39040.4765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 154 | train_loss : 39630.37109375 | val_loss : 65637.78125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 155 | train_loss : 79545.53125 | val_loss : 73517.0703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 156 | train_loss : 63553.36328125 | val_loss : 10732.5673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 157 | train_loss : 19765.564453125 | val_loss : 52711.48046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 158 | train_loss : 50399.87109375 | val_loss : 75393.7109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 159 | train_loss : 94053.7421875 | val_loss : 116620.8984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 160 | train_loss : 102359.4375 | val_loss : 18493.033203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 161 | train_loss : 29145.974609375 | val_loss : 20457.796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 162 | train_loss : 24941.1796875 | val_loss : 52298.3203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 163 | train_loss : 70950.9921875 | val_loss : 47182.5703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 164 | train_loss : 43139.84375 | val_loss : 15105.70703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 165 | train_loss : 18582.494140625 | val_loss : 57473.48828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 166 | train_loss : 50688.2265625 | val_loss : 19885.853515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 167 | train_loss : 30167.482421875 | val_loss : 39110.0234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 168 | train_loss : 40721.375 | val_loss : 69787.7265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 169 | train_loss : 88291.859375 | val_loss : 95341.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 170 | train_loss : 85195.40625 | val_loss : 23360.267578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 171 | train_loss : 27432.26953125 | val_loss : 33087.1171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 172 | train_loss : 43212.828125 | val_loss : 51532.625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 173 | train_loss : 49823.93359375 | val_loss : 2699.87744140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 174 | train_loss : 8674.0634765625 | val_loss : 4930.7587890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 175 | train_loss : 10461.5126953125 | val_loss : 30366.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 176 | train_loss : 39244.56640625 | val_loss : 72711.1328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 177 | train_loss : 66313.3515625 | val_loss : 19128.744140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 178 | train_loss : 28636.703125 | val_loss : 25049.970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 179 | train_loss : 26874.8828125 | val_loss : 30716.005859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 180 | train_loss : 35916.96875 | val_loss : 28829.884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 181 | train_loss : 28819.365234375 | val_loss : 31479.1015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 182 | train_loss : 34648.44140625 | val_loss : 10350.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 183 | train_loss : 14173.9775390625 | val_loss : 22338.85546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 184 | train_loss : 24786.935546875 | val_loss : 25119.28515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 185 | train_loss : 31026.880859375 | val_loss : 85249.109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 186 | train_loss : 75354.625 | val_loss : 31635.98828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 187 | train_loss : 38890.47265625 | val_loss : 29381.58984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 188 | train_loss : 28468.828125 | val_loss : 26683.8828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 189 | train_loss : 30321.97265625 | val_loss : 11745.7236328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 190 | train_loss : 15387.6865234375 | val_loss : 27881.962890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 191 | train_loss : 28603.193359375 | val_loss : 18422.40625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 192 | train_loss : 26086.908203125 | val_loss : 66632.7890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 193 | train_loss : 62431.38671875 | val_loss : 43067.24609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 194 | train_loss : 54856.890625 | val_loss : 24900.505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 195 | train_loss : 31285.97265625 | val_loss : 14414.537109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 196 | train_loss : 24232.41015625 | val_loss : 14391.4287109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 197 | train_loss : 19152.38671875 | val_loss : 11111.3173828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 198 | train_loss : 20741.44140625 | val_loss : 19680.744140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 199 | train_loss : 22611.240234375 | val_loss : 58939.05078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 200 | train_loss : 73795.765625 | val_loss : 70436.703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 201 | train_loss : 62229.24609375 | val_loss : 13190.244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 202 | train_loss : 17664.41796875 | val_loss : 41847.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 203 | train_loss : 52528.0703125 | val_loss : 55795.23046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 204 | train_loss : 54223.4609375 | val_loss : 11756.7099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 205 | train_loss : 14981.212890625 | val_loss : 42951.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 206 | train_loss : 53592.484375 | val_loss : 69215.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 207 | train_loss : 64193.41015625 | val_loss : 25604.984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 208 | train_loss : 35604.2734375 | val_loss : 45146.18359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 209 | train_loss : 44939.23828125 | val_loss : 41801.50390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 210 | train_loss : 56279.35546875 | val_loss : 64267.66015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 211 | train_loss : 57432.83984375 | val_loss : 23590.015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 212 | train_loss : 34214.0859375 | val_loss : 49819.71484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 213 | train_loss : 48507.38671875 | val_loss : 25272.693359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 214 | train_loss : 37828.421875 | val_loss : 45566.64453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 215 | train_loss : 42053.2265625 | val_loss : 10983.4453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 216 | train_loss : 20122.08203125 | val_loss : 35177.4375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 217 | train_loss : 32776.23828125 | val_loss : 27143.697265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 218 | train_loss : 38429.53515625 | val_loss : 56156.89453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 219 | train_loss : 51107.3359375 | val_loss : 20640.216796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 220 | train_loss : 29612.171875 | val_loss : 37929.21484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 221 | train_loss : 36131.390625 | val_loss : 48066.34375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 222 | train_loss : 63377.26171875 | val_loss : 78710.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 223 | train_loss : 65090.69140625 | val_loss : 8945.9052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 224 | train_loss : 19392.69921875 | val_loss : 8464.3671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 225 | train_loss : 11392.3115234375 | val_loss : 684.3162231445312 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 226 | train_loss : 8489.5439453125 | val_loss : 14833.0234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 227 | train_loss : 18082.38671875 | val_loss : 53200.1484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 228 | train_loss : 66256.8984375 | val_loss : 67285.2265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 229 | train_loss : 56512.5390625 | val_loss : 8677.3662109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 230 | train_loss : 16594.099609375 | val_loss : 27071.8203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 231 | train_loss : 36076.60546875 | val_loss : 60837.80078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 232 | train_loss : 55401.55859375 | val_loss : 6617.6201171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 233 | train_loss : 14636.962890625 | val_loss : 21965.349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 234 | train_loss : 23130.181640625 | val_loss : 36660.44921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 235 | train_loss : 35239.0390625 | val_loss : 5376.40625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 236 | train_loss : 12849.1611328125 | val_loss : 28640.85546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 237 | train_loss : 31657.427734375 | val_loss : 34127.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 238 | train_loss : 43920.7265625 | val_loss : 54313.4140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 239 | train_loss : 51791.1953125 | val_loss : 13606.44140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 240 | train_loss : 20973.740234375 | val_loss : 28972.380859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 241 | train_loss : 29795.822265625 | val_loss : 34037.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 242 | train_loss : 44090.90625 | val_loss : 52729.01953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 243 | train_loss : 46772.37109375 | val_loss : 13236.1572265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 244 | train_loss : 20536.283203125 | val_loss : 32804.75 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 245 | train_loss : 32270.740234375 | val_loss : 32634.962890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 246 | train_loss : 44085.109375 | val_loss : 39855.09375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 247 | train_loss : 35110.78515625 | val_loss : 16866.814453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 248 | train_loss : 24155.66796875 | val_loss : 52385.765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 249 | train_loss : 50722.03515625 | val_loss : 14853.2197265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 250 | train_loss : 21856.009765625 | val_loss : 24915.9609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 251 | train_loss : 23810.869140625 | val_loss : 33339.4765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 252 | train_loss : 44204.6015625 | val_loss : 59424.11328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 253 | train_loss : 54573.93359375 | val_loss : 15791.01953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 254 | train_loss : 19783.45703125 | val_loss : 9574.1376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 255 | train_loss : 17798.833984375 | val_loss : 41354.0703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 256 | train_loss : 40439.12109375 | val_loss : 24003.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 257 | train_loss : 33254.17578125 | val_loss : 32686.810546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 258 | train_loss : 33858.2265625 | val_loss : 34763.73828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 259 | train_loss : 44891.05078125 | val_loss : 50230.26171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 260 | train_loss : 45219.50390625 | val_loss : 12029.7265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 261 | train_loss : 20375.458984375 | val_loss : 24346.484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 262 | train_loss : 24244.642578125 | val_loss : 29080.044921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 263 | train_loss : 38574.12109375 | val_loss : 50679.49609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 264 | train_loss : 43767.98828125 | val_loss : 4599.51513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 265 | train_loss : 13062.62890625 | val_loss : 11909.982421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 266 | train_loss : 14711.39453125 | val_loss : 18602.556640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 267 | train_loss : 29150.6875 | val_loss : 32736.865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 268 | train_loss : 31202.984375 | val_loss : 10938.9326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 269 | train_loss : 19749.154296875 | val_loss : 24598.830078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 270 | train_loss : 24307.162109375 | val_loss : 29060.48828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 271 | train_loss : 38433.7734375 | val_loss : 50281.1484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 272 | train_loss : 42022.92578125 | val_loss : 6683.60888671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 273 | train_loss : 14670.0751953125 | val_loss : 19832.5625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 274 | train_loss : 18794.51171875 | val_loss : 54359.50390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 275 | train_loss : 59720.8046875 | val_loss : 74303.078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 276 | train_loss : 63595.58984375 | val_loss : 29717.501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 277 | train_loss : 30559.2734375 | val_loss : 3881.387451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 278 | train_loss : 10301.951171875 | val_loss : 7995.82763671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 279 | train_loss : 10072.7958984375 | val_loss : 2534.896240234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 280 | train_loss : 10868.4384765625 | val_loss : 11823.1611328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 281 | train_loss : 14630.3359375 | val_loss : 17656.310546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 282 | train_loss : 26923.244140625 | val_loss : 103092.5078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 283 | train_loss : 106037.390625 | val_loss : 36127.59375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 284 | train_loss : 45658.5703125 | val_loss : 45814.8984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 285 | train_loss : 39003.796875 | val_loss : 5193.1435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 286 | train_loss : 13962.0078125 | val_loss : 19044.611328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 287 | train_loss : 19314.779296875 | val_loss : 17770.94140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 288 | train_loss : 26990.169921875 | val_loss : 38323.5234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 289 | train_loss : 34562.99609375 | val_loss : 6126.583984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 290 | train_loss : 14668.39453125 | val_loss : 13176.8974609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 291 | train_loss : 14375.8671875 | val_loss : 15819.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 292 | train_loss : 23654.802734375 | val_loss : 38623.82421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 293 | train_loss : 33902.75390625 | val_loss : 6303.97021484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 294 | train_loss : 14870.87109375 | val_loss : 16008.962890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 295 | train_loss : 16093.482421875 | val_loss : 50583.53125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 296 | train_loss : 55740.6640625 | val_loss : 85727.640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 297 | train_loss : 71442.0859375 | val_loss : 34386.859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 298 | train_loss : 37154.484375 | val_loss : 6336.267578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 299 | train_loss : 9252.16796875 | val_loss : 3084.22509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 300 | train_loss : 10593.50390625 | val_loss : 21719.150390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 301 | train_loss : 22141.390625 | val_loss : 20957.345703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 302 | train_loss : 28186.623046875 | val_loss : 47135.390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 303 | train_loss : 43495.58984375 | val_loss : 7785.10498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 304 | train_loss : 16696.318359375 | val_loss : 22062.703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 305 | train_loss : 21594.421875 | val_loss : 15310.66796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 306 | train_loss : 22296.255859375 | val_loss : 35650.98828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 307 | train_loss : 30775.748046875 | val_loss : 9817.333984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 308 | train_loss : 18123.892578125 | val_loss : 26342.779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 309 | train_loss : 24411.89453125 | val_loss : 12400.4326171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 310 | train_loss : 20448.2734375 | val_loss : 27352.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 311 | train_loss : 25105.697265625 | val_loss : 10312.08203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 312 | train_loss : 18984.2578125 | val_loss : 26394.552734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 313 | train_loss : 23970.75 | val_loss : 10649.83984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 314 | train_loss : 19066.650390625 | val_loss : 27994.259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 315 | train_loss : 25143.384765625 | val_loss : 5399.73388671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 316 | train_loss : 13379.44921875 | val_loss : 15548.0927734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 317 | train_loss : 15930.1748046875 | val_loss : 20684.41796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 318 | train_loss : 27243.685546875 | val_loss : 49332.96875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 319 | train_loss : 42383.09375 | val_loss : 6505.6474609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 320 | train_loss : 13438.2177734375 | val_loss : 13434.90234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 321 | train_loss : 15255.2099609375 | val_loss : 6205.31640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 322 | train_loss : 12092.24609375 | val_loss : 12174.3271484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 323 | train_loss : 15711.26953125 | val_loss : 25089.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 324 | train_loss : 26148.80078125 | val_loss : 15370.291015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 325 | train_loss : 18674.01953125 | val_loss : 8502.45703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 326 | train_loss : 14559.8916015625 | val_loss : 12813.8984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 327 | train_loss : 15774.017578125 | val_loss : 14067.259765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 328 | train_loss : 16897.5546875 | val_loss : 13014.26953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 329 | train_loss : 15200.0283203125 | val_loss : 17050.564453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 330 | train_loss : 18859.787109375 | val_loss : 19517.048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 331 | train_loss : 20670.349609375 | val_loss : 24506.5078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 332 | train_loss : 25673.404296875 | val_loss : 17506.89453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 333 | train_loss : 19925.595703125 | val_loss : 7856.06982421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 334 | train_loss : 14050.99609375 | val_loss : 11565.599609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 335 | train_loss : 14753.1572265625 | val_loss : 11698.646484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 336 | train_loss : 14594.3935546875 | val_loss : 7903.67138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 337 | train_loss : 12403.255859375 | val_loss : 12637.4384765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 338 | train_loss : 15332.21484375 | val_loss : 6735.25146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 339 | train_loss : 11289.9638671875 | val_loss : 12258.7470703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 340 | train_loss : 15604.275390625 | val_loss : 10260.3115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 341 | train_loss : 13686.1259765625 | val_loss : 9696.51171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 342 | train_loss : 13332.9736328125 | val_loss : 83472.7265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 343 | train_loss : 90809.1171875 | val_loss : 66529.203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 344 | train_loss : 66663.8515625 | val_loss : 27319.9140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 345 | train_loss : 32969.046875 | val_loss : 28102.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 346 | train_loss : 40647.62890625 | val_loss : 10297.4111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 347 | train_loss : 12034.5029296875 | val_loss : 3828.021240234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 348 | train_loss : 11792.677734375 | val_loss : 16972.931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 349 | train_loss : 17402.8515625 | val_loss : 8560.919921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 350 | train_loss : 17225.587890625 | val_loss : 21116.859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 351 | train_loss : 21078.83203125 | val_loss : 12171.0927734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 352 | train_loss : 20762.0078125 | val_loss : 25200.5625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 353 | train_loss : 24125.240234375 | val_loss : 16709.015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 354 | train_loss : 24815.3046875 | val_loss : 25663.740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 355 | train_loss : 24035.732421875 | val_loss : 7739.99853515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 356 | train_loss : 16906.01953125 | val_loss : 14708.2373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 357 | train_loss : 14936.5546875 | val_loss : 7540.75048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 358 | train_loss : 15804.71875 | val_loss : 14800.9072265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 359 | train_loss : 15096.9853515625 | val_loss : 6766.79052734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 360 | train_loss : 14806.099609375 | val_loss : 31050.080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 361 | train_loss : 28379.056640625 | val_loss : 20218.341796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 362 | train_loss : 29091.748046875 | val_loss : 27133.34765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 363 | train_loss : 22434.037109375 | val_loss : 5186.83251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 364 | train_loss : 14764.5791015625 | val_loss : 16259.7177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 365 | train_loss : 15984.01953125 | val_loss : 7889.873046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 366 | train_loss : 16571.94921875 | val_loss : 15220.8974609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 367 | train_loss : 15355.275390625 | val_loss : 7538.3330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 368 | train_loss : 15365.802734375 | val_loss : 21205.98046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 369 | train_loss : 19321.4453125 | val_loss : 4861.00048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 370 | train_loss : 12175.197265625 | val_loss : 11485.8154296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 371 | train_loss : 11505.83984375 | val_loss : 6600.68994140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 372 | train_loss : 14959.90234375 | val_loss : 20089.591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 373 | train_loss : 17579.9609375 | val_loss : 5319.25390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 374 | train_loss : 12861.9189453125 | val_loss : 40550.640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 375 | train_loss : 33852.10546875 | val_loss : 20128.59765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 376 | train_loss : 27034.4765625 | val_loss : 32715.849609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 377 | train_loss : 27109.7265625 | val_loss : 5342.61376953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 378 | train_loss : 14559.1875 | val_loss : 18505.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 379 | train_loss : 16203.681640625 | val_loss : 3529.85009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 380 | train_loss : 11908.9404296875 | val_loss : 15368.4921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 381 | train_loss : 15094.2109375 | val_loss : 7706.412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 382 | train_loss : 15551.94140625 | val_loss : 15154.9599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 383 | train_loss : 14936.2861328125 | val_loss : 7781.59814453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 384 | train_loss : 15296.701171875 | val_loss : 12331.5810546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 385 | train_loss : 11027.8408203125 | val_loss : 8476.4560546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 386 | train_loss : 16964.1875 | val_loss : 32891.8984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 387 | train_loss : 30308.8828125 | val_loss : 14763.5703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 388 | train_loss : 22911.220703125 | val_loss : 15524.84765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 389 | train_loss : 14241.7021484375 | val_loss : 3992.55615234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 390 | train_loss : 10619.4853515625 | val_loss : 12117.556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 391 | train_loss : 10965.869140625 | val_loss : 5105.6513671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 392 | train_loss : 12239.361328125 | val_loss : 14914.0302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 393 | train_loss : 13480.599609375 | val_loss : 4393.9482421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 394 | train_loss : 12714.8359375 | val_loss : 14926.6279296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 395 | train_loss : 13053.6962890625 | val_loss : 6474.7138671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 396 | train_loss : 14323.634765625 | val_loss : 16778.626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 397 | train_loss : 15202.798828125 | val_loss : 6828.0087890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 398 | train_loss : 14831.1416015625 | val_loss : 17832.6328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 399 | train_loss : 14476.8603515625 | val_loss : 5431.72021484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 400 | train_loss : 12818.35546875 | val_loss : 16890.07421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 401 | train_loss : 15129.1171875 | val_loss : 5191.3466796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 402 | train_loss : 12853.6484375 | val_loss : 12775.2373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 403 | train_loss : 11465.9091796875 | val_loss : 4485.33251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 404 | train_loss : 12324.4189453125 | val_loss : 18749.404296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 405 | train_loss : 15020.396484375 | val_loss : 7831.5361328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 406 | train_loss : 14328.9345703125 | val_loss : 22351.115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 407 | train_loss : 18583.681640625 | val_loss : 7586.205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 408 | train_loss : 14872.67578125 | val_loss : 14515.8740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 409 | train_loss : 12456.5322265625 | val_loss : 4259.36865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 410 | train_loss : 12625.724609375 | val_loss : 15195.9501953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 411 | train_loss : 12469.9423828125 | val_loss : 4567.24853515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 412 | train_loss : 12205.5009765625 | val_loss : 16340.009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 413 | train_loss : 13762.3388671875 | val_loss : 4852.779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 414 | train_loss : 12288.2490234375 | val_loss : 13428.01953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 415 | train_loss : 10956.4033203125 | val_loss : 6024.58740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 416 | train_loss : 13866.8935546875 | val_loss : 19358.435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 417 | train_loss : 15598.736328125 | val_loss : 4371.3701171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 418 | train_loss : 12527.96484375 | val_loss : 37875.78125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 419 | train_loss : 31631.4609375 | val_loss : 22206.501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 420 | train_loss : 25434.455078125 | val_loss : 38163.65234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 421 | train_loss : 41427.44140625 | val_loss : 17249.53125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 422 | train_loss : 17994.41015625 | val_loss : 812.1849975585938 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 423 | train_loss : 7552.24609375 | val_loss : 6799.21484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 424 | train_loss : 7842.0830078125 | val_loss : 5698.580078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 425 | train_loss : 13599.625 | val_loss : 10961.89453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 426 | train_loss : 10694.4052734375 | val_loss : 6122.6435546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 427 | train_loss : 14661.806640625 | val_loss : 16087.8408203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 428 | train_loss : 13887.302734375 | val_loss : 8904.7041015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 429 | train_loss : 16285.607421875 | val_loss : 16001.2021484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 430 | train_loss : 13267.4423828125 | val_loss : 5870.8388671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 431 | train_loss : 13962.6337890625 | val_loss : 17405.03515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 432 | train_loss : 14380.4453125 | val_loss : 6413.5888671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 433 | train_loss : 14261.3115234375 | val_loss : 12493.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 434 | train_loss : 10133.634765625 | val_loss : 4555.32861328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 435 | train_loss : 11690.197265625 | val_loss : 12796.3388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 436 | train_loss : 10670.8115234375 | val_loss : 2382.89501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 437 | train_loss : 9791.7109375 | val_loss : 11115.8623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 438 | train_loss : 9448.724609375 | val_loss : 3008.318115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 439 | train_loss : 10149.75 | val_loss : 11502.9296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 440 | train_loss : 9603.4072265625 | val_loss : 4044.693115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 441 | train_loss : 11171.2958984375 | val_loss : 15747.912109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 442 | train_loss : 11902.990234375 | val_loss : 3757.978759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 443 | train_loss : 10723.11328125 | val_loss : 14161.396484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 444 | train_loss : 10816.9013671875 | val_loss : 5384.70068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 445 | train_loss : 12556.04296875 | val_loss : 21305.9609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 446 | train_loss : 16184.857421875 | val_loss : 3658.9462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 447 | train_loss : 10280.962890625 | val_loss : 13388.3984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 448 | train_loss : 10689.30859375 | val_loss : 4970.88623046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 449 | train_loss : 12240.7421875 | val_loss : 13386.34765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 450 | train_loss : 10641.923828125 | val_loss : 3821.219970703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 451 | train_loss : 11017.09375 | val_loss : 13114.9609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 452 | train_loss : 9985.537109375 | val_loss : 3715.0107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 453 | train_loss : 10520.271484375 | val_loss : 12704.75390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 454 | train_loss : 9902.1787109375 | val_loss : 3251.21435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 455 | train_loss : 10179.7275390625 | val_loss : 9994.337890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 456 | train_loss : 8075.5556640625 | val_loss : 3896.638671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 457 | train_loss : 10722.291015625 | val_loss : 15439.9521484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 458 | train_loss : 11210.052734375 | val_loss : 5225.6201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 459 | train_loss : 12483.5849609375 | val_loss : 14702.8701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 460 | train_loss : 11450.40625 | val_loss : 4560.85693359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 461 | train_loss : 12120.619140625 | val_loss : 12727.193359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 462 | train_loss : 10005.7548828125 | val_loss : 2209.36572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 463 | train_loss : 8961.42578125 | val_loss : 12718.5771484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 464 | train_loss : 10052.2080078125 | val_loss : 5202.74267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 465 | train_loss : 11782.0283203125 | val_loss : 14855.6875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 466 | train_loss : 10286.310546875 | val_loss : 3688.4150390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 467 | train_loss : 9905.666015625 | val_loss : 12744.9697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 468 | train_loss : 9714.078125 | val_loss : 3954.940673828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 469 | train_loss : 11285.50390625 | val_loss : 10971.2177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 470 | train_loss : 8580.203125 | val_loss : 3022.76806640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 471 | train_loss : 10076.0615234375 | val_loss : 11457.125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 472 | train_loss : 8618.8154296875 | val_loss : 738.7212524414062 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 473 | train_loss : 6381.99560546875 | val_loss : 8955.0947265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 474 | train_loss : 7041.01611328125 | val_loss : 56.248748779296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 475 | train_loss : 5430.4814453125 | val_loss : 8009.92041015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 476 | train_loss : 5685.955078125 | val_loss : 291.2449951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 477 | train_loss : 4231.33349609375 | val_loss : 6725.10546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 478 | train_loss : 4434.37548828125 | val_loss : 802.657470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 479 | train_loss : 5144.11767578125 | val_loss : 8673.6494140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 480 | train_loss : 5898.67236328125 | val_loss : 16554.36328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 481 | train_loss : 21632.0546875 | val_loss : 61340.35546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 482 | train_loss : 51205.421875 | val_loss : 20023.41796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 483 | train_loss : 21842.455078125 | val_loss : 12961.822265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 484 | train_loss : 14105.06640625 | val_loss : 4974.4248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 485 | train_loss : 6994.9150390625 | val_loss : 4022.268798828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 486 | train_loss : 6258.923828125 | val_loss : 3202.4130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 487 | train_loss : 5965.03076171875 | val_loss : 2853.84130859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 488 | train_loss : 4861.60986328125 | val_loss : 4254.50244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 489 | train_loss : 5943.38671875 | val_loss : 3434.57177734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 490 | train_loss : 5239.27490234375 | val_loss : 4626.17138671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 491 | train_loss : 5911.46484375 | val_loss : 2363.63134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 492 | train_loss : 5348.62939453125 | val_loss : 4453.1943359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 493 | train_loss : 4903.5712890625 | val_loss : 2398.554931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 494 | train_loss : 5615.48388671875 | val_loss : 8186.20361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 495 | train_loss : 6437.52978515625 | val_loss : 7825.83251953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 496 | train_loss : 9984.32421875 | val_loss : 8525.23828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 497 | train_loss : 6982.857421875 | val_loss : 6811.751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 498 | train_loss : 11424.09375 | val_loss : 15115.8603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 499 | train_loss : 12529.076171875 | val_loss : 1322.378173828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 500 | train_loss : 5129.892578125 | val_loss : 6409.837890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 501 | train_loss : 4606.06494140625 | val_loss : 1147.09375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 502 | train_loss : 5362.18994140625 | val_loss : 4864.22802734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 503 | train_loss : 3564.97314453125 | val_loss : 309.3424987792969 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 504 | train_loss : 2532.6416015625 | val_loss : 2116.639404296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 505 | train_loss : 2175.224365234375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 506 | train_loss : 1369.5390625 | val_loss : 175.6181182861328 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 507 | train_loss : 1072.1728515625 | val_loss : 404.39373779296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 508 | train_loss : 1155.6519775390625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 509 | train_loss : 931.3438110351562 | val_loss : 1555.32373046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 510 | train_loss : 1637.3262939453125 | val_loss : 831.6087646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 511 | train_loss : 2843.82958984375 | val_loss : 6571.26708984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 512 | train_loss : 4486.322265625 | val_loss : 936.541259765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 513 | train_loss : 3491.0859375 | val_loss : 5523.75439453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 514 | train_loss : 4425.18896484375 | val_loss : 2572.954345703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 515 | train_loss : 6272.44873046875 | val_loss : 8121.33544921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 516 | train_loss : 6387.1123046875 | val_loss : 3658.1767578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 517 | train_loss : 7906.7275390625 | val_loss : 23514.056640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 518 | train_loss : 24756.962890625 | val_loss : 38480.359375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 519 | train_loss : 49038.7265625 | val_loss : 40485.7734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 520 | train_loss : 37853.53515625 | val_loss : 6476.328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 521 | train_loss : 12752.9052734375 | val_loss : 8939.1484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 522 | train_loss : 11917.517578125 | val_loss : 1941.280029296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 523 | train_loss : 3429.238525390625 | val_loss : 7806.2783203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 524 | train_loss : 6341.3330078125 | val_loss : 11464.0478515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 525 | train_loss : 15202.1962890625 | val_loss : 13472.642578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 526 | train_loss : 9923.4228515625 | val_loss : 5322.373046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 527 | train_loss : 11094.97265625 | val_loss : 6702.90234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 528 | train_loss : 5757.6591796875 | val_loss : 352.396240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 529 | train_loss : 5645.75439453125 | val_loss : 4927.0537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 530 | train_loss : 4393.40576171875 | val_loss : 50.09187316894531 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 531 | train_loss : 4883.80322265625 | val_loss : 5866.912109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 532 | train_loss : 5110.26904296875 | val_loss : 1352.59130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 533 | train_loss : 7001.9814453125 | val_loss : 6723.6943359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 534 | train_loss : 5862.2685546875 | val_loss : 1129.6962890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 535 | train_loss : 6291.6806640625 | val_loss : 7168.05615234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 536 | train_loss : 5886.97119140625 | val_loss : 1004.6687622070312 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 537 | train_loss : 5986.43701171875 | val_loss : 7506.685546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 538 | train_loss : 5909.83447265625 | val_loss : 1306.0350341796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 539 | train_loss : 7059.25732421875 | val_loss : 9500.6259765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 540 | train_loss : 8584.7109375 | val_loss : 12357.6259765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 541 | train_loss : 19098.2421875 | val_loss : 19005.580078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 542 | train_loss : 15907.1884765625 | val_loss : 2637.8076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 543 | train_loss : 6440.4091796875 | val_loss : 2483.1943359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 544 | train_loss : 2178.272216796875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 545 | train_loss : 1545.7379150390625 | val_loss : 402.1731262207031 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 546 | train_loss : 911.0595092773438 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 547 | train_loss : 1465.84228515625 | val_loss : 2949.9912109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 548 | train_loss : 2426.073486328125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 549 | train_loss : 2779.12158203125 | val_loss : 3470.468017578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 550 | train_loss : 2490.82177734375 | val_loss : 137.02374267578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 551 | train_loss : 3789.516357421875 | val_loss : 5948.43017578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 552 | train_loss : 3632.133544921875 | val_loss : 553.9400024414062 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 553 | train_loss : 3716.1025390625 | val_loss : 4563.5849609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 554 | train_loss : 2890.27490234375 | val_loss : 27.0049991607666 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 555 | train_loss : 2252.584716796875 | val_loss : 3341.793701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 556 | train_loss : 2081.885986328125 | val_loss : 592.1087646484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 557 | train_loss : 2876.300537109375 | val_loss : 4998.6005859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 558 | train_loss : 3281.625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 559 | train_loss : 2025.8822021484375 | val_loss : 2800.273681640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 560 | train_loss : 2215.49365234375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 561 | train_loss : 1503.302490234375 | val_loss : 3001.679931640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 562 | train_loss : 2017.759521484375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 563 | train_loss : 1551.1138916015625 | val_loss : 4271.25439453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 564 | train_loss : 2576.326171875 | val_loss : 103.15875244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 565 | train_loss : 2051.19677734375 | val_loss : 2947.269287109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 566 | train_loss : 1979.0853271484375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 567 | train_loss : 1521.7412109375 | val_loss : 4308.6689453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 568 | train_loss : 2561.541259765625 | val_loss : 90.12625122070312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 569 | train_loss : 2027.267822265625 | val_loss : 2949.353759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 570 | train_loss : 1936.9837646484375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 571 | train_loss : 1501.8043212890625 | val_loss : 4304.0693359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 572 | train_loss : 2533.462890625 | val_loss : 79.84375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 573 | train_loss : 2013.951904296875 | val_loss : 2921.5849609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 574 | train_loss : 1889.540771484375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 575 | train_loss : 1506.545654296875 | val_loss : 38432.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 576 | train_loss : 33796.078125 | val_loss : 61152.48828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 577 | train_loss : 74242.8046875 | val_loss : 36208.546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 578 | train_loss : 35735.44140625 | val_loss : 2177.88427734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 579 | train_loss : 7778.8857421875 | val_loss : 8796.9560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 580 | train_loss : 9521.439453125 | val_loss : 1846.390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 581 | train_loss : 3178.060546875 | val_loss : 2500.3505859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 582 | train_loss : 2114.23681640625 | val_loss : 876.603759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 583 | train_loss : 1899.550048828125 | val_loss : 753.625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 584 | train_loss : 1483.5201416015625 | val_loss : 129.3262481689453 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 585 | train_loss : 1556.16162109375 | val_loss : 529.6268920898438 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 586 | train_loss : 1275.586181640625 | val_loss : 170.47500610351562 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 587 | train_loss : 1474.8681640625 | val_loss : 651.8343505859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 588 | train_loss : 1361.2637939453125 | val_loss : 823.423095703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 589 | train_loss : 1759.6300048828125 | val_loss : 853.6981201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 590 | train_loss : 1931.0894775390625 | val_loss : 1328.815673828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 591 | train_loss : 2221.288818359375 | val_loss : 545.9093627929688 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 592 | train_loss : 2604.62939453125 | val_loss : 2436.882568359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 593 | train_loss : 2255.207763671875 | val_loss : 211.0675048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 594 | train_loss : 1659.905517578125 | val_loss : 763.9068603515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 595 | train_loss : 1305.11474609375 | val_loss : 204.59750366210938 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 596 | train_loss : 882.5184936523438 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 597 | train_loss : 783.4522094726562 | val_loss : 255.3368682861328 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 598 | train_loss : 758.1439819335938 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 599 | train_loss : 810.5321655273438 | val_loss : 239.24000549316406 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 600 | train_loss : 839.7103881835938 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 601 | train_loss : 692.593505859375 | val_loss : 232.09625244140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 602 | train_loss : 748.6076049804688 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 603 | train_loss : 609.2371215820312 | val_loss : 290.1650085449219 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 604 | train_loss : 654.1576538085938 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 605 | train_loss : 1003.44580078125 | val_loss : 1645.157470703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 606 | train_loss : 1624.1268310546875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 607 | train_loss : 1878.513427734375 | val_loss : 3792.66064453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 608 | train_loss : 2426.45947265625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 609 | train_loss : 2098.32666015625 | val_loss : 3425.5537109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 610 | train_loss : 2029.97265625 | val_loss : 119.8218765258789 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 611 | train_loss : 3056.257568359375 | val_loss : 3579.173095703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 612 | train_loss : 2385.537841796875 | val_loss : 596.7324829101562 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 613 | train_loss : 2933.54248046875 | val_loss : 4344.3642578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 614 | train_loss : 2744.06103515625 | val_loss : 1323.5718994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 615 | train_loss : 5153.708984375 | val_loss : 7022.99072265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 616 | train_loss : 5421.22509765625 | val_loss : 5151.79541015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 617 | train_loss : 9204.568359375 | val_loss : 10574.037109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 618 | train_loss : 10411.01171875 | val_loss : 6928.37744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 619 | train_loss : 10561.0546875 | val_loss : 5327.46044921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 620 | train_loss : 5313.55126953125 | val_loss : 724.0175170898438 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 621 | train_loss : 4170.86572265625 | val_loss : 2594.794921875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 622 | train_loss : 2186.804443359375 | val_loss : 633.9893798828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 623 | train_loss : 3683.578857421875 | val_loss : 2832.116943359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 624 | train_loss : 2371.116455078125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 625 | train_loss : 2046.3714599609375 | val_loss : 1450.02880859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 626 | train_loss : 1534.559326171875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 627 | train_loss : 1596.5804443359375 | val_loss : 1056.5087890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 628 | train_loss : 1193.902587890625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 629 | train_loss : 1378.7193603515625 | val_loss : 2255.556884765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 630 | train_loss : 1546.5849609375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 631 | train_loss : 1369.430908203125 | val_loss : 3550.50439453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 632 | train_loss : 2071.0966796875 | val_loss : 24.506874084472656 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 633 | train_loss : 1950.44873046875 | val_loss : 3128.36572265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 634 | train_loss : 1864.4453125 | val_loss : 65.53874969482422 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 635 | train_loss : 1570.9681396484375 | val_loss : 2509.748046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 636 | train_loss : 1572.102783203125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 637 | train_loss : 1055.680908203125 | val_loss : 2869.346923828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 638 | train_loss : 1729.7059326171875 | val_loss : 84.14812469482422 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 639 | train_loss : 1926.8824462890625 | val_loss : 3741.951904296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 640 | train_loss : 2435.215576171875 | val_loss : 807.844970703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 641 | train_loss : 3416.28662109375 | val_loss : 4787.77294921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 642 | train_loss : 2865.474365234375 | val_loss : 48.818748474121094 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 643 | train_loss : 1952.95068359375 | val_loss : 2981.072509765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 644 | train_loss : 1903.34814453125 | val_loss : 14.717499732971191 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 645 | train_loss : 1029.599365234375 | val_loss : 1035.5430908203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 646 | train_loss : 778.7086181640625 | val_loss : 16.08187484741211 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 647 | train_loss : 874.053955078125 | val_loss : 1958.8980712890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 648 | train_loss : 1120.2100830078125 | val_loss : 93.21375274658203 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 649 | train_loss : 1549.0123291015625 | val_loss : 4198.93896484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 650 | train_loss : 2437.96875 | val_loss : 402.9381103515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 651 | train_loss : 2702.566650390625 | val_loss : 4285.82958984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 652 | train_loss : 3089.961669921875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 653 | train_loss : 1250.60888671875 | val_loss : 37667.25390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 654 | train_loss : 29942.787109375 | val_loss : 56763.5 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 655 | train_loss : 62270.6796875 | val_loss : 63456.2265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 656 | train_loss : 57632.2109375 | val_loss : 5539.1005859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 657 | train_loss : 10441.76171875 | val_loss : 10147.0673828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 658 | train_loss : 8408.3212890625 | val_loss : 8549.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 659 | train_loss : 13504.9599609375 | val_loss : 17848.939453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 660 | train_loss : 12569.3447265625 | val_loss : 2060.22314453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 661 | train_loss : 7073.427734375 | val_loss : 10525.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 662 | train_loss : 6844.96826171875 | val_loss : 6726.06298828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 663 | train_loss : 11281.2529296875 | val_loss : 10181.30078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 664 | train_loss : 6815.2841796875 | val_loss : 6958.90771484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 665 | train_loss : 10737.244140625 | val_loss : 8251.1279296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 666 | train_loss : 5860.7099609375 | val_loss : 1568.3275146484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 667 | train_loss : 5532.89697265625 | val_loss : 3209.7080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 668 | train_loss : 2899.44189453125 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 669 | train_loss : 2055.751953125 | val_loss : 1158.140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 670 | train_loss : 1453.1689453125 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 671 | train_loss : 1547.977783203125 | val_loss : 970.161865234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 672 | train_loss : 1454.713134765625 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 673 | train_loss : 1620.450927734375 | val_loss : 1146.71630859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 674 | train_loss : 1438.9776611328125 | val_loss : 398.5793762207031 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 675 | train_loss : 1478.9541015625 | val_loss : 447.2699890136719 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 676 | train_loss : 1043.880126953125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 677 | train_loss : 896.7968139648438 | val_loss : 146.65687561035156 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 678 | train_loss : 1091.885498046875 | val_loss : 1305.936279296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 679 | train_loss : 1705.167236328125 | val_loss : 39.48625183105469 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 680 | train_loss : 1244.4862060546875 | val_loss : 2425.71875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 681 | train_loss : 1879.38232421875 | val_loss : 311.7762451171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 682 | train_loss : 1330.53125 | val_loss : 731.3212280273438 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 683 | train_loss : 1186.3231201171875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 684 | train_loss : 551.0578002929688 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 685 | train_loss : 616.0980224609375 | val_loss : 1033.5006103515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 686 | train_loss : 1302.125244140625 | val_loss : 962.3912353515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 687 | train_loss : 3761.983154296875 | val_loss : 4715.11572265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 688 | train_loss : 2857.480712890625 | val_loss : 62.471248626708984 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 689 | train_loss : 1645.4072265625 | val_loss : 1140.6962890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 690 | train_loss : 885.0402221679688 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 691 | train_loss : 895.275146484375 | val_loss : 629.635009765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 692 | train_loss : 819.3226318359375 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 693 | train_loss : 1243.3892822265625 | val_loss : 819.5437622070312 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 694 | train_loss : 598.7373657226562 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 695 | train_loss : 489.2237548828125 | val_loss : 38.40937423706055 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 696 | train_loss : 415.45147705078125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 697 | train_loss : 592.3584594726562 | val_loss : 1553.8675537109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 698 | train_loss : 1272.87939453125 | val_loss : 52.705623626708984 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 699 | train_loss : 1897.5487060546875 | val_loss : 2300.6787109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 700 | train_loss : 1304.80810546875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 701 | train_loss : 1514.0072021484375 | val_loss : 1527.0550537109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 702 | train_loss : 1195.8436279296875 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 703 | train_loss : 2325.15380859375 | val_loss : 4162.70263671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 704 | train_loss : 2670.263671875 | val_loss : 107.04000091552734 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 705 | train_loss : 2634.63037109375 | val_loss : 2070.9169921875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 706 | train_loss : 2012.8807373046875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 707 | train_loss : 1174.2723388671875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 708 | train_loss : 689.6132202148438 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 709 | train_loss : 957.6431884765625 | val_loss : 923.5243530273438 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 710 | train_loss : 1372.2384033203125 | val_loss : 516.5631103515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 711 | train_loss : 3127.910400390625 | val_loss : 3142.123046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 712 | train_loss : 1896.19384765625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 713 | train_loss : 1429.1658935546875 | val_loss : 2665.905029296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 714 | train_loss : 1537.8310546875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 715 | train_loss : 1903.45068359375 | val_loss : 2924.16552734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 716 | train_loss : 1808.227783203125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 717 | train_loss : 1037.4246826171875 | val_loss : 1948.826904296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 718 | train_loss : 1141.5794677734375 | val_loss : 35.883750915527344 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 719 | train_loss : 1919.9647216796875 | val_loss : 3581.958740234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 720 | train_loss : 1602.23974609375 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 721 | train_loss : 1817.1767578125 | val_loss : 4044.952392578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 722 | train_loss : 2611.36474609375 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 723 | train_loss : 2587.835693359375 | val_loss : 2125.81689453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 724 | train_loss : 1972.80712890625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 725 | train_loss : 798.57958984375 | val_loss : 19.166250228881836 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 726 | train_loss : 475.36016845703125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 727 | train_loss : 751.2340698242188 | val_loss : 962.4312744140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 728 | train_loss : 1037.537109375 | val_loss : 201.0518798828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 729 | train_loss : 2078.34912109375 | val_loss : 3302.8544921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 730 | train_loss : 1692.3316650390625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 731 | train_loss : 1969.5162353515625 | val_loss : 5744.591796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 732 | train_loss : 3458.230712890625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 733 | train_loss : 2438.137451171875 | val_loss : 1451.0362548828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 734 | train_loss : 1715.252197265625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 735 | train_loss : 813.9971923828125 | val_loss : 28.223125457763672 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 736 | train_loss : 464.650634765625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 737 | train_loss : 829.3779907226562 | val_loss : 1523.3319091796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 738 | train_loss : 1208.2347412109375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 739 | train_loss : 1594.014404296875 | val_loss : 2874.57177734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 740 | train_loss : 1506.42431640625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 741 | train_loss : 1699.70654296875 | val_loss : 3147.91748046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 742 | train_loss : 1999.6624755859375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 743 | train_loss : 1405.4512939453125 | val_loss : 1911.396240234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 744 | train_loss : 1836.615966796875 | val_loss : 68.98124694824219 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 745 | train_loss : 2628.12255859375 | val_loss : 5441.65380859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 746 | train_loss : 2929.780517578125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 747 | train_loss : 2101.898681640625 | val_loss : 1358.4168701171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 748 | train_loss : 1362.9056396484375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 749 | train_loss : 856.6874389648438 | val_loss : 589.3624877929688 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 750 | train_loss : 586.03759765625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 751 | train_loss : 256.4432067871094 | val_loss : 98.04624938964844 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 752 | train_loss : 250.33351135253906 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 753 | train_loss : 686.984619140625 | val_loss : 2055.42822265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 754 | train_loss : 1355.7266845703125 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 755 | train_loss : 1963.552001953125 | val_loss : 3372.826171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 756 | train_loss : 1823.1474609375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 757 | train_loss : 1336.7706298828125 | val_loss : 2172.6455078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 758 | train_loss : 1469.5697021484375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 759 | train_loss : 730.8577270507812 | val_loss : 1588.603759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 760 | train_loss : 994.850341796875 | val_loss : 460.08563232421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 761 | train_loss : 2544.63916015625 | val_loss : 3509.01806640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 762 | train_loss : 1521.78076171875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 763 | train_loss : 1623.535888671875 | val_loss : 4716.33447265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 764 | train_loss : 2656.145263671875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 765 | train_loss : 2122.457763671875 | val_loss : 2276.8837890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 766 | train_loss : 2099.762451171875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 767 | train_loss : 393.89453125 | val_loss : 509.228759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 768 | train_loss : 516.991943359375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 769 | train_loss : 249.72726440429688 | val_loss : 374.84625244140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 770 | train_loss : 220.8116455078125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 771 | train_loss : 327.9969482421875 | val_loss : 1376.083740234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 772 | train_loss : 614.2355346679688 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 773 | train_loss : 347.70001220703125 | val_loss : 1232.0631103515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 774 | train_loss : 571.6434936523438 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 775 | train_loss : 171.33937072753906 | val_loss : 72.26000213623047 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 776 | train_loss : 89.42758178710938 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 777 | train_loss : 222.7167205810547 | val_loss : 1183.536865234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 778 | train_loss : 663.7492065429688 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 779 | train_loss : 211.26156616210938 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 780 | train_loss : 127.41023254394531 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 781 | train_loss : 58.480079650878906 | val_loss : 316.5299987792969 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 782 | train_loss : 123.28585815429688 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 783 | train_loss : 347.5891418457031 | val_loss : 16108.4765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 784 | train_loss : 13217.80859375 | val_loss : 92578.4765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 785 | train_loss : 86156.9609375 | val_loss : 61154.7890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 786 | train_loss : 60131.89453125 | val_loss : 3060.590576171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 787 | train_loss : 7203.98486328125 | val_loss : 16529.958984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 788 | train_loss : 15847.416015625 | val_loss : 14978.2626953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 789 | train_loss : 15811.4658203125 | val_loss : 16282.8974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 790 | train_loss : 11582.4501953125 | val_loss : 8771.181640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 791 | train_loss : 11329.3603515625 | val_loss : 9543.650390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 792 | train_loss : 6828.77001953125 | val_loss : 8381.6708984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 793 | train_loss : 11061.22265625 | val_loss : 6674.4599609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 794 | train_loss : 5328.5556640625 | val_loss : 1621.6324462890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 795 | train_loss : 5316.9794921875 | val_loss : 2996.140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 796 | train_loss : 3115.08935546875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 797 | train_loss : 2897.37841796875 | val_loss : 1324.030029296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 798 | train_loss : 1510.5975341796875 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 799 | train_loss : 1233.685546875 | val_loss : 641.2468872070312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 1 | epoch : 800 | train_loss : 1103.9395751953125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 2 | epoch : 1 | train_loss : 2428206.5 | val_loss : 784989.4375 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 2 | train_loss : 976787.375 | val_loss : 717321.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 3 | train_loss : 720754.625 | val_loss : 570284.5625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 4 | train_loss : 636546.1875 | val_loss : 513417.28125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 5 | train_loss : 468381.4375 | val_loss : 629366.0 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 6 | train_loss : 538833.5 | val_loss : 321299.09375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 7 | train_loss : 327705.0625 | val_loss : 359832.8125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 8 | train_loss : 265809.34375 | val_loss : 464801.46875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 9 | train_loss : 420322.8125 | val_loss : 273298.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 10 | train_loss : 192122.015625 | val_loss : 234974.28125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 11 | train_loss : 271439.46875 | val_loss : 308511.5 | test_acc : 0.04 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 12 | train_loss : 326932.875 | val_loss : 540781.0625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 13 | train_loss : 430003.15625 | val_loss : 520519.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 14 | train_loss : 402867.28125 | val_loss : 118051.640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 15 | train_loss : 105814.9609375 | val_loss : 241684.3125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 16 | train_loss : 238890.578125 | val_loss : 368869.625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 17 | train_loss : 322696.25 | val_loss : 375027.8125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 18 | train_loss : 317988.8125 | val_loss : 185940.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 19 | train_loss : 252353.140625 | val_loss : 78469.5234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 20 | train_loss : 117247.8984375 | val_loss : 246512.65625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 21 | train_loss : 260429.484375 | val_loss : 253555.453125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 22 | train_loss : 196052.59375 | val_loss : 161235.984375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 23 | train_loss : 133685.078125 | val_loss : 188314.3125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 24 | train_loss : 240670.421875 | val_loss : 78221.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 25 | train_loss : 78588.2578125 | val_loss : 218048.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 26 | train_loss : 206420.21875 | val_loss : 272841.375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 27 | train_loss : 201442.5 | val_loss : 107631.4296875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 28 | train_loss : 167317.875 | val_loss : 185559.625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 29 | train_loss : 169329.515625 | val_loss : 210266.625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 30 | train_loss : 150636.984375 | val_loss : 194446.15625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 31 | train_loss : 191428.0 | val_loss : 161041.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 32 | train_loss : 136812.84375 | val_loss : 85180.890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 33 | train_loss : 93932.109375 | val_loss : 266632.15625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 34 | train_loss : 188331.375 | val_loss : 195449.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 35 | train_loss : 252810.875 | val_loss : 152011.25 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 36 | train_loss : 139252.765625 | val_loss : 76472.046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 37 | train_loss : 56382.0234375 | val_loss : 175946.421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 38 | train_loss : 240461.84375 | val_loss : 171157.421875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 39 | train_loss : 126937.828125 | val_loss : 230941.3125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 40 | train_loss : 212926.9375 | val_loss : 159734.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 41 | train_loss : 207204.140625 | val_loss : 228148.984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 42 | train_loss : 160563.0625 | val_loss : 163248.0625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 43 | train_loss : 184077.859375 | val_loss : 160095.15625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 44 | train_loss : 122231.8828125 | val_loss : 88898.3828125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 45 | train_loss : 125536.203125 | val_loss : 221299.984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 46 | train_loss : 156266.0 | val_loss : 160731.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 47 | train_loss : 176073.21875 | val_loss : 83468.2578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 48 | train_loss : 68224.2890625 | val_loss : 190873.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 49 | train_loss : 218725.0625 | val_loss : 146498.140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 50 | train_loss : 106896.9296875 | val_loss : 41556.9296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 51 | train_loss : 61172.984375 | val_loss : 156974.65625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 52 | train_loss : 110648.4375 | val_loss : 81362.6640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 53 | train_loss : 146209.765625 | val_loss : 193647.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 54 | train_loss : 171959.4375 | val_loss : 295193.0 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 55 | train_loss : 232568.546875 | val_loss : 95720.9765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 56 | train_loss : 114232.7421875 | val_loss : 160340.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 57 | train_loss : 115699.8203125 | val_loss : 137277.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 58 | train_loss : 203425.203125 | val_loss : 162540.5625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 59 | train_loss : 187375.5625 | val_loss : 119482.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 60 | train_loss : 78878.46875 | val_loss : 93216.109375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 61 | train_loss : 112393.4921875 | val_loss : 167918.78125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 62 | train_loss : 163674.28125 | val_loss : 176710.28125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 63 | train_loss : 136061.265625 | val_loss : 33466.7578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 64 | train_loss : 43861.0703125 | val_loss : 126982.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 65 | train_loss : 134611.28125 | val_loss : 171195.546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 66 | train_loss : 120388.3671875 | val_loss : 126199.9765625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 67 | train_loss : 180228.515625 | val_loss : 141925.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 68 | train_loss : 146369.796875 | val_loss : 124521.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 69 | train_loss : 81652.8828125 | val_loss : 56165.609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 70 | train_loss : 89137.296875 | val_loss : 147363.34375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 71 | train_loss : 112721.9765625 | val_loss : 36927.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 72 | train_loss : 25549.544921875 | val_loss : 24770.73046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 73 | train_loss : 32297.119140625 | val_loss : 67660.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 74 | train_loss : 42795.71875 | val_loss : 32262.037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 75 | train_loss : 41169.75390625 | val_loss : 145812.46875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 76 | train_loss : 126872.65625 | val_loss : 214566.71875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 77 | train_loss : 161572.953125 | val_loss : 68735.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 78 | train_loss : 97607.609375 | val_loss : 181833.71875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 79 | train_loss : 134853.453125 | val_loss : 164890.984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 80 | train_loss : 152811.984375 | val_loss : 118255.5234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 81 | train_loss : 106856.109375 | val_loss : 173207.484375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 82 | train_loss : 226866.140625 | val_loss : 187426.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 83 | train_loss : 130244.1171875 | val_loss : 72711.90625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 84 | train_loss : 83877.1171875 | val_loss : 179627.234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 85 | train_loss : 146532.796875 | val_loss : 77418.2265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 86 | train_loss : 67319.7734375 | val_loss : 26411.28515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 87 | train_loss : 29502.810546875 | val_loss : 100882.78125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 88 | train_loss : 123444.078125 | val_loss : 138016.46875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 89 | train_loss : 89763.7578125 | val_loss : 50041.14453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 90 | train_loss : 66178.5078125 | val_loss : 135612.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 91 | train_loss : 124454.09375 | val_loss : 103067.6328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 92 | train_loss : 63661.34375 | val_loss : 77879.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 93 | train_loss : 121219.2109375 | val_loss : 110457.203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 94 | train_loss : 99228.640625 | val_loss : 81811.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 95 | train_loss : 51785.28515625 | val_loss : 19314.947265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 96 | train_loss : 32781.93359375 | val_loss : 103197.6171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 97 | train_loss : 59401.84375 | val_loss : 71065.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 98 | train_loss : 110714.203125 | val_loss : 64959.078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 99 | train_loss : 40938.37890625 | val_loss : 70417.8046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 100 | train_loss : 80488.296875 | val_loss : 179268.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 101 | train_loss : 146822.0625 | val_loss : 87278.5390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 102 | train_loss : 73304.15625 | val_loss : 23275.466796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 103 | train_loss : 23367.240234375 | val_loss : 83709.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 104 | train_loss : 101532.1171875 | val_loss : 128178.84375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 105 | train_loss : 93856.5078125 | val_loss : 93258.96875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 106 | train_loss : 68360.421875 | val_loss : 141893.875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 107 | train_loss : 132032.890625 | val_loss : 122172.5390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 108 | train_loss : 140231.171875 | val_loss : 96532.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 109 | train_loss : 58900.13671875 | val_loss : 22614.837890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 110 | train_loss : 34289.59765625 | val_loss : 87876.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 111 | train_loss : 50577.140625 | val_loss : 61512.19140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 112 | train_loss : 88030.203125 | val_loss : 168791.625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 113 | train_loss : 168818.953125 | val_loss : 239059.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 114 | train_loss : 168047.265625 | val_loss : 49316.71484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 115 | train_loss : 69010.6875 | val_loss : 75934.2734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 116 | train_loss : 61603.64453125 | val_loss : 73146.703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 117 | train_loss : 63724.359375 | val_loss : 119601.3828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 118 | train_loss : 88948.8828125 | val_loss : 32337.5390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 119 | train_loss : 34377.8046875 | val_loss : 125161.8984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 120 | train_loss : 113474.9375 | val_loss : 141863.78125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 121 | train_loss : 106841.3984375 | val_loss : 26925.169921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 122 | train_loss : 41016.96875 | val_loss : 114777.4609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 123 | train_loss : 99658.7734375 | val_loss : 140168.953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 124 | train_loss : 98812.890625 | val_loss : 27976.48828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 125 | train_loss : 52660.84375 | val_loss : 179500.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 126 | train_loss : 148566.515625 | val_loss : 188209.078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 127 | train_loss : 138341.046875 | val_loss : 12188.455078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 128 | train_loss : 18789.853515625 | val_loss : 49784.00390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 129 | train_loss : 37157.984375 | val_loss : 62627.859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 130 | train_loss : 57854.91015625 | val_loss : 87703.8203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 131 | train_loss : 75068.203125 | val_loss : 119699.78125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 132 | train_loss : 93379.4296875 | val_loss : 92064.8125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 133 | train_loss : 72169.734375 | val_loss : 119977.2421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 134 | train_loss : 130019.65625 | val_loss : 53399.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 135 | train_loss : 39686.80859375 | val_loss : 64989.85546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 136 | train_loss : 62699.76171875 | val_loss : 100868.5 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 137 | train_loss : 82547.296875 | val_loss : 114158.890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 138 | train_loss : 86366.453125 | val_loss : 78988.3203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 139 | train_loss : 64414.4296875 | val_loss : 113432.84375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 140 | train_loss : 114447.0703125 | val_loss : 67421.6171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 141 | train_loss : 44530.41015625 | val_loss : 48515.7890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 142 | train_loss : 49087.359375 | val_loss : 143896.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 143 | train_loss : 115860.3671875 | val_loss : 132316.9375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 144 | train_loss : 96482.0078125 | val_loss : 20060.591796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 145 | train_loss : 24209.98046875 | val_loss : 50500.2109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 146 | train_loss : 42571.0546875 | val_loss : 104765.8203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 147 | train_loss : 91794.7265625 | val_loss : 61985.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 148 | train_loss : 34674.05078125 | val_loss : 31498.8359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 149 | train_loss : 41774.671875 | val_loss : 133309.171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 150 | train_loss : 118403.3984375 | val_loss : 104723.4921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 151 | train_loss : 64909.12109375 | val_loss : 39552.953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 152 | train_loss : 59994.4609375 | val_loss : 95462.4765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 153 | train_loss : 52502.90625 | val_loss : 47291.0234375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 154 | train_loss : 70589.9140625 | val_loss : 73522.2578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 155 | train_loss : 50197.5 | val_loss : 36300.55859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 156 | train_loss : 37100.2265625 | val_loss : 103163.796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 157 | train_loss : 88700.71875 | val_loss : 78969.171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 158 | train_loss : 46284.13671875 | val_loss : 22739.96484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 159 | train_loss : 36660.87109375 | val_loss : 106695.6015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 160 | train_loss : 77720.59375 | val_loss : 90365.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 161 | train_loss : 63625.0390625 | val_loss : 91073.8984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 162 | train_loss : 82751.1953125 | val_loss : 120299.09375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 163 | train_loss : 102810.453125 | val_loss : 79461.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 164 | train_loss : 44752.63671875 | val_loss : 41071.76171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 165 | train_loss : 65375.671875 | val_loss : 156238.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 166 | train_loss : 130473.453125 | val_loss : 196610.90625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 167 | train_loss : 145800.984375 | val_loss : 43766.30859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 168 | train_loss : 50982.09375 | val_loss : 81653.21875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 169 | train_loss : 69546.4921875 | val_loss : 82142.0234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 170 | train_loss : 51603.56640625 | val_loss : 33354.41015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 171 | train_loss : 39891.42578125 | val_loss : 105432.6484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 172 | train_loss : 112859.7109375 | val_loss : 128274.046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 173 | train_loss : 76048.5625 | val_loss : 41934.0234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 174 | train_loss : 58735.43359375 | val_loss : 67564.7734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 175 | train_loss : 43575.1953125 | val_loss : 36311.203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 176 | train_loss : 42691.484375 | val_loss : 117911.2421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 177 | train_loss : 101401.9296875 | val_loss : 82977.0625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 178 | train_loss : 47884.78125 | val_loss : 39637.57421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 179 | train_loss : 52275.07421875 | val_loss : 100931.5234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 180 | train_loss : 85723.296875 | val_loss : 61444.62890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 181 | train_loss : 33495.17578125 | val_loss : 20005.900390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 182 | train_loss : 31675.921875 | val_loss : 56660.390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 183 | train_loss : 37117.28125 | val_loss : 35955.41796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 184 | train_loss : 42472.671875 | val_loss : 107722.5 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 185 | train_loss : 94838.796875 | val_loss : 76812.3515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 186 | train_loss : 42412.89453125 | val_loss : 19168.283203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 187 | train_loss : 30919.26953125 | val_loss : 62280.9296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 188 | train_loss : 41850.11328125 | val_loss : 40533.328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 189 | train_loss : 33539.97265625 | val_loss : 121366.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 190 | train_loss : 105332.71875 | val_loss : 122394.4609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 191 | train_loss : 84079.703125 | val_loss : 31302.119140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 192 | train_loss : 27691.29296875 | val_loss : 50204.26171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 193 | train_loss : 36740.03125 | val_loss : 106332.0390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 194 | train_loss : 94044.359375 | val_loss : 114067.6015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 195 | train_loss : 79335.171875 | val_loss : 23473.810546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 196 | train_loss : 16722.685546875 | val_loss : 17565.615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 197 | train_loss : 14686.8115234375 | val_loss : 37774.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 198 | train_loss : 26305.447265625 | val_loss : 70717.34375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 199 | train_loss : 84959.953125 | val_loss : 110260.078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 200 | train_loss : 76320.8203125 | val_loss : 54179.76953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 201 | train_loss : 30167.20703125 | val_loss : 26220.052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 202 | train_loss : 29507.220703125 | val_loss : 101476.5625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 203 | train_loss : 93969.640625 | val_loss : 152297.15625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 204 | train_loss : 108341.859375 | val_loss : 59728.00390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 205 | train_loss : 77489.0546875 | val_loss : 136568.203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 206 | train_loss : 98119.8125 | val_loss : 75049.4921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 207 | train_loss : 53346.703125 | val_loss : 20625.1484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 208 | train_loss : 21950.82421875 | val_loss : 63416.66015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 209 | train_loss : 54602.62109375 | val_loss : 64988.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 210 | train_loss : 57711.25390625 | val_loss : 90990.4765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 211 | train_loss : 67607.09375 | val_loss : 46462.6796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 212 | train_loss : 39481.79296875 | val_loss : 83427.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 213 | train_loss : 78897.4375 | val_loss : 74402.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 214 | train_loss : 49569.25390625 | val_loss : 48734.19921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 215 | train_loss : 37876.46484375 | val_loss : 95165.7578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 216 | train_loss : 84450.6015625 | val_loss : 113185.5390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 217 | train_loss : 79896.4921875 | val_loss : 22728.11328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 218 | train_loss : 28852.181640625 | val_loss : 105778.296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 219 | train_loss : 85984.296875 | val_loss : 67677.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 220 | train_loss : 36284.2734375 | val_loss : 27116.748046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 221 | train_loss : 36667.9765625 | val_loss : 69126.1171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 222 | train_loss : 43238.25 | val_loss : 26846.1484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 223 | train_loss : 30541.654296875 | val_loss : 90899.6171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 224 | train_loss : 77091.3984375 | val_loss : 51474.5234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 225 | train_loss : 26963.720703125 | val_loss : 15156.0595703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 226 | train_loss : 21358.64453125 | val_loss : 63547.48828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 227 | train_loss : 46058.2734375 | val_loss : 40592.6328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 228 | train_loss : 35823.61328125 | val_loss : 121927.84375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 229 | train_loss : 114959.359375 | val_loss : 107737.7578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 230 | train_loss : 70730.28125 | val_loss : 60022.76953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 231 | train_loss : 48632.40625 | val_loss : 72787.4296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 232 | train_loss : 65849.8515625 | val_loss : 93483.703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 233 | train_loss : 66006.5859375 | val_loss : 75928.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 234 | train_loss : 64408.94140625 | val_loss : 150475.671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 235 | train_loss : 151488.890625 | val_loss : 74463.46875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 236 | train_loss : 44548.09375 | val_loss : 20217.669921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 237 | train_loss : 24167.609375 | val_loss : 71867.453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 238 | train_loss : 55706.9453125 | val_loss : 41724.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 239 | train_loss : 25958.060546875 | val_loss : 34629.66015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 240 | train_loss : 36325.9765625 | val_loss : 75055.828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 241 | train_loss : 63432.5703125 | val_loss : 84074.9296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 242 | train_loss : 55523.65625 | val_loss : 10117.599609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 243 | train_loss : 15074.6279296875 | val_loss : 38820.8125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 244 | train_loss : 24443.515625 | val_loss : 59815.30859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 245 | train_loss : 55819.65625 | val_loss : 89537.6015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 246 | train_loss : 66909.140625 | val_loss : 32829.296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 247 | train_loss : 19025.455078125 | val_loss : 24074.86328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 248 | train_loss : 26667.2734375 | val_loss : 92098.3828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 249 | train_loss : 81341.9375 | val_loss : 111477.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 250 | train_loss : 78875.0546875 | val_loss : 19817.83203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 251 | train_loss : 27271.216796875 | val_loss : 79156.40625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 252 | train_loss : 72238.6484375 | val_loss : 105455.203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 253 | train_loss : 71753.40625 | val_loss : 16548.654296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 254 | train_loss : 29090.439453125 | val_loss : 82953.78125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 255 | train_loss : 72371.2421875 | val_loss : 94164.703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 256 | train_loss : 62006.3359375 | val_loss : 15524.607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 257 | train_loss : 21475.845703125 | val_loss : 68849.4765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 258 | train_loss : 60063.74609375 | val_loss : 51166.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 259 | train_loss : 35386.2734375 | val_loss : 47588.640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 260 | train_loss : 38059.57421875 | val_loss : 62063.5390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 261 | train_loss : 58961.74609375 | val_loss : 85970.78125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 262 | train_loss : 59055.40625 | val_loss : 11920.2001953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 263 | train_loss : 14925.369140625 | val_loss : 39309.59765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 264 | train_loss : 28868.322265625 | val_loss : 49421.30859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 265 | train_loss : 48037.25 | val_loss : 84046.9375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 266 | train_loss : 60957.05859375 | val_loss : 28368.9375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 267 | train_loss : 17773.501953125 | val_loss : 31238.04296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 268 | train_loss : 27504.462890625 | val_loss : 61350.390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 269 | train_loss : 57756.48828125 | val_loss : 86644.7421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 270 | train_loss : 59493.703125 | val_loss : 16449.099609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 271 | train_loss : 15005.04296875 | val_loss : 24786.658203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 272 | train_loss : 15744.9658203125 | val_loss : 13638.1904296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 273 | train_loss : 10694.6533203125 | val_loss : 33593.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 274 | train_loss : 27336.025390625 | val_loss : 65782.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 275 | train_loss : 59392.609375 | val_loss : 146539.84375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 276 | train_loss : 124305.9609375 | val_loss : 89051.2578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 277 | train_loss : 59366.3359375 | val_loss : 74511.2578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 278 | train_loss : 74848.4609375 | val_loss : 48412.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 279 | train_loss : 43576.0703125 | val_loss : 76330.0 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 280 | train_loss : 54831.17578125 | val_loss : 15688.23046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 281 | train_loss : 14871.919921875 | val_loss : 44292.9609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 282 | train_loss : 32696.625 | val_loss : 39141.5625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 283 | train_loss : 34969.43359375 | val_loss : 69422.8984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 284 | train_loss : 53985.90625 | val_loss : 30445.419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 285 | train_loss : 20797.546875 | val_loss : 35445.28125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 286 | train_loss : 30114.52734375 | val_loss : 52386.421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 287 | train_loss : 47890.2890625 | val_loss : 135104.234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 288 | train_loss : 116310.921875 | val_loss : 83670.359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 289 | train_loss : 57624.7109375 | val_loss : 72445.8515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 290 | train_loss : 63194.2265625 | val_loss : 47709.2734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 291 | train_loss : 39623.859375 | val_loss : 62237.98046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 292 | train_loss : 44107.5234375 | val_loss : 17240.865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 293 | train_loss : 18660.525390625 | val_loss : 53692.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 294 | train_loss : 39127.4375 | val_loss : 31505.0625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 295 | train_loss : 23506.07421875 | val_loss : 50073.4140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 296 | train_loss : 37393.703125 | val_loss : 27448.107421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 297 | train_loss : 23650.73046875 | val_loss : 55741.2890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 298 | train_loss : 40997.8984375 | val_loss : 22180.98828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 299 | train_loss : 19146.822265625 | val_loss : 50727.05859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 300 | train_loss : 37072.30859375 | val_loss : 23528.162109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 301 | train_loss : 22632.419921875 | val_loss : 53794.21875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 302 | train_loss : 38322.18359375 | val_loss : 23043.314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 303 | train_loss : 21090.69921875 | val_loss : 52247.1796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 304 | train_loss : 38150.5390625 | val_loss : 22419.88671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 305 | train_loss : 20498.255859375 | val_loss : 50129.73046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 306 | train_loss : 35297.32421875 | val_loss : 25617.3828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 307 | train_loss : 23875.974609375 | val_loss : 60872.98046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 308 | train_loss : 44427.9296875 | val_loss : 14747.8701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 309 | train_loss : 15486.603515625 | val_loss : 45765.484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 310 | train_loss : 31704.517578125 | val_loss : 31157.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 311 | train_loss : 27804.6640625 | val_loss : 73320.5078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 312 | train_loss : 55096.7890625 | val_loss : 13898.1376953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 313 | train_loss : 11491.193359375 | val_loss : 17229.0625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 314 | train_loss : 11999.0849609375 | val_loss : 37235.85546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 315 | train_loss : 34694.10546875 | val_loss : 81810.8671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 316 | train_loss : 64583.83984375 | val_loss : 21323.7421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 317 | train_loss : 13847.857421875 | val_loss : 13237.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 318 | train_loss : 16088.58203125 | val_loss : 41426.83984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 319 | train_loss : 24843.990234375 | val_loss : 23068.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 320 | train_loss : 25511.828125 | val_loss : 70649.0859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 321 | train_loss : 51108.78515625 | val_loss : 10800.2470703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 322 | train_loss : 7911.94482421875 | val_loss : 6877.8623046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 323 | train_loss : 9917.0068359375 | val_loss : 26610.703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 324 | train_loss : 13947.478515625 | val_loss : 16474.46484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 325 | train_loss : 23044.123046875 | val_loss : 59861.3984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 326 | train_loss : 38639.62109375 | val_loss : 11374.419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 327 | train_loss : 18087.380859375 | val_loss : 58955.0703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 328 | train_loss : 37200.37109375 | val_loss : 15475.712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 329 | train_loss : 23319.8515625 | val_loss : 52462.80078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 330 | train_loss : 31965.33984375 | val_loss : 15481.087890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 331 | train_loss : 23899.73046875 | val_loss : 51616.9765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 332 | train_loss : 30818.40234375 | val_loss : 19017.6953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 333 | train_loss : 27249.21484375 | val_loss : 55095.30859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 334 | train_loss : 33229.40625 | val_loss : 15276.34765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 335 | train_loss : 22739.412109375 | val_loss : 45296.3203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 336 | train_loss : 26356.912109375 | val_loss : 12937.9228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 337 | train_loss : 19100.93359375 | val_loss : 51816.98046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 338 | train_loss : 30233.890625 | val_loss : 13569.9970703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 339 | train_loss : 19756.07421875 | val_loss : 44721.96484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 340 | train_loss : 25498.578125 | val_loss : 17813.6328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 341 | train_loss : 23613.185546875 | val_loss : 56075.5703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 342 | train_loss : 36014.40625 | val_loss : 12896.1298828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 343 | train_loss : 14747.3623046875 | val_loss : 25153.4765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 344 | train_loss : 12827.98046875 | val_loss : 7793.8173828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 345 | train_loss : 15297.0029296875 | val_loss : 37228.015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 346 | train_loss : 19549.828125 | val_loss : 16702.720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 347 | train_loss : 23853.908203125 | val_loss : 53364.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 348 | train_loss : 32211.0078125 | val_loss : 9473.9501953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 349 | train_loss : 14314.37109375 | val_loss : 45461.9296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 350 | train_loss : 31569.48046875 | val_loss : 26422.494140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 351 | train_loss : 23534.890625 | val_loss : 46353.60546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 352 | train_loss : 35171.8359375 | val_loss : 47142.734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 353 | train_loss : 37425.49609375 | val_loss : 58046.51953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 354 | train_loss : 45417.78515625 | val_loss : 54176.66015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 355 | train_loss : 42684.8984375 | val_loss : 60827.171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 356 | train_loss : 46487.6015625 | val_loss : 34806.68359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 357 | train_loss : 29505.6796875 | val_loss : 53143.12109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 358 | train_loss : 41221.13671875 | val_loss : 25535.421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 359 | train_loss : 23224.810546875 | val_loss : 43260.5 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 360 | train_loss : 33485.44140625 | val_loss : 22992.0078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 361 | train_loss : 22535.349609375 | val_loss : 53605.8515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 362 | train_loss : 41863.578125 | val_loss : 26716.41796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 363 | train_loss : 19883.07421875 | val_loss : 35999.37109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 364 | train_loss : 26986.84765625 | val_loss : 36952.671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 365 | train_loss : 35410.55078125 | val_loss : 75925.578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 366 | train_loss : 58278.49609375 | val_loss : 117620.4375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 367 | train_loss : 93703.5078125 | val_loss : 155767.546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 368 | train_loss : 164915.609375 | val_loss : 56878.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 369 | train_loss : 44843.09375 | val_loss : 23861.1484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 370 | train_loss : 14340.197265625 | val_loss : 10621.107421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 371 | train_loss : 12165.6923828125 | val_loss : 36721.375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 372 | train_loss : 31860.375 | val_loss : 51649.7890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 373 | train_loss : 35148.13671875 | val_loss : 22119.1953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 374 | train_loss : 20242.755859375 | val_loss : 55049.53515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 375 | train_loss : 40625.41015625 | val_loss : 11639.3798828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 376 | train_loss : 14151.51953125 | val_loss : 39676.390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 377 | train_loss : 28473.55078125 | val_loss : 24748.7890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 378 | train_loss : 23562.1171875 | val_loss : 51600.1015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 379 | train_loss : 37812.515625 | val_loss : 13852.427734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 380 | train_loss : 14456.0888671875 | val_loss : 35565.5546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 381 | train_loss : 24857.8359375 | val_loss : 42065.4609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 382 | train_loss : 39977.76171875 | val_loss : 82568.265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 383 | train_loss : 64943.1796875 | val_loss : 20028.07421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 384 | train_loss : 15665.5849609375 | val_loss : 29471.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 385 | train_loss : 29762.498046875 | val_loss : 65246.69140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 386 | train_loss : 46918.9609375 | val_loss : 9364.1796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 387 | train_loss : 7039.58544921875 | val_loss : 8039.6650390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 388 | train_loss : 9147.2177734375 | val_loss : 14879.724609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 389 | train_loss : 11003.9375 | val_loss : 21208.080078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 390 | train_loss : 15428.8828125 | val_loss : 33660.37890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 391 | train_loss : 32392.517578125 | val_loss : 72560.5 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 392 | train_loss : 57925.3359375 | val_loss : 19900.990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 393 | train_loss : 18147.5234375 | val_loss : 33024.6484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 394 | train_loss : 23783.029296875 | val_loss : 30730.783203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 395 | train_loss : 29762.2890625 | val_loss : 64872.98828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 396 | train_loss : 49601.9609375 | val_loss : 11249.025390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 397 | train_loss : 12919.927734375 | val_loss : 23342.60546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 398 | train_loss : 15905.298828125 | val_loss : 30888.3828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 399 | train_loss : 31819.08984375 | val_loss : 54674.08984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 400 | train_loss : 39534.49609375 | val_loss : 9563.4970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 401 | train_loss : 13121.4873046875 | val_loss : 36241.234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 402 | train_loss : 25950.671875 | val_loss : 20707.123046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 403 | train_loss : 21228.533203125 | val_loss : 53742.99609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 404 | train_loss : 39510.0234375 | val_loss : 10663.85546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 405 | train_loss : 13694.7021484375 | val_loss : 32104.4140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 406 | train_loss : 22677.4140625 | val_loss : 23844.267578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 407 | train_loss : 22239.5859375 | val_loss : 45077.26953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 408 | train_loss : 32031.572265625 | val_loss : 14877.455078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 409 | train_loss : 17151.341796875 | val_loss : 43095.51953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 410 | train_loss : 30578.0390625 | val_loss : 15561.39453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 411 | train_loss : 17067.34765625 | val_loss : 45770.6796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 412 | train_loss : 32339.552734375 | val_loss : 14410.2998046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 413 | train_loss : 16290.259765625 | val_loss : 37733.3125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 414 | train_loss : 26867.1171875 | val_loss : 19719.83203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 415 | train_loss : 18598.5625 | val_loss : 36594.1953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 416 | train_loss : 25304.9765625 | val_loss : 18550.3984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 417 | train_loss : 18674.619140625 | val_loss : 50665.859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 418 | train_loss : 36646.32421875 | val_loss : 9986.9423828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 419 | train_loss : 12969.90234375 | val_loss : 31214.439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 420 | train_loss : 21420.109375 | val_loss : 24072.36328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 421 | train_loss : 22378.912109375 | val_loss : 46133.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 422 | train_loss : 32756.55078125 | val_loss : 13251.5947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 423 | train_loss : 15341.2978515625 | val_loss : 39075.71875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 424 | train_loss : 28018.640625 | val_loss : 16913.5390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 425 | train_loss : 17169.337890625 | val_loss : 39398.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 426 | train_loss : 27053.609375 | val_loss : 21685.61328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 427 | train_loss : 21869.982421875 | val_loss : 52947.5859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 428 | train_loss : 38351.9453125 | val_loss : 7482.47998046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 429 | train_loss : 12019.98046875 | val_loss : 30098.8046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 430 | train_loss : 20179.498046875 | val_loss : 22840.740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 431 | train_loss : 21676.95703125 | val_loss : 49487.3515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 432 | train_loss : 34637.12890625 | val_loss : 15059.6123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 433 | train_loss : 15717.607421875 | val_loss : 34603.640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 434 | train_loss : 23797.66015625 | val_loss : 20678.900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 435 | train_loss : 20511.8984375 | val_loss : 47294.671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 436 | train_loss : 32117.982421875 | val_loss : 14625.71484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 437 | train_loss : 16356.1962890625 | val_loss : 38013.1328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 438 | train_loss : 26493.71484375 | val_loss : 15824.47265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 439 | train_loss : 16817.35546875 | val_loss : 51009.0 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 440 | train_loss : 38161.7890625 | val_loss : 22212.16015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 441 | train_loss : 21166.015625 | val_loss : 42267.91015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 442 | train_loss : 29907.984375 | val_loss : 14247.9091796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 443 | train_loss : 15760.2626953125 | val_loss : 36889.66796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 444 | train_loss : 25683.306640625 | val_loss : 15944.0302734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 445 | train_loss : 16859.369140625 | val_loss : 34928.23828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 446 | train_loss : 24437.3046875 | val_loss : 17666.654296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 447 | train_loss : 17783.3671875 | val_loss : 39296.6328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 448 | train_loss : 26895.060546875 | val_loss : 15695.146484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 449 | train_loss : 17968.384765625 | val_loss : 42342.17578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 450 | train_loss : 29370.44921875 | val_loss : 11227.6923828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 451 | train_loss : 14686.0126953125 | val_loss : 33025.6171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 452 | train_loss : 22415.45703125 | val_loss : 16209.7626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 453 | train_loss : 17415.408203125 | val_loss : 33818.90234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 454 | train_loss : 22997.599609375 | val_loss : 17021.5078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 455 | train_loss : 18395.36328125 | val_loss : 43671.51953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 456 | train_loss : 30178.259765625 | val_loss : 14183.5224609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 457 | train_loss : 15636.28125 | val_loss : 33433.4140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 458 | train_loss : 22700.244140625 | val_loss : 15724.33984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 459 | train_loss : 16556.359375 | val_loss : 31881.498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 460 | train_loss : 21511.4375 | val_loss : 18220.115234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 461 | train_loss : 19469.693359375 | val_loss : 42984.40625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 462 | train_loss : 29451.818359375 | val_loss : 14985.39453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 463 | train_loss : 15974.51171875 | val_loss : 34968.13671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 464 | train_loss : 23902.337890625 | val_loss : 15869.630859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 465 | train_loss : 16877.806640625 | val_loss : 36573.44140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 466 | train_loss : 24590.572265625 | val_loss : 16533.39453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 467 | train_loss : 17621.76171875 | val_loss : 39112.67578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 468 | train_loss : 26178.015625 | val_loss : 12240.294921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 469 | train_loss : 15526.4697265625 | val_loss : 38299.6484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 470 | train_loss : 25263.927734375 | val_loss : 16227.583984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 471 | train_loss : 17048.046875 | val_loss : 35378.78515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 472 | train_loss : 23240.435546875 | val_loss : 17832.1328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 473 | train_loss : 18660.8203125 | val_loss : 45290.71875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 474 | train_loss : 31319.314453125 | val_loss : 9026.5615234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 475 | train_loss : 13173.625 | val_loss : 30422.7109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 476 | train_loss : 21913.20703125 | val_loss : 28015.671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 477 | train_loss : 25194.177734375 | val_loss : 40757.62890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 478 | train_loss : 27596.115234375 | val_loss : 11484.80078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 479 | train_loss : 14745.9228515625 | val_loss : 40406.29296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 480 | train_loss : 27345.482421875 | val_loss : 9870.548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 481 | train_loss : 14262.3798828125 | val_loss : 34202.66015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 482 | train_loss : 22593.48828125 | val_loss : 18042.771484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 483 | train_loss : 17693.1640625 | val_loss : 31030.51953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 484 | train_loss : 19533.623046875 | val_loss : 13750.18359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 485 | train_loss : 16608.779296875 | val_loss : 37845.67578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 486 | train_loss : 24416.359375 | val_loss : 14259.771484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 487 | train_loss : 16328.3291015625 | val_loss : 34193.66015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 488 | train_loss : 22208.2578125 | val_loss : 13919.6923828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 489 | train_loss : 15429.4326171875 | val_loss : 30105.099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 490 | train_loss : 19494.76171875 | val_loss : 17723.36328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 491 | train_loss : 18108.029296875 | val_loss : 33367.48828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 492 | train_loss : 21286.91015625 | val_loss : 16203.9404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 493 | train_loss : 17733.669921875 | val_loss : 39262.66796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 494 | train_loss : 26475.078125 | val_loss : 11354.2138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 495 | train_loss : 14325.1904296875 | val_loss : 31094.2109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 496 | train_loss : 20273.224609375 | val_loss : 15642.2490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 497 | train_loss : 16707.1484375 | val_loss : 27898.759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 498 | train_loss : 18276.310546875 | val_loss : 15742.90625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 499 | train_loss : 16749.138671875 | val_loss : 30930.373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 500 | train_loss : 20355.4296875 | val_loss : 17258.056640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 501 | train_loss : 18387.181640625 | val_loss : 40725.58203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 502 | train_loss : 27799.98046875 | val_loss : 17009.478515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 503 | train_loss : 19095.89453125 | val_loss : 42071.19921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 504 | train_loss : 29471.283203125 | val_loss : 13805.4111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 505 | train_loss : 15632.630859375 | val_loss : 43979.44140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 506 | train_loss : 32036.04296875 | val_loss : 44963.8203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 507 | train_loss : 36962.265625 | val_loss : 66469.796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 508 | train_loss : 50098.25390625 | val_loss : 42472.671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 509 | train_loss : 33406.7890625 | val_loss : 50751.2734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 510 | train_loss : 37846.67578125 | val_loss : 14733.10546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 511 | train_loss : 14578.5146484375 | val_loss : 20684.109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 512 | train_loss : 13035.869140625 | val_loss : 11727.537109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 513 | train_loss : 14585.9208984375 | val_loss : 27329.392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 514 | train_loss : 15570.3154296875 | val_loss : 15714.01171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 515 | train_loss : 15740.044921875 | val_loss : 129896.390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 516 | train_loss : 132842.703125 | val_loss : 108701.4296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 517 | train_loss : 72550.0 | val_loss : 63227.46875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 518 | train_loss : 54329.9140625 | val_loss : 12912.7578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 519 | train_loss : 16693.005859375 | val_loss : 31692.390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 520 | train_loss : 19086.421875 | val_loss : 15344.9248046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 521 | train_loss : 14988.2578125 | val_loss : 27765.400390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 522 | train_loss : 16230.8515625 | val_loss : 11571.724609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 523 | train_loss : 14671.34765625 | val_loss : 26480.1640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 524 | train_loss : 15314.7158203125 | val_loss : 10316.0283203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 525 | train_loss : 14467.2763671875 | val_loss : 25542.13671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 526 | train_loss : 15107.7373046875 | val_loss : 12676.2529296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 527 | train_loss : 15498.177734375 | val_loss : 25812.892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 528 | train_loss : 15247.865234375 | val_loss : 30998.61328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 529 | train_loss : 28511.51171875 | val_loss : 51547.43359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 530 | train_loss : 37801.98828125 | val_loss : 8020.0751953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 531 | train_loss : 12830.77734375 | val_loss : 22658.259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 532 | train_loss : 13185.884765625 | val_loss : 12030.419921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 533 | train_loss : 14416.537109375 | val_loss : 26880.85546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 534 | train_loss : 15183.93359375 | val_loss : 15742.056640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 535 | train_loss : 17704.982421875 | val_loss : 37174.87890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 536 | train_loss : 23891.19921875 | val_loss : 13116.072265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 537 | train_loss : 16146.0185546875 | val_loss : 34446.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 538 | train_loss : 21025.107421875 | val_loss : 11136.93359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 539 | train_loss : 14724.177734375 | val_loss : 31092.52734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 540 | train_loss : 17857.865234375 | val_loss : 13030.771484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 541 | train_loss : 15658.3447265625 | val_loss : 32004.904296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 542 | train_loss : 18911.234375 | val_loss : 11663.927734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 543 | train_loss : 15235.236328125 | val_loss : 31691.84765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 544 | train_loss : 18596.232421875 | val_loss : 8943.572265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 545 | train_loss : 12822.021484375 | val_loss : 25073.67578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 546 | train_loss : 14249.16796875 | val_loss : 10125.0859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 547 | train_loss : 13976.2578125 | val_loss : 25672.908203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 548 | train_loss : 14801.212890625 | val_loss : 10864.5712890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 549 | train_loss : 14606.548828125 | val_loss : 24931.25 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 550 | train_loss : 14642.8271484375 | val_loss : 12938.3134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 551 | train_loss : 15973.6103515625 | val_loss : 24118.517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 552 | train_loss : 14438.892578125 | val_loss : 11975.23046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 553 | train_loss : 15250.9423828125 | val_loss : 25372.5234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 554 | train_loss : 14716.224609375 | val_loss : 18648.75 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 555 | train_loss : 19764.76171875 | val_loss : 35305.296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 556 | train_loss : 22912.13671875 | val_loss : 12242.1279296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 557 | train_loss : 15366.0703125 | val_loss : 29518.939453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 558 | train_loss : 17708.966796875 | val_loss : 14149.5341796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 559 | train_loss : 16623.978515625 | val_loss : 33714.73828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 560 | train_loss : 21632.154296875 | val_loss : 9868.7412109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 561 | train_loss : 13761.40234375 | val_loss : 25393.890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 562 | train_loss : 15744.166015625 | val_loss : 9793.2470703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 563 | train_loss : 13392.5400390625 | val_loss : 21226.5390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 564 | train_loss : 13253.205078125 | val_loss : 9878.646484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 565 | train_loss : 13335.0634765625 | val_loss : 23308.642578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 566 | train_loss : 13927.611328125 | val_loss : 12632.53515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 567 | train_loss : 14991.3115234375 | val_loss : 23690.330078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 568 | train_loss : 15432.8251953125 | val_loss : 14618.103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 569 | train_loss : 17238.62109375 | val_loss : 33088.48828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 570 | train_loss : 21964.779296875 | val_loss : 15537.2548828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 571 | train_loss : 19596.974609375 | val_loss : 31337.134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 572 | train_loss : 21303.619140625 | val_loss : 12178.1435546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 573 | train_loss : 15448.5595703125 | val_loss : 22369.3984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 574 | train_loss : 12349.2236328125 | val_loss : 12321.19140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 575 | train_loss : 13470.494140625 | val_loss : 26619.837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 576 | train_loss : 17273.501953125 | val_loss : 13585.8935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 577 | train_loss : 16275.232421875 | val_loss : 22566.134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 578 | train_loss : 12710.740234375 | val_loss : 11249.9228515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 579 | train_loss : 13212.7646484375 | val_loss : 29426.3984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 580 | train_loss : 18260.796875 | val_loss : 12924.12109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 581 | train_loss : 16242.7109375 | val_loss : 30725.283203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 582 | train_loss : 19719.986328125 | val_loss : 8444.458984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 583 | train_loss : 13023.7509765625 | val_loss : 21840.765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 584 | train_loss : 12402.2412109375 | val_loss : 14403.2265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 585 | train_loss : 15828.375 | val_loss : 24267.84765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 586 | train_loss : 15564.8720703125 | val_loss : 16161.4462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 587 | train_loss : 17278.16796875 | val_loss : 22688.828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 588 | train_loss : 14678.66796875 | val_loss : 7663.052734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 589 | train_loss : 11468.912109375 | val_loss : 25054.154296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 590 | train_loss : 14241.5791015625 | val_loss : 14055.7890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 591 | train_loss : 15801.4697265625 | val_loss : 28983.171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 592 | train_loss : 17777.224609375 | val_loss : 11567.490234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 593 | train_loss : 14301.2900390625 | val_loss : 29050.197265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 594 | train_loss : 17795.408203125 | val_loss : 10078.638671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 595 | train_loss : 13527.3984375 | val_loss : 26922.04296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 596 | train_loss : 15399.70703125 | val_loss : 9796.8779296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 597 | train_loss : 12555.896484375 | val_loss : 24343.169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 598 | train_loss : 13967.6572265625 | val_loss : 5686.84521484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 599 | train_loss : 9730.9921875 | val_loss : 14985.572265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 600 | train_loss : 7104.5400390625 | val_loss : 6302.794921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 601 | train_loss : 8921.912109375 | val_loss : 19140.923828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 602 | train_loss : 11751.4033203125 | val_loss : 12041.576171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 603 | train_loss : 14649.5859375 | val_loss : 22272.0078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 604 | train_loss : 13911.7822265625 | val_loss : 10080.083984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 605 | train_loss : 13154.6962890625 | val_loss : 27149.244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 606 | train_loss : 17230.025390625 | val_loss : 13645.88671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 607 | train_loss : 16361.916015625 | val_loss : 30355.51171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 608 | train_loss : 19615.33984375 | val_loss : 13310.787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 609 | train_loss : 16343.91015625 | val_loss : 26717.60546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 610 | train_loss : 17882.556640625 | val_loss : 11276.111328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 611 | train_loss : 13311.0361328125 | val_loss : 19955.712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 612 | train_loss : 11640.9326171875 | val_loss : 8471.244140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 613 | train_loss : 11404.6396484375 | val_loss : 18594.935546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 614 | train_loss : 11823.2958984375 | val_loss : 7135.9423828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 615 | train_loss : 9519.9111328125 | val_loss : 17396.3359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 616 | train_loss : 11137.2685546875 | val_loss : 9554.7822265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 617 | train_loss : 12244.517578125 | val_loss : 19811.654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 618 | train_loss : 12637.9560546875 | val_loss : 14000.1396484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 619 | train_loss : 15873.69921875 | val_loss : 28259.421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 620 | train_loss : 18814.435546875 | val_loss : 14054.416015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 621 | train_loss : 17884.876953125 | val_loss : 26536.982421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 622 | train_loss : 17003.091796875 | val_loss : 10972.4658203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 623 | train_loss : 13416.49609375 | val_loss : 23349.150390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 624 | train_loss : 14548.0078125 | val_loss : 10385.919921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 625 | train_loss : 13544.884765625 | val_loss : 18408.30859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 626 | train_loss : 11493.490234375 | val_loss : 8627.1328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 627 | train_loss : 10034.724609375 | val_loss : 17827.4921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 628 | train_loss : 11958.5849609375 | val_loss : 4907.51611328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 629 | train_loss : 8249.84765625 | val_loss : 168080.3125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 630 | train_loss : 193586.125 | val_loss : 106799.7421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 631 | train_loss : 70906.8046875 | val_loss : 52174.73828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 632 | train_loss : 48568.91015625 | val_loss : 40808.39453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 633 | train_loss : 42671.03125 | val_loss : 149027.984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 634 | train_loss : 167115.0625 | val_loss : 66761.5703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 635 | train_loss : 43868.4609375 | val_loss : 20120.5546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 636 | train_loss : 13913.486328125 | val_loss : 9050.91796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 637 | train_loss : 12989.8720703125 | val_loss : 27184.380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 638 | train_loss : 14013.7138671875 | val_loss : 2413.06005859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 639 | train_loss : 7943.8369140625 | val_loss : 18255.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 640 | train_loss : 8622.79296875 | val_loss : 2672.81005859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 641 | train_loss : 7828.35498046875 | val_loss : 16188.5791015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 642 | train_loss : 7937.708984375 | val_loss : 4102.603515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 643 | train_loss : 7262.9150390625 | val_loss : 14084.255859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 644 | train_loss : 7014.439453125 | val_loss : 5115.7724609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 645 | train_loss : 7700.04833984375 | val_loss : 14186.76171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 646 | train_loss : 7309.916015625 | val_loss : 5965.072265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 647 | train_loss : 8199.560546875 | val_loss : 13971.2421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 648 | train_loss : 8207.052734375 | val_loss : 9298.8603515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 649 | train_loss : 10016.775390625 | val_loss : 20213.337890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 650 | train_loss : 12493.0224609375 | val_loss : 15091.298828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 651 | train_loss : 17793.080078125 | val_loss : 25435.404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 652 | train_loss : 16268.0078125 | val_loss : 18416.94921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 653 | train_loss : 19673.833984375 | val_loss : 25419.51171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 654 | train_loss : 16077.6123046875 | val_loss : 12063.0390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 655 | train_loss : 14232.7001953125 | val_loss : 22614.7421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 656 | train_loss : 13022.4052734375 | val_loss : 11928.52734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 657 | train_loss : 14313.05078125 | val_loss : 24566.650390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 658 | train_loss : 14449.7109375 | val_loss : 10112.34375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 659 | train_loss : 13322.2900390625 | val_loss : 21052.1015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 660 | train_loss : 11241.3046875 | val_loss : 8623.9833984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 661 | train_loss : 11268.9775390625 | val_loss : 19552.828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 662 | train_loss : 11511.4375 | val_loss : 5059.21484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 663 | train_loss : 8482.302734375 | val_loss : 14287.5615234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 664 | train_loss : 7061.1025390625 | val_loss : 5497.5263671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 665 | train_loss : 7814.25830078125 | val_loss : 13382.9970703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 666 | train_loss : 7292.68603515625 | val_loss : 7538.26611328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 667 | train_loss : 9363.8740234375 | val_loss : 15746.103515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 668 | train_loss : 8696.6962890625 | val_loss : 6005.2763671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 669 | train_loss : 7779.67431640625 | val_loss : 14102.4501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 670 | train_loss : 8366.2158203125 | val_loss : 7396.34619140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 671 | train_loss : 9216.42578125 | val_loss : 20027.169921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 672 | train_loss : 12398.5849609375 | val_loss : 16595.001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 673 | train_loss : 17720.970703125 | val_loss : 30698.6953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 674 | train_loss : 21954.634765625 | val_loss : 17323.025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 675 | train_loss : 19936.158203125 | val_loss : 25983.599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 676 | train_loss : 17793.009765625 | val_loss : 8384.1240234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 677 | train_loss : 11692.4404296875 | val_loss : 15604.669921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 678 | train_loss : 8723.88671875 | val_loss : 8542.541015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 679 | train_loss : 8658.2998046875 | val_loss : 13466.4560546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 680 | train_loss : 8610.7939453125 | val_loss : 5224.53759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 681 | train_loss : 7422.470703125 | val_loss : 11132.9541015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 682 | train_loss : 6820.9873046875 | val_loss : 7961.9375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 683 | train_loss : 8945.818359375 | val_loss : 15121.8251953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 684 | train_loss : 10385.6162109375 | val_loss : 8230.5146484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 685 | train_loss : 10295.853515625 | val_loss : 19366.111328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 686 | train_loss : 12850.5703125 | val_loss : 14858.2822265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 687 | train_loss : 17223.490234375 | val_loss : 20919.640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 688 | train_loss : 13588.6376953125 | val_loss : 12183.318359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 689 | train_loss : 14003.1123046875 | val_loss : 22966.76953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 690 | train_loss : 14730.791015625 | val_loss : 13093.576171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 691 | train_loss : 14616.66796875 | val_loss : 20737.154296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 692 | train_loss : 13084.982421875 | val_loss : 6156.021484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 693 | train_loss : 9285.8388671875 | val_loss : 14707.8984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 694 | train_loss : 8739.45703125 | val_loss : 8400.9873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 695 | train_loss : 8679.28125 | val_loss : 13003.0908203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 696 | train_loss : 8504.5673828125 | val_loss : 5074.52734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 697 | train_loss : 7528.72021484375 | val_loss : 11473.7060546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 698 | train_loss : 6574.90869140625 | val_loss : 9828.0263671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 699 | train_loss : 9744.3330078125 | val_loss : 15405.576171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 700 | train_loss : 10967.037109375 | val_loss : 17496.23828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 701 | train_loss : 17175.69921875 | val_loss : 22175.23828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 702 | train_loss : 15106.693359375 | val_loss : 19264.505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 703 | train_loss : 20344.732421875 | val_loss : 26328.39453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 704 | train_loss : 17655.65625 | val_loss : 12555.1865234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 705 | train_loss : 15471.9677734375 | val_loss : 24242.759765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 706 | train_loss : 14559.53515625 | val_loss : 9099.37890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 707 | train_loss : 10903.271484375 | val_loss : 15391.2109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 708 | train_loss : 8351.0029296875 | val_loss : 6332.71630859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 709 | train_loss : 6860.5625 | val_loss : 8872.0986328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 710 | train_loss : 6029.0625 | val_loss : 5202.71875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 711 | train_loss : 5470.42041015625 | val_loss : 8222.0185546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 712 | train_loss : 5542.484375 | val_loss : 5206.0751953125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 713 | train_loss : 5373.28515625 | val_loss : 8722.8251953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 714 | train_loss : 5961.3701171875 | val_loss : 5596.22607421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 715 | train_loss : 6575.96044921875 | val_loss : 9636.322265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 716 | train_loss : 6357.42578125 | val_loss : 6502.9599609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 717 | train_loss : 7546.22119140625 | val_loss : 13205.2861328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 718 | train_loss : 8738.42578125 | val_loss : 13068.4716796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 719 | train_loss : 14190.763671875 | val_loss : 22791.2890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 720 | train_loss : 15402.7958984375 | val_loss : 15344.1025390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 721 | train_loss : 17440.068359375 | val_loss : 20994.171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 722 | train_loss : 13051.599609375 | val_loss : 12301.32421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 723 | train_loss : 14208.35546875 | val_loss : 19809.533203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 724 | train_loss : 12058.5498046875 | val_loss : 8227.4814453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 725 | train_loss : 10557.1474609375 | val_loss : 20171.80078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 726 | train_loss : 12386.322265625 | val_loss : 9829.6552734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 727 | train_loss : 12173.0537109375 | val_loss : 19725.328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 728 | train_loss : 11857.6337890625 | val_loss : 8840.2861328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 729 | train_loss : 11145.583984375 | val_loss : 17602.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 730 | train_loss : 10523.599609375 | val_loss : 4642.24365234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 731 | train_loss : 6361.5048828125 | val_loss : 8265.7470703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 732 | train_loss : 5142.89453125 | val_loss : 5976.642578125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 733 | train_loss : 6561.52685546875 | val_loss : 11262.052734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 734 | train_loss : 7455.2431640625 | val_loss : 7040.728515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 735 | train_loss : 7597.54833984375 | val_loss : 11136.361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 736 | train_loss : 7719.48193359375 | val_loss : 7024.98388671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 737 | train_loss : 7332.0029296875 | val_loss : 12699.1572265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 738 | train_loss : 8764.3203125 | val_loss : 7724.478515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 739 | train_loss : 8159.787109375 | val_loss : 14203.6298828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 740 | train_loss : 9982.697265625 | val_loss : 11244.5654296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 741 | train_loss : 12590.3173828125 | val_loss : 20452.98046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 742 | train_loss : 15078.6220703125 | val_loss : 16311.3935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 743 | train_loss : 18918.14453125 | val_loss : 21827.619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 744 | train_loss : 14964.5263671875 | val_loss : 12914.5849609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 745 | train_loss : 14273.755859375 | val_loss : 21622.1015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 746 | train_loss : 13588.5947265625 | val_loss : 10322.49609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 747 | train_loss : 11715.974609375 | val_loss : 20388.015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 748 | train_loss : 12009.044921875 | val_loss : 7173.81103515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 749 | train_loss : 9244.0146484375 | val_loss : 14516.9951171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 750 | train_loss : 8981.3203125 | val_loss : 5329.2763671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 751 | train_loss : 6452.236328125 | val_loss : 8580.2216796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 752 | train_loss : 6079.9736328125 | val_loss : 5421.919921875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 753 | train_loss : 5120.69970703125 | val_loss : 8426.28125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 754 | train_loss : 5958.2158203125 | val_loss : 5221.88134765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 755 | train_loss : 5190.6884765625 | val_loss : 8218.7978515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 756 | train_loss : 5890.33203125 | val_loss : 5491.91015625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 757 | train_loss : 5590.17333984375 | val_loss : 9347.2353515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 758 | train_loss : 6676.22021484375 | val_loss : 7464.03271484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 759 | train_loss : 8302.5458984375 | val_loss : 14953.1865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 760 | train_loss : 10159.2392578125 | val_loss : 11357.68359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 761 | train_loss : 12216.3291015625 | val_loss : 23723.017578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 762 | train_loss : 16882.86328125 | val_loss : 20809.806640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 763 | train_loss : 18835.484375 | val_loss : 21725.1328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 764 | train_loss : 13960.486328125 | val_loss : 15273.5908203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 765 | train_loss : 16171.9658203125 | val_loss : 22055.580078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 766 | train_loss : 14575.5166015625 | val_loss : 8044.08251953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 767 | train_loss : 9687.611328125 | val_loss : 13727.0986328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 768 | train_loss : 8058.09765625 | val_loss : 11511.8515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 769 | train_loss : 10657.677734375 | val_loss : 126531.921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 770 | train_loss : 145350.984375 | val_loss : 78048.6328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 771 | train_loss : 53333.23828125 | val_loss : 34151.48828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 772 | train_loss : 28666.11328125 | val_loss : 8132.177734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 773 | train_loss : 11385.01953125 | val_loss : 19997.703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 774 | train_loss : 9176.2421875 | val_loss : 3327.257568359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 775 | train_loss : 8642.25390625 | val_loss : 15062.568359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 776 | train_loss : 6519.986328125 | val_loss : 1698.637451171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 777 | train_loss : 5476.29541015625 | val_loss : 8882.9423828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 778 | train_loss : 4136.177734375 | val_loss : 912.1624755859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 779 | train_loss : 3439.9150390625 | val_loss : 7541.892578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 780 | train_loss : 3498.41748046875 | val_loss : 606.0374755859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 781 | train_loss : 3691.320068359375 | val_loss : 7642.34228515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 782 | train_loss : 3807.1494140625 | val_loss : 2039.6337890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 783 | train_loss : 5097.08447265625 | val_loss : 8805.7958984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 784 | train_loss : 4832.50927734375 | val_loss : 5742.271484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 785 | train_loss : 7943.8095703125 | val_loss : 16630.748046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 786 | train_loss : 10156.8857421875 | val_loss : 15852.3310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 787 | train_loss : 19480.232421875 | val_loss : 18814.2265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 788 | train_loss : 11085.2763671875 | val_loss : 9715.43359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 789 | train_loss : 11470.548828125 | val_loss : 19645.376953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 790 | train_loss : 11190.787109375 | val_loss : 9761.240234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 791 | train_loss : 9928.7626953125 | val_loss : 17724.486328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 792 | train_loss : 10266.3916015625 | val_loss : 6976.22607421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 793 | train_loss : 8649.451171875 | val_loss : 14449.794921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 794 | train_loss : 7975.208984375 | val_loss : 6880.93896484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 795 | train_loss : 7810.59765625 | val_loss : 12750.4873046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 796 | train_loss : 8353.6875 | val_loss : 5339.955078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 797 | train_loss : 6459.53173828125 | val_loss : 9939.83203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 798 | train_loss : 6335.15673828125 | val_loss : 4475.31884765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 799 | train_loss : 5045.69140625 | val_loss : 7736.75 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 2 | epoch : 800 | train_loss : 5256.42333984375 | val_loss : 4643.38623046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 3 | epoch : 1 | train_loss : 442405.125 | val_loss : 251864.015625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 2 | train_loss : 369396.03125 | val_loss : 329840.09375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 3 | train_loss : 475814.28125 | val_loss : 433642.15625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 4 | train_loss : 543900.875 | val_loss : 178540.65625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 5 | train_loss : 237896.765625 | val_loss : 184321.703125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 6 | train_loss : 171565.4375 | val_loss : 227324.921875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 7 | train_loss : 239824.921875 | val_loss : 268013.03125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 8 | train_loss : 245227.515625 | val_loss : 101627.703125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 9 | train_loss : 197702.28125 | val_loss : 299634.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 10 | train_loss : 318466.59375 | val_loss : 330115.40625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 11 | train_loss : 307640.40625 | val_loss : 200734.21875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 12 | train_loss : 141247.484375 | val_loss : 92020.0 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 13 | train_loss : 86740.2265625 | val_loss : 262473.53125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 14 | train_loss : 194717.09375 | val_loss : 247938.234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 15 | train_loss : 191750.6875 | val_loss : 218653.421875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 16 | train_loss : 195473.453125 | val_loss : 207823.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 17 | train_loss : 203808.765625 | val_loss : 135702.875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 18 | train_loss : 120178.921875 | val_loss : 111822.78125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 19 | train_loss : 111379.9921875 | val_loss : 90268.9921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 20 | train_loss : 71641.2578125 | val_loss : 168925.625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 21 | train_loss : 170135.265625 | val_loss : 85811.3515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 22 | train_loss : 82053.53125 | val_loss : 110835.3671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 23 | train_loss : 97064.5390625 | val_loss : 213813.6875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 24 | train_loss : 169050.34375 | val_loss : 49725.3203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 25 | train_loss : 49643.85546875 | val_loss : 84605.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 26 | train_loss : 96003.578125 | val_loss : 163594.125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 27 | train_loss : 156126.640625 | val_loss : 99678.4765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 28 | train_loss : 83192.5859375 | val_loss : 177668.015625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 29 | train_loss : 150295.265625 | val_loss : 77256.46875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 30 | train_loss : 77271.9296875 | val_loss : 78633.75 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 31 | train_loss : 74745.9609375 | val_loss : 98362.4375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 32 | train_loss : 93919.7578125 | val_loss : 99029.859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 33 | train_loss : 100057.5234375 | val_loss : 40448.46484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 34 | train_loss : 32021.662109375 | val_loss : 67996.4921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 35 | train_loss : 69977.9375 | val_loss : 52016.4296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 36 | train_loss : 43382.98828125 | val_loss : 89431.7890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 37 | train_loss : 86364.8828125 | val_loss : 21816.181640625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 38 | train_loss : 23348.197265625 | val_loss : 98338.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 39 | train_loss : 105161.9609375 | val_loss : 56095.12109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 40 | train_loss : 46264.578125 | val_loss : 28011.35546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 41 | train_loss : 26352.814453125 | val_loss : 130422.6796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 42 | train_loss : 112667.6015625 | val_loss : 145056.875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 43 | train_loss : 147896.625 | val_loss : 183727.640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 44 | train_loss : 142071.359375 | val_loss : 74816.421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 45 | train_loss : 58075.58984375 | val_loss : 109014.8125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 46 | train_loss : 111886.796875 | val_loss : 120889.6328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 47 | train_loss : 120310.53125 | val_loss : 83124.1640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 48 | train_loss : 67280.1171875 | val_loss : 105652.9765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 49 | train_loss : 89151.171875 | val_loss : 58342.8984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 50 | train_loss : 63505.61328125 | val_loss : 27914.267578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 51 | train_loss : 25009.73046875 | val_loss : 77022.6875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 52 | train_loss : 64452.88671875 | val_loss : 29253.982421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 53 | train_loss : 30110.447265625 | val_loss : 42693.1015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 54 | train_loss : 37513.046875 | val_loss : 90621.15625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 55 | train_loss : 86592.0625 | val_loss : 94715.359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 56 | train_loss : 78629.453125 | val_loss : 66663.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 57 | train_loss : 80323.1015625 | val_loss : 39486.859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 58 | train_loss : 41404.30078125 | val_loss : 103323.1875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 59 | train_loss : 80470.296875 | val_loss : 68721.2109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 60 | train_loss : 68415.1328125 | val_loss : 60132.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 61 | train_loss : 52000.23828125 | val_loss : 50552.4453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 62 | train_loss : 63208.140625 | val_loss : 81353.734375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 63 | train_loss : 71425.2578125 | val_loss : 122569.6796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 64 | train_loss : 107065.1015625 | val_loss : 89658.28125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 65 | train_loss : 89961.6328125 | val_loss : 106951.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 66 | train_loss : 87888.6015625 | val_loss : 133619.296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 67 | train_loss : 114949.296875 | val_loss : 54343.3515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 68 | train_loss : 53791.93359375 | val_loss : 25976.8203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 69 | train_loss : 23533.0703125 | val_loss : 80902.4140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 70 | train_loss : 83494.0 | val_loss : 29960.869140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 71 | train_loss : 24864.681640625 | val_loss : 39029.28515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 72 | train_loss : 45368.11328125 | val_loss : 79585.5 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 73 | train_loss : 63741.28515625 | val_loss : 69427.15625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 74 | train_loss : 71179.2734375 | val_loss : 36561.453125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 75 | train_loss : 37498.671875 | val_loss : 92234.859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 76 | train_loss : 96786.4921875 | val_loss : 34009.82421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 77 | train_loss : 25215.119140625 | val_loss : 5284.5986328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 78 | train_loss : 12757.1015625 | val_loss : 49758.23046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 79 | train_loss : 44191.07421875 | val_loss : 53220.14453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 80 | train_loss : 57183.53125 | val_loss : 57408.19140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 81 | train_loss : 46145.6796875 | val_loss : 72673.7421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 82 | train_loss : 72149.9375 | val_loss : 42516.33984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 83 | train_loss : 32643.845703125 | val_loss : 21639.759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 84 | train_loss : 31779.60546875 | val_loss : 90189.4296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 85 | train_loss : 73510.0703125 | val_loss : 84205.6328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 86 | train_loss : 74626.1171875 | val_loss : 11628.5224609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 87 | train_loss : 16347.9140625 | val_loss : 34730.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 88 | train_loss : 27911.21484375 | val_loss : 18241.693359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 89 | train_loss : 28357.8046875 | val_loss : 46001.76953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 90 | train_loss : 39015.1796875 | val_loss : 30867.86328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 91 | train_loss : 34301.703125 | val_loss : 77651.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 92 | train_loss : 64964.66015625 | val_loss : 70213.078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 93 | train_loss : 72944.5234375 | val_loss : 27735.509765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 94 | train_loss : 24045.154296875 | val_loss : 40838.91015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 95 | train_loss : 46613.9765625 | val_loss : 67373.6328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 96 | train_loss : 53891.62890625 | val_loss : 60969.62890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 97 | train_loss : 55140.359375 | val_loss : 10165.767578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 98 | train_loss : 14194.4296875 | val_loss : 28393.814453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 99 | train_loss : 22902.54296875 | val_loss : 49850.53125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 100 | train_loss : 43206.3984375 | val_loss : 76331.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 101 | train_loss : 78180.3671875 | val_loss : 54172.171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 102 | train_loss : 40765.06640625 | val_loss : 37078.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 103 | train_loss : 37810.89453125 | val_loss : 38905.66796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 104 | train_loss : 34086.796875 | val_loss : 18181.40625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 105 | train_loss : 24462.046875 | val_loss : 37567.13671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 106 | train_loss : 33989.765625 | val_loss : 14551.4033203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 107 | train_loss : 17073.69921875 | val_loss : 38770.19921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 108 | train_loss : 36559.99609375 | val_loss : 16111.357421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 109 | train_loss : 15622.8212890625 | val_loss : 42153.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 110 | train_loss : 44172.71875 | val_loss : 37111.69921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 111 | train_loss : 29521.685546875 | val_loss : 9861.0498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 112 | train_loss : 22114.765625 | val_loss : 31733.427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 113 | train_loss : 28842.373046875 | val_loss : 43511.828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 114 | train_loss : 46460.140625 | val_loss : 45802.578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 115 | train_loss : 43505.6015625 | val_loss : 8789.31640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 116 | train_loss : 9808.6669921875 | val_loss : 9794.4638671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 117 | train_loss : 13645.4296875 | val_loss : 67563.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 118 | train_loss : 52738.8359375 | val_loss : 64870.76953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 119 | train_loss : 58917.74609375 | val_loss : 18572.51953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 120 | train_loss : 22944.33984375 | val_loss : 69933.90625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 121 | train_loss : 56586.03515625 | val_loss : 40925.32421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 122 | train_loss : 42525.73828125 | val_loss : 45784.8046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 123 | train_loss : 36571.3515625 | val_loss : 66528.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 124 | train_loss : 66538.8359375 | val_loss : 36784.81640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 125 | train_loss : 31074.404296875 | val_loss : 24423.9609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 126 | train_loss : 35943.4140625 | val_loss : 56796.31640625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 127 | train_loss : 48527.109375 | val_loss : 54484.3984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 128 | train_loss : 54916.7265625 | val_loss : 17309.396484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 129 | train_loss : 16817.79296875 | val_loss : 39139.12109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 130 | train_loss : 44340.94921875 | val_loss : 52674.66015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 131 | train_loss : 41951.98046875 | val_loss : 32134.953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 132 | train_loss : 38116.44921875 | val_loss : 60615.53515625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 133 | train_loss : 51150.05078125 | val_loss : 51842.69921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 134 | train_loss : 55885.69140625 | val_loss : 30957.2890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 135 | train_loss : 25982.54296875 | val_loss : 27669.294921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 136 | train_loss : 34959.87109375 | val_loss : 50481.73046875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 137 | train_loss : 48123.5859375 | val_loss : 64643.25 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 138 | train_loss : 64929.578125 | val_loss : 31918.080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 139 | train_loss : 27836.69921875 | val_loss : 16285.947265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 140 | train_loss : 30733.2109375 | val_loss : 28277.169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 141 | train_loss : 28715.869140625 | val_loss : 28661.11328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 142 | train_loss : 32406.962890625 | val_loss : 31162.73828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 143 | train_loss : 28922.8671875 | val_loss : 24045.830078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 144 | train_loss : 29026.314453125 | val_loss : 30999.115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 145 | train_loss : 26500.779296875 | val_loss : 25774.865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 146 | train_loss : 30791.279296875 | val_loss : 30525.63671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 147 | train_loss : 25616.0 | val_loss : 20514.0546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 148 | train_loss : 25651.001953125 | val_loss : 25820.28515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 149 | train_loss : 24367.17578125 | val_loss : 16721.6640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 150 | train_loss : 18504.265625 | val_loss : 51795.1796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 151 | train_loss : 52688.0703125 | val_loss : 14389.5185546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 152 | train_loss : 11705.3759765625 | val_loss : 4744.2724609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 153 | train_loss : 9408.5888671875 | val_loss : 11402.806640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 154 | train_loss : 12211.8720703125 | val_loss : 26773.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 155 | train_loss : 24517.087890625 | val_loss : 45964.91015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 156 | train_loss : 46861.41015625 | val_loss : 25864.16015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 157 | train_loss : 23705.966796875 | val_loss : 16570.591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 158 | train_loss : 26992.697265625 | val_loss : 36550.26171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 159 | train_loss : 34972.828125 | val_loss : 28272.072265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 160 | train_loss : 30999.921875 | val_loss : 32241.595703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 161 | train_loss : 29091.337890625 | val_loss : 59298.33984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 162 | train_loss : 61652.796875 | val_loss : 31814.455078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 163 | train_loss : 25770.740234375 | val_loss : 16854.287109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 164 | train_loss : 25181.990234375 | val_loss : 50930.91015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 165 | train_loss : 43574.8359375 | val_loss : 67084.421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 166 | train_loss : 67798.453125 | val_loss : 33837.46484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 167 | train_loss : 27897.322265625 | val_loss : 34189.55859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 168 | train_loss : 41083.07421875 | val_loss : 30164.994140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 169 | train_loss : 27133.345703125 | val_loss : 23289.54296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 170 | train_loss : 29813.17578125 | val_loss : 37583.98046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 171 | train_loss : 32306.23046875 | val_loss : 43187.5390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 172 | train_loss : 41124.21875 | val_loss : 16541.5390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 173 | train_loss : 12963.4296875 | val_loss : 10175.41796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 174 | train_loss : 16027.62890625 | val_loss : 35844.421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 175 | train_loss : 31283.095703125 | val_loss : 40748.49609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 176 | train_loss : 43123.08984375 | val_loss : 19193.58984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 177 | train_loss : 16428.814453125 | val_loss : 21662.259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 178 | train_loss : 29864.1875 | val_loss : 42704.0 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 179 | train_loss : 36560.765625 | val_loss : 34017.55859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 180 | train_loss : 35922.92578125 | val_loss : 15511.5712890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 181 | train_loss : 15789.037109375 | val_loss : 21362.984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 182 | train_loss : 24503.01953125 | val_loss : 21090.626953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 183 | train_loss : 21035.404296875 | val_loss : 32369.306640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 184 | train_loss : 35997.16796875 | val_loss : 20125.83203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 185 | train_loss : 17127.87890625 | val_loss : 11596.55078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 186 | train_loss : 19804.279296875 | val_loss : 18021.529296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 187 | train_loss : 18135.453125 | val_loss : 28387.7265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 188 | train_loss : 31720.7890625 | val_loss : 16303.9404296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 189 | train_loss : 17671.2578125 | val_loss : 72073.4609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 190 | train_loss : 78081.8984375 | val_loss : 32824.171875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 191 | train_loss : 37694.44140625 | val_loss : 29567.634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 192 | train_loss : 38089.7890625 | val_loss : 15744.0234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 193 | train_loss : 16909.880859375 | val_loss : 18255.517578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 194 | train_loss : 22549.630859375 | val_loss : 14380.619140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 195 | train_loss : 16147.5615234375 | val_loss : 25258.814453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 196 | train_loss : 28305.482421875 | val_loss : 15433.8046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 197 | train_loss : 17046.796875 | val_loss : 24782.6484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 198 | train_loss : 26654.91796875 | val_loss : 15237.912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 199 | train_loss : 16133.1640625 | val_loss : 23220.171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 200 | train_loss : 27238.03515625 | val_loss : 19104.296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 201 | train_loss : 20087.599609375 | val_loss : 30614.060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 202 | train_loss : 32682.224609375 | val_loss : 13595.96484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 203 | train_loss : 10897.861328125 | val_loss : 5694.37890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 204 | train_loss : 12308.0283203125 | val_loss : 10293.869140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 205 | train_loss : 12431.287109375 | val_loss : 15480.5146484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 206 | train_loss : 20805.794921875 | val_loss : 16100.740234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 207 | train_loss : 18074.306640625 | val_loss : 21824.41015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 208 | train_loss : 25944.189453125 | val_loss : 15089.22265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 209 | train_loss : 16860.98046875 | val_loss : 21684.509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 210 | train_loss : 24977.8828125 | val_loss : 14773.525390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 211 | train_loss : 17192.3203125 | val_loss : 25644.46484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 212 | train_loss : 29895.6484375 | val_loss : 19879.2734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 213 | train_loss : 19643.27734375 | val_loss : 23601.060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 214 | train_loss : 27669.822265625 | val_loss : 10348.681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 215 | train_loss : 12594.236328125 | val_loss : 20084.359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 216 | train_loss : 22973.890625 | val_loss : 22727.994140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 217 | train_loss : 29173.599609375 | val_loss : 36804.00390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 218 | train_loss : 47907.62890625 | val_loss : 11400.40625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 219 | train_loss : 14810.40234375 | val_loss : 25002.294921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 220 | train_loss : 25168.25 | val_loss : 17174.95703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 221 | train_loss : 13623.28515625 | val_loss : 8350.0302734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 222 | train_loss : 15614.1259765625 | val_loss : 14503.4501953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 223 | train_loss : 16263.763671875 | val_loss : 20603.591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 224 | train_loss : 25944.02734375 | val_loss : 19977.201171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 225 | train_loss : 20495.224609375 | val_loss : 21206.28515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 226 | train_loss : 24937.275390625 | val_loss : 12375.4912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 227 | train_loss : 15348.6865234375 | val_loss : 16389.14453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 228 | train_loss : 20887.79296875 | val_loss : 9732.1552734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 229 | train_loss : 13737.50390625 | val_loss : 16235.5126953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 230 | train_loss : 21210.384765625 | val_loss : 10738.205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 231 | train_loss : 13744.51171875 | val_loss : 14417.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 232 | train_loss : 19076.9453125 | val_loss : 11527.5712890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 233 | train_loss : 15764.0048828125 | val_loss : 16817.435546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 234 | train_loss : 20912.529296875 | val_loss : 8552.955078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 235 | train_loss : 12753.2373046875 | val_loss : 17793.44921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 236 | train_loss : 21863.650390625 | val_loss : 12047.4658203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 237 | train_loss : 16157.8515625 | val_loss : 18914.01953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 238 | train_loss : 22102.634765625 | val_loss : 9908.80859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 239 | train_loss : 11380.5166015625 | val_loss : 7964.62890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 240 | train_loss : 14111.6953125 | val_loss : 8557.673828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 241 | train_loss : 11890.2958984375 | val_loss : 9816.5615234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 242 | train_loss : 15202.6484375 | val_loss : 7578.1962890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 243 | train_loss : 11999.6376953125 | val_loss : 9330.0791015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 244 | train_loss : 15801.931640625 | val_loss : 6571.03857421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 245 | train_loss : 10397.00390625 | val_loss : 9203.962890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 246 | train_loss : 14441.103515625 | val_loss : 6531.63134765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 247 | train_loss : 11017.224609375 | val_loss : 9555.236328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 248 | train_loss : 16343.400390625 | val_loss : 6730.6435546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 249 | train_loss : 10856.39453125 | val_loss : 9657.5751953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 250 | train_loss : 16430.8203125 | val_loss : 8172.58251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 251 | train_loss : 11928.650390625 | val_loss : 13965.4228515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 252 | train_loss : 18643.755859375 | val_loss : 14938.9921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 253 | train_loss : 17427.544921875 | val_loss : 17605.541015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 254 | train_loss : 21239.96484375 | val_loss : 9985.056640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 255 | train_loss : 13939.3095703125 | val_loss : 14403.888671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 256 | train_loss : 19299.04296875 | val_loss : 8025.294921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 257 | train_loss : 12616.224609375 | val_loss : 33654.88671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 258 | train_loss : 37602.4765625 | val_loss : 24922.330078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 259 | train_loss : 24669.037109375 | val_loss : 25379.552734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 260 | train_loss : 30215.76953125 | val_loss : 10801.5859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 261 | train_loss : 12719.3525390625 | val_loss : 17178.642578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 262 | train_loss : 18989.953125 | val_loss : 13008.1728515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 263 | train_loss : 13345.64453125 | val_loss : 22607.1875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 264 | train_loss : 29845.3515625 | val_loss : 24673.087890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 265 | train_loss : 25174.330078125 | val_loss : 22164.953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 266 | train_loss : 24934.134765625 | val_loss : 10334.0185546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 267 | train_loss : 12641.3671875 | val_loss : 10494.7509765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 268 | train_loss : 14813.6328125 | val_loss : 8460.8623046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 269 | train_loss : 11978.056640625 | val_loss : 8361.3896484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 270 | train_loss : 13995.49609375 | val_loss : 4452.8798828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 271 | train_loss : 8789.9873046875 | val_loss : 6257.6513671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 272 | train_loss : 13406.4462890625 | val_loss : 3517.498779296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 273 | train_loss : 8429.5439453125 | val_loss : 6165.03271484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 274 | train_loss : 13751.0234375 | val_loss : 4936.7900390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 275 | train_loss : 9819.65234375 | val_loss : 6369.259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 276 | train_loss : 13843.4501953125 | val_loss : 2981.607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 277 | train_loss : 7471.93994140625 | val_loss : 5607.15625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 278 | train_loss : 11316.1884765625 | val_loss : 5688.76611328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 279 | train_loss : 11023.1396484375 | val_loss : 10917.77734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 280 | train_loss : 16991.828125 | val_loss : 5634.08740234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 281 | train_loss : 11983.958984375 | val_loss : 116355.7578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 282 | train_loss : 127104.5234375 | val_loss : 42826.015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 283 | train_loss : 53298.5546875 | val_loss : 33990.2734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 284 | train_loss : 42010.3359375 | val_loss : 1185.5999755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 285 | train_loss : 5229.671875 | val_loss : 667.96875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 286 | train_loss : 5340.96728515625 | val_loss : 6277.38232421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 287 | train_loss : 8396.7646484375 | val_loss : 7496.72998046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 288 | train_loss : 18947.720703125 | val_loss : 23656.9609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 289 | train_loss : 25880.123046875 | val_loss : 19529.91796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 290 | train_loss : 25997.234375 | val_loss : 12767.7353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 291 | train_loss : 16159.1240234375 | val_loss : 17608.80078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 292 | train_loss : 25053.529296875 | val_loss : 13196.19140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 293 | train_loss : 15640.87109375 | val_loss : 13518.1748046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 294 | train_loss : 20056.1640625 | val_loss : 12439.1787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 295 | train_loss : 14170.1259765625 | val_loss : 9310.3466796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 296 | train_loss : 18720.541015625 | val_loss : 11039.142578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 297 | train_loss : 12316.58203125 | val_loss : 7975.03369140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 298 | train_loss : 18003.904296875 | val_loss : 11931.48046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 299 | train_loss : 13823.7333984375 | val_loss : 7626.79248046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 300 | train_loss : 17547.943359375 | val_loss : 12764.8046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 301 | train_loss : 13064.1640625 | val_loss : 7056.3876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 302 | train_loss : 16357.4453125 | val_loss : 10587.00390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 303 | train_loss : 12174.763671875 | val_loss : 7129.12255859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 304 | train_loss : 17440.095703125 | val_loss : 13922.107421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 305 | train_loss : 13981.9423828125 | val_loss : 6741.80615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 306 | train_loss : 17140.392578125 | val_loss : 11697.693359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 307 | train_loss : 11845.552734375 | val_loss : 2850.28125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 308 | train_loss : 11099.0 | val_loss : 12612.5283203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 309 | train_loss : 12346.8623046875 | val_loss : 6263.31982421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 310 | train_loss : 17454.484375 | val_loss : 11378.669921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 311 | train_loss : 10662.8466796875 | val_loss : 3197.202392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 312 | train_loss : 11102.134765625 | val_loss : 5581.8798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 313 | train_loss : 7825.03271484375 | val_loss : 2650.264892578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 314 | train_loss : 10108.7265625 | val_loss : 4413.54248046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 315 | train_loss : 7365.005859375 | val_loss : 1682.6400146484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 316 | train_loss : 8630.8037109375 | val_loss : 5215.91357421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 317 | train_loss : 7615.93505859375 | val_loss : 2713.04248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 318 | train_loss : 10808.2978515625 | val_loss : 6060.39990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 319 | train_loss : 7056.234375 | val_loss : 2082.38134765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 320 | train_loss : 10039.04296875 | val_loss : 3623.52490234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 321 | train_loss : 6006.40771484375 | val_loss : 1494.6500244140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 322 | train_loss : 8263.58984375 | val_loss : 2372.090087890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 323 | train_loss : 6165.4599609375 | val_loss : 1681.9749755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 324 | train_loss : 8589.4443359375 | val_loss : 6014.8076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 325 | train_loss : 9386.2666015625 | val_loss : 9162.24609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 326 | train_loss : 18162.349609375 | val_loss : 7740.00244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 327 | train_loss : 10405.62109375 | val_loss : 6799.6748046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 328 | train_loss : 14822.7890625 | val_loss : 8209.7587890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 329 | train_loss : 11052.80078125 | val_loss : 6810.7314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 330 | train_loss : 14978.8720703125 | val_loss : 8516.7314453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 331 | train_loss : 11463.03515625 | val_loss : 7541.64013671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 332 | train_loss : 16818.884765625 | val_loss : 10385.5478515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 333 | train_loss : 11734.4296875 | val_loss : 7512.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 334 | train_loss : 16561.421875 | val_loss : 8885.3974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 335 | train_loss : 9814.1591796875 | val_loss : 6149.513671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 336 | train_loss : 17181.54296875 | val_loss : 13877.451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 337 | train_loss : 15031.1171875 | val_loss : 13216.630859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 338 | train_loss : 25102.740234375 | val_loss : 23072.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 339 | train_loss : 24011.626953125 | val_loss : 9459.9501953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 340 | train_loss : 22915.435546875 | val_loss : 98479.296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 341 | train_loss : 91580.2265625 | val_loss : 71572.1171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 342 | train_loss : 82532.9375 | val_loss : 7226.2060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 343 | train_loss : 17160.71875 | val_loss : 11657.7841796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 344 | train_loss : 14293.16796875 | val_loss : 15962.48046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 345 | train_loss : 20916.603515625 | val_loss : 14314.76953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 346 | train_loss : 13928.44921875 | val_loss : 3904.614990234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 347 | train_loss : 12548.7958984375 | val_loss : 3141.139892578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 348 | train_loss : 7097.001953125 | val_loss : 1280.63623046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 349 | train_loss : 8201.4609375 | val_loss : 3247.1298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 350 | train_loss : 7739.52392578125 | val_loss : 2897.760009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 351 | train_loss : 11229.6328125 | val_loss : 16519.55078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 352 | train_loss : 25261.82421875 | val_loss : 20199.5234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 353 | train_loss : 32230.84765625 | val_loss : 8371.9970703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 354 | train_loss : 11074.3740234375 | val_loss : 10434.2861328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 355 | train_loss : 13866.7802734375 | val_loss : 7434.138671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 356 | train_loss : 12959.0498046875 | val_loss : 6701.29248046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 357 | train_loss : 11866.7021484375 | val_loss : 4278.78125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 358 | train_loss : 11168.3525390625 | val_loss : 9712.3134765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 359 | train_loss : 14632.4248046875 | val_loss : 8959.1240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 360 | train_loss : 15770.8359375 | val_loss : 7409.42236328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 361 | train_loss : 12978.5966796875 | val_loss : 3726.695068359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 362 | train_loss : 9710.43359375 | val_loss : 5466.09619140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 363 | train_loss : 10776.94921875 | val_loss : 1941.967529296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 364 | train_loss : 7975.30126953125 | val_loss : 3025.284912109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 365 | train_loss : 8456.1494140625 | val_loss : 1243.3924560546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 366 | train_loss : 6688.4736328125 | val_loss : 1222.1737060546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 367 | train_loss : 7586.107421875 | val_loss : 1674.675048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 368 | train_loss : 6832.43603515625 | val_loss : 1337.643798828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 369 | train_loss : 6495.20068359375 | val_loss : 932.6649780273438 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 370 | train_loss : 5885.27978515625 | val_loss : 273.2149963378906 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 371 | train_loss : 6004.5986328125 | val_loss : 3235.72119140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 372 | train_loss : 9040.7734375 | val_loss : 2964.4150390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 373 | train_loss : 9943.16796875 | val_loss : 1248.396240234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 374 | train_loss : 6002.5625 | val_loss : 992.8362426757812 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 375 | train_loss : 5294.59375 | val_loss : 860.6787719726562 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 376 | train_loss : 5351.677734375 | val_loss : 584.9137573242188 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 377 | train_loss : 5603.337890625 | val_loss : 1752.8675537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 378 | train_loss : 6250.64111328125 | val_loss : 1167.0037841796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 379 | train_loss : 6229.9580078125 | val_loss : 2277.35498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 380 | train_loss : 7075.166015625 | val_loss : 507.0350036621094 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 381 | train_loss : 6114.90771484375 | val_loss : 2861.5712890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 382 | train_loss : 8682.8046875 | val_loss : 1752.293701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 383 | train_loss : 9293.6201171875 | val_loss : 2862.6875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 384 | train_loss : 6884.478515625 | val_loss : 1731.4725341796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 385 | train_loss : 8472.2783203125 | val_loss : 2364.11865234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 386 | train_loss : 8175.9345703125 | val_loss : 2746.503662109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 387 | train_loss : 8678.0810546875 | val_loss : 5989.634765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 388 | train_loss : 14815.8876953125 | val_loss : 10943.4716796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 389 | train_loss : 16849.421875 | val_loss : 6011.615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 390 | train_loss : 11217.62109375 | val_loss : 2990.09375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 391 | train_loss : 7847.70263671875 | val_loss : 3847.052490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 392 | train_loss : 11213.94921875 | val_loss : 3417.52880859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 393 | train_loss : 8513.50390625 | val_loss : 4579.80517578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 394 | train_loss : 13385.8916015625 | val_loss : 3803.07373046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 395 | train_loss : 11336.26171875 | val_loss : 4029.1025390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 396 | train_loss : 9329.2412109375 | val_loss : 1651.2962646484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 397 | train_loss : 7856.28857421875 | val_loss : 2688.607421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 398 | train_loss : 7757.283203125 | val_loss : 2009.8399658203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 399 | train_loss : 8739.177734375 | val_loss : 1246.61376953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 400 | train_loss : 4161.34765625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 401 | train_loss : 3345.58447265625 | val_loss : 1084.98876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 402 | train_loss : 4243.0205078125 | val_loss : 751.9525146484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 403 | train_loss : 4044.7177734375 | val_loss : 1475.728759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 404 | train_loss : 3961.375732421875 | val_loss : 386.30499267578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 405 | train_loss : 4835.431640625 | val_loss : 1572.8387451171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 406 | train_loss : 5762.10009765625 | val_loss : 700.083740234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 407 | train_loss : 6394.16357421875 | val_loss : 1036.6624755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 408 | train_loss : 5555.77197265625 | val_loss : 1061.6912841796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 409 | train_loss : 6785.28857421875 | val_loss : 1372.05126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 410 | train_loss : 5984.9462890625 | val_loss : 1602.59130859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 411 | train_loss : 7445.533203125 | val_loss : 1081.606201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 412 | train_loss : 4387.18798828125 | val_loss : 272.3575134277344 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 413 | train_loss : 5102.72998046875 | val_loss : 2453.632568359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 414 | train_loss : 8165.572265625 | val_loss : 2408.711181640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 415 | train_loss : 10096.2236328125 | val_loss : 2862.9326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 416 | train_loss : 7333.47314453125 | val_loss : 2991.538818359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 417 | train_loss : 8137.33740234375 | val_loss : 6550.20361328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 418 | train_loss : 13119.9453125 | val_loss : 182106.203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 419 | train_loss : 195256.84375 | val_loss : 16146.4072265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 420 | train_loss : 27790.41015625 | val_loss : 39519.59375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 421 | train_loss : 51335.87890625 | val_loss : 22964.205078125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 422 | train_loss : 34336.06640625 | val_loss : 50070.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 423 | train_loss : 47948.16015625 | val_loss : 14054.6845703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 424 | train_loss : 13809.7587890625 | val_loss : 11570.9111328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 425 | train_loss : 13232.2626953125 | val_loss : 2399.085693359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 426 | train_loss : 9856.25 | val_loss : 1881.1700439453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 427 | train_loss : 7761.44921875 | val_loss : 684.2062377929688 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 428 | train_loss : 7398.5751953125 | val_loss : 1271.791259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 429 | train_loss : 6782.22265625 | val_loss : 956.12060546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 430 | train_loss : 7235.74365234375 | val_loss : 1654.34130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 431 | train_loss : 6944.611328125 | val_loss : 431.42938232421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 432 | train_loss : 6889.87890625 | val_loss : 1186.958740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 433 | train_loss : 6232.20068359375 | val_loss : 273.15625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 434 | train_loss : 6089.75146484375 | val_loss : 1332.8487548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 435 | train_loss : 6434.25244140625 | val_loss : 113.37249755859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 436 | train_loss : 6127.736328125 | val_loss : 2526.360107421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 437 | train_loss : 9144.3837890625 | val_loss : 5044.4423828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 438 | train_loss : 13216.712890625 | val_loss : 8222.916015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 439 | train_loss : 15505.9189453125 | val_loss : 1664.603759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 440 | train_loss : 10067.5380859375 | val_loss : 2889.824951171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 441 | train_loss : 7252.08251953125 | val_loss : 2.221250057220459 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 442 | train_loss : 5552.6611328125 | val_loss : 434.8662414550781 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 443 | train_loss : 4039.658203125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 444 | train_loss : 3004.31689453125 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 445 | train_loss : 3320.8642578125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 446 | train_loss : 2969.265869140625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 447 | train_loss : 3257.215576171875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 448 | train_loss : 2722.47314453125 | val_loss : 0.0 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 449 | train_loss : 3371.206298828125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 450 | train_loss : 2254.156005859375 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 451 | train_loss : 3035.315673828125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 452 | train_loss : 2280.85693359375 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 453 | train_loss : 2707.171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 454 | train_loss : 2191.961181640625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 455 | train_loss : 2825.01416015625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 456 | train_loss : 2215.030029296875 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 457 | train_loss : 2692.38623046875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 458 | train_loss : 2057.649169921875 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 459 | train_loss : 3010.746337890625 | val_loss : 23688.087890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 460 | train_loss : 27326.626953125 | val_loss : 32814.90234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 461 | train_loss : 32462.58203125 | val_loss : 11137.3046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 462 | train_loss : 18699.26953125 | val_loss : 9696.53125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 463 | train_loss : 14471.150390625 | val_loss : 4928.69677734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 464 | train_loss : 10897.455078125 | val_loss : 6646.904296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 465 | train_loss : 11512.6875 | val_loss : 2774.864990234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 466 | train_loss : 10913.4501953125 | val_loss : 2315.771240234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 467 | train_loss : 6780.43701171875 | val_loss : 273.47125244140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 468 | train_loss : 3969.664306640625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 469 | train_loss : 2853.38134765625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 470 | train_loss : 1913.6851806640625 | val_loss : 23.545000076293945 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 471 | train_loss : 2351.6650390625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 472 | train_loss : 1525.675048828125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 473 | train_loss : 1634.95751953125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 474 | train_loss : 1137.144287109375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 475 | train_loss : 1045.9654541015625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 476 | train_loss : 998.6146850585938 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 477 | train_loss : 998.9429931640625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 478 | train_loss : 964.6400146484375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 479 | train_loss : 908.5653076171875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 480 | train_loss : 2830.188232421875 | val_loss : 5417.22265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 481 | train_loss : 11729.34375 | val_loss : 3203.083740234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 482 | train_loss : 12318.4326171875 | val_loss : 726.592529296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 483 | train_loss : 3554.244384765625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 484 | train_loss : 2055.04345703125 | val_loss : 130.3699951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 485 | train_loss : 2542.57470703125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 486 | train_loss : 2162.3798828125 | val_loss : 357.0987548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 487 | train_loss : 3102.500732421875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 488 | train_loss : 1526.8551025390625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 489 | train_loss : 2353.4443359375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 490 | train_loss : 1386.3712158203125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 491 | train_loss : 2230.0048828125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 492 | train_loss : 1405.0194091796875 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 493 | train_loss : 2290.5244140625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 494 | train_loss : 1320.044677734375 | val_loss : 151.97999572753906 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 495 | train_loss : 2074.464111328125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 496 | train_loss : 1636.0374755859375 | val_loss : 0.0 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 497 | train_loss : 2713.609375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 498 | train_loss : 1136.857421875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 499 | train_loss : 1951.9727783203125 | val_loss : 132.46624755859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 500 | train_loss : 1836.7393798828125 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 501 | train_loss : 3985.423828125 | val_loss : 474.21875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 502 | train_loss : 4350.404296875 | val_loss : 1865.3662109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 503 | train_loss : 9084.4453125 | val_loss : 613.10498046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 504 | train_loss : 3880.779296875 | val_loss : 908.8099975585938 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 505 | train_loss : 7788.095703125 | val_loss : 1254.768798828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 506 | train_loss : 6354.13330078125 | val_loss : 3101.7138671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 507 | train_loss : 11665.78515625 | val_loss : 1666.96875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 508 | train_loss : 6460.1279296875 | val_loss : 2445.097412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 509 | train_loss : 10592.5947265625 | val_loss : 1311.177490234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 510 | train_loss : 5689.380859375 | val_loss : 993.594970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 511 | train_loss : 7738.90380859375 | val_loss : 939.7525024414062 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 512 | train_loss : 4194.0224609375 | val_loss : 1178.927490234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 513 | train_loss : 6364.43994140625 | val_loss : 768.15625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 514 | train_loss : 3056.831298828125 | val_loss : 181.0437469482422 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 515 | train_loss : 4938.5361328125 | val_loss : 902.3200073242188 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 516 | train_loss : 3675.2138671875 | val_loss : 222.8262481689453 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 517 | train_loss : 4935.11572265625 | val_loss : 585.896240234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 518 | train_loss : 3307.177734375 | val_loss : 178.47125244140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 519 | train_loss : 4908.1484375 | val_loss : 534.4550170898438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 520 | train_loss : 3271.660888671875 | val_loss : 155.4499969482422 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 521 | train_loss : 4909.63623046875 | val_loss : 570.8587646484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 522 | train_loss : 3218.35302734375 | val_loss : 237.0437469482422 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 523 | train_loss : 5308.74169921875 | val_loss : 823.3474731445312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 524 | train_loss : 3449.039794921875 | val_loss : 213.65374755859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 525 | train_loss : 5000.4208984375 | val_loss : 963.030029296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 526 | train_loss : 5143.7236328125 | val_loss : 1786.49755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 527 | train_loss : 9652.0322265625 | val_loss : 568.8250122070312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 528 | train_loss : 3630.80029296875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 529 | train_loss : 4982.70458984375 | val_loss : 238.06124877929688 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 530 | train_loss : 3012.01806640625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 531 | train_loss : 4631.33740234375 | val_loss : 177.35499572753906 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 532 | train_loss : 3267.967529296875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 533 | train_loss : 4365.22412109375 | val_loss : 442.177490234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 534 | train_loss : 2989.882568359375 | val_loss : 205.97125244140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 535 | train_loss : 5325.896484375 | val_loss : 742.8074951171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 536 | train_loss : 3239.004150390625 | val_loss : 229.80624389648438 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 537 | train_loss : 5030.681640625 | val_loss : 247.2725067138672 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 538 | train_loss : 2763.5869140625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 539 | train_loss : 4066.352294921875 | val_loss : 357.6387634277344 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 540 | train_loss : 3476.91748046875 | val_loss : 295.0325012207031 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 541 | train_loss : 5380.25439453125 | val_loss : 527.40625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 542 | train_loss : 2996.33056640625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 543 | train_loss : 3735.324951171875 | val_loss : 242.67250061035156 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 544 | train_loss : 3375.353515625 | val_loss : 465.87249755859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 545 | train_loss : 5100.109375 | val_loss : 558.6012573242188 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 546 | train_loss : 2883.41162109375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 547 | train_loss : 3572.599365234375 | val_loss : 401.978759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 548 | train_loss : 2401.821044921875 | val_loss : 102.0999984741211 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 549 | train_loss : 3642.00634765625 | val_loss : 2658.978759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 550 | train_loss : 6769.2705078125 | val_loss : 10476.63671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 551 | train_loss : 21393.01953125 | val_loss : 5596.75146484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 552 | train_loss : 15469.10546875 | val_loss : 30443.564453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 553 | train_loss : 37222.70703125 | val_loss : 12118.98828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 554 | train_loss : 9408.07421875 | val_loss : 4498.89111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 555 | train_loss : 11557.1171875 | val_loss : 1015.9924926757812 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 556 | train_loss : 3554.758056640625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 557 | train_loss : 3137.871337890625 | val_loss : 279.927490234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 558 | train_loss : 3678.7587890625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 559 | train_loss : 3711.766357421875 | val_loss : 162.4862518310547 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 560 | train_loss : 3090.789306640625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 561 | train_loss : 2943.59619140625 | val_loss : 737.35498046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 562 | train_loss : 3694.234375 | val_loss : 1.430511264999268e-08 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 563 | train_loss : 4581.9150390625 | val_loss : 896.1099853515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 564 | train_loss : 3664.69287109375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 565 | train_loss : 3732.69189453125 | val_loss : 636.2224731445312 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 566 | train_loss : 3745.0888671875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 567 | train_loss : 4009.2763671875 | val_loss : 565.1587524414062 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 568 | train_loss : 3362.635009765625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 569 | train_loss : 3714.874267578125 | val_loss : 518.6099853515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 570 | train_loss : 2923.464111328125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 571 | train_loss : 3164.553466796875 | val_loss : 3602.278076171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 572 | train_loss : 12805.494140625 | val_loss : 25566.58203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 573 | train_loss : 35077.2890625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 574 | train_loss : 1535.7076416015625 | val_loss : 120.7125015258789 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 575 | train_loss : 986.6370239257812 | val_loss : 1716.04248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 576 | train_loss : 9653.6943359375 | val_loss : 18642.193359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 577 | train_loss : 25661.755859375 | val_loss : 801.4824829101562 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 578 | train_loss : 7454.689453125 | val_loss : 580.39501953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 579 | train_loss : 2788.1953125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 580 | train_loss : 4314.982421875 | val_loss : 35.029998779296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 581 | train_loss : 2641.40185546875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 582 | train_loss : 2431.139892578125 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 583 | train_loss : 2120.66455078125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 584 | train_loss : 1718.8614501953125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 585 | train_loss : 1094.1856689453125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 586 | train_loss : 980.7898559570312 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 587 | train_loss : 838.53662109375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 588 | train_loss : 775.0873413085938 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 589 | train_loss : 740.3314208984375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 590 | train_loss : 666.909423828125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 591 | train_loss : 676.11669921875 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 592 | train_loss : 667.5430297851562 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 593 | train_loss : 647.4745483398438 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 594 | train_loss : 642.9400024414062 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 595 | train_loss : 626.3439331054688 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 596 | train_loss : 526.8078002929688 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 597 | train_loss : 551.0900268554688 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 598 | train_loss : 478.5522766113281 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 599 | train_loss : 477.89788818359375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 600 | train_loss : 439.02423095703125 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 601 | train_loss : 433.60015869140625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 602 | train_loss : 434.5659484863281 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 603 | train_loss : 514.2424926757812 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 604 | train_loss : 455.6612548828125 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 605 | train_loss : 414.519775390625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 606 | train_loss : 415.08343505859375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 607 | train_loss : 358.4921875 | val_loss : 72218.0859375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 608 | train_loss : 141515.9375 | val_loss : 110370.2265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 609 | train_loss : 129414.0625 | val_loss : 67519.5546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 610 | train_loss : 88548.828125 | val_loss : 57628.98046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 611 | train_loss : 67130.1640625 | val_loss : 34110.0859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 612 | train_loss : 43533.984375 | val_loss : 812.3099975585938 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 613 | train_loss : 4655.97265625 | val_loss : 15.361249923706055 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 614 | train_loss : 3086.2451171875 | val_loss : 75.72000122070312 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 615 | train_loss : 2398.02001953125 | val_loss : 459.9674987792969 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 616 | train_loss : 2088.785400390625 | val_loss : 153.41624450683594 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 617 | train_loss : 1642.1192626953125 | val_loss : 194.2050018310547 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 618 | train_loss : 1531.8504638671875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 619 | train_loss : 1405.3118896484375 | val_loss : 135.5749969482422 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 620 | train_loss : 1453.7379150390625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 621 | train_loss : 1582.66064453125 | val_loss : 755.125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 622 | train_loss : 1477.0576171875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 623 | train_loss : 1199.1495361328125 | val_loss : 612.1187744140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 624 | train_loss : 1317.006591796875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 625 | train_loss : 1044.8740234375 | val_loss : 525.416259765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 626 | train_loss : 1140.7769775390625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 627 | train_loss : 963.128662109375 | val_loss : 662.2575073242188 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 628 | train_loss : 1086.3292236328125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 629 | train_loss : 870.7714233398438 | val_loss : 553.6799926757812 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 630 | train_loss : 927.98095703125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 631 | train_loss : 805.6361083984375 | val_loss : 692.29248046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 632 | train_loss : 813.3395385742188 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 633 | train_loss : 767.190185546875 | val_loss : 1469.75244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 634 | train_loss : 2373.23779296875 | val_loss : 1094.760009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 635 | train_loss : 8502.078125 | val_loss : 531.260009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 636 | train_loss : 1888.4676513671875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 637 | train_loss : 2312.66845703125 | val_loss : 39994.9140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 638 | train_loss : 40209.96484375 | val_loss : 49233.48046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 639 | train_loss : 54330.78515625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 640 | train_loss : 1999.164794921875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 641 | train_loss : 1302.91943359375 | val_loss : 25881.8359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 642 | train_loss : 28532.4765625 | val_loss : 50822.0703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 643 | train_loss : 51939.4140625 | val_loss : 232.90875244140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 644 | train_loss : 3996.860107421875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 645 | train_loss : 1078.0340576171875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 646 | train_loss : 787.4684448242188 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 647 | train_loss : 718.927978515625 | val_loss : 29.700000762939453 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 648 | train_loss : 717.1165771484375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 649 | train_loss : 648.2246704101562 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 650 | train_loss : 627.268310546875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 651 | train_loss : 651.1151733398438 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 652 | train_loss : 598.3720092773438 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 653 | train_loss : 642.8273315429688 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 654 | train_loss : 563.856689453125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 655 | train_loss : 550.3751831054688 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 656 | train_loss : 506.2743835449219 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 657 | train_loss : 501.7228088378906 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 658 | train_loss : 525.2687377929688 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 659 | train_loss : 516.19140625 | val_loss : 197.34124755859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 660 | train_loss : 675.5862426757812 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 661 | train_loss : 529.89453125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 662 | train_loss : 503.75860595703125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 663 | train_loss : 425.8968811035156 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 664 | train_loss : 428.01953125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 665 | train_loss : 383.3671875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 666 | train_loss : 382.36749267578125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 667 | train_loss : 385.5753173828125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 668 | train_loss : 343.13592529296875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 669 | train_loss : 332.84405517578125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 670 | train_loss : 346.54827880859375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 671 | train_loss : 286.5503845214844 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 672 | train_loss : 304.029052734375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 673 | train_loss : 298.8776550292969 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 674 | train_loss : 253.06219482421875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 675 | train_loss : 212.8484344482422 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 676 | train_loss : 292.2421875 | val_loss : 111.51625061035156 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 677 | train_loss : 734.768310546875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 678 | train_loss : 1694.5452880859375 | val_loss : 1226.7349853515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 679 | train_loss : 2274.486572265625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 680 | train_loss : 3318.229736328125 | val_loss : 661.3524780273438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 681 | train_loss : 1960.31201171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 682 | train_loss : 2210.11572265625 | val_loss : 719.59375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 683 | train_loss : 1512.73486328125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 684 | train_loss : 1802.850341796875 | val_loss : 958.1950073242188 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 685 | train_loss : 2219.654052734375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 686 | train_loss : 3548.37939453125 | val_loss : 805.9650268554688 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 687 | train_loss : 2486.6103515625 | val_loss : 195.93499755859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 688 | train_loss : 3959.140380859375 | val_loss : 599.9600219726562 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 689 | train_loss : 1604.137939453125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 690 | train_loss : 1367.4981689453125 | val_loss : 856.5125122070312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 691 | train_loss : 2488.296875 | val_loss : 146.88624572753906 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 692 | train_loss : 3892.157470703125 | val_loss : 846.385009765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 693 | train_loss : 1749.3834228515625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 694 | train_loss : 2052.75048828125 | val_loss : 396.5737609863281 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 695 | train_loss : 1904.0042724609375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 696 | train_loss : 2132.42431640625 | val_loss : 554.9625244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 697 | train_loss : 1522.4259033203125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 698 | train_loss : 1370.4989013671875 | val_loss : 771.5974731445312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 699 | train_loss : 1348.67626953125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 700 | train_loss : 2444.5029296875 | val_loss : 473.4837646484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 701 | train_loss : 1465.81201171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 702 | train_loss : 1411.1446533203125 | val_loss : 784.0700073242188 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 703 | train_loss : 1745.458740234375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 704 | train_loss : 1982.2581787109375 | val_loss : 568.6649780273438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 705 | train_loss : 1991.5592041015625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 706 | train_loss : 2237.59765625 | val_loss : 217.49000549316406 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 707 | train_loss : 1301.6307373046875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 708 | train_loss : 1375.0665283203125 | val_loss : 195.37374877929688 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 709 | train_loss : 902.16845703125 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 710 | train_loss : 868.6535034179688 | val_loss : 212.9875030517578 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 711 | train_loss : 1009.0454711914062 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 712 | train_loss : 1197.93408203125 | val_loss : 215.9812469482422 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 713 | train_loss : 1038.6287841796875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 714 | train_loss : 1173.6527099609375 | val_loss : 216.1687469482422 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 715 | train_loss : 1026.353271484375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 716 | train_loss : 1367.4945068359375 | val_loss : 700.08251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 717 | train_loss : 2315.826171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 718 | train_loss : 3202.996337890625 | val_loss : 695.251220703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 719 | train_loss : 1704.0701904296875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 720 | train_loss : 1993.550048828125 | val_loss : 218.50999450683594 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 721 | train_loss : 1780.949951171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 722 | train_loss : 1558.1058349609375 | val_loss : 394.7724914550781 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 723 | train_loss : 1967.0513916015625 | val_loss : 5.737500190734863 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 724 | train_loss : 3009.126953125 | val_loss : 1674.9837646484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 725 | train_loss : 3575.148193359375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 726 | train_loss : 3446.93310546875 | val_loss : 421.09375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 727 | train_loss : 1753.31201171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 728 | train_loss : 1896.529052734375 | val_loss : 177.74624633789062 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 729 | train_loss : 1586.184814453125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 730 | train_loss : 1204.957275390625 | val_loss : 34.35749816894531 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 731 | train_loss : 1155.9332275390625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 732 | train_loss : 1266.7261962890625 | val_loss : 81.41874694824219 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 733 | train_loss : 864.685302734375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 734 | train_loss : 783.0879516601562 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 735 | train_loss : 520.3070068359375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 736 | train_loss : 417.7487487792969 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 737 | train_loss : 364.163818359375 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 738 | train_loss : 367.4477233886719 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 739 | train_loss : 394.76617431640625 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 740 | train_loss : 308.2732849121094 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 741 | train_loss : 440.84625244140625 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 742 | train_loss : 502.9263916015625 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 743 | train_loss : 815.900634765625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 744 | train_loss : 1233.9373779296875 | val_loss : 501.15625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 745 | train_loss : 1980.290283203125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 746 | train_loss : 2473.10302734375 | val_loss : 333.614990234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 747 | train_loss : 1339.4749755859375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 748 | train_loss : 1499.614501953125 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 749 | train_loss : 1586.1590576171875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 750 | train_loss : 1323.9033203125 | val_loss : 235.0987548828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 751 | train_loss : 1777.6539306640625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 752 | train_loss : 2035.3221435546875 | val_loss : 70.91625213623047 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 753 | train_loss : 1176.723388671875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 754 | train_loss : 1559.8807373046875 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 755 | train_loss : 1501.8668212890625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 756 | train_loss : 1410.2947998046875 | val_loss : 215.47999572753906 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 757 | train_loss : 1692.005126953125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 758 | train_loss : 1622.74169921875 | val_loss : 169.49000549316406 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 759 | train_loss : 1647.6390380859375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 760 | train_loss : 1668.2550048828125 | val_loss : 432.77874755859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 761 | train_loss : 1832.6361083984375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 762 | train_loss : 2577.927734375 | val_loss : 708.4600219726562 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 763 | train_loss : 1588.9814453125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 764 | train_loss : 2316.052001953125 | val_loss : 229.7899932861328 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 765 | train_loss : 1585.381591796875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 766 | train_loss : 1691.5311279296875 | val_loss : 209.32875061035156 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 767 | train_loss : 1553.9237060546875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 768 | train_loss : 1722.3084716796875 | val_loss : 180.3037567138672 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 769 | train_loss : 1508.71142578125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 770 | train_loss : 1765.35791015625 | val_loss : 144.7012481689453 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 771 | train_loss : 1452.607177734375 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 772 | train_loss : 1817.90234375 | val_loss : 101.83000183105469 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 773 | train_loss : 1387.73681640625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 774 | train_loss : 1878.9959716796875 | val_loss : 57.51124954223633 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 775 | train_loss : 1314.6365966796875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 776 | train_loss : 1948.1204833984375 | val_loss : 322.0924987792969 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 777 | train_loss : 1459.6160888671875 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 778 | train_loss : 2022.90087890625 | val_loss : 274.8387451171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 779 | train_loss : 1369.9688720703125 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 780 | train_loss : 1878.662353515625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 781 | train_loss : 1127.0565185546875 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 782 | train_loss : 794.4927368164062 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 783 | train_loss : 857.238525390625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 784 | train_loss : 650.7832641601562 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 785 | train_loss : 598.8345336914062 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 786 | train_loss : 298.6136779785156 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 787 | train_loss : 431.6346740722656 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 788 | train_loss : 233.00538635253906 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 789 | train_loss : 496.90399169921875 | val_loss : 0.0 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 790 | train_loss : 686.8438110351562 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 791 | train_loss : 532.1026611328125 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 792 | train_loss : 1123.2972412109375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 793 | train_loss : 1259.5767822265625 | val_loss : 0.0 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 794 | train_loss : 1667.60107421875 | val_loss : 164.6962432861328 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 795 | train_loss : 1383.7047119140625 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 796 | train_loss : 1296.468017578125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 797 | train_loss : 1238.9827880859375 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 798 | train_loss : 1108.4652099609375 | val_loss : 116.9312515258789 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 799 | train_loss : 1006.7645874023438 | val_loss : 0.0 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 3 | epoch : 800 | train_loss : 1281.299560546875 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 4 | epoch : 1 | train_loss : 619826.375 | val_loss : 581680.9375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 2 | train_loss : 537981.9375 | val_loss : 406765.1875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 3 | train_loss : 365386.0 | val_loss : 408062.53125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 4 | train_loss : 475608.8125 | val_loss : 653644.75 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 5 | train_loss : 623940.1875 | val_loss : 164294.140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 6 | train_loss : 146438.75 | val_loss : 127344.4609375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 7 | train_loss : 162326.046875 | val_loss : 128432.2421875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 8 | train_loss : 137279.34375 | val_loss : 216918.859375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 9 | train_loss : 254038.34375 | val_loss : 232329.015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 10 | train_loss : 241612.375 | val_loss : 241682.0 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 11 | train_loss : 210978.765625 | val_loss : 237881.4375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 12 | train_loss : 312392.6875 | val_loss : 73227.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 13 | train_loss : 78489.75 | val_loss : 144138.671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 14 | train_loss : 127702.2265625 | val_loss : 158901.296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 15 | train_loss : 231494.921875 | val_loss : 56012.4609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 16 | train_loss : 49701.203125 | val_loss : 99899.609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 17 | train_loss : 88750.859375 | val_loss : 59158.19921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 18 | train_loss : 100770.8984375 | val_loss : 169655.796875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 19 | train_loss : 157112.6875 | val_loss : 218772.515625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 20 | train_loss : 206336.921875 | val_loss : 155413.09375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 21 | train_loss : 239184.0 | val_loss : 36261.203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 22 | train_loss : 39112.921875 | val_loss : 134995.046875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 23 | train_loss : 111613.421875 | val_loss : 114326.5625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 24 | train_loss : 133494.140625 | val_loss : 113221.921875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 25 | train_loss : 94614.46875 | val_loss : 66511.8203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 26 | train_loss : 122029.7421875 | val_loss : 65994.2890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 27 | train_loss : 47066.5390625 | val_loss : 139049.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 28 | train_loss : 155565.546875 | val_loss : 44653.94921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 29 | train_loss : 34144.05859375 | val_loss : 69531.5 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 30 | train_loss : 105721.8828125 | val_loss : 54008.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 31 | train_loss : 55116.42578125 | val_loss : 127190.21875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 32 | train_loss : 123159.453125 | val_loss : 101578.59375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 33 | train_loss : 142311.84375 | val_loss : 131122.53125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 34 | train_loss : 152191.703125 | val_loss : 150490.640625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 35 | train_loss : 145083.296875 | val_loss : 48523.00390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 36 | train_loss : 105386.1015625 | val_loss : 29409.505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 37 | train_loss : 25617.373046875 | val_loss : 101050.40625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 38 | train_loss : 99918.078125 | val_loss : 47463.8046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 39 | train_loss : 115234.078125 | val_loss : 85297.7734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 40 | train_loss : 56131.94921875 | val_loss : 145864.203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 41 | train_loss : 125822.203125 | val_loss : 35234.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 42 | train_loss : 58904.64453125 | val_loss : 116973.2109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 43 | train_loss : 99915.53125 | val_loss : 126421.4609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 44 | train_loss : 145895.6875 | val_loss : 34725.76171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 45 | train_loss : 24854.265625 | val_loss : 99540.140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 46 | train_loss : 78137.46875 | val_loss : 84233.0078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 47 | train_loss : 95419.7421875 | val_loss : 173251.125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 48 | train_loss : 171388.484375 | val_loss : 76272.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 49 | train_loss : 109335.359375 | val_loss : 106732.421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 50 | train_loss : 105772.109375 | val_loss : 138844.125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 51 | train_loss : 135077.359375 | val_loss : 80307.1171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 52 | train_loss : 109557.84375 | val_loss : 86090.7265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 53 | train_loss : 68260.15625 | val_loss : 140719.546875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 54 | train_loss : 128256.6171875 | val_loss : 51572.23046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 55 | train_loss : 69495.21875 | val_loss : 90233.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 56 | train_loss : 67484.1484375 | val_loss : 90590.9609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 57 | train_loss : 137544.515625 | val_loss : 42110.8046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 58 | train_loss : 22611.623046875 | val_loss : 28714.375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 59 | train_loss : 29696.322265625 | val_loss : 107820.1875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 60 | train_loss : 82056.3984375 | val_loss : 108689.5234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 61 | train_loss : 137609.59375 | val_loss : 27075.55078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 62 | train_loss : 19867.435546875 | val_loss : 76633.5390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 63 | train_loss : 67566.15625 | val_loss : 44297.0390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 64 | train_loss : 65530.18359375 | val_loss : 93836.6484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 65 | train_loss : 82960.171875 | val_loss : 84343.8125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 66 | train_loss : 72865.7265625 | val_loss : 24100.53515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 67 | train_loss : 22136.19921875 | val_loss : 66165.3671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 68 | train_loss : 69912.3515625 | val_loss : 99833.2421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 69 | train_loss : 97464.640625 | val_loss : 70517.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 70 | train_loss : 61679.2265625 | val_loss : 53056.03125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 71 | train_loss : 112413.0 | val_loss : 45035.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 72 | train_loss : 44334.85546875 | val_loss : 121166.421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 73 | train_loss : 96440.203125 | val_loss : 69349.3203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 74 | train_loss : 106806.9609375 | val_loss : 89444.2265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 75 | train_loss : 75771.5546875 | val_loss : 43625.953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 76 | train_loss : 63797.73046875 | val_loss : 95820.7734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 77 | train_loss : 70066.3515625 | val_loss : 102506.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 78 | train_loss : 130089.1015625 | val_loss : 29930.123046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 79 | train_loss : 15488.80859375 | val_loss : 60762.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 80 | train_loss : 58351.640625 | val_loss : 115076.21875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 81 | train_loss : 92444.359375 | val_loss : 61497.140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 82 | train_loss : 110769.53125 | val_loss : 62789.1015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 83 | train_loss : 34829.4609375 | val_loss : 96989.0703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 84 | train_loss : 108656.703125 | val_loss : 42152.05859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 85 | train_loss : 30702.744140625 | val_loss : 53398.73828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 86 | train_loss : 58883.24609375 | val_loss : 106863.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 87 | train_loss : 77636.5078125 | val_loss : 57382.4453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 88 | train_loss : 100042.171875 | val_loss : 61088.16015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 89 | train_loss : 37030.16796875 | val_loss : 100888.3671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 90 | train_loss : 129633.5625 | val_loss : 30868.572265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 91 | train_loss : 33076.30859375 | val_loss : 82014.828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 92 | train_loss : 65697.90625 | val_loss : 79198.75 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 93 | train_loss : 71842.8125 | val_loss : 38296.515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 94 | train_loss : 31999.4375 | val_loss : 52389.56640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 95 | train_loss : 97208.203125 | val_loss : 34937.5234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 96 | train_loss : 38584.25 | val_loss : 67277.953125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 97 | train_loss : 64350.15625 | val_loss : 73823.8828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 98 | train_loss : 113562.7265625 | val_loss : 48047.0859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 99 | train_loss : 70765.4375 | val_loss : 78129.390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 100 | train_loss : 66817.4921875 | val_loss : 46294.578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 101 | train_loss : 40477.83984375 | val_loss : 87105.0703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 102 | train_loss : 69094.34375 | val_loss : 49837.91015625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 103 | train_loss : 46972.671875 | val_loss : 49021.390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 104 | train_loss : 33874.99609375 | val_loss : 29922.904296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 105 | train_loss : 47775.109375 | val_loss : 60345.41015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 106 | train_loss : 53389.98828125 | val_loss : 44486.7890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 107 | train_loss : 67225.3984375 | val_loss : 27143.9609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 108 | train_loss : 19162.212890625 | val_loss : 50798.12890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 109 | train_loss : 57151.7734375 | val_loss : 74474.109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 110 | train_loss : 66651.2265625 | val_loss : 21357.380859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 111 | train_loss : 23216.59765625 | val_loss : 45955.5703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 112 | train_loss : 38124.875 | val_loss : 25916.869140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 113 | train_loss : 45043.671875 | val_loss : 60374.12890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 114 | train_loss : 54757.296875 | val_loss : 35532.57421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 115 | train_loss : 47918.9453125 | val_loss : 36553.38671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 116 | train_loss : 30203.294921875 | val_loss : 50566.30078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 117 | train_loss : 87917.796875 | val_loss : 21083.314453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 118 | train_loss : 30439.140625 | val_loss : 65231.55078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 119 | train_loss : 61569.7890625 | val_loss : 71742.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 120 | train_loss : 108759.5078125 | val_loss : 48178.13671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 121 | train_loss : 69910.3046875 | val_loss : 63567.87109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 122 | train_loss : 52801.9609375 | val_loss : 52051.5390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 123 | train_loss : 44018.51953125 | val_loss : 96586.953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 124 | train_loss : 83355.8125 | val_loss : 63538.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 125 | train_loss : 85466.2578125 | val_loss : 30981.52734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 126 | train_loss : 31264.13671875 | val_loss : 53610.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 127 | train_loss : 39328.0234375 | val_loss : 65387.0234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 128 | train_loss : 54714.984375 | val_loss : 16735.591796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 129 | train_loss : 13153.767578125 | val_loss : 39929.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 130 | train_loss : 20644.505859375 | val_loss : 61580.859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 131 | train_loss : 78439.2265625 | val_loss : 65428.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 132 | train_loss : 37200.12109375 | val_loss : 59051.05078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 133 | train_loss : 55011.76171875 | val_loss : 92999.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 134 | train_loss : 75219.796875 | val_loss : 44025.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 135 | train_loss : 91662.8125 | val_loss : 29701.189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 136 | train_loss : 19645.0859375 | val_loss : 81084.8046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 137 | train_loss : 73465.796875 | val_loss : 53003.37890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 138 | train_loss : 83711.4375 | val_loss : 50277.46484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 139 | train_loss : 39022.2265625 | val_loss : 101456.109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 140 | train_loss : 83580.65625 | val_loss : 51431.890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 141 | train_loss : 85445.4609375 | val_loss : 36365.2109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 142 | train_loss : 23370.88671875 | val_loss : 22543.095703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 143 | train_loss : 26666.703125 | val_loss : 47938.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 144 | train_loss : 37338.6484375 | val_loss : 31309.015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 145 | train_loss : 45596.49609375 | val_loss : 31517.484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 146 | train_loss : 23052.349609375 | val_loss : 31053.53515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 147 | train_loss : 53312.71875 | val_loss : 26723.705078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 148 | train_loss : 15529.740234375 | val_loss : 42450.48046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 149 | train_loss : 50613.984375 | val_loss : 64024.94140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 150 | train_loss : 41829.0078125 | val_loss : 37992.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 151 | train_loss : 53777.92578125 | val_loss : 75363.796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 152 | train_loss : 47033.3046875 | val_loss : 69241.953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 153 | train_loss : 87897.3125 | val_loss : 31157.767578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 154 | train_loss : 15796.2109375 | val_loss : 45831.3515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 155 | train_loss : 44071.7890625 | val_loss : 70294.3984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 156 | train_loss : 56147.8515625 | val_loss : 27905.71484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 157 | train_loss : 65425.62109375 | val_loss : 34859.51171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 158 | train_loss : 15412.49609375 | val_loss : 19054.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 159 | train_loss : 27373.810546875 | val_loss : 70781.8984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 160 | train_loss : 66851.203125 | val_loss : 43889.109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 161 | train_loss : 73989.78125 | val_loss : 39812.94921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 162 | train_loss : 37273.05859375 | val_loss : 62824.1015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 163 | train_loss : 50205.0390625 | val_loss : 29771.294921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 164 | train_loss : 29245.349609375 | val_loss : 52299.06640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 165 | train_loss : 50738.3046875 | val_loss : 55291.82421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 166 | train_loss : 82302.71875 | val_loss : 21421.130859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 167 | train_loss : 32424.515625 | val_loss : 45626.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 168 | train_loss : 39107.43359375 | val_loss : 24392.9296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 169 | train_loss : 45220.7734375 | val_loss : 37130.80859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 170 | train_loss : 20652.412109375 | val_loss : 45964.7265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 171 | train_loss : 51341.00390625 | val_loss : 50175.36328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 172 | train_loss : 34478.28125 | val_loss : 23317.578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 173 | train_loss : 43835.30078125 | val_loss : 43016.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 174 | train_loss : 24414.5390625 | val_loss : 49747.87890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 175 | train_loss : 66028.859375 | val_loss : 27995.849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 176 | train_loss : 14246.1328125 | val_loss : 34824.76171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 177 | train_loss : 30625.099609375 | val_loss : 76957.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 178 | train_loss : 64906.2265625 | val_loss : 36135.13671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 179 | train_loss : 69146.453125 | val_loss : 32734.154296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 180 | train_loss : 24383.142578125 | val_loss : 60753.203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 181 | train_loss : 55308.21484375 | val_loss : 36844.41796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 182 | train_loss : 51184.1640625 | val_loss : 57999.5 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 183 | train_loss : 41325.06640625 | val_loss : 25702.876953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 184 | train_loss : 25507.634765625 | val_loss : 49902.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 185 | train_loss : 37751.6796875 | val_loss : 23503.404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 186 | train_loss : 34953.7890625 | val_loss : 32102.642578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 187 | train_loss : 23757.734375 | val_loss : 27652.03515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 188 | train_loss : 50648.4609375 | val_loss : 18322.755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 189 | train_loss : 10257.3076171875 | val_loss : 23900.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 190 | train_loss : 19589.04296875 | val_loss : 107501.1171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 191 | train_loss : 93071.578125 | val_loss : 29030.474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 192 | train_loss : 64808.14453125 | val_loss : 31186.927734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 193 | train_loss : 14273.025390625 | val_loss : 29007.3203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 194 | train_loss : 22343.875 | val_loss : 74013.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 195 | train_loss : 58752.375 | val_loss : 25731.48046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 196 | train_loss : 58395.87109375 | val_loss : 29525.904296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 197 | train_loss : 12822.2177734375 | val_loss : 16533.818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 198 | train_loss : 14136.6787109375 | val_loss : 17266.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 199 | train_loss : 12027.087890625 | val_loss : 52031.671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 200 | train_loss : 49260.05078125 | val_loss : 29113.875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 201 | train_loss : 55658.37109375 | val_loss : 17323.14453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 202 | train_loss : 12321.2001953125 | val_loss : 42405.41015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 203 | train_loss : 30206.3203125 | val_loss : 20526.51953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 204 | train_loss : 31624.568359375 | val_loss : 27483.970703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 205 | train_loss : 23387.482421875 | val_loss : 22779.572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 206 | train_loss : 34581.8515625 | val_loss : 17393.212890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 207 | train_loss : 13238.25390625 | val_loss : 22141.2578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 208 | train_loss : 25129.982421875 | val_loss : 35338.93359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 209 | train_loss : 26587.2578125 | val_loss : 26076.8125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 210 | train_loss : 42925.62890625 | val_loss : 17538.62890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 211 | train_loss : 12760.927734375 | val_loss : 34736.1640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 212 | train_loss : 31627.998046875 | val_loss : 73635.1328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 213 | train_loss : 59365.63671875 | val_loss : 22002.6640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 214 | train_loss : 42231.109375 | val_loss : 29885.751953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 215 | train_loss : 20589.578125 | val_loss : 11873.43359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 216 | train_loss : 28714.552734375 | val_loss : 73880.3828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 217 | train_loss : 44805.78515625 | val_loss : 85345.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 218 | train_loss : 92459.671875 | val_loss : 11741.1103515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 219 | train_loss : 9708.4716796875 | val_loss : 16785.423828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 220 | train_loss : 20335.046875 | val_loss : 48577.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 221 | train_loss : 42405.23046875 | val_loss : 18436.744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 222 | train_loss : 45571.125 | val_loss : 30030.134765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 223 | train_loss : 14153.20703125 | val_loss : 14556.0185546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 224 | train_loss : 16172.7021484375 | val_loss : 26421.7890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 225 | train_loss : 16199.0927734375 | val_loss : 13739.916015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 226 | train_loss : 34148.84375 | val_loss : 44773.25 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 227 | train_loss : 25214.552734375 | val_loss : 50426.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 228 | train_loss : 58812.984375 | val_loss : 34466.37109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 229 | train_loss : 22819.982421875 | val_loss : 27187.14453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 230 | train_loss : 24406.935546875 | val_loss : 61268.05859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 231 | train_loss : 52732.30859375 | val_loss : 20486.505859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 232 | train_loss : 50567.23828125 | val_loss : 25147.3359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 233 | train_loss : 13841.46875 | val_loss : 38610.86328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 234 | train_loss : 34964.29296875 | val_loss : 26919.1796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 235 | train_loss : 37250.07421875 | val_loss : 17115.62109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 236 | train_loss : 8530.98828125 | val_loss : 18409.681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 237 | train_loss : 24324.6015625 | val_loss : 50059.30078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 238 | train_loss : 31501.837890625 | val_loss : 36646.5390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 239 | train_loss : 50989.375 | val_loss : 28378.9140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 240 | train_loss : 12095.19140625 | val_loss : 16928.529296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 241 | train_loss : 25499.3671875 | val_loss : 40784.5078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 242 | train_loss : 27662.33203125 | val_loss : 29335.330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 243 | train_loss : 50041.2890625 | val_loss : 31237.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 244 | train_loss : 12558.0224609375 | val_loss : 26233.064453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 245 | train_loss : 25578.78515625 | val_loss : 56358.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 246 | train_loss : 42655.46484375 | val_loss : 21327.005859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 247 | train_loss : 47372.75 | val_loss : 35163.87109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 248 | train_loss : 15461.462890625 | val_loss : 15196.693359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 249 | train_loss : 23020.265625 | val_loss : 45422.06640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 250 | train_loss : 34310.2578125 | val_loss : 30815.88671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 251 | train_loss : 46868.62890625 | val_loss : 29387.60546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 252 | train_loss : 14379.1220703125 | val_loss : 32945.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 253 | train_loss : 25257.77734375 | val_loss : 63450.48828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 254 | train_loss : 53868.01953125 | val_loss : 25616.19921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 255 | train_loss : 41635.53125 | val_loss : 26924.28515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 256 | train_loss : 19588.990234375 | val_loss : 14967.2548828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 257 | train_loss : 29810.11328125 | val_loss : 30426.20703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 258 | train_loss : 17303.21484375 | val_loss : 23080.330078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 259 | train_loss : 36457.2421875 | val_loss : 28292.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 260 | train_loss : 13321.0146484375 | val_loss : 22484.900390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 261 | train_loss : 27245.607421875 | val_loss : 45507.98046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 262 | train_loss : 29034.375 | val_loss : 22593.404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 263 | train_loss : 42282.296875 | val_loss : 20151.830078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 264 | train_loss : 7849.99755859375 | val_loss : 7736.40673828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 265 | train_loss : 8210.677734375 | val_loss : 35872.51171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 266 | train_loss : 17390.86328125 | val_loss : 28129.60546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 267 | train_loss : 34621.68359375 | val_loss : 38758.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 268 | train_loss : 22724.0703125 | val_loss : 30994.5625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 269 | train_loss : 42337.42578125 | val_loss : 24345.330078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 270 | train_loss : 10726.8251953125 | val_loss : 17031.373046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 271 | train_loss : 19136.609375 | val_loss : 42337.39453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 272 | train_loss : 33612.53515625 | val_loss : 20874.716796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 273 | train_loss : 45768.9296875 | val_loss : 16486.490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 274 | train_loss : 6926.15625 | val_loss : 16562.314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 275 | train_loss : 11187.4501953125 | val_loss : 19807.125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 276 | train_loss : 23717.265625 | val_loss : 24644.1640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 277 | train_loss : 18144.9453125 | val_loss : 21039.158203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 278 | train_loss : 40657.05078125 | val_loss : 11345.138671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 279 | train_loss : 4116.93310546875 | val_loss : 5807.46484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 280 | train_loss : 3790.974365234375 | val_loss : 19519.14453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 281 | train_loss : 8636.3564453125 | val_loss : 21038.890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 282 | train_loss : 28903.349609375 | val_loss : 40814.3359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 283 | train_loss : 25233.716796875 | val_loss : 34989.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 284 | train_loss : 43478.23828125 | val_loss : 24463.5703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 285 | train_loss : 12291.5498046875 | val_loss : 22659.95703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 286 | train_loss : 35697.9765625 | val_loss : 30568.85546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 287 | train_loss : 15044.9970703125 | val_loss : 15518.357421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 288 | train_loss : 29915.91015625 | val_loss : 31478.94921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 289 | train_loss : 17793.0390625 | val_loss : 13014.365234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 290 | train_loss : 28347.671875 | val_loss : 29834.92578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 291 | train_loss : 16438.6171875 | val_loss : 18537.5859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 292 | train_loss : 29110.8359375 | val_loss : 30051.482421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 293 | train_loss : 16767.0859375 | val_loss : 19069.0546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 294 | train_loss : 28831.9296875 | val_loss : 23370.419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 295 | train_loss : 15079.1572265625 | val_loss : 19636.857421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 296 | train_loss : 26334.36328125 | val_loss : 37127.6484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 297 | train_loss : 23692.072265625 | val_loss : 14740.89453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 298 | train_loss : 25527.6640625 | val_loss : 28124.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 299 | train_loss : 14838.74609375 | val_loss : 21411.595703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 300 | train_loss : 30232.267578125 | val_loss : 30498.794921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 301 | train_loss : 15726.5595703125 | val_loss : 17698.5078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 302 | train_loss : 28502.990234375 | val_loss : 26318.525390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 303 | train_loss : 15106.0146484375 | val_loss : 8365.7314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 304 | train_loss : 21807.10546875 | val_loss : 35258.4140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 305 | train_loss : 17760.876953125 | val_loss : 19089.796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 306 | train_loss : 26703.615234375 | val_loss : 29106.59765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 307 | train_loss : 16328.587890625 | val_loss : 16034.6552734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 308 | train_loss : 26420.7421875 | val_loss : 25132.76171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 309 | train_loss : 13802.4296875 | val_loss : 12920.80859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 310 | train_loss : 18487.892578125 | val_loss : 35882.3046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 311 | train_loss : 22638.53515625 | val_loss : 14823.7001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 312 | train_loss : 25061.505859375 | val_loss : 63641.19921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 313 | train_loss : 46524.71875 | val_loss : 51841.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 314 | train_loss : 63464.57421875 | val_loss : 22403.57421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 315 | train_loss : 9463.2939453125 | val_loss : 6310.37890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 316 | train_loss : 4911.15869140625 | val_loss : 16300.09765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 317 | train_loss : 5675.10888671875 | val_loss : 7986.333984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 318 | train_loss : 9019.16015625 | val_loss : 28783.859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 319 | train_loss : 13481.89453125 | val_loss : 20978.1640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 320 | train_loss : 29930.990234375 | val_loss : 31966.744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 321 | train_loss : 17497.94921875 | val_loss : 19301.078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 322 | train_loss : 29786.1171875 | val_loss : 26791.01171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 323 | train_loss : 14699.884765625 | val_loss : 54363.6015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 324 | train_loss : 87736.359375 | val_loss : 111927.5390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 325 | train_loss : 65715.796875 | val_loss : 119831.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 326 | train_loss : 140263.609375 | val_loss : 24039.404296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 327 | train_loss : 14758.11328125 | val_loss : 12987.3662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 328 | train_loss : 22705.0546875 | val_loss : 15880.9521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 329 | train_loss : 11962.87109375 | val_loss : 11840.287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 330 | train_loss : 18017.509765625 | val_loss : 21182.38671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 331 | train_loss : 16245.880859375 | val_loss : 16879.3984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 332 | train_loss : 20285.259765625 | val_loss : 16817.57421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 333 | train_loss : 11491.8095703125 | val_loss : 57880.64453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 334 | train_loss : 74414.5703125 | val_loss : 32374.1171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 335 | train_loss : 23502.953125 | val_loss : 13003.4462890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 336 | train_loss : 23114.189453125 | val_loss : 26811.251953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 337 | train_loss : 17280.234375 | val_loss : 9145.60546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 338 | train_loss : 25405.53515625 | val_loss : 36247.24609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 339 | train_loss : 23538.2734375 | val_loss : 11302.677734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 340 | train_loss : 19417.265625 | val_loss : 26361.154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 341 | train_loss : 14225.224609375 | val_loss : 9899.041015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 342 | train_loss : 20447.822265625 | val_loss : 24635.2890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 343 | train_loss : 12321.6572265625 | val_loss : 14459.9052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 344 | train_loss : 22882.931640625 | val_loss : 30797.1640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 345 | train_loss : 16378.5185546875 | val_loss : 12729.8173828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 346 | train_loss : 22682.45703125 | val_loss : 22161.41796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 347 | train_loss : 11862.8427734375 | val_loss : 4214.84130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 348 | train_loss : 12803.6064453125 | val_loss : 18792.494140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 349 | train_loss : 10848.462890625 | val_loss : 4502.60888671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 350 | train_loss : 14581.8603515625 | val_loss : 26388.33203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 351 | train_loss : 12749.4677734375 | val_loss : 14030.708984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 352 | train_loss : 16903.2890625 | val_loss : 25104.755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 353 | train_loss : 13641.337890625 | val_loss : 12062.4150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 354 | train_loss : 15889.205078125 | val_loss : 25987.177734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 355 | train_loss : 13535.6298828125 | val_loss : 9252.990234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 356 | train_loss : 15794.4599609375 | val_loss : 28245.53515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 357 | train_loss : 14343.98046875 | val_loss : 11382.3095703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 358 | train_loss : 20156.501953125 | val_loss : 26430.125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 359 | train_loss : 14688.9541015625 | val_loss : 5921.32177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 360 | train_loss : 17480.599609375 | val_loss : 30170.599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 361 | train_loss : 16955.17578125 | val_loss : 49007.30078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 362 | train_loss : 83310.921875 | val_loss : 98511.75 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 363 | train_loss : 57675.98046875 | val_loss : 50999.67578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 364 | train_loss : 46109.8515625 | val_loss : 20814.150390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 365 | train_loss : 16336.9521484375 | val_loss : 14921.7314453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 366 | train_loss : 18151.716796875 | val_loss : 16077.76953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 367 | train_loss : 10471.94140625 | val_loss : 11258.5302734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 368 | train_loss : 10403.8623046875 | val_loss : 16276.19921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 369 | train_loss : 9556.732421875 | val_loss : 10531.017578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 370 | train_loss : 12934.16015625 | val_loss : 17973.01953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 371 | train_loss : 10972.169921875 | val_loss : 9087.6435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 372 | train_loss : 15007.4951171875 | val_loss : 19999.4765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 373 | train_loss : 11692.3515625 | val_loss : 6446.24267578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 374 | train_loss : 15040.166015625 | val_loss : 28013.869140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 375 | train_loss : 12857.5927734375 | val_loss : 11788.0078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 376 | train_loss : 17079.119140625 | val_loss : 26765.10546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 377 | train_loss : 11972.615234375 | val_loss : 11954.6572265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 378 | train_loss : 15439.0771484375 | val_loss : 24371.474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 379 | train_loss : 10918.068359375 | val_loss : 9287.568359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 380 | train_loss : 13588.63671875 | val_loss : 148102.203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 381 | train_loss : 130030.046875 | val_loss : 62448.21484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 382 | train_loss : 72575.7578125 | val_loss : 8908.263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 383 | train_loss : 8485.6220703125 | val_loss : 20070.939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 384 | train_loss : 16190.4375 | val_loss : 24920.55078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 385 | train_loss : 28101.732421875 | val_loss : 30462.296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 386 | train_loss : 21826.625 | val_loss : 19701.625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 387 | train_loss : 17632.515625 | val_loss : 23591.04296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 388 | train_loss : 15869.91796875 | val_loss : 12721.130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 389 | train_loss : 11111.1162109375 | val_loss : 11003.259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 390 | train_loss : 6295.95361328125 | val_loss : 6885.1787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 391 | train_loss : 6138.21044921875 | val_loss : 13407.625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 392 | train_loss : 6438.27685546875 | val_loss : 5128.80810546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 393 | train_loss : 6020.2060546875 | val_loss : 20784.685546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 394 | train_loss : 9048.7138671875 | val_loss : 9028.1806640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 395 | train_loss : 16631.298828125 | val_loss : 24594.314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 396 | train_loss : 12691.90234375 | val_loss : 6695.0068359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 397 | train_loss : 14463.1220703125 | val_loss : 27361.25 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 398 | train_loss : 13530.494140625 | val_loss : 8696.7666015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 399 | train_loss : 15281.91796875 | val_loss : 25974.376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 400 | train_loss : 11984.2109375 | val_loss : 11535.08203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 401 | train_loss : 14635.3984375 | val_loss : 21226.744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 402 | train_loss : 9543.4228515625 | val_loss : 5812.03125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 403 | train_loss : 12358.4736328125 | val_loss : 26083.9609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 404 | train_loss : 12140.5849609375 | val_loss : 3798.67431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 405 | train_loss : 9370.228515625 | val_loss : 21317.7265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 406 | train_loss : 8523.94140625 | val_loss : 4774.9033203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 407 | train_loss : 8084.15771484375 | val_loss : 22055.5703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 408 | train_loss : 8939.14453125 | val_loss : 7246.96923828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 409 | train_loss : 12067.138671875 | val_loss : 23005.494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 410 | train_loss : 10784.134765625 | val_loss : 4781.296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 411 | train_loss : 11303.509765625 | val_loss : 23927.970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 412 | train_loss : 11575.892578125 | val_loss : 3436.094482421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 413 | train_loss : 9535.7890625 | val_loss : 22597.466796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 414 | train_loss : 11558.57421875 | val_loss : 5327.64697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 415 | train_loss : 14273.5625 | val_loss : 28867.865234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 416 | train_loss : 14543.962890625 | val_loss : 10231.9873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 417 | train_loss : 15744.798828125 | val_loss : 23259.890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 418 | train_loss : 12439.7529296875 | val_loss : 18741.615234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 419 | train_loss : 16556.03515625 | val_loss : 27241.875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 420 | train_loss : 16786.876953125 | val_loss : 11348.3037109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 421 | train_loss : 15469.2236328125 | val_loss : 20355.171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 422 | train_loss : 9710.037109375 | val_loss : 7609.4091796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 423 | train_loss : 8132.07080078125 | val_loss : 18566.572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 424 | train_loss : 7216.669921875 | val_loss : 5200.68505859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 425 | train_loss : 8926.3388671875 | val_loss : 27487.48046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 426 | train_loss : 16433.185546875 | val_loss : 6142.75634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 427 | train_loss : 12231.2451171875 | val_loss : 24824.845703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 428 | train_loss : 13946.49609375 | val_loss : 5326.9912109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 429 | train_loss : 11668.5810546875 | val_loss : 26262.095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 430 | train_loss : 13198.9384765625 | val_loss : 5804.32763671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 431 | train_loss : 12560.9287109375 | val_loss : 23216.564453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 432 | train_loss : 10706.5087890625 | val_loss : 7566.77490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 433 | train_loss : 11769.75390625 | val_loss : 21642.73046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 434 | train_loss : 8263.61328125 | val_loss : 11508.0361328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 435 | train_loss : 10054.5546875 | val_loss : 21703.599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 436 | train_loss : 9069.966796875 | val_loss : 10405.0673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 437 | train_loss : 9933.5234375 | val_loss : 20248.73046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 438 | train_loss : 7671.43994140625 | val_loss : 4672.416015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 439 | train_loss : 7783.572265625 | val_loss : 19938.671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 440 | train_loss : 8948.8359375 | val_loss : 3936.153076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 441 | train_loss : 8171.755859375 | val_loss : 24361.2890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 442 | train_loss : 12154.5458984375 | val_loss : 5592.45947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 443 | train_loss : 12896.947265625 | val_loss : 27157.07421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 444 | train_loss : 14266.2890625 | val_loss : 4329.66796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 445 | train_loss : 12016.853515625 | val_loss : 26494.640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 446 | train_loss : 12742.6865234375 | val_loss : 4780.625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 447 | train_loss : 8674.23828125 | val_loss : 18072.115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 448 | train_loss : 7129.8564453125 | val_loss : 3476.434326171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 449 | train_loss : 5713.9873046875 | val_loss : 16522.841796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 450 | train_loss : 6358.93896484375 | val_loss : 2836.894287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 451 | train_loss : 5169.32763671875 | val_loss : 15128.962890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 452 | train_loss : 6120.82080078125 | val_loss : 2641.97509765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 453 | train_loss : 6787.5810546875 | val_loss : 19144.064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 454 | train_loss : 8208.76953125 | val_loss : 3640.843017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 455 | train_loss : 8196.390625 | val_loss : 23100.857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 456 | train_loss : 13479.46484375 | val_loss : 4074.14501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 457 | train_loss : 11707.1875 | val_loss : 25833.9921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 458 | train_loss : 14061.8828125 | val_loss : 4320.82958984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 459 | train_loss : 10534.15234375 | val_loss : 21889.025390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 460 | train_loss : 10793.0595703125 | val_loss : 21929.029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 461 | train_loss : 15939.6064453125 | val_loss : 19185.681640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 462 | train_loss : 10108.6787109375 | val_loss : 9263.89453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 463 | train_loss : 12515.0712890625 | val_loss : 18882.8359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 464 | train_loss : 9642.9462890625 | val_loss : 7756.94189453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 465 | train_loss : 12459.5546875 | val_loss : 23963.08984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 466 | train_loss : 12908.21484375 | val_loss : 5083.40869140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 467 | train_loss : 10044.0634765625 | val_loss : 22684.73828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 468 | train_loss : 11144.6220703125 | val_loss : 8193.123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 469 | train_loss : 16904.818359375 | val_loss : 37420.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 470 | train_loss : 21304.982421875 | val_loss : 25653.748046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 471 | train_loss : 23886.01171875 | val_loss : 20753.822265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 472 | train_loss : 11585.6416015625 | val_loss : 8364.96484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 473 | train_loss : 10005.2958984375 | val_loss : 19928.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 474 | train_loss : 10807.9208984375 | val_loss : 7736.52001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 475 | train_loss : 7826.0693359375 | val_loss : 18916.71875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 476 | train_loss : 8100.53271484375 | val_loss : 6842.80419921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 477 | train_loss : 9984.78125 | val_loss : 29288.359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 478 | train_loss : 14659.0185546875 | val_loss : 4750.216796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 479 | train_loss : 10466.158203125 | val_loss : 26221.224609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 480 | train_loss : 13396.44140625 | val_loss : 4382.79296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 481 | train_loss : 8727.43359375 | val_loss : 16629.796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 482 | train_loss : 6643.4580078125 | val_loss : 3760.3974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 483 | train_loss : 5630.7294921875 | val_loss : 20600.234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 484 | train_loss : 7877.50244140625 | val_loss : 6691.34228515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 485 | train_loss : 8939.0517578125 | val_loss : 16089.080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 486 | train_loss : 6141.41552734375 | val_loss : 4106.048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 487 | train_loss : 4925.76025390625 | val_loss : 16021.55859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 488 | train_loss : 5878.61572265625 | val_loss : 2691.918701171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 489 | train_loss : 5002.759765625 | val_loss : 15194.4453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 490 | train_loss : 6533.87646484375 | val_loss : 3541.773193359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 491 | train_loss : 7036.15576171875 | val_loss : 25674.240234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 492 | train_loss : 14600.6650390625 | val_loss : 4011.0048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 493 | train_loss : 9583.6650390625 | val_loss : 23528.990234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 494 | train_loss : 13073.357421875 | val_loss : 3516.0673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 495 | train_loss : 8977.1591796875 | val_loss : 20103.14453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 496 | train_loss : 8577.2802734375 | val_loss : 4108.41064453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 497 | train_loss : 7485.67041015625 | val_loss : 18326.376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 498 | train_loss : 6913.89501953125 | val_loss : 6867.29638671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 499 | train_loss : 6577.58056640625 | val_loss : 17781.80078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 500 | train_loss : 6633.544921875 | val_loss : 98642.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 501 | train_loss : 114427.34375 | val_loss : 49389.44921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 502 | train_loss : 34078.3125 | val_loss : 10696.5615234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 503 | train_loss : 11882.35546875 | val_loss : 21486.783203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 504 | train_loss : 14008.19140625 | val_loss : 8006.0498046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 505 | train_loss : 9261.1953125 | val_loss : 19251.46484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 506 | train_loss : 12209.3720703125 | val_loss : 7697.412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 507 | train_loss : 8146.7587890625 | val_loss : 13132.88671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 508 | train_loss : 6724.009765625 | val_loss : 7224.708984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 509 | train_loss : 6096.162109375 | val_loss : 18345.77734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 510 | train_loss : 14363.9228515625 | val_loss : 16515.705078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 511 | train_loss : 24253.810546875 | val_loss : 18700.685546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 512 | train_loss : 14464.0908203125 | val_loss : 13921.857421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 513 | train_loss : 6125.0263671875 | val_loss : 5800.17138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 514 | train_loss : 4759.630859375 | val_loss : 13071.87109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 515 | train_loss : 4161.20556640625 | val_loss : 4473.09375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 516 | train_loss : 3513.79443359375 | val_loss : 9397.361328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 517 | train_loss : 2688.038818359375 | val_loss : 4064.141845703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 518 | train_loss : 2782.50439453125 | val_loss : 13666.5634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 519 | train_loss : 3626.659423828125 | val_loss : 3976.583740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 520 | train_loss : 4477.79296875 | val_loss : 14317.83984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 521 | train_loss : 3708.8173828125 | val_loss : 3760.014892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 522 | train_loss : 4064.222412109375 | val_loss : 12916.080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 523 | train_loss : 3479.858642578125 | val_loss : 3490.9287109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 524 | train_loss : 3328.37744140625 | val_loss : 11835.3515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 525 | train_loss : 2781.075927734375 | val_loss : 102456.8828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 526 | train_loss : 94530.84375 | val_loss : 71414.75 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 527 | train_loss : 65474.12890625 | val_loss : 30815.669921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 528 | train_loss : 27873.2734375 | val_loss : 30493.240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 529 | train_loss : 26028.5 | val_loss : 12689.1474609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 530 | train_loss : 4861.96728515625 | val_loss : 10749.076171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 531 | train_loss : 4983.0712890625 | val_loss : 10508.1787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 532 | train_loss : 4513.18798828125 | val_loss : 12287.90234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 533 | train_loss : 5607.2939453125 | val_loss : 9758.83984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 534 | train_loss : 5280.6806640625 | val_loss : 17419.7578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 535 | train_loss : 10553.54296875 | val_loss : 7252.03857421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 536 | train_loss : 7296.21142578125 | val_loss : 23842.4453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 537 | train_loss : 12705.384765625 | val_loss : 6314.15771484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 538 | train_loss : 6302.697265625 | val_loss : 16452.828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 539 | train_loss : 6230.26708984375 | val_loss : 4958.3017578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 540 | train_loss : 5710.369140625 | val_loss : 15393.115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 541 | train_loss : 5361.17919921875 | val_loss : 3452.3505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 542 | train_loss : 3169.285400390625 | val_loss : 10304.7373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 543 | train_loss : 3588.58056640625 | val_loss : 3551.764892578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 544 | train_loss : 3093.851318359375 | val_loss : 11091.49609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 545 | train_loss : 3686.4248046875 | val_loss : 3179.57373046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 546 | train_loss : 3587.363525390625 | val_loss : 13320.48046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 547 | train_loss : 4894.205078125 | val_loss : 3959.66259765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 548 | train_loss : 4674.4169921875 | val_loss : 14391.3125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 549 | train_loss : 5144.85009765625 | val_loss : 3770.01123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 550 | train_loss : 4312.1474609375 | val_loss : 13824.0 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 551 | train_loss : 5008.61328125 | val_loss : 4626.93798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 552 | train_loss : 5245.1611328125 | val_loss : 15166.5283203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 553 | train_loss : 5133.12890625 | val_loss : 3472.734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 554 | train_loss : 4475.7177734375 | val_loss : 14079.6240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 555 | train_loss : 4959.10595703125 | val_loss : 2848.478759765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 556 | train_loss : 3603.862548828125 | val_loss : 15985.1640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 557 | train_loss : 6538.11572265625 | val_loss : 3369.83056640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 558 | train_loss : 6765.16943359375 | val_loss : 24338.03515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 559 | train_loss : 13100.3564453125 | val_loss : 3749.1474609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 560 | train_loss : 7616.6025390625 | val_loss : 22303.650390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 561 | train_loss : 12180.8388671875 | val_loss : 3286.478759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 562 | train_loss : 6431.55859375 | val_loss : 16028.5546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 563 | train_loss : 6247.80517578125 | val_loss : 3492.154296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 564 | train_loss : 4387.6904296875 | val_loss : 11002.724609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 565 | train_loss : 4161.4140625 | val_loss : 3242.820556640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 566 | train_loss : 3578.7978515625 | val_loss : 12917.8828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 567 | train_loss : 4645.73291015625 | val_loss : 3548.246826171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 568 | train_loss : 4308.416015625 | val_loss : 15099.787109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 569 | train_loss : 5263.17919921875 | val_loss : 3643.00634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 570 | train_loss : 4303.91748046875 | val_loss : 14206.5263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 571 | train_loss : 5076.00830078125 | val_loss : 3670.416259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 572 | train_loss : 4098.03466796875 | val_loss : 12849.9853515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 573 | train_loss : 4407.201171875 | val_loss : 3768.905517578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 574 | train_loss : 4899.02685546875 | val_loss : 15176.732421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 575 | train_loss : 5052.697265625 | val_loss : 3687.7275390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 576 | train_loss : 4803.34423828125 | val_loss : 14799.25 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 577 | train_loss : 5239.7451171875 | val_loss : 3162.845703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 578 | train_loss : 3458.5986328125 | val_loss : 11273.6435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 579 | train_loss : 3717.13818359375 | val_loss : 3456.4580078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 580 | train_loss : 3552.47119140625 | val_loss : 11892.537109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 581 | train_loss : 4193.36083984375 | val_loss : 3400.88134765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 582 | train_loss : 3324.9306640625 | val_loss : 11131.7177734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 583 | train_loss : 3641.13134765625 | val_loss : 3444.203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 584 | train_loss : 3478.9736328125 | val_loss : 12178.7138671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 585 | train_loss : 4340.48193359375 | val_loss : 3444.64501953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 586 | train_loss : 3154.150634765625 | val_loss : 11185.728515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 587 | train_loss : 3719.434326171875 | val_loss : 3548.58251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 588 | train_loss : 3172.322265625 | val_loss : 11129.3779296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 589 | train_loss : 3640.4892578125 | val_loss : 3476.47119140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 590 | train_loss : 3336.0498046875 | val_loss : 11682.9111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 591 | train_loss : 4095.81591796875 | val_loss : 2958.871337890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 592 | train_loss : 4177.39990234375 | val_loss : 13026.513671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 593 | train_loss : 4363.3349609375 | val_loss : 2820.621337890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 594 | train_loss : 3510.5869140625 | val_loss : 12450.0224609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 595 | train_loss : 4297.27685546875 | val_loss : 3790.02001953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 596 | train_loss : 4895.78515625 | val_loss : 17767.79296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 597 | train_loss : 6572.24853515625 | val_loss : 4499.1123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 598 | train_loss : 6376.47509765625 | val_loss : 23263.0 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 599 | train_loss : 12093.958984375 | val_loss : 3327.336181640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 600 | train_loss : 6880.71484375 | val_loss : 21243.4453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 601 | train_loss : 10129.7548828125 | val_loss : 3613.686279296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 602 | train_loss : 8128.7451171875 | val_loss : 22818.873046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 603 | train_loss : 11106.61328125 | val_loss : 10481.6201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 604 | train_loss : 15198.41015625 | val_loss : 30566.232421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 605 | train_loss : 20251.4140625 | val_loss : 15009.025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 606 | train_loss : 12470.13671875 | val_loss : 19663.67578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 607 | train_loss : 10003.0908203125 | val_loss : 7635.1748046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 608 | train_loss : 8161.27392578125 | val_loss : 16162.2939453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 609 | train_loss : 8059.6630859375 | val_loss : 5204.71826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 610 | train_loss : 5785.1298828125 | val_loss : 14858.1962890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 611 | train_loss : 6069.294921875 | val_loss : 4730.50732421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 612 | train_loss : 4506.58642578125 | val_loss : 12374.1533203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 613 | train_loss : 4497.5322265625 | val_loss : 4439.380859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 614 | train_loss : 3320.864990234375 | val_loss : 14393.6591796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 615 | train_loss : 4925.31298828125 | val_loss : 3701.081787109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 616 | train_loss : 3639.383056640625 | val_loss : 13372.791015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 617 | train_loss : 4286.64306640625 | val_loss : 4050.09130859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 618 | train_loss : 5177.35205078125 | val_loss : 15378.9765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 619 | train_loss : 5161.89697265625 | val_loss : 4209.53759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 620 | train_loss : 5345.74267578125 | val_loss : 13363.4990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 621 | train_loss : 4468.24267578125 | val_loss : 3476.1201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 622 | train_loss : 2977.664794921875 | val_loss : 10759.302734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 623 | train_loss : 3657.68310546875 | val_loss : 3564.326171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 624 | train_loss : 3502.515625 | val_loss : 9981.9560546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 625 | train_loss : 3387.8857421875 | val_loss : 3384.46435546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 626 | train_loss : 2793.646484375 | val_loss : 10932.2646484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 627 | train_loss : 3752.163818359375 | val_loss : 3096.952392578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 628 | train_loss : 3517.42626953125 | val_loss : 12455.7587890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 629 | train_loss : 4268.0244140625 | val_loss : 2614.87060546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 630 | train_loss : 3881.0126953125 | val_loss : 13137.7275390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 631 | train_loss : 4519.28759765625 | val_loss : 2444.601318359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 632 | train_loss : 3420.663818359375 | val_loss : 10578.48828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 633 | train_loss : 3820.8095703125 | val_loss : 2511.561279296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 634 | train_loss : 3693.233154296875 | val_loss : 16970.3515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 635 | train_loss : 6939.7685546875 | val_loss : 8199.2890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 636 | train_loss : 12287.3173828125 | val_loss : 24073.560546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 637 | train_loss : 12710.763671875 | val_loss : 5074.77294921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 638 | train_loss : 6788.23486328125 | val_loss : 16406.3828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 639 | train_loss : 6549.48681640625 | val_loss : 2821.74755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 640 | train_loss : 4345.7080078125 | val_loss : 13870.39453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 641 | train_loss : 4671.7099609375 | val_loss : 2704.3037109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 642 | train_loss : 3291.145263671875 | val_loss : 13059.3427734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 643 | train_loss : 3850.078125 | val_loss : 3188.427490234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 644 | train_loss : 3546.601806640625 | val_loss : 12697.025390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 645 | train_loss : 4478.87255859375 | val_loss : 3471.891357421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 646 | train_loss : 4163.697265625 | val_loss : 13696.4697265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 647 | train_loss : 4779.5361328125 | val_loss : 3278.193115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 648 | train_loss : 3474.39990234375 | val_loss : 13068.3388671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 649 | train_loss : 4261.66259765625 | val_loss : 2992.434326171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 650 | train_loss : 3659.67431640625 | val_loss : 12274.3740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 651 | train_loss : 4285.06298828125 | val_loss : 2913.613037109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 652 | train_loss : 3006.630615234375 | val_loss : 10450.5703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 653 | train_loss : 3567.263671875 | val_loss : 3101.188232421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 654 | train_loss : 3398.29541015625 | val_loss : 14247.4052734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 655 | train_loss : 4878.7138671875 | val_loss : 2903.517578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 656 | train_loss : 3269.99755859375 | val_loss : 11799.505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 657 | train_loss : 4627.8134765625 | val_loss : 2902.84814453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 658 | train_loss : 3355.1630859375 | val_loss : 10019.1748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 659 | train_loss : 3526.95458984375 | val_loss : 3064.984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 660 | train_loss : 2573.460205078125 | val_loss : 10565.58984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 661 | train_loss : 3882.513671875 | val_loss : 2774.63427734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 662 | train_loss : 3214.702392578125 | val_loss : 9788.72265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 663 | train_loss : 3311.97216796875 | val_loss : 2411.331787109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 664 | train_loss : 3165.188232421875 | val_loss : 12597.482421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 665 | train_loss : 4502.83251953125 | val_loss : 2524.7412109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 666 | train_loss : 2688.04443359375 | val_loss : 10652.6328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 667 | train_loss : 3877.740234375 | val_loss : 3031.435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 668 | train_loss : 2590.803466796875 | val_loss : 9441.380859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 669 | train_loss : 3703.905517578125 | val_loss : 3172.26123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 670 | train_loss : 2600.28173828125 | val_loss : 10010.6796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 671 | train_loss : 4107.14306640625 | val_loss : 2954.985107421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 672 | train_loss : 2689.795654296875 | val_loss : 9225.509765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 673 | train_loss : 3520.636474609375 | val_loss : 2395.224365234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 674 | train_loss : 2997.016357421875 | val_loss : 12181.8095703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 675 | train_loss : 4946.974609375 | val_loss : 3193.1875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 676 | train_loss : 4774.9130859375 | val_loss : 14706.00390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 677 | train_loss : 5788.986328125 | val_loss : 2208.603759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 678 | train_loss : 3163.153076171875 | val_loss : 13111.5791015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 679 | train_loss : 4256.890625 | val_loss : 3779.027587890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 680 | train_loss : 4283.40625 | val_loss : 13706.603515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 681 | train_loss : 5240.1044921875 | val_loss : 4182.177734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 682 | train_loss : 5195.31298828125 | val_loss : 14940.4111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 683 | train_loss : 5374.625 | val_loss : 4839.900390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 684 | train_loss : 5014.33642578125 | val_loss : 10938.3623046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 685 | train_loss : 3918.72314453125 | val_loss : 2906.304931640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 686 | train_loss : 2257.16796875 | val_loss : 11233.09375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 687 | train_loss : 4194.6064453125 | val_loss : 2591.0419921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 688 | train_loss : 3309.90478515625 | val_loss : 13547.41796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 689 | train_loss : 5152.6982421875 | val_loss : 2289.68115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 690 | train_loss : 2968.341796875 | val_loss : 10129.8388671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 691 | train_loss : 3964.33740234375 | val_loss : 3018.0869140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 692 | train_loss : 3348.535400390625 | val_loss : 12018.2890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 693 | train_loss : 4163.12353515625 | val_loss : 2821.55322265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 694 | train_loss : 3188.672119140625 | val_loss : 13098.79296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 695 | train_loss : 4551.49658203125 | val_loss : 2668.00244140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 696 | train_loss : 3587.297607421875 | val_loss : 13031.9189453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 697 | train_loss : 4697.7431640625 | val_loss : 2801.454345703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 698 | train_loss : 3389.240234375 | val_loss : 13031.09375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 699 | train_loss : 4908.6015625 | val_loss : 1944.3125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 700 | train_loss : 3370.7880859375 | val_loss : 12039.6220703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 701 | train_loss : 4290.33203125 | val_loss : 1992.5074462890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 702 | train_loss : 2894.014404296875 | val_loss : 12450.67578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 703 | train_loss : 4608.4306640625 | val_loss : 2889.3388671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 704 | train_loss : 3760.267822265625 | val_loss : 14369.9404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 705 | train_loss : 5247.4658203125 | val_loss : 3739.963134765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 706 | train_loss : 4393.83935546875 | val_loss : 13682.974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 707 | train_loss : 5088.259765625 | val_loss : 4364.21826171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 708 | train_loss : 4654.91015625 | val_loss : 15854.603515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 709 | train_loss : 5904.9794921875 | val_loss : 5094.43310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 710 | train_loss : 5168.98583984375 | val_loss : 12200.05078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 711 | train_loss : 4478.30517578125 | val_loss : 3581.324951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 712 | train_loss : 2854.17724609375 | val_loss : 11856.7734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 713 | train_loss : 4815.30224609375 | val_loss : 3590.126953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 714 | train_loss : 3824.26416015625 | val_loss : 16802.666015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 715 | train_loss : 7051.5341796875 | val_loss : 3538.75 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 716 | train_loss : 5163.755859375 | val_loss : 21097.060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 717 | train_loss : 10197.173828125 | val_loss : 3932.8798828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 718 | train_loss : 4875.9169921875 | val_loss : 14130.04296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 719 | train_loss : 5616.25732421875 | val_loss : 3189.01123046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 720 | train_loss : 2760.373779296875 | val_loss : 8418.611328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 721 | train_loss : 2447.711181640625 | val_loss : 3545.559326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 722 | train_loss : 2162.832275390625 | val_loss : 8531.18359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 723 | train_loss : 2826.10302734375 | val_loss : 3633.190673828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 724 | train_loss : 1834.4013671875 | val_loss : 9840.2958984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 725 | train_loss : 3857.746826171875 | val_loss : 3477.139404296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 726 | train_loss : 2759.512451171875 | val_loss : 10297.140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 727 | train_loss : 4214.7470703125 | val_loss : 3452.550537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 728 | train_loss : 2009.44091796875 | val_loss : 9766.2978515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 729 | train_loss : 3685.5625 | val_loss : 3117.550048828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 730 | train_loss : 2189.47900390625 | val_loss : 11375.73828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 731 | train_loss : 4106.75927734375 | val_loss : 2514.873779296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 732 | train_loss : 3156.68310546875 | val_loss : 12829.900390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 733 | train_loss : 4488.7138671875 | val_loss : 3314.706787109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 734 | train_loss : 3947.267822265625 | val_loss : 14809.294921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 735 | train_loss : 5245.53369140625 | val_loss : 4385.92626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 736 | train_loss : 4377.7138671875 | val_loss : 12394.9833984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 737 | train_loss : 4253.96826171875 | val_loss : 2487.92431640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 738 | train_loss : 2944.63623046875 | val_loss : 13689.02734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 739 | train_loss : 4987.3076171875 | val_loss : 2508.768798828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 740 | train_loss : 3525.244384765625 | val_loss : 13128.3876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 741 | train_loss : 4743.2412109375 | val_loss : 2586.75244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 742 | train_loss : 3766.156982421875 | val_loss : 12424.798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 743 | train_loss : 4438.01416015625 | val_loss : 71991.609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 744 | train_loss : 106544.3828125 | val_loss : 108211.203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 745 | train_loss : 67027.9921875 | val_loss : 50397.43359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 746 | train_loss : 41564.203125 | val_loss : 16962.892578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 747 | train_loss : 15682.1083984375 | val_loss : 30014.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 748 | train_loss : 23260.408203125 | val_loss : 17098.359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 749 | train_loss : 13683.1875 | val_loss : 18801.849609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 750 | train_loss : 8218.3896484375 | val_loss : 11298.9599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 751 | train_loss : 4975.39013671875 | val_loss : 8889.771484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 752 | train_loss : 2169.804931640625 | val_loss : 7796.583984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 753 | train_loss : 1747.173583984375 | val_loss : 9814.349609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 754 | train_loss : 1455.9168701171875 | val_loss : 6289.16064453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 755 | train_loss : 1884.6256103515625 | val_loss : 13994.4697265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 756 | train_loss : 2267.47900390625 | val_loss : 5215.2470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 757 | train_loss : 2930.66748046875 | val_loss : 12799.8564453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 758 | train_loss : 2305.840576171875 | val_loss : 4410.8095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 759 | train_loss : 2813.2880859375 | val_loss : 12460.5751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 760 | train_loss : 3274.764404296875 | val_loss : 8502.3759765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 761 | train_loss : 6657.60107421875 | val_loss : 16608.341796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 762 | train_loss : 15301.6552734375 | val_loss : 37973.1953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 763 | train_loss : 31302.6171875 | val_loss : 13975.802734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 764 | train_loss : 4221.40869140625 | val_loss : 5293.71826171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 765 | train_loss : 3738.793701171875 | val_loss : 12545.7861328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 766 | train_loss : 2615.35009765625 | val_loss : 5212.90576171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 767 | train_loss : 1909.1309814453125 | val_loss : 12592.40234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 768 | train_loss : 2323.761474609375 | val_loss : 4565.1650390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 769 | train_loss : 2015.0643310546875 | val_loss : 12032.8603515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 770 | train_loss : 2166.72216796875 | val_loss : 4254.16748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 771 | train_loss : 2892.277099609375 | val_loss : 12223.5498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 772 | train_loss : 2392.3916015625 | val_loss : 3922.94189453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 773 | train_loss : 2770.82275390625 | val_loss : 10926.15234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 774 | train_loss : 2177.726806640625 | val_loss : 4087.992431640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 775 | train_loss : 1526.9827880859375 | val_loss : 10249.1025390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 776 | train_loss : 1877.653564453125 | val_loss : 3853.83251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 777 | train_loss : 1206.2928466796875 | val_loss : 7341.48876953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 778 | train_loss : 1325.778076171875 | val_loss : 3549.2431640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 779 | train_loss : 1521.830322265625 | val_loss : 10411.8720703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 780 | train_loss : 2016.368408203125 | val_loss : 3558.822509765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 781 | train_loss : 1992.727783203125 | val_loss : 10301.5947265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 782 | train_loss : 2061.48486328125 | val_loss : 2902.5830078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 783 | train_loss : 1779.685302734375 | val_loss : 8723.8681640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 784 | train_loss : 1785.919677734375 | val_loss : 2916.463134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 785 | train_loss : 1327.699951171875 | val_loss : 10406.9541015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 786 | train_loss : 2228.3603515625 | val_loss : 3212.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 787 | train_loss : 2510.06494140625 | val_loss : 10705.2783203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 788 | train_loss : 2621.796875 | val_loss : 2737.482421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 789 | train_loss : 1821.10791015625 | val_loss : 10238.9228515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 790 | train_loss : 2542.491943359375 | val_loss : 3382.73876953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 791 | train_loss : 2689.359375 | val_loss : 12592.55078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 792 | train_loss : 3271.375 | val_loss : 5109.45458984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 793 | train_loss : 4565.099609375 | val_loss : 15257.3427734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 794 | train_loss : 4643.083984375 | val_loss : 7503.95703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 795 | train_loss : 6093.7412109375 | val_loss : 11502.3876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 796 | train_loss : 3922.689453125 | val_loss : 5604.92919921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 797 | train_loss : 3491.37353515625 | val_loss : 11888.4697265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 798 | train_loss : 3279.32666015625 | val_loss : 5090.35498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 799 | train_loss : 4814.1787109375 | val_loss : 12154.0908203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 4 | epoch : 800 | train_loss : 3751.242919921875 | val_loss : 4329.2001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 5 | epoch : 1 | train_loss : 914296.9375 | val_loss : 342125.28125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 2 | train_loss : 379266.3125 | val_loss : 305220.1875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 3 | train_loss : 297159.59375 | val_loss : 585523.25 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 4 | train_loss : 494312.59375 | val_loss : 447006.5625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 5 | train_loss : 409967.71875 | val_loss : 264250.75 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 6 | train_loss : 245524.65625 | val_loss : 159345.515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 7 | train_loss : 177794.078125 | val_loss : 138296.296875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 8 | train_loss : 140271.8125 | val_loss : 234930.453125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 9 | train_loss : 215546.359375 | val_loss : 195292.359375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 10 | train_loss : 243777.90625 | val_loss : 250538.796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 11 | train_loss : 215498.734375 | val_loss : 172558.859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 12 | train_loss : 167575.71875 | val_loss : 208442.21875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 13 | train_loss : 180597.140625 | val_loss : 100041.953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 14 | train_loss : 117714.0078125 | val_loss : 111714.7421875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 15 | train_loss : 104649.078125 | val_loss : 60088.390625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 16 | train_loss : 83818.8203125 | val_loss : 189648.4375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 17 | train_loss : 135792.140625 | val_loss : 78798.2265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 18 | train_loss : 68497.21875 | val_loss : 163848.71875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 19 | train_loss : 127718.609375 | val_loss : 86579.296875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 20 | train_loss : 79186.34375 | val_loss : 163335.34375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 21 | train_loss : 132064.828125 | val_loss : 126764.4921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 22 | train_loss : 127851.2265625 | val_loss : 79929.671875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 23 | train_loss : 72037.21875 | val_loss : 60834.6796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 24 | train_loss : 66990.625 | val_loss : 102636.578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 25 | train_loss : 122776.25 | val_loss : 163681.5625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 26 | train_loss : 147490.3125 | val_loss : 55116.8359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 27 | train_loss : 40617.98046875 | val_loss : 40087.54296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 28 | train_loss : 42070.99609375 | val_loss : 80511.484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 29 | train_loss : 87804.3984375 | val_loss : 176822.5625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 30 | train_loss : 142466.5 | val_loss : 45095.87890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 31 | train_loss : 48448.75390625 | val_loss : 176019.15625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 32 | train_loss : 136016.703125 | val_loss : 187644.09375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 33 | train_loss : 142127.5625 | val_loss : 156650.71875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 34 | train_loss : 168032.125 | val_loss : 103757.53125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 35 | train_loss : 80993.9140625 | val_loss : 38125.07421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 36 | train_loss : 47115.8046875 | val_loss : 149702.953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 37 | train_loss : 136883.203125 | val_loss : 88308.71875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 38 | train_loss : 71611.3671875 | val_loss : 59258.1796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 39 | train_loss : 67024.8125 | val_loss : 100790.65625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 40 | train_loss : 115653.8125 | val_loss : 139816.9375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 41 | train_loss : 135186.671875 | val_loss : 95822.0625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 42 | train_loss : 61441.0859375 | val_loss : 67815.71875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 43 | train_loss : 80911.5 | val_loss : 78957.9921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 44 | train_loss : 46322.55078125 | val_loss : 19567.1875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 45 | train_loss : 20522.779296875 | val_loss : 98404.2578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 46 | train_loss : 91944.9609375 | val_loss : 94551.3828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 47 | train_loss : 100905.546875 | val_loss : 122590.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 48 | train_loss : 120128.15625 | val_loss : 117519.3203125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 49 | train_loss : 91358.921875 | val_loss : 124825.203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 50 | train_loss : 102660.2265625 | val_loss : 104933.390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 51 | train_loss : 112204.109375 | val_loss : 150199.90625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 52 | train_loss : 130201.71875 | val_loss : 99279.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 53 | train_loss : 70825.15625 | val_loss : 46433.69921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 54 | train_loss : 32189.998046875 | val_loss : 82244.1484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 55 | train_loss : 76692.734375 | val_loss : 60691.3046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 56 | train_loss : 55035.21484375 | val_loss : 113072.6484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 57 | train_loss : 92962.078125 | val_loss : 31179.408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 58 | train_loss : 31296.67578125 | val_loss : 122958.84375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 59 | train_loss : 105314.6328125 | val_loss : 28024.92578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 60 | train_loss : 19724.248046875 | val_loss : 65600.5703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 61 | train_loss : 60313.55859375 | val_loss : 89690.046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 62 | train_loss : 74503.421875 | val_loss : 108007.828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 63 | train_loss : 87980.546875 | val_loss : 38746.8828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 64 | train_loss : 50969.84375 | val_loss : 148489.609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 65 | train_loss : 124556.5078125 | val_loss : 17413.3203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 66 | train_loss : 12718.0576171875 | val_loss : 42525.390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 67 | train_loss : 45498.3984375 | val_loss : 95526.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 68 | train_loss : 101394.5234375 | val_loss : 48598.87109375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 69 | train_loss : 57724.14453125 | val_loss : 102104.2109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 70 | train_loss : 83420.40625 | val_loss : 93057.0234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 71 | train_loss : 69717.1328125 | val_loss : 41933.37890625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 72 | train_loss : 45105.9296875 | val_loss : 57874.01171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 73 | train_loss : 42352.9765625 | val_loss : 65100.46875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 74 | train_loss : 65474.40625 | val_loss : 70967.546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 75 | train_loss : 60102.30078125 | val_loss : 138186.21875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 76 | train_loss : 106058.25 | val_loss : 115709.6796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 77 | train_loss : 94094.75 | val_loss : 43012.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 78 | train_loss : 36737.7265625 | val_loss : 92911.296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 79 | train_loss : 95327.9609375 | val_loss : 41675.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 80 | train_loss : 43999.67578125 | val_loss : 81800.15625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 81 | train_loss : 66723.1015625 | val_loss : 39383.80859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 82 | train_loss : 39362.38671875 | val_loss : 43560.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 83 | train_loss : 38982.84765625 | val_loss : 80992.1328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 84 | train_loss : 89334.453125 | val_loss : 49625.14453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 85 | train_loss : 52480.62109375 | val_loss : 61345.38671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 86 | train_loss : 53048.3203125 | val_loss : 39625.125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 87 | train_loss : 40643.2265625 | val_loss : 88674.9296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 88 | train_loss : 73194.1328125 | val_loss : 127241.0703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 89 | train_loss : 132453.609375 | val_loss : 115209.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 90 | train_loss : 106542.359375 | val_loss : 63349.86328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 91 | train_loss : 40000.25390625 | val_loss : 52734.328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 92 | train_loss : 59878.32421875 | val_loss : 33437.56640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 93 | train_loss : 19104.462890625 | val_loss : 50855.9453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 94 | train_loss : 43037.35546875 | val_loss : 98543.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 95 | train_loss : 72586.6015625 | val_loss : 63834.1484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 96 | train_loss : 41422.1015625 | val_loss : 33706.87890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 97 | train_loss : 39260.44140625 | val_loss : 63220.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 98 | train_loss : 62312.46875 | val_loss : 32234.984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 99 | train_loss : 28375.669921875 | val_loss : 92139.796875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 100 | train_loss : 67979.9921875 | val_loss : 78197.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 101 | train_loss : 56106.609375 | val_loss : 47776.8359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 102 | train_loss : 33896.87109375 | val_loss : 42463.4140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 103 | train_loss : 46443.34375 | val_loss : 100592.171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 104 | train_loss : 89782.1875 | val_loss : 25610.912109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 105 | train_loss : 26265.53515625 | val_loss : 52624.83984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 106 | train_loss : 38393.90625 | val_loss : 44354.33984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 107 | train_loss : 41724.234375 | val_loss : 52598.765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 108 | train_loss : 44998.57421875 | val_loss : 45281.61328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 109 | train_loss : 51583.99609375 | val_loss : 30675.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 110 | train_loss : 13003.7578125 | val_loss : 21949.61328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 111 | train_loss : 21096.17578125 | val_loss : 131076.515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 112 | train_loss : 120355.96875 | val_loss : 91923.3515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 113 | train_loss : 98437.46875 | val_loss : 56560.23828125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 114 | train_loss : 50722.55078125 | val_loss : 58335.671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 115 | train_loss : 47973.125 | val_loss : 50440.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 116 | train_loss : 29527.109375 | val_loss : 60264.68359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 117 | train_loss : 62785.94921875 | val_loss : 24186.16796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 118 | train_loss : 12751.4599609375 | val_loss : 71304.7890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 119 | train_loss : 64400.26953125 | val_loss : 75042.0078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 120 | train_loss : 72750.6484375 | val_loss : 46249.265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 121 | train_loss : 54634.48046875 | val_loss : 93804.7109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 122 | train_loss : 62477.06640625 | val_loss : 56511.265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 123 | train_loss : 61704.4609375 | val_loss : 22300.095703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 124 | train_loss : 17031.412109375 | val_loss : 74995.453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 125 | train_loss : 47584.69140625 | val_loss : 115767.4375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 126 | train_loss : 96713.203125 | val_loss : 112530.4609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 127 | train_loss : 83502.84375 | val_loss : 16982.318359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 128 | train_loss : 19694.7578125 | val_loss : 37423.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 129 | train_loss : 30541.6484375 | val_loss : 37839.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 130 | train_loss : 37778.70703125 | val_loss : 90397.203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 131 | train_loss : 80327.9375 | val_loss : 24671.189453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 132 | train_loss : 22492.8984375 | val_loss : 67834.28125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 133 | train_loss : 50849.31640625 | val_loss : 97383.65625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 134 | train_loss : 72668.6796875 | val_loss : 58544.08984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 135 | train_loss : 43745.984375 | val_loss : 35708.0390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 136 | train_loss : 33180.01171875 | val_loss : 41143.19921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 137 | train_loss : 45050.078125 | val_loss : 24520.26171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 138 | train_loss : 12160.8125 | val_loss : 50438.75390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 139 | train_loss : 40967.4453125 | val_loss : 58501.78125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 140 | train_loss : 42846.51171875 | val_loss : 53899.87109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 141 | train_loss : 36502.08984375 | val_loss : 46333.515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 142 | train_loss : 44655.75390625 | val_loss : 80514.1640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 143 | train_loss : 70905.5625 | val_loss : 24980.3203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 144 | train_loss : 22533.080078125 | val_loss : 53148.609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 145 | train_loss : 38035.88671875 | val_loss : 98146.5390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 146 | train_loss : 76693.375 | val_loss : 63756.640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 147 | train_loss : 47931.8046875 | val_loss : 28191.19921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 148 | train_loss : 27665.77734375 | val_loss : 44939.55859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 149 | train_loss : 42822.24609375 | val_loss : 27400.408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 150 | train_loss : 18007.5234375 | val_loss : 66294.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 151 | train_loss : 48328.7109375 | val_loss : 55878.3359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 152 | train_loss : 40403.6953125 | val_loss : 46085.5390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 153 | train_loss : 31327.552734375 | val_loss : 42204.5859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 154 | train_loss : 39114.73828125 | val_loss : 70365.109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 155 | train_loss : 64790.0 | val_loss : 23373.10546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 156 | train_loss : 21412.8046875 | val_loss : 59010.73046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 157 | train_loss : 43472.34375 | val_loss : 64679.01953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 158 | train_loss : 69782.3515625 | val_loss : 33298.1875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 159 | train_loss : 28807.115234375 | val_loss : 38459.13671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 160 | train_loss : 24506.39453125 | val_loss : 42368.51953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 161 | train_loss : 42278.68359375 | val_loss : 22096.359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 162 | train_loss : 10074.52734375 | val_loss : 33882.26953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 163 | train_loss : 26190.869140625 | val_loss : 65526.484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 164 | train_loss : 47263.37109375 | val_loss : 50646.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 165 | train_loss : 37928.15625 | val_loss : 20622.05078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 166 | train_loss : 20605.1875 | val_loss : 67929.90625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 167 | train_loss : 54978.4140625 | val_loss : 34824.80078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 168 | train_loss : 25480.775390625 | val_loss : 47703.5 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 169 | train_loss : 30414.904296875 | val_loss : 60153.921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 170 | train_loss : 45122.43359375 | val_loss : 50232.80859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 171 | train_loss : 40877.5234375 | val_loss : 19792.591796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 172 | train_loss : 15526.044921875 | val_loss : 55890.375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 173 | train_loss : 41362.98046875 | val_loss : 45452.3984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 174 | train_loss : 34382.296875 | val_loss : 53498.921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 175 | train_loss : 42307.80078125 | val_loss : 23933.615234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 176 | train_loss : 21221.462890625 | val_loss : 89384.1015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 177 | train_loss : 77597.3046875 | val_loss : 25974.935546875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 178 | train_loss : 24792.755859375 | val_loss : 30363.287109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 179 | train_loss : 24571.033203125 | val_loss : 38582.74609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 180 | train_loss : 39818.06640625 | val_loss : 19874.306640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 181 | train_loss : 10611.6748046875 | val_loss : 42166.5 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 182 | train_loss : 43160.3359375 | val_loss : 70547.71875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 183 | train_loss : 51806.765625 | val_loss : 26518.69921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 184 | train_loss : 18593.71875 | val_loss : 60946.15625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 185 | train_loss : 38723.38671875 | val_loss : 59352.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 186 | train_loss : 43636.640625 | val_loss : 65952.1796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 187 | train_loss : 49857.5 | val_loss : 18347.3203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 188 | train_loss : 17142.056640625 | val_loss : 57635.96875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 189 | train_loss : 44166.640625 | val_loss : 17911.060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 190 | train_loss : 12665.4189453125 | val_loss : 57518.57421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 191 | train_loss : 47497.85546875 | val_loss : 24853.76953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 192 | train_loss : 17040.314453125 | val_loss : 47009.05078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 193 | train_loss : 32513.787109375 | val_loss : 63005.62890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 194 | train_loss : 47379.75390625 | val_loss : 46128.21484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 195 | train_loss : 36693.92578125 | val_loss : 23005.0 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 196 | train_loss : 24737.828125 | val_loss : 36913.15625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 197 | train_loss : 33769.1484375 | val_loss : 23099.619140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 198 | train_loss : 10884.8974609375 | val_loss : 35965.5546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 199 | train_loss : 31646.1875 | val_loss : 27557.546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 200 | train_loss : 13299.6162109375 | val_loss : 50033.7109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 201 | train_loss : 38691.3359375 | val_loss : 50126.23828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 202 | train_loss : 35599.6484375 | val_loss : 31086.115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 203 | train_loss : 14153.6279296875 | val_loss : 29611.494140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 204 | train_loss : 33676.10546875 | val_loss : 71246.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 205 | train_loss : 60660.07421875 | val_loss : 28359.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 206 | train_loss : 26454.28515625 | val_loss : 30702.064453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 207 | train_loss : 25394.990234375 | val_loss : 32072.39453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 208 | train_loss : 29717.337890625 | val_loss : 19613.734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 209 | train_loss : 14082.7763671875 | val_loss : 45453.359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 210 | train_loss : 47081.796875 | val_loss : 16929.13671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 211 | train_loss : 8891.962890625 | val_loss : 16628.970703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 212 | train_loss : 14314.7490234375 | val_loss : 39812.94140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 213 | train_loss : 33737.53515625 | val_loss : 16494.10546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 214 | train_loss : 15512.6826171875 | val_loss : 48486.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 215 | train_loss : 35347.7890625 | val_loss : 28833.212890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 216 | train_loss : 22076.900390625 | val_loss : 41491.58984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 217 | train_loss : 34364.953125 | val_loss : 20337.66796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 218 | train_loss : 14351.2890625 | val_loss : 40044.7578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 219 | train_loss : 29435.466796875 | val_loss : 65074.35546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 220 | train_loss : 49748.3046875 | val_loss : 31963.283203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 221 | train_loss : 31021.82421875 | val_loss : 39315.53515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 222 | train_loss : 28543.935546875 | val_loss : 37489.73046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 223 | train_loss : 35302.015625 | val_loss : 19419.66796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 224 | train_loss : 6660.9375 | val_loss : 28640.9140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 225 | train_loss : 14521.103515625 | val_loss : 35810.2734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 226 | train_loss : 25131.45703125 | val_loss : 57128.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 227 | train_loss : 40468.046875 | val_loss : 41913.88671875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 228 | train_loss : 23216.189453125 | val_loss : 35124.25390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 229 | train_loss : 40253.89453125 | val_loss : 88769.4921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 230 | train_loss : 83890.9921875 | val_loss : 23914.83984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 231 | train_loss : 22573.15234375 | val_loss : 51509.953125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 232 | train_loss : 28676.30078125 | val_loss : 18738.623046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 233 | train_loss : 22442.234375 | val_loss : 37922.49609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 234 | train_loss : 23074.107421875 | val_loss : 24587.60546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 235 | train_loss : 27579.158203125 | val_loss : 51655.921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 236 | train_loss : 45105.21484375 | val_loss : 18645.634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 237 | train_loss : 16936.2421875 | val_loss : 45560.765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 238 | train_loss : 30177.580078125 | val_loss : 28134.310546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 239 | train_loss : 22458.7109375 | val_loss : 53936.01171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 240 | train_loss : 44675.83984375 | val_loss : 14158.64453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 241 | train_loss : 11226.0498046875 | val_loss : 37652.51171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 242 | train_loss : 22663.205078125 | val_loss : 43488.69140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 243 | train_loss : 34434.953125 | val_loss : 40376.94140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 244 | train_loss : 34255.484375 | val_loss : 14893.5302734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 245 | train_loss : 11347.26171875 | val_loss : 47455.30859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 246 | train_loss : 26706.599609375 | val_loss : 38095.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 247 | train_loss : 36926.07421875 | val_loss : 36289.4140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 248 | train_loss : 15198.7158203125 | val_loss : 16381.1591796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 249 | train_loss : 7873.88330078125 | val_loss : 28759.623046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 250 | train_loss : 11832.255859375 | val_loss : 17044.115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 251 | train_loss : 11500.962890625 | val_loss : 43822.03515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 252 | train_loss : 34349.11328125 | val_loss : 17481.369140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 253 | train_loss : 14179.41015625 | val_loss : 62906.69140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 254 | train_loss : 45244.12109375 | val_loss : 22183.904296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 255 | train_loss : 17605.9140625 | val_loss : 48568.4140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 256 | train_loss : 34106.37890625 | val_loss : 23098.640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 257 | train_loss : 14959.6474609375 | val_loss : 35631.18359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 258 | train_loss : 22437.470703125 | val_loss : 28438.404296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 259 | train_loss : 20199.81640625 | val_loss : 44763.30859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 260 | train_loss : 34497.98828125 | val_loss : 11171.1376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 261 | train_loss : 7047.9619140625 | val_loss : 29815.859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 262 | train_loss : 19357.6328125 | val_loss : 23275.28515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 263 | train_loss : 20593.6484375 | val_loss : 57912.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 264 | train_loss : 48091.84375 | val_loss : 15974.2890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 265 | train_loss : 15603.384765625 | val_loss : 81406.5078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 266 | train_loss : 70832.4140625 | val_loss : 25185.58984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 267 | train_loss : 24260.1796875 | val_loss : 49750.828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 268 | train_loss : 30579.08203125 | val_loss : 47361.71875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 269 | train_loss : 50689.046875 | val_loss : 34710.82421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 270 | train_loss : 18976.48828125 | val_loss : 27145.572265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 271 | train_loss : 21537.0234375 | val_loss : 55959.86328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 272 | train_loss : 42906.85546875 | val_loss : 14728.6875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 273 | train_loss : 9572.6083984375 | val_loss : 29169.59765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 274 | train_loss : 9251.7197265625 | val_loss : 15224.0283203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 275 | train_loss : 5398.56640625 | val_loss : 49912.546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 276 | train_loss : 35340.640625 | val_loss : 46755.4765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 277 | train_loss : 46479.28515625 | val_loss : 29226.599609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 278 | train_loss : 18200.79296875 | val_loss : 44900.55078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 279 | train_loss : 28720.095703125 | val_loss : 28395.845703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 280 | train_loss : 11665.955078125 | val_loss : 24898.390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 281 | train_loss : 28222.7109375 | val_loss : 51942.26953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 282 | train_loss : 36791.18359375 | val_loss : 25383.39453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 283 | train_loss : 17360.63671875 | val_loss : 38794.28515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 284 | train_loss : 17838.8125 | val_loss : 37557.76171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 285 | train_loss : 32406.9140625 | val_loss : 51013.38671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 286 | train_loss : 38573.46875 | val_loss : 13874.478515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 287 | train_loss : 8161.66015625 | val_loss : 29613.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 288 | train_loss : 11499.44921875 | val_loss : 15428.0146484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 289 | train_loss : 6634.04638671875 | val_loss : 38176.43359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 290 | train_loss : 20890.630859375 | val_loss : 26877.875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 291 | train_loss : 22187.57421875 | val_loss : 18579.4609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 292 | train_loss : 10508.455078125 | val_loss : 31953.880859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 293 | train_loss : 27524.662109375 | val_loss : 17687.7578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 294 | train_loss : 7423.333984375 | val_loss : 23137.9453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 295 | train_loss : 17250.029296875 | val_loss : 30332.2578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 296 | train_loss : 25974.07421875 | val_loss : 23827.91015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 297 | train_loss : 22041.310546875 | val_loss : 26698.802734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 298 | train_loss : 15795.7236328125 | val_loss : 26847.376953125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 299 | train_loss : 25848.83984375 | val_loss : 30308.140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 300 | train_loss : 20813.8203125 | val_loss : 22620.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 301 | train_loss : 22407.97265625 | val_loss : 22924.689453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 302 | train_loss : 12994.1337890625 | val_loss : 22649.17578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 303 | train_loss : 22158.404296875 | val_loss : 25442.724609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 304 | train_loss : 21286.171875 | val_loss : 22210.51953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 305 | train_loss : 22899.359375 | val_loss : 17701.1953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 306 | train_loss : 6676.9560546875 | val_loss : 8817.5556640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 307 | train_loss : 5237.16552734375 | val_loss : 16966.310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 308 | train_loss : 7385.669921875 | val_loss : 14623.494140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 309 | train_loss : 12795.6748046875 | val_loss : 26240.484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 310 | train_loss : 17335.7265625 | val_loss : 30365.04296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 311 | train_loss : 28312.623046875 | val_loss : 22192.1640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 312 | train_loss : 10260.0048828125 | val_loss : 11645.90625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 313 | train_loss : 6060.615234375 | val_loss : 22633.359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 314 | train_loss : 11084.4970703125 | val_loss : 17343.82421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 315 | train_loss : 20935.732421875 | val_loss : 52021.30859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 316 | train_loss : 37047.23828125 | val_loss : 16916.90234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 317 | train_loss : 12054.7470703125 | val_loss : 28754.859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 318 | train_loss : 11178.712890625 | val_loss : 34667.4765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 319 | train_loss : 26191.955078125 | val_loss : 30692.580078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 320 | train_loss : 21762.927734375 | val_loss : 12197.962890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 321 | train_loss : 10008.54296875 | val_loss : 33636.359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 322 | train_loss : 21076.314453125 | val_loss : 19244.09765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 323 | train_loss : 22906.4609375 | val_loss : 52425.56640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 324 | train_loss : 37715.01171875 | val_loss : 12196.2314453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 325 | train_loss : 6061.5087890625 | val_loss : 24233.080078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 326 | train_loss : 8718.0634765625 | val_loss : 29318.724609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 327 | train_loss : 22674.32421875 | val_loss : 30823.23046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 328 | train_loss : 23528.349609375 | val_loss : 11923.3076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 329 | train_loss : 4299.45166015625 | val_loss : 28348.8359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 330 | train_loss : 13181.357421875 | val_loss : 24259.849609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 331 | train_loss : 19528.498046875 | val_loss : 38712.90625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 332 | train_loss : 31319.1015625 | val_loss : 13043.634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 333 | train_loss : 7321.58740234375 | val_loss : 26473.4453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 334 | train_loss : 10401.9404296875 | val_loss : 13058.1103515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 335 | train_loss : 10228.6064453125 | val_loss : 32943.6171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 336 | train_loss : 25577.134765625 | val_loss : 11213.03125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 337 | train_loss : 9216.8623046875 | val_loss : 35454.4375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 338 | train_loss : 22411.58984375 | val_loss : 14807.4111328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 339 | train_loss : 7324.630859375 | val_loss : 27328.470703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 340 | train_loss : 13971.6416015625 | val_loss : 22794.755859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 341 | train_loss : 16969.025390625 | val_loss : 33988.65625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 342 | train_loss : 25643.9296875 | val_loss : 10205.3408203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 343 | train_loss : 4895.22119140625 | val_loss : 23261.6953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 344 | train_loss : 8376.498046875 | val_loss : 27360.58203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 345 | train_loss : 22563.693359375 | val_loss : 42247.046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 346 | train_loss : 35136.56640625 | val_loss : 17719.2578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 347 | train_loss : 12535.6240234375 | val_loss : 42274.56640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 348 | train_loss : 23749.9296875 | val_loss : 28582.123046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 349 | train_loss : 26692.052734375 | val_loss : 21892.435546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 350 | train_loss : 3769.38134765625 | val_loss : 15346.0400390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 351 | train_loss : 4911.11767578125 | val_loss : 30156.1953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 352 | train_loss : 10768.3447265625 | val_loss : 30483.60546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 353 | train_loss : 25194.009765625 | val_loss : 45961.80859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 354 | train_loss : 31851.5078125 | val_loss : 12702.884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 355 | train_loss : 7784.97314453125 | val_loss : 25259.1640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 356 | train_loss : 11095.212890625 | val_loss : 16417.09375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 357 | train_loss : 19193.67578125 | val_loss : 27014.587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 358 | train_loss : 16460.76953125 | val_loss : 15885.978515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 359 | train_loss : 15531.08203125 | val_loss : 45295.01953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 360 | train_loss : 29025.533203125 | val_loss : 13351.544921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 361 | train_loss : 5949.87451171875 | val_loss : 23567.2421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 362 | train_loss : 9814.1162109375 | val_loss : 22574.23828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 363 | train_loss : 17789.5703125 | val_loss : 32452.640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 364 | train_loss : 23047.095703125 | val_loss : 9461.0205078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 365 | train_loss : 4389.0205078125 | val_loss : 22389.26953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 366 | train_loss : 8638.56640625 | val_loss : 16582.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 367 | train_loss : 11916.7998046875 | val_loss : 30095.75 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 368 | train_loss : 19917.16796875 | val_loss : 9574.751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 369 | train_loss : 5607.08740234375 | val_loss : 25177.587890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 370 | train_loss : 10765.947265625 | val_loss : 21055.314453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 371 | train_loss : 16135.9208984375 | val_loss : 30737.599609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 372 | train_loss : 21634.1640625 | val_loss : 9312.4814453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 373 | train_loss : 4773.59619140625 | val_loss : 21575.822265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 374 | train_loss : 8641.3740234375 | val_loss : 17779.720703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 375 | train_loss : 12514.2822265625 | val_loss : 29769.642578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 376 | train_loss : 20787.296875 | val_loss : 8828.4970703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 377 | train_loss : 5020.35693359375 | val_loss : 20814.33203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 378 | train_loss : 8021.70751953125 | val_loss : 13004.9853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 379 | train_loss : 12754.9638671875 | val_loss : 33710.23828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 380 | train_loss : 22382.875 | val_loss : 8930.1728515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 381 | train_loss : 6245.85986328125 | val_loss : 34685.65625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 382 | train_loss : 25870.365234375 | val_loss : 13652.4326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 383 | train_loss : 19899.044921875 | val_loss : 18975.48828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 384 | train_loss : 9464.2490234375 | val_loss : 11636.1513671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 385 | train_loss : 8008.49609375 | val_loss : 21016.759765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 386 | train_loss : 10880.5927734375 | val_loss : 12280.7041015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 387 | train_loss : 10294.8623046875 | val_loss : 30910.73046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 388 | train_loss : 17137.880859375 | val_loss : 19180.20703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 389 | train_loss : 11277.357421875 | val_loss : 24515.5546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 390 | train_loss : 12024.4296875 | val_loss : 17357.2109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 391 | train_loss : 9472.7822265625 | val_loss : 23672.71484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 392 | train_loss : 12842.017578125 | val_loss : 17513.048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 393 | train_loss : 9260.0283203125 | val_loss : 24544.240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 394 | train_loss : 11641.98828125 | val_loss : 18167.9140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 395 | train_loss : 10100.3984375 | val_loss : 25514.9296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 396 | train_loss : 14312.974609375 | val_loss : 13571.38671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 397 | train_loss : 7458.6689453125 | val_loss : 26030.265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 398 | train_loss : 11669.4423828125 | val_loss : 13057.3935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 399 | train_loss : 10613.4970703125 | val_loss : 53510.96484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 400 | train_loss : 44678.55859375 | val_loss : 31942.60546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 401 | train_loss : 44997.62890625 | val_loss : 90318.8125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 402 | train_loss : 53622.55859375 | val_loss : 27506.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 403 | train_loss : 15667.26171875 | val_loss : 25195.13671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 404 | train_loss : 24803.26171875 | val_loss : 17024.283203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 405 | train_loss : 4224.95556640625 | val_loss : 12242.34765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 406 | train_loss : 5515.66552734375 | val_loss : 19311.23046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 407 | train_loss : 7924.4501953125 | val_loss : 15488.7001953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 408 | train_loss : 9955.677734375 | val_loss : 28859.740234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 409 | train_loss : 16479.51953125 | val_loss : 13302.1328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 410 | train_loss : 8915.884765625 | val_loss : 29702.1328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 411 | train_loss : 14645.1015625 | val_loss : 21349.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 412 | train_loss : 10746.138671875 | val_loss : 24224.091796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 413 | train_loss : 8622.5595703125 | val_loss : 14742.4326171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 414 | train_loss : 6644.3876953125 | val_loss : 25850.974609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 415 | train_loss : 11964.6240234375 | val_loss : 14927.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 416 | train_loss : 11340.806640625 | val_loss : 33388.796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 417 | train_loss : 19297.38671875 | val_loss : 11586.83203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 418 | train_loss : 5515.86767578125 | val_loss : 19135.640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 419 | train_loss : 5825.33447265625 | val_loss : 12738.2275390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 420 | train_loss : 6753.1611328125 | val_loss : 24852.21484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 421 | train_loss : 10639.138671875 | val_loss : 13184.4453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 422 | train_loss : 9186.599609375 | val_loss : 63084.6796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 423 | train_loss : 44089.75 | val_loss : 42922.7265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 424 | train_loss : 43813.49609375 | val_loss : 76157.2578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 425 | train_loss : 40735.78515625 | val_loss : 27743.76953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 426 | train_loss : 19689.63671875 | val_loss : 25186.65234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 427 | train_loss : 21568.76953125 | val_loss : 14898.58203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 428 | train_loss : 2334.66357421875 | val_loss : 13771.607421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 429 | train_loss : 1799.31982421875 | val_loss : 16610.552734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 430 | train_loss : 1691.670166015625 | val_loss : 12994.1796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 431 | train_loss : 1955.7215576171875 | val_loss : 19077.8828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 432 | train_loss : 2578.29931640625 | val_loss : 12767.77734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 433 | train_loss : 3430.10693359375 | val_loss : 20209.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 434 | train_loss : 4385.19873046875 | val_loss : 14640.23046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 435 | train_loss : 6178.57763671875 | val_loss : 18372.462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 436 | train_loss : 10203.4072265625 | val_loss : 23399.685546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 437 | train_loss : 17224.970703125 | val_loss : 16166.4951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 438 | train_loss : 8310.6220703125 | val_loss : 21530.28515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 439 | train_loss : 13682.8212890625 | val_loss : 18949.751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 440 | train_loss : 8993.087890625 | val_loss : 19564.115234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 441 | train_loss : 12972.7451171875 | val_loss : 17475.501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 442 | train_loss : 7434.18310546875 | val_loss : 15879.61328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 443 | train_loss : 8973.3583984375 | val_loss : 17784.1796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 444 | train_loss : 7886.1669921875 | val_loss : 16115.1376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 445 | train_loss : 10313.615234375 | val_loss : 15868.0302734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 446 | train_loss : 6327.9638671875 | val_loss : 15763.33984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 447 | train_loss : 8552.2001953125 | val_loss : 17393.744140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 448 | train_loss : 7320.13623046875 | val_loss : 15892.412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 449 | train_loss : 10083.3701171875 | val_loss : 15823.62109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 450 | train_loss : 5942.138671875 | val_loss : 15760.076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 451 | train_loss : 9187.2255859375 | val_loss : 16294.4990234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 452 | train_loss : 6829.95361328125 | val_loss : 14899.4833984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 453 | train_loss : 9056.564453125 | val_loss : 15889.0625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 454 | train_loss : 5624.990234375 | val_loss : 13995.3154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 455 | train_loss : 7746.48681640625 | val_loss : 16224.1474609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 456 | train_loss : 5765.46728515625 | val_loss : 109585.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 457 | train_loss : 117098.4765625 | val_loss : 98530.7578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 458 | train_loss : 66696.3515625 | val_loss : 51081.03125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 459 | train_loss : 27375.845703125 | val_loss : 23040.130859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 460 | train_loss : 15217.599609375 | val_loss : 32150.224609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 461 | train_loss : 10935.37890625 | val_loss : 19896.580078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 462 | train_loss : 6360.658203125 | val_loss : 15236.5146484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 463 | train_loss : 6061.34130859375 | val_loss : 23604.60546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 464 | train_loss : 8493.4951171875 | val_loss : 20184.39453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 465 | train_loss : 9524.10546875 | val_loss : 29379.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 466 | train_loss : 13273.2099609375 | val_loss : 17791.009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 467 | train_loss : 8819.8623046875 | val_loss : 30644.384765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 468 | train_loss : 12534.2109375 | val_loss : 21065.44921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 469 | train_loss : 8120.37255859375 | val_loss : 26958.7421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 470 | train_loss : 9387.525390625 | val_loss : 18383.189453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 471 | train_loss : 6759.568359375 | val_loss : 23216.744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 472 | train_loss : 7391.552734375 | val_loss : 18910.33984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 473 | train_loss : 6415.66064453125 | val_loss : 28911.814453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 474 | train_loss : 11482.150390625 | val_loss : 16262.2451171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 475 | train_loss : 10119.0478515625 | val_loss : 25820.189453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 476 | train_loss : 10131.13671875 | val_loss : 13987.7890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 477 | train_loss : 6701.1787109375 | val_loss : 22867.76171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 478 | train_loss : 7340.27392578125 | val_loss : 15014.2783203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 479 | train_loss : 5120.287109375 | val_loss : 24019.310546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 480 | train_loss : 7742.95947265625 | val_loss : 13934.634765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 481 | train_loss : 6843.142578125 | val_loss : 23024.119140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 482 | train_loss : 7323.4248046875 | val_loss : 15615.8095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 483 | train_loss : 6976.67919921875 | val_loss : 28191.76953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 484 | train_loss : 11829.65625 | val_loss : 14484.6572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 485 | train_loss : 6200.1904296875 | val_loss : 22552.83984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 486 | train_loss : 7211.150390625 | val_loss : 16127.853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 487 | train_loss : 5753.34619140625 | val_loss : 23547.259765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 488 | train_loss : 6794.6513671875 | val_loss : 16147.75 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 489 | train_loss : 5634.8779296875 | val_loss : 23635.96484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 490 | train_loss : 7132.49609375 | val_loss : 17756.552734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 491 | train_loss : 5677.41064453125 | val_loss : 23200.125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 492 | train_loss : 6885.0380859375 | val_loss : 15493.25390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 493 | train_loss : 6666.9462890625 | val_loss : 23158.251953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 494 | train_loss : 7703.06396484375 | val_loss : 15399.05859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 495 | train_loss : 8908.1552734375 | val_loss : 28129.216796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 496 | train_loss : 12254.82421875 | val_loss : 14042.8759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 497 | train_loss : 8670.1923828125 | val_loss : 24025.5390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 498 | train_loss : 8781.708984375 | val_loss : 14052.9638671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 499 | train_loss : 6485.06982421875 | val_loss : 22794.58203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 500 | train_loss : 7224.1123046875 | val_loss : 16386.16796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 501 | train_loss : 4734.5322265625 | val_loss : 22339.63671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 502 | train_loss : 5776.6533203125 | val_loss : 15426.607421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 503 | train_loss : 4779.626953125 | val_loss : 21155.654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 504 | train_loss : 5036.44873046875 | val_loss : 14326.3974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 505 | train_loss : 3957.518798828125 | val_loss : 20670.671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 506 | train_loss : 4492.5517578125 | val_loss : 15144.8984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 507 | train_loss : 4135.18115234375 | val_loss : 22290.220703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 508 | train_loss : 5383.04296875 | val_loss : 15297.4248046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 509 | train_loss : 4625.6533203125 | val_loss : 23840.20703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 510 | train_loss : 6817.2568359375 | val_loss : 15198.5458984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 511 | train_loss : 9558.2578125 | val_loss : 25997.7890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 512 | train_loss : 11380.4873046875 | val_loss : 14034.3720703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 513 | train_loss : 9948.3359375 | val_loss : 24694.123046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 514 | train_loss : 10439.568359375 | val_loss : 14255.5625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 515 | train_loss : 7136.5498046875 | val_loss : 22870.615234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 516 | train_loss : 6980.74609375 | val_loss : 16374.525390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 517 | train_loss : 4759.357421875 | val_loss : 23897.015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 518 | train_loss : 5607.88623046875 | val_loss : 17955.904296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 519 | train_loss : 6849.134765625 | val_loss : 24960.34765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 520 | train_loss : 8461.177734375 | val_loss : 18401.498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 521 | train_loss : 6453.61669921875 | val_loss : 23696.849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 522 | train_loss : 6909.892578125 | val_loss : 20501.314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 523 | train_loss : 7755.234375 | val_loss : 25773.080078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 524 | train_loss : 9647.5966796875 | val_loss : 17204.51171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 525 | train_loss : 6439.11669921875 | val_loss : 25077.685546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 526 | train_loss : 8811.71484375 | val_loss : 14977.8876953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 527 | train_loss : 9662.36328125 | val_loss : 24628.724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 528 | train_loss : 9104.7744140625 | val_loss : 14806.3427734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 529 | train_loss : 7978.22021484375 | val_loss : 22996.14453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 530 | train_loss : 7864.20947265625 | val_loss : 14699.955078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 531 | train_loss : 5913.39892578125 | val_loss : 20268.658203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 532 | train_loss : 5620.32958984375 | val_loss : 15802.7626953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 533 | train_loss : 3061.597412109375 | val_loss : 21704.13671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 534 | train_loss : 4589.0498046875 | val_loss : 13872.27734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 535 | train_loss : 4056.409423828125 | val_loss : 21566.408203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 536 | train_loss : 4998.60693359375 | val_loss : 14961.91015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 537 | train_loss : 4852.6962890625 | val_loss : 20604.244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 538 | train_loss : 4705.03076171875 | val_loss : 13385.7353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 539 | train_loss : 3769.4658203125 | val_loss : 19375.220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 540 | train_loss : 3489.5419921875 | val_loss : 14317.080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 541 | train_loss : 3076.50927734375 | val_loss : 21633.546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 542 | train_loss : 4971.48291015625 | val_loss : 14211.0595703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 543 | train_loss : 9161.26953125 | val_loss : 24962.490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 544 | train_loss : 10292.5166015625 | val_loss : 12909.3388671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 545 | train_loss : 10204.765625 | val_loss : 22754.244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 546 | train_loss : 9494.0576171875 | val_loss : 13576.607421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 547 | train_loss : 7155.34130859375 | val_loss : 28282.171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 548 | train_loss : 11573.4287109375 | val_loss : 16720.609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 549 | train_loss : 10014.955078125 | val_loss : 28355.16015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 550 | train_loss : 10855.9775390625 | val_loss : 18604.466796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 551 | train_loss : 6267.82080078125 | val_loss : 21067.3984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 552 | train_loss : 4868.51416015625 | val_loss : 18604.3828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 553 | train_loss : 10036.9033203125 | val_loss : 30307.185546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 554 | train_loss : 14470.8046875 | val_loss : 12338.1201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 555 | train_loss : 5231.796875 | val_loss : 19411.435546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 556 | train_loss : 5660.05517578125 | val_loss : 13412.3984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 557 | train_loss : 5775.48876953125 | val_loss : 21318.0390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 558 | train_loss : 5859.83544921875 | val_loss : 13952.275390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 559 | train_loss : 5318.1845703125 | val_loss : 22332.67578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 560 | train_loss : 6291.443359375 | val_loss : 15866.580078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 561 | train_loss : 4522.888671875 | val_loss : 20206.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 562 | train_loss : 3811.95068359375 | val_loss : 12613.72265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 563 | train_loss : 3300.018798828125 | val_loss : 44890.1484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 564 | train_loss : 31670.251953125 | val_loss : 31532.564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 565 | train_loss : 24908.275390625 | val_loss : 29320.79296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 566 | train_loss : 16687.265625 | val_loss : 15246.92578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 567 | train_loss : 9714.58984375 | val_loss : 25183.0390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 568 | train_loss : 10122.052734375 | val_loss : 13029.900390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 569 | train_loss : 7754.9736328125 | val_loss : 20460.041015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 570 | train_loss : 5797.9033203125 | val_loss : 13730.5498046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 571 | train_loss : 3219.0244140625 | val_loss : 18365.48828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 572 | train_loss : 2920.5048828125 | val_loss : 12744.68359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 573 | train_loss : 3042.557861328125 | val_loss : 17282.90234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 574 | train_loss : 2208.1943359375 | val_loss : 13845.5927734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 575 | train_loss : 1988.85498046875 | val_loss : 20596.220703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 576 | train_loss : 2922.324951171875 | val_loss : 14034.861328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 577 | train_loss : 3289.96435546875 | val_loss : 20097.591796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 578 | train_loss : 3715.284423828125 | val_loss : 13833.662109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 579 | train_loss : 3537.814453125 | val_loss : 20022.2109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 580 | train_loss : 4092.469482421875 | val_loss : 12846.7822265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 581 | train_loss : 7755.8935546875 | val_loss : 23036.318359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 582 | train_loss : 8642.634765625 | val_loss : 13868.9208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 583 | train_loss : 9507.4228515625 | val_loss : 24048.1953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 584 | train_loss : 9061.33203125 | val_loss : 13105.6748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 585 | train_loss : 7245.78369140625 | val_loss : 21472.181640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 586 | train_loss : 6069.2099609375 | val_loss : 14129.625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 587 | train_loss : 4017.772216796875 | val_loss : 19638.828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 588 | train_loss : 3879.1533203125 | val_loss : 13098.830078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 589 | train_loss : 3741.90283203125 | val_loss : 17576.556640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 590 | train_loss : 2799.30908203125 | val_loss : 13194.330078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 591 | train_loss : 2093.700439453125 | val_loss : 16960.2578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 592 | train_loss : 2297.660400390625 | val_loss : 12717.5341796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 593 | train_loss : 1925.3653564453125 | val_loss : 18129.015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 594 | train_loss : 1924.3052978515625 | val_loss : 12760.615234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 595 | train_loss : 2770.080078125 | val_loss : 19546.92578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 596 | train_loss : 3072.86376953125 | val_loss : 13313.4970703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 597 | train_loss : 3605.838134765625 | val_loss : 19430.0390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 598 | train_loss : 3608.08447265625 | val_loss : 12654.4208984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 599 | train_loss : 4710.58349609375 | val_loss : 20377.228515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 600 | train_loss : 6416.24951171875 | val_loss : 13670.0400390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 601 | train_loss : 13857.072265625 | val_loss : 22682.990234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 602 | train_loss : 10279.728515625 | val_loss : 12053.080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 603 | train_loss : 7418.37255859375 | val_loss : 21335.681640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 604 | train_loss : 7054.7119140625 | val_loss : 11508.8779296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 605 | train_loss : 6823.03271484375 | val_loss : 17884.1796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 606 | train_loss : 4492.443359375 | val_loss : 13114.2099609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 607 | train_loss : 2228.701171875 | val_loss : 18290.001953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 608 | train_loss : 2537.98876953125 | val_loss : 11637.5029296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 609 | train_loss : 2832.84375 | val_loss : 17067.79296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 610 | train_loss : 1950.6722412109375 | val_loss : 11661.869140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 611 | train_loss : 2796.621337890625 | val_loss : 16871.626953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 612 | train_loss : 1507.09130859375 | val_loss : 12269.4375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 613 | train_loss : 2233.14208984375 | val_loss : 17373.76953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 614 | train_loss : 1704.5853271484375 | val_loss : 12644.3046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 615 | train_loss : 2908.492431640625 | val_loss : 18691.3359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 616 | train_loss : 2689.390625 | val_loss : 12441.1201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 617 | train_loss : 2839.4130859375 | val_loss : 17080.263671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 618 | train_loss : 1684.1422119140625 | val_loss : 11989.3466796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 619 | train_loss : 1906.315185546875 | val_loss : 16253.892578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 620 | train_loss : 945.1962280273438 | val_loss : 12729.6748046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 621 | train_loss : 978.5042114257812 | val_loss : 17737.08203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 622 | train_loss : 1152.61572265625 | val_loss : 12524.4990234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 623 | train_loss : 1592.9404296875 | val_loss : 17868.38671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 624 | train_loss : 1253.795166015625 | val_loss : 12906.3154296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 625 | train_loss : 1791.9580078125 | val_loss : 54740.82421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 626 | train_loss : 32750.3125 | val_loss : 33885.87109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 627 | train_loss : 29458.5 | val_loss : 34037.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 628 | train_loss : 22454.015625 | val_loss : 10626.5859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 629 | train_loss : 7233.15625 | val_loss : 19512.404296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 630 | train_loss : 6174.32421875 | val_loss : 13808.7177734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 631 | train_loss : 9050.0849609375 | val_loss : 24213.150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 632 | train_loss : 9305.59765625 | val_loss : 12192.3076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 633 | train_loss : 7313.60009765625 | val_loss : 19710.40234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 634 | train_loss : 5306.810546875 | val_loss : 13596.75 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 635 | train_loss : 3630.4755859375 | val_loss : 18068.01953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 636 | train_loss : 2835.37939453125 | val_loss : 12258.224609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 637 | train_loss : 3122.099365234375 | val_loss : 16763.712890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 638 | train_loss : 1872.2674560546875 | val_loss : 12499.263671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 639 | train_loss : 2135.671875 | val_loss : 18255.193359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 640 | train_loss : 1791.8343505859375 | val_loss : 12518.96484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 641 | train_loss : 2520.88623046875 | val_loss : 17289.90234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 642 | train_loss : 1751.2967529296875 | val_loss : 12765.8154296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 643 | train_loss : 2186.00146484375 | val_loss : 17764.94921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 644 | train_loss : 1957.0894775390625 | val_loss : 13263.0078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 645 | train_loss : 2062.590087890625 | val_loss : 17896.240234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 646 | train_loss : 1638.073486328125 | val_loss : 12636.9375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 647 | train_loss : 1950.6087646484375 | val_loss : 17771.416015625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 648 | train_loss : 1198.1318359375 | val_loss : 12920.462890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 649 | train_loss : 1324.2606201171875 | val_loss : 17940.5703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 650 | train_loss : 1174.1234130859375 | val_loss : 13415.7509765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 651 | train_loss : 1360.484375 | val_loss : 18220.810546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 652 | train_loss : 1483.766845703125 | val_loss : 13027.4296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 653 | train_loss : 1505.6221923828125 | val_loss : 31681.654296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 654 | train_loss : 13621.6171875 | val_loss : 32250.134765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 655 | train_loss : 26317.595703125 | val_loss : 163716.34375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 656 | train_loss : 134176.359375 | val_loss : 21861.779296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 657 | train_loss : 21627.435546875 | val_loss : 25953.734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 658 | train_loss : 10853.771484375 | val_loss : 13479.65234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 659 | train_loss : 3912.935546875 | val_loss : 18541.126953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 660 | train_loss : 4623.13427734375 | val_loss : 11931.92578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 661 | train_loss : 5904.09130859375 | val_loss : 20112.3828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 662 | train_loss : 6158.17041015625 | val_loss : 13091.3583984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 663 | train_loss : 8223.0791015625 | val_loss : 22622.189453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 664 | train_loss : 7629.5693359375 | val_loss : 12131.1435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 665 | train_loss : 8069.3681640625 | val_loss : 19161.8359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 666 | train_loss : 4884.63916015625 | val_loss : 13850.8115234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 667 | train_loss : 2984.1005859375 | val_loss : 18852.197265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 668 | train_loss : 2554.92822265625 | val_loss : 12221.455078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 669 | train_loss : 2882.19775390625 | val_loss : 16859.494140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 670 | train_loss : 1691.156982421875 | val_loss : 12761.7001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 671 | train_loss : 1777.4580078125 | val_loss : 18204.07421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 672 | train_loss : 1650.3616943359375 | val_loss : 14247.26171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 673 | train_loss : 4122.1875 | val_loss : 25952.400390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 674 | train_loss : 8541.66796875 | val_loss : 16588.62109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 675 | train_loss : 5005.5341796875 | val_loss : 20569.072265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 676 | train_loss : 4838.96728515625 | val_loss : 13161.572265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 677 | train_loss : 5958.54833984375 | val_loss : 20057.9453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 678 | train_loss : 6171.6689453125 | val_loss : 13209.1748046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 679 | train_loss : 8204.44921875 | val_loss : 21915.34765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 680 | train_loss : 7043.9970703125 | val_loss : 12059.505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 681 | train_loss : 7792.650390625 | val_loss : 20321.185546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 682 | train_loss : 5723.27978515625 | val_loss : 12750.900390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 683 | train_loss : 4785.84521484375 | val_loss : 19773.021484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 684 | train_loss : 4746.77587890625 | val_loss : 13046.8623046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 685 | train_loss : 2837.19384765625 | val_loss : 16798.564453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 686 | train_loss : 1536.4208984375 | val_loss : 12130.9423828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 687 | train_loss : 2143.44677734375 | val_loss : 16848.740234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 688 | train_loss : 1243.858642578125 | val_loss : 28781.669921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 689 | train_loss : 29180.025390625 | val_loss : 65292.87890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 690 | train_loss : 43559.015625 | val_loss : 23056.984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 691 | train_loss : 9549.9833984375 | val_loss : 16967.185546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 692 | train_loss : 3826.834716796875 | val_loss : 12631.5595703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 693 | train_loss : 3966.591796875 | val_loss : 15573.642578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 694 | train_loss : 2102.135009765625 | val_loss : 13622.2490234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 695 | train_loss : 2684.88916015625 | val_loss : 17913.505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 696 | train_loss : 1844.425048828125 | val_loss : 13664.1376953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 697 | train_loss : 2314.23681640625 | val_loss : 18604.974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 698 | train_loss : 2272.1220703125 | val_loss : 13046.974609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 699 | train_loss : 2429.32080078125 | val_loss : 16626.267578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 700 | train_loss : 1619.3062744140625 | val_loss : 14092.5322265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 701 | train_loss : 1383.8909912109375 | val_loss : 19356.7890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 702 | train_loss : 2354.427978515625 | val_loss : 14233.5 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 703 | train_loss : 2241.9326171875 | val_loss : 18387.435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 704 | train_loss : 2278.852294921875 | val_loss : 14011.5625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 705 | train_loss : 3150.277587890625 | val_loss : 16896.484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 706 | train_loss : 3113.0615234375 | val_loss : 15755.4228515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 707 | train_loss : 3676.650634765625 | val_loss : 16514.466796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 708 | train_loss : 10019.28515625 | val_loss : 18824.92578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 709 | train_loss : 11365.1865234375 | val_loss : 16145.9228515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 710 | train_loss : 8162.28759765625 | val_loss : 15099.34765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 711 | train_loss : 6719.32373046875 | val_loss : 15600.3173828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 712 | train_loss : 6997.37060546875 | val_loss : 12933.705078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 713 | train_loss : 5648.0830078125 | val_loss : 15188.9287109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 714 | train_loss : 2505.494140625 | val_loss : 11877.3349609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 715 | train_loss : 2122.125 | val_loss : 15959.15625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 716 | train_loss : 1678.9732666015625 | val_loss : 11583.95703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 717 | train_loss : 2146.70654296875 | val_loss : 15969.705078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 718 | train_loss : 1621.5189208984375 | val_loss : 11764.3779296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 719 | train_loss : 1989.0284423828125 | val_loss : 16210.88671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 720 | train_loss : 1546.64892578125 | val_loss : 11529.365234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 721 | train_loss : 2140.628173828125 | val_loss : 16405.15625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 722 | train_loss : 1328.516845703125 | val_loss : 11624.9853515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 723 | train_loss : 2100.407470703125 | val_loss : 16426.794921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 724 | train_loss : 1375.1646728515625 | val_loss : 11700.3125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 725 | train_loss : 2046.5263671875 | val_loss : 15410.89453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 726 | train_loss : 884.8270874023438 | val_loss : 12298.177734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 727 | train_loss : 845.330810546875 | val_loss : 16780.0703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 728 | train_loss : 1105.3988037109375 | val_loss : 11707.4140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 729 | train_loss : 1949.2049560546875 | val_loss : 15844.0263671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 730 | train_loss : 1102.46875 | val_loss : 11332.333984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 731 | train_loss : 1777.966552734375 | val_loss : 15635.423828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 732 | train_loss : 829.9335327148438 | val_loss : 12120.85546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 733 | train_loss : 801.3934326171875 | val_loss : 17069.54296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 734 | train_loss : 1235.52294921875 | val_loss : 11762.3935546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 735 | train_loss : 1957.4681396484375 | val_loss : 15923.599609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 736 | train_loss : 976.176025390625 | val_loss : 11781.6328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 737 | train_loss : 1873.97607421875 | val_loss : 16031.380859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 738 | train_loss : 1176.590576171875 | val_loss : 11425.607421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 739 | train_loss : 1773.041259765625 | val_loss : 15843.8046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 740 | train_loss : 869.6779174804688 | val_loss : 11671.537109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 741 | train_loss : 1404.28662109375 | val_loss : 15891.177734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 742 | train_loss : 880.311279296875 | val_loss : 11630.587890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 743 | train_loss : 1372.989990234375 | val_loss : 15980.25 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 744 | train_loss : 936.1813354492188 | val_loss : 11470.2470703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 745 | train_loss : 1757.0240478515625 | val_loss : 15906.986328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 746 | train_loss : 913.3470458984375 | val_loss : 11396.38671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 747 | train_loss : 1834.803466796875 | val_loss : 15721.052734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 748 | train_loss : 856.9143676757812 | val_loss : 11528.5 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 749 | train_loss : 1434.8543701171875 | val_loss : 15739.6533203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 750 | train_loss : 865.792724609375 | val_loss : 11509.3447265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 751 | train_loss : 1415.2784423828125 | val_loss : 15651.88671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 752 | train_loss : 810.4169311523438 | val_loss : 11601.0625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 753 | train_loss : 1341.0340576171875 | val_loss : 15748.7763671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 754 | train_loss : 882.393798828125 | val_loss : 11625.6474609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 755 | train_loss : 1329.58056640625 | val_loss : 15757.8916015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 756 | train_loss : 895.1470947265625 | val_loss : 11548.0771484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 757 | train_loss : 1387.8984375 | val_loss : 15647.8896484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 758 | train_loss : 824.7464599609375 | val_loss : 11558.92578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 759 | train_loss : 1392.5350341796875 | val_loss : 15631.166015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 760 | train_loss : 816.298095703125 | val_loss : 11572.9521484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 761 | train_loss : 1400.2286376953125 | val_loss : 15663.4853515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 762 | train_loss : 882.0691528320312 | val_loss : 11524.8154296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 763 | train_loss : 1393.8197021484375 | val_loss : 15539.7275390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 764 | train_loss : 814.0906982421875 | val_loss : 11729.6123046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 765 | train_loss : 1044.546630859375 | val_loss : 16826.837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 766 | train_loss : 1274.2501220703125 | val_loss : 11376.9873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 767 | train_loss : 1766.9150390625 | val_loss : 16004.9296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 768 | train_loss : 1345.8677978515625 | val_loss : 11308.3916015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 769 | train_loss : 2200.26953125 | val_loss : 17156.130859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 770 | train_loss : 1931.6385498046875 | val_loss : 12963.962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 771 | train_loss : 3685.590576171875 | val_loss : 20639.029296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 772 | train_loss : 3647.143798828125 | val_loss : 13611.232421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 773 | train_loss : 3122.350341796875 | val_loss : 18835.111328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 774 | train_loss : 2800.825927734375 | val_loss : 12408.705078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 775 | train_loss : 2927.113037109375 | val_loss : 17807.078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 776 | train_loss : 2113.094482421875 | val_loss : 11488.89453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 777 | train_loss : 2105.167724609375 | val_loss : 15422.1474609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 778 | train_loss : 1083.65478515625 | val_loss : 11710.5576171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 779 | train_loss : 825.9302978515625 | val_loss : 16590.767578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 780 | train_loss : 1251.165771484375 | val_loss : 11727.66015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 781 | train_loss : 2107.763427734375 | val_loss : 17127.060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 782 | train_loss : 1733.1964111328125 | val_loss : 10678.75 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 783 | train_loss : 1648.5970458984375 | val_loss : 15530.8271484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 784 | train_loss : 949.740234375 | val_loss : 11804.0927734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 785 | train_loss : 815.3956909179688 | val_loss : 16670.439453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 786 | train_loss : 1341.1190185546875 | val_loss : 11331.59765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 787 | train_loss : 1805.02685546875 | val_loss : 15522.5263671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 788 | train_loss : 1031.056396484375 | val_loss : 11322.0302734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 789 | train_loss : 1831.5213623046875 | val_loss : 15534.9951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 790 | train_loss : 1065.66650390625 | val_loss : 11232.48828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 791 | train_loss : 1904.382080078125 | val_loss : 15493.625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 792 | train_loss : 1079.53857421875 | val_loss : 11215.3662109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 793 | train_loss : 1791.29052734375 | val_loss : 15389.63671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 794 | train_loss : 1044.4322509765625 | val_loss : 11107.607421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 795 | train_loss : 1828.3643798828125 | val_loss : 15528.2001953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 796 | train_loss : 1150.9356689453125 | val_loss : 11167.64453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 797 | train_loss : 1536.1409912109375 | val_loss : 269470.90625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 798 | train_loss : 224887.15625 | val_loss : 42230.671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 799 | train_loss : 48080.75390625 | val_loss : 57052.25390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 5 | epoch : 800 | train_loss : 41975.17578125 | val_loss : 9875.115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 6 | epoch : 1 | train_loss : 473198.8125 | val_loss : 254231.28125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 2 | train_loss : 301853.96875 | val_loss : 460469.03125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 3 | train_loss : 427298.90625 | val_loss : 140240.515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 4 | train_loss : 127910.3125 | val_loss : 215937.8125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 5 | train_loss : 257763.140625 | val_loss : 209138.265625 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 6 | train_loss : 148962.140625 | val_loss : 347082.40625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 7 | train_loss : 270940.40625 | val_loss : 290028.25 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 8 | train_loss : 273921.5 | val_loss : 312539.65625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 9 | train_loss : 304464.8125 | val_loss : 149612.4375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 10 | train_loss : 113467.7421875 | val_loss : 100604.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 11 | train_loss : 146323.5625 | val_loss : 86874.953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 12 | train_loss : 78209.96875 | val_loss : 179409.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 13 | train_loss : 128050.140625 | val_loss : 182126.296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 14 | train_loss : 173130.015625 | val_loss : 76167.03125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 15 | train_loss : 59353.80859375 | val_loss : 68234.9765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 16 | train_loss : 82424.3984375 | val_loss : 96320.0 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 17 | train_loss : 75698.984375 | val_loss : 86347.4375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 18 | train_loss : 81267.578125 | val_loss : 214963.65625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 19 | train_loss : 143753.015625 | val_loss : 158932.484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 20 | train_loss : 122710.78125 | val_loss : 141104.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 21 | train_loss : 113772.2109375 | val_loss : 94187.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 22 | train_loss : 111587.390625 | val_loss : 158003.203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 23 | train_loss : 132004.40625 | val_loss : 73750.7578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 24 | train_loss : 59337.73828125 | val_loss : 96185.1171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 25 | train_loss : 112810.578125 | val_loss : 162413.78125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 26 | train_loss : 119069.203125 | val_loss : 113757.3984375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 27 | train_loss : 90369.6875 | val_loss : 94594.8828125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 28 | train_loss : 104832.6796875 | val_loss : 73259.03125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 29 | train_loss : 47160.62890625 | val_loss : 48199.171875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 30 | train_loss : 42084.5390625 | val_loss : 82718.4765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 31 | train_loss : 55758.359375 | val_loss : 95108.7109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 32 | train_loss : 99798.0703125 | val_loss : 143177.984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 33 | train_loss : 124421.2734375 | val_loss : 44264.92578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 34 | train_loss : 26999.765625 | val_loss : 73427.40625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 35 | train_loss : 82602.3671875 | val_loss : 199500.59375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 36 | train_loss : 132654.65625 | val_loss : 191807.40625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 37 | train_loss : 137266.734375 | val_loss : 64919.76171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 38 | train_loss : 52950.015625 | val_loss : 89350.03125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 39 | train_loss : 86469.4609375 | val_loss : 136221.359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 40 | train_loss : 118505.953125 | val_loss : 23142.630859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 41 | train_loss : 13477.5654296875 | val_loss : 43165.94921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 42 | train_loss : 35039.43359375 | val_loss : 58210.57421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 43 | train_loss : 77504.7578125 | val_loss : 60283.6953125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 44 | train_loss : 37791.5859375 | val_loss : 60175.6796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 45 | train_loss : 69622.328125 | val_loss : 151823.375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 46 | train_loss : 104366.0703125 | val_loss : 101019.9609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 47 | train_loss : 77319.1953125 | val_loss : 71461.6875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 48 | train_loss : 61980.18359375 | val_loss : 115040.25 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 49 | train_loss : 89867.6328125 | val_loss : 142148.640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 50 | train_loss : 92643.84375 | val_loss : 32812.5234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 51 | train_loss : 23386.392578125 | val_loss : 53306.67578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 52 | train_loss : 37527.07421875 | val_loss : 53820.80859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 53 | train_loss : 63152.80859375 | val_loss : 72749.0234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 54 | train_loss : 56514.1640625 | val_loss : 48102.96875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 55 | train_loss : 46306.19921875 | val_loss : 52604.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 56 | train_loss : 42189.69140625 | val_loss : 38699.48828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 57 | train_loss : 39525.05078125 | val_loss : 62621.62890625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 58 | train_loss : 45283.875 | val_loss : 51663.98828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 59 | train_loss : 55518.4140625 | val_loss : 101786.53125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 60 | train_loss : 67617.7421875 | val_loss : 34633.36328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 61 | train_loss : 22790.064453125 | val_loss : 52152.26171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 62 | train_loss : 43049.265625 | val_loss : 139144.34375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 63 | train_loss : 93574.046875 | val_loss : 75393.8984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 64 | train_loss : 49490.265625 | val_loss : 20653.548828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 65 | train_loss : 14118.630859375 | val_loss : 105226.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 66 | train_loss : 110322.203125 | val_loss : 150240.9375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 67 | train_loss : 106642.28125 | val_loss : 105194.7890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 68 | train_loss : 78407.046875 | val_loss : 109839.796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 69 | train_loss : 92131.9921875 | val_loss : 73797.453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 70 | train_loss : 86715.0 | val_loss : 45971.08984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 71 | train_loss : 34569.015625 | val_loss : 41526.6953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 72 | train_loss : 39190.90625 | val_loss : 94285.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 73 | train_loss : 67913.6015625 | val_loss : 29763.359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 74 | train_loss : 30949.845703125 | val_loss : 67103.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 75 | train_loss : 68010.0234375 | val_loss : 82217.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 76 | train_loss : 62222.87109375 | val_loss : 23711.162109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 77 | train_loss : 14874.6376953125 | val_loss : 29542.572265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 78 | train_loss : 19898.931640625 | val_loss : 53573.43359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 79 | train_loss : 44643.37890625 | val_loss : 22665.80078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 80 | train_loss : 23786.626953125 | val_loss : 32536.90234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 81 | train_loss : 27740.10546875 | val_loss : 70522.2421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 82 | train_loss : 62831.7734375 | val_loss : 43782.23046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 83 | train_loss : 31403.3203125 | val_loss : 100697.3515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 84 | train_loss : 71283.7265625 | val_loss : 23438.181640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 85 | train_loss : 19459.796875 | val_loss : 63633.16015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 86 | train_loss : 64760.58984375 | val_loss : 131768.859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 87 | train_loss : 88426.75 | val_loss : 75384.671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 88 | train_loss : 48379.890625 | val_loss : 27552.962890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 89 | train_loss : 18670.615234375 | val_loss : 42356.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 90 | train_loss : 38492.55078125 | val_loss : 96751.6796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 91 | train_loss : 65983.1171875 | val_loss : 32638.998046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 92 | train_loss : 22195.064453125 | val_loss : 43407.6484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 93 | train_loss : 38563.640625 | val_loss : 100753.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 94 | train_loss : 69509.8828125 | val_loss : 35722.67578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 95 | train_loss : 24303.689453125 | val_loss : 31418.740234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 96 | train_loss : 26747.587890625 | val_loss : 130279.2578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 97 | train_loss : 96612.3125 | val_loss : 112614.03125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 98 | train_loss : 106392.2265625 | val_loss : 89345.9375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 99 | train_loss : 66887.0078125 | val_loss : 45578.34375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 100 | train_loss : 41363.23828125 | val_loss : 64468.26171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 101 | train_loss : 73832.90625 | val_loss : 92233.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 102 | train_loss : 60897.515625 | val_loss : 30295.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 103 | train_loss : 24700.220703125 | val_loss : 74566.3828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 104 | train_loss : 57960.38671875 | val_loss : 27395.35546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 105 | train_loss : 23961.046875 | val_loss : 73567.0234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 106 | train_loss : 59582.8046875 | val_loss : 28641.552734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 107 | train_loss : 25990.193359375 | val_loss : 43261.48828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 108 | train_loss : 34588.6640625 | val_loss : 81993.296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 109 | train_loss : 66686.484375 | val_loss : 117600.890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 110 | train_loss : 73458.5078125 | val_loss : 62886.0703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 111 | train_loss : 42669.92578125 | val_loss : 73456.8515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 112 | train_loss : 55919.453125 | val_loss : 28176.765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 113 | train_loss : 17512.404296875 | val_loss : 25946.822265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 114 | train_loss : 18080.626953125 | val_loss : 50233.046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 115 | train_loss : 40337.66015625 | val_loss : 93864.578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 116 | train_loss : 63634.03125 | val_loss : 33046.86328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 117 | train_loss : 27510.7578125 | val_loss : 31159.015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 118 | train_loss : 25123.85546875 | val_loss : 67114.5390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 119 | train_loss : 43634.65625 | val_loss : 30547.35546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 120 | train_loss : 20998.5 | val_loss : 45377.61328125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 121 | train_loss : 38318.82421875 | val_loss : 40295.2734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 122 | train_loss : 36129.3984375 | val_loss : 79104.671875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 123 | train_loss : 54368.98046875 | val_loss : 55955.7265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 124 | train_loss : 39516.54296875 | val_loss : 61610.328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 125 | train_loss : 48656.18359375 | val_loss : 37899.90625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 126 | train_loss : 26288.21484375 | val_loss : 49985.10546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 127 | train_loss : 46649.9140625 | val_loss : 84818.5625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 128 | train_loss : 60515.01171875 | val_loss : 34720.99609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 129 | train_loss : 30552.53515625 | val_loss : 33816.6171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 130 | train_loss : 33698.0234375 | val_loss : 50090.84375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 131 | train_loss : 37165.6953125 | val_loss : 38583.765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 132 | train_loss : 39660.34375 | val_loss : 51960.55859375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 133 | train_loss : 38890.62890625 | val_loss : 34302.015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 134 | train_loss : 29175.990234375 | val_loss : 38333.51171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 135 | train_loss : 30299.94921875 | val_loss : 38637.55859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 136 | train_loss : 34606.0859375 | val_loss : 68635.28125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 137 | train_loss : 47071.1015625 | val_loss : 26064.740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 138 | train_loss : 15902.73828125 | val_loss : 51489.515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 139 | train_loss : 41311.9765625 | val_loss : 76996.0234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 140 | train_loss : 54193.37890625 | val_loss : 25322.92578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 141 | train_loss : 19777.5078125 | val_loss : 35119.88671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 142 | train_loss : 24771.921875 | val_loss : 67434.9921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 143 | train_loss : 46902.85546875 | val_loss : 23616.880859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 144 | train_loss : 15150.51171875 | val_loss : 29314.91015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 145 | train_loss : 19256.990234375 | val_loss : 53344.30859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 146 | train_loss : 36905.06640625 | val_loss : 11135.6123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 147 | train_loss : 8147.478515625 | val_loss : 19983.7109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 148 | train_loss : 12857.2333984375 | val_loss : 27431.78515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 149 | train_loss : 23555.03515625 | val_loss : 28097.9296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 150 | train_loss : 24891.51171875 | val_loss : 29633.376953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 151 | train_loss : 24544.302734375 | val_loss : 30064.619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 152 | train_loss : 26362.490234375 | val_loss : 50811.671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 153 | train_loss : 36674.80078125 | val_loss : 29631.5 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 154 | train_loss : 24271.619140625 | val_loss : 42169.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 155 | train_loss : 29681.177734375 | val_loss : 34599.3203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 156 | train_loss : 30003.71484375 | val_loss : 59693.9609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 157 | train_loss : 42418.51171875 | val_loss : 25674.595703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 158 | train_loss : 16226.6025390625 | val_loss : 48175.12109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 159 | train_loss : 38066.30078125 | val_loss : 63770.078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 160 | train_loss : 43820.9453125 | val_loss : 12842.2177734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 161 | train_loss : 10102.1083984375 | val_loss : 22778.65234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 162 | train_loss : 12424.8212890625 | val_loss : 32343.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 163 | train_loss : 23357.279296875 | val_loss : 25436.759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 164 | train_loss : 14683.7685546875 | val_loss : 52931.73828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 165 | train_loss : 36427.09375 | val_loss : 10793.322265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 166 | train_loss : 8439.458984375 | val_loss : 21570.162109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 167 | train_loss : 13164.7041015625 | val_loss : 23116.220703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 168 | train_loss : 19617.1953125 | val_loss : 31204.3203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 169 | train_loss : 27870.02734375 | val_loss : 50264.96875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 170 | train_loss : 35887.51171875 | val_loss : 30729.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 171 | train_loss : 22595.310546875 | val_loss : 40997.1328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 172 | train_loss : 31981.63671875 | val_loss : 34582.63671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 173 | train_loss : 28607.169921875 | val_loss : 71194.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 174 | train_loss : 48065.640625 | val_loss : 34042.73828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 175 | train_loss : 20848.205078125 | val_loss : 20352.380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 176 | train_loss : 14052.1865234375 | val_loss : 46649.796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 177 | train_loss : 35602.921875 | val_loss : 24572.015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 178 | train_loss : 18345.8671875 | val_loss : 39856.88671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 179 | train_loss : 32264.017578125 | val_loss : 32401.759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 180 | train_loss : 22067.857421875 | val_loss : 64046.71484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 181 | train_loss : 45156.62109375 | val_loss : 15841.8623046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 182 | train_loss : 14819.0302734375 | val_loss : 28685.55078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 183 | train_loss : 19493.11328125 | val_loss : 61081.37109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 184 | train_loss : 41361.7265625 | val_loss : 26378.650390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 185 | train_loss : 14248.111328125 | val_loss : 41779.78515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 186 | train_loss : 30927.66796875 | val_loss : 55267.1953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 187 | train_loss : 37783.11328125 | val_loss : 18102.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 188 | train_loss : 14526.451171875 | val_loss : 47534.390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 189 | train_loss : 32464.1796875 | val_loss : 14729.375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 190 | train_loss : 10291.603515625 | val_loss : 38394.18359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 191 | train_loss : 27320.189453125 | val_loss : 28379.47265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 192 | train_loss : 21018.1796875 | val_loss : 54606.19140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 193 | train_loss : 41038.75390625 | val_loss : 20803.71484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 194 | train_loss : 16339.458984375 | val_loss : 35152.1015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 195 | train_loss : 25834.990234375 | val_loss : 52582.8515625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 196 | train_loss : 40665.23828125 | val_loss : 88345.796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 197 | train_loss : 55170.94921875 | val_loss : 40237.9296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 198 | train_loss : 23900.07421875 | val_loss : 21328.552734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 199 | train_loss : 13905.353515625 | val_loss : 16987.8984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 200 | train_loss : 8762.474609375 | val_loss : 18152.8359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 201 | train_loss : 10303.333984375 | val_loss : 29542.755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 202 | train_loss : 32832.64453125 | val_loss : 65943.078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 203 | train_loss : 43572.453125 | val_loss : 42968.44921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 204 | train_loss : 27004.8359375 | val_loss : 50012.59375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 205 | train_loss : 36582.9375 | val_loss : 19107.498046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 206 | train_loss : 8963.26953125 | val_loss : 19311.90625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 207 | train_loss : 14523.1435546875 | val_loss : 35384.234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 208 | train_loss : 27846.533203125 | val_loss : 56484.2109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 209 | train_loss : 38973.59765625 | val_loss : 15396.275390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 210 | train_loss : 8159.60107421875 | val_loss : 35193.94140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 211 | train_loss : 28337.8125 | val_loss : 60118.01171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 212 | train_loss : 41706.94921875 | val_loss : 15683.669921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 213 | train_loss : 11294.9609375 | val_loss : 14486.5029296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 214 | train_loss : 9190.404296875 | val_loss : 18852.9140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 215 | train_loss : 14714.6865234375 | val_loss : 50720.26953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 216 | train_loss : 35274.8359375 | val_loss : 13221.65234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 217 | train_loss : 10173.6787109375 | val_loss : 21756.640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 218 | train_loss : 14793.638671875 | val_loss : 36313.515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 219 | train_loss : 27480.16796875 | val_loss : 60734.625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 220 | train_loss : 40387.890625 | val_loss : 20043.447265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 221 | train_loss : 12660.7333984375 | val_loss : 29655.431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 222 | train_loss : 18164.560546875 | val_loss : 55646.69140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 223 | train_loss : 37146.06640625 | val_loss : 25103.685546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 224 | train_loss : 13954.8916015625 | val_loss : 38584.01171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 225 | train_loss : 29318.59765625 | val_loss : 51588.73046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 226 | train_loss : 35109.359375 | val_loss : 16785.41015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 227 | train_loss : 12252.48046875 | val_loss : 41778.2890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 228 | train_loss : 28905.107421875 | val_loss : 12058.59765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 229 | train_loss : 8060.57177734375 | val_loss : 20143.3515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 230 | train_loss : 13228.4716796875 | val_loss : 36420.0234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 231 | train_loss : 26517.912109375 | val_loss : 58241.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 232 | train_loss : 39292.20703125 | val_loss : 19056.49609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 233 | train_loss : 12052.6474609375 | val_loss : 27547.654296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 234 | train_loss : 16036.5673828125 | val_loss : 47201.12890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 235 | train_loss : 31765.6171875 | val_loss : 13987.28515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 236 | train_loss : 7379.60205078125 | val_loss : 22362.724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 237 | train_loss : 15881.0986328125 | val_loss : 34170.484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 238 | train_loss : 28390.58984375 | val_loss : 26070.0859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 239 | train_loss : 17587.513671875 | val_loss : 46905.578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 240 | train_loss : 31506.517578125 | val_loss : 11592.9970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 241 | train_loss : 6568.57080078125 | val_loss : 13666.0224609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 242 | train_loss : 6353.8125 | val_loss : 9146.9443359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 243 | train_loss : 5433.7314453125 | val_loss : 17515.697265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 244 | train_loss : 10876.2666015625 | val_loss : 32015.490234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 245 | train_loss : 22350.462890625 | val_loss : 63305.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 246 | train_loss : 40708.30859375 | val_loss : 30038.306640625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 247 | train_loss : 19440.060546875 | val_loss : 14378.037109375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 248 | train_loss : 7992.35888671875 | val_loss : 7339.904296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 249 | train_loss : 4507.974609375 | val_loss : 18051.3515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 250 | train_loss : 12997.919921875 | val_loss : 57770.671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 251 | train_loss : 38227.17578125 | val_loss : 21426.865234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 252 | train_loss : 14766.544921875 | val_loss : 26380.45703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 253 | train_loss : 20143.26953125 | val_loss : 17436.599609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 254 | train_loss : 13934.0888671875 | val_loss : 14637.0849609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 255 | train_loss : 9530.259765625 | val_loss : 20008.498046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 256 | train_loss : 14771.4521484375 | val_loss : 33119.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 257 | train_loss : 25034.17578125 | val_loss : 58445.30859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 258 | train_loss : 36969.97265625 | val_loss : 20116.3515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 259 | train_loss : 12223.3515625 | val_loss : 28633.044921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 260 | train_loss : 15440.662109375 | val_loss : 35821.05078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 261 | train_loss : 23470.505859375 | val_loss : 13589.8837890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 262 | train_loss : 6775.46142578125 | val_loss : 26443.97265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 263 | train_loss : 17139.310546875 | val_loss : 22271.359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 264 | train_loss : 17590.07421875 | val_loss : 29837.296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 265 | train_loss : 20295.533203125 | val_loss : 22943.17578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 266 | train_loss : 16728.984375 | val_loss : 30720.66796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 267 | train_loss : 22300.873046875 | val_loss : 27223.439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 268 | train_loss : 22370.267578125 | val_loss : 38861.4375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 269 | train_loss : 28484.455078125 | val_loss : 29888.490234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 270 | train_loss : 19683.515625 | val_loss : 30592.314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 271 | train_loss : 22639.5859375 | val_loss : 24128.283203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 272 | train_loss : 15274.9072265625 | val_loss : 29413.671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 273 | train_loss : 20995.6875 | val_loss : 54407.76953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 274 | train_loss : 71281.7421875 | val_loss : 71659.265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 275 | train_loss : 54401.953125 | val_loss : 37628.84375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 276 | train_loss : 25810.767578125 | val_loss : 38028.48046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 277 | train_loss : 23045.025390625 | val_loss : 16983.828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 278 | train_loss : 11682.53125 | val_loss : 21206.96484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 279 | train_loss : 14816.7197265625 | val_loss : 35523.51171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 280 | train_loss : 24865.41796875 | val_loss : 12910.552734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 281 | train_loss : 6691.32373046875 | val_loss : 14215.1376953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 282 | train_loss : 8026.798828125 | val_loss : 21165.4453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 283 | train_loss : 13297.943359375 | val_loss : 33720.74609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 284 | train_loss : 23019.025390625 | val_loss : 11487.4853515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 285 | train_loss : 7293.75390625 | val_loss : 19067.359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 286 | train_loss : 12391.494140625 | val_loss : 25663.45703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 287 | train_loss : 15948.1025390625 | val_loss : 40315.50390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 288 | train_loss : 26306.5703125 | val_loss : 9615.7890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 289 | train_loss : 6571.3837890625 | val_loss : 14082.037109375 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 290 | train_loss : 6511.39501953125 | val_loss : 7616.63134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 291 | train_loss : 5297.95556640625 | val_loss : 12906.919921875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 292 | train_loss : 5750.59228515625 | val_loss : 7743.87548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 293 | train_loss : 5117.7060546875 | val_loss : 14291.4345703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 294 | train_loss : 8320.7353515625 | val_loss : 21683.947265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 295 | train_loss : 13442.6484375 | val_loss : 32955.26171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 296 | train_loss : 21010.345703125 | val_loss : 11377.10546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 297 | train_loss : 8282.990234375 | val_loss : 26592.73828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 298 | train_loss : 17882.81640625 | val_loss : 15356.955078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 299 | train_loss : 11061.927734375 | val_loss : 37509.1171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 300 | train_loss : 25252.392578125 | val_loss : 11668.5654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 301 | train_loss : 6807.23876953125 | val_loss : 20123.068359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 302 | train_loss : 11844.8125 | val_loss : 19377.1796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 303 | train_loss : 15506.1513671875 | val_loss : 34131.984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 304 | train_loss : 21858.310546875 | val_loss : 9660.8447265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 305 | train_loss : 5654.78369140625 | val_loss : 17725.76953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 306 | train_loss : 10333.1787109375 | val_loss : 30279.099609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 307 | train_loss : 22727.212890625 | val_loss : 56932.44921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 308 | train_loss : 39244.50390625 | val_loss : 18176.759765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 309 | train_loss : 10439.26171875 | val_loss : 21739.365234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 310 | train_loss : 10072.1611328125 | val_loss : 15333.087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 311 | train_loss : 9920.8359375 | val_loss : 20712.083984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 312 | train_loss : 10548.77734375 | val_loss : 32586.650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 313 | train_loss : 21388.255859375 | val_loss : 11629.025390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 314 | train_loss : 4752.078125 | val_loss : 14847.8349609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 315 | train_loss : 8660.1513671875 | val_loss : 22046.98828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 316 | train_loss : 14900.40234375 | val_loss : 30875.759765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 317 | train_loss : 23331.671875 | val_loss : 15965.775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 318 | train_loss : 9819.2021484375 | val_loss : 28540.056640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 319 | train_loss : 19422.783203125 | val_loss : 14777.7490234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 320 | train_loss : 7860.076171875 | val_loss : 28543.615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 321 | train_loss : 18274.994140625 | val_loss : 98026.890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 322 | train_loss : 109819.8984375 | val_loss : 92952.6015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 323 | train_loss : 75380.0078125 | val_loss : 36152.40625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 324 | train_loss : 22415.052734375 | val_loss : 11452.3134765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 325 | train_loss : 6281.15771484375 | val_loss : 14333.3671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 326 | train_loss : 8464.4365234375 | val_loss : 17536.51171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 327 | train_loss : 12413.0751953125 | val_loss : 24085.939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 328 | train_loss : 13916.0029296875 | val_loss : 26216.42578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 329 | train_loss : 17452.328125 | val_loss : 17558.078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 330 | train_loss : 13674.1904296875 | val_loss : 32869.1328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 331 | train_loss : 22497.244140625 | val_loss : 10042.916015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 332 | train_loss : 6381.6923828125 | val_loss : 11215.7197265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 333 | train_loss : 5218.66455078125 | val_loss : 12552.7998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 334 | train_loss : 7678.9736328125 | val_loss : 18463.123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 335 | train_loss : 10808.900390625 | val_loss : 17946.5234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 336 | train_loss : 12954.3408203125 | val_loss : 24642.255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 337 | train_loss : 15482.443359375 | val_loss : 13011.0078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 338 | train_loss : 7786.94140625 | val_loss : 16504.205078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 339 | train_loss : 10062.248046875 | val_loss : 20118.818359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 340 | train_loss : 12732.29296875 | val_loss : 23698.126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 341 | train_loss : 15533.39453125 | val_loss : 13608.201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 342 | train_loss : 7700.611328125 | val_loss : 15701.830078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 343 | train_loss : 9768.3671875 | val_loss : 19665.953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 344 | train_loss : 11097.548828125 | val_loss : 28349.919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 345 | train_loss : 17647.05078125 | val_loss : 12514.9775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 346 | train_loss : 8085.79296875 | val_loss : 20627.71875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 347 | train_loss : 12536.1337890625 | val_loss : 15754.7421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 348 | train_loss : 11507.0439453125 | val_loss : 27210.365234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 349 | train_loss : 16910.376953125 | val_loss : 13073.517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 350 | train_loss : 7666.84521484375 | val_loss : 18444.98828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 351 | train_loss : 10686.7421875 | val_loss : 15442.76953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 352 | train_loss : 9650.8037109375 | val_loss : 22722.0859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 353 | train_loss : 13738.4091796875 | val_loss : 12310.3076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 354 | train_loss : 7640.28271484375 | val_loss : 14739.2802734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 355 | train_loss : 8330.3662109375 | val_loss : 21074.32421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 356 | train_loss : 12501.6337890625 | val_loss : 22427.044921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 357 | train_loss : 13991.7900390625 | val_loss : 12184.59765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 358 | train_loss : 8053.91357421875 | val_loss : 13318.86328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 359 | train_loss : 7780.26513671875 | val_loss : 15376.462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 360 | train_loss : 9172.20703125 | val_loss : 21209.9296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 361 | train_loss : 13300.9248046875 | val_loss : 16119.802734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 362 | train_loss : 10621.5048828125 | val_loss : 27827.880859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 363 | train_loss : 17128.60546875 | val_loss : 12341.8974609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 364 | train_loss : 7398.87060546875 | val_loss : 18046.1875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 365 | train_loss : 9882.3447265625 | val_loss : 15219.59765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 366 | train_loss : 10137.5966796875 | val_loss : 23028.08984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 367 | train_loss : 13710.115234375 | val_loss : 14603.2353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 368 | train_loss : 8657.6171875 | val_loss : 21847.189453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 369 | train_loss : 13004.5283203125 | val_loss : 28543.2578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 370 | train_loss : 21230.01953125 | val_loss : 42367.25 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 371 | train_loss : 29904.21484375 | val_loss : 10597.6728515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 372 | train_loss : 7883.67236328125 | val_loss : 16937.927734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 373 | train_loss : 8814.73828125 | val_loss : 12649.2822265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 374 | train_loss : 8163.515625 | val_loss : 16749.4921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 375 | train_loss : 8875.662109375 | val_loss : 12172.01953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 376 | train_loss : 7172.01416015625 | val_loss : 16337.2822265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 377 | train_loss : 8073.39111328125 | val_loss : 12410.5078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 378 | train_loss : 8056.6220703125 | val_loss : 19083.564453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 379 | train_loss : 10807.8486328125 | val_loss : 21540.1640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 380 | train_loss : 14925.8583984375 | val_loss : 17432.7109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 381 | train_loss : 8613.6357421875 | val_loss : 15543.04296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 382 | train_loss : 11856.2490234375 | val_loss : 18599.82421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 383 | train_loss : 9173.8505859375 | val_loss : 15162.974609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 384 | train_loss : 9921.67578125 | val_loss : 17874.677734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 385 | train_loss : 8587.2138671875 | val_loss : 11918.0771484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 386 | train_loss : 8639.8681640625 | val_loss : 36473.6328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 387 | train_loss : 41104.6171875 | val_loss : 67455.8671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 388 | train_loss : 49389.68359375 | val_loss : 61074.484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 389 | train_loss : 38193.4765625 | val_loss : 41799.171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 390 | train_loss : 32548.55078125 | val_loss : 36706.34375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 391 | train_loss : 46298.62109375 | val_loss : 33876.234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 392 | train_loss : 23158.59765625 | val_loss : 15821.7099609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 393 | train_loss : 9228.771484375 | val_loss : 9909.3837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 394 | train_loss : 6195.349609375 | val_loss : 14232.72265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 395 | train_loss : 7666.40380859375 | val_loss : 9098.9814453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 396 | train_loss : 5724.798828125 | val_loss : 12402.6279296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 397 | train_loss : 4893.7109375 | val_loss : 7253.26953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 398 | train_loss : 5121.9912109375 | val_loss : 12168.462890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 399 | train_loss : 4271.40625 | val_loss : 6142.56689453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 400 | train_loss : 3701.581298828125 | val_loss : 11531.3115234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 401 | train_loss : 3606.51123046875 | val_loss : 6391.80322265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 402 | train_loss : 3617.7939453125 | val_loss : 11437.5126953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 403 | train_loss : 3816.520263671875 | val_loss : 9396.2041015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 404 | train_loss : 4290.70458984375 | val_loss : 10579.919921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 405 | train_loss : 3428.6953125 | val_loss : 11078.6171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 406 | train_loss : 4768.6044921875 | val_loss : 15271.9775390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 407 | train_loss : 8170.18017578125 | val_loss : 22197.9765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 408 | train_loss : 12558.7314453125 | val_loss : 10593.349609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 409 | train_loss : 6117.42041015625 | val_loss : 11093.33984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 410 | train_loss : 4917.59765625 | val_loss : 11035.6376953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 411 | train_loss : 5105.56640625 | val_loss : 14593.3349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 412 | train_loss : 6884.7861328125 | val_loss : 15125.1748046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 413 | train_loss : 10402.3720703125 | val_loss : 46201.609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 414 | train_loss : 29631.63671875 | val_loss : 12667.4326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 415 | train_loss : 10558.8876953125 | val_loss : 22564.0234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 416 | train_loss : 16028.576171875 | val_loss : 21567.0078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 417 | train_loss : 13069.857421875 | val_loss : 15375.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 418 | train_loss : 10115.00390625 | val_loss : 21356.455078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 419 | train_loss : 11976.5576171875 | val_loss : 14704.8701171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 420 | train_loss : 8352.8798828125 | val_loss : 16575.45703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 421 | train_loss : 10008.27734375 | val_loss : 20362.091796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 422 | train_loss : 13298.681640625 | val_loss : 15683.240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 423 | train_loss : 9784.92578125 | val_loss : 18589.4765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 424 | train_loss : 11126.337890625 | val_loss : 14725.0400390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 425 | train_loss : 8936.130859375 | val_loss : 16647.134765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 426 | train_loss : 9146.8671875 | val_loss : 14416.8623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 427 | train_loss : 9046.9501953125 | val_loss : 17227.078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 428 | train_loss : 9515.267578125 | val_loss : 14962.59765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 429 | train_loss : 9007.9814453125 | val_loss : 19603.431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 430 | train_loss : 11637.2724609375 | val_loss : 12745.5625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 431 | train_loss : 6783.841796875 | val_loss : 13545.2978515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 432 | train_loss : 7702.66552734375 | val_loss : 15316.7529296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 433 | train_loss : 8530.4326171875 | val_loss : 17511.541015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 434 | train_loss : 10254.8154296875 | val_loss : 12659.28515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 435 | train_loss : 7466.09619140625 | val_loss : 13781.08984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 436 | train_loss : 8925.7275390625 | val_loss : 20021.171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 437 | train_loss : 12010.677734375 | val_loss : 19888.296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 438 | train_loss : 12241.3408203125 | val_loss : 13467.5625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 439 | train_loss : 9900.126953125 | val_loss : 18603.1796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 440 | train_loss : 10448.623046875 | val_loss : 13214.87109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 441 | train_loss : 9669.361328125 | val_loss : 18314.994140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 442 | train_loss : 10236.458984375 | val_loss : 12967.0654296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 443 | train_loss : 8057.5498046875 | val_loss : 14279.0322265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 444 | train_loss : 7681.90771484375 | val_loss : 12105.86328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 445 | train_loss : 6342.48388671875 | val_loss : 12496.869140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 446 | train_loss : 6921.55859375 | val_loss : 11894.521484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 447 | train_loss : 6293.9599609375 | val_loss : 13348.2666015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 448 | train_loss : 6535.58935546875 | val_loss : 11620.9423828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 449 | train_loss : 6235.126953125 | val_loss : 11980.2197265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 450 | train_loss : 5870.8525390625 | val_loss : 10581.1572265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 451 | train_loss : 4747.17236328125 | val_loss : 12206.5302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 452 | train_loss : 5488.12060546875 | val_loss : 9257.6015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 453 | train_loss : 4629.689453125 | val_loss : 11754.1220703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 454 | train_loss : 5581.90625 | val_loss : 11214.892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 455 | train_loss : 5842.35888671875 | val_loss : 16387.568359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 456 | train_loss : 8874.87109375 | val_loss : 12663.3095703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 457 | train_loss : 8572.587890625 | val_loss : 18054.021484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 458 | train_loss : 10480.92578125 | val_loss : 13810.26953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 459 | train_loss : 9873.306640625 | val_loss : 18873.634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 460 | train_loss : 11032.55859375 | val_loss : 12459.712890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 461 | train_loss : 8986.7177734375 | val_loss : 16764.029296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 462 | train_loss : 9190.935546875 | val_loss : 12871.955078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 463 | train_loss : 9219.0927734375 | val_loss : 15880.041015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 464 | train_loss : 8579.83203125 | val_loss : 11012.2421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 465 | train_loss : 6653.38623046875 | val_loss : 13204.3876953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 466 | train_loss : 6923.85009765625 | val_loss : 10405.0859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 467 | train_loss : 6122.677734375 | val_loss : 10998.693359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 468 | train_loss : 5544.47998046875 | val_loss : 9069.6201171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 469 | train_loss : 5427.8486328125 | val_loss : 10876.4921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 470 | train_loss : 4911.60009765625 | val_loss : 6920.4951171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 471 | train_loss : 3456.566162109375 | val_loss : 10005.2626953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 472 | train_loss : 3686.762451171875 | val_loss : 9002.2197265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 473 | train_loss : 4612.466796875 | val_loss : 10503.017578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 474 | train_loss : 4578.486328125 | val_loss : 13658.400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 475 | train_loss : 7824.11669921875 | val_loss : 17080.107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 476 | train_loss : 10165.6533203125 | val_loss : 13574.287109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 477 | train_loss : 7746.623046875 | val_loss : 12732.9189453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 478 | train_loss : 9409.943359375 | val_loss : 10450.7109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 479 | train_loss : 4561.05908203125 | val_loss : 10149.275390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 480 | train_loss : 4061.755615234375 | val_loss : 8803.193359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 481 | train_loss : 4341.650390625 | val_loss : 9597.2431640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 482 | train_loss : 3602.095703125 | val_loss : 7816.18359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 483 | train_loss : 3665.798828125 | val_loss : 10965.076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 484 | train_loss : 4251.423828125 | val_loss : 9205.5771484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 485 | train_loss : 5345.08056640625 | val_loss : 13243.8271484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 486 | train_loss : 5629.04736328125 | val_loss : 25823.671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 487 | train_loss : 26977.990234375 | val_loss : 44696.87890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 488 | train_loss : 28896.998046875 | val_loss : 14062.7509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 489 | train_loss : 8691.9853515625 | val_loss : 12924.900390625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 490 | train_loss : 5070.0654296875 | val_loss : 5709.59375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 491 | train_loss : 2594.585205078125 | val_loss : 8231.3515625 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 492 | train_loss : 2369.131591796875 | val_loss : 4776.939453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 493 | train_loss : 2924.01318359375 | val_loss : 7553.48388671875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 494 | train_loss : 1916.4146728515625 | val_loss : 5451.0224609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 495 | train_loss : 2326.52197265625 | val_loss : 8074.248046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 496 | train_loss : 2650.19091796875 | val_loss : 4209.88671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 497 | train_loss : 3529.422607421875 | val_loss : 8831.8291015625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 498 | train_loss : 3351.952880859375 | val_loss : 4076.621826171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 499 | train_loss : 2725.0107421875 | val_loss : 7377.0498046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 500 | train_loss : 2194.6611328125 | val_loss : 5806.06005859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 501 | train_loss : 3986.4873046875 | val_loss : 8350.3046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 502 | train_loss : 3388.355712890625 | val_loss : 6118.1201171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 503 | train_loss : 3492.6357421875 | val_loss : 9616.974609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 504 | train_loss : 4249.169921875 | val_loss : 7148.98388671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 505 | train_loss : 3956.44677734375 | val_loss : 10728.556640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 506 | train_loss : 4686.04638671875 | val_loss : 9838.96484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 507 | train_loss : 5778.04296875 | val_loss : 12271.8720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 508 | train_loss : 6192.74755859375 | val_loss : 14457.6474609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 509 | train_loss : 10801.4638671875 | val_loss : 22641.85546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 510 | train_loss : 14096.2802734375 | val_loss : 72176.6640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 511 | train_loss : 87499.640625 | val_loss : 69249.9296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 512 | train_loss : 53757.28515625 | val_loss : 25324.3125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 513 | train_loss : 15547.83203125 | val_loss : 7721.68017578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 514 | train_loss : 3845.217529296875 | val_loss : 7833.18359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 515 | train_loss : 4286.70654296875 | val_loss : 8219.05078125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 516 | train_loss : 4272.57421875 | val_loss : 5974.052734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 517 | train_loss : 4035.46630859375 | val_loss : 7165.728515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 518 | train_loss : 3292.2626953125 | val_loss : 4558.8369140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 519 | train_loss : 4042.57177734375 | val_loss : 7103.421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 520 | train_loss : 3319.06494140625 | val_loss : 4075.6943359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 521 | train_loss : 4065.86181640625 | val_loss : 7086.12353515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 522 | train_loss : 2986.704345703125 | val_loss : 5874.8251953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 523 | train_loss : 5504.7861328125 | val_loss : 14806.8701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 524 | train_loss : 8546.8642578125 | val_loss : 13708.1904296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 525 | train_loss : 10585.27734375 | val_loss : 18460.859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 526 | train_loss : 10465.89453125 | val_loss : 12749.76953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 527 | train_loss : 11403.572265625 | val_loss : 20789.404296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 528 | train_loss : 11927.7177734375 | val_loss : 10951.6396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 529 | train_loss : 8951.5654296875 | val_loss : 15520.3564453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 530 | train_loss : 7729.17138671875 | val_loss : 14019.09375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 531 | train_loss : 10504.57421875 | val_loss : 15526.8271484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 532 | train_loss : 7838.80322265625 | val_loss : 11607.7021484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 533 | train_loss : 6943.00146484375 | val_loss : 48400.10546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 534 | train_loss : 33437.97265625 | val_loss : 24173.310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 535 | train_loss : 22275.34765625 | val_loss : 24729.517578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 536 | train_loss : 15903.16015625 | val_loss : 17089.869140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 537 | train_loss : 10207.5986328125 | val_loss : 14361.5283203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 538 | train_loss : 7341.6826171875 | val_loss : 16999.2421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 539 | train_loss : 8213.7353515625 | val_loss : 9947.326171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 540 | train_loss : 4323.859375 | val_loss : 8294.9990234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 541 | train_loss : 4240.658203125 | val_loss : 8956.037109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 542 | train_loss : 3336.0361328125 | val_loss : 7869.8779296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 543 | train_loss : 3790.338134765625 | val_loss : 8293.62109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 544 | train_loss : 3149.5966796875 | val_loss : 5311.86376953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 545 | train_loss : 3580.639404296875 | val_loss : 7848.7080078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 546 | train_loss : 2498.553955078125 | val_loss : 5948.04638671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 547 | train_loss : 3850.571044921875 | val_loss : 8480.2783203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 548 | train_loss : 3648.841796875 | val_loss : 5418.986328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 549 | train_loss : 3089.486328125 | val_loss : 7252.15234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 550 | train_loss : 2344.19384765625 | val_loss : 5823.900390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 551 | train_loss : 3310.775390625 | val_loss : 7820.30126953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 552 | train_loss : 3202.62255859375 | val_loss : 4683.52392578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 553 | train_loss : 2912.2861328125 | val_loss : 7086.95263671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 554 | train_loss : 2148.79150390625 | val_loss : 5890.6064453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 555 | train_loss : 3973.864990234375 | val_loss : 7558.86767578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 556 | train_loss : 2787.08740234375 | val_loss : 5069.63330078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 557 | train_loss : 3117.659912109375 | val_loss : 7197.03955078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 558 | train_loss : 2141.047119140625 | val_loss : 5386.302734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 559 | train_loss : 2796.00927734375 | val_loss : 7781.5673828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 560 | train_loss : 2112.250244140625 | val_loss : 5604.37890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 561 | train_loss : 3227.62646484375 | val_loss : 6919.10693359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 562 | train_loss : 2329.775390625 | val_loss : 4773.78271484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 563 | train_loss : 3134.684326171875 | val_loss : 8444.72265625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 564 | train_loss : 2908.149169921875 | val_loss : 4667.93017578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 565 | train_loss : 2751.67529296875 | val_loss : 6652.6162109375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 566 | train_loss : 2270.09814453125 | val_loss : 5268.23291015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 567 | train_loss : 3247.252197265625 | val_loss : 8590.740234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 568 | train_loss : 3136.539794921875 | val_loss : 5460.41796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 569 | train_loss : 2715.396240234375 | val_loss : 8556.5498046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 570 | train_loss : 3223.914306640625 | val_loss : 5753.10791015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 571 | train_loss : 3248.968017578125 | val_loss : 8728.4189453125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 572 | train_loss : 3316.171630859375 | val_loss : 6719.20263671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 573 | train_loss : 4189.65625 | val_loss : 8771.65234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 574 | train_loss : 3343.949462890625 | val_loss : 5596.55322265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 575 | train_loss : 2959.982177734375 | val_loss : 8134.419921875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 576 | train_loss : 2574.7216796875 | val_loss : 5515.75244140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 577 | train_loss : 3120.6826171875 | val_loss : 6656.388671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 578 | train_loss : 2003.4425048828125 | val_loss : 4766.6591796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 579 | train_loss : 2760.4599609375 | val_loss : 8121.31640625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 580 | train_loss : 2992.59619140625 | val_loss : 5334.81640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 581 | train_loss : 3514.0224609375 | val_loss : 8652.4248046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 582 | train_loss : 3335.4443359375 | val_loss : 5461.32666015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 583 | train_loss : 3305.945068359375 | val_loss : 9054.927734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 584 | train_loss : 3544.579345703125 | val_loss : 5133.92041015625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 585 | train_loss : 3217.956298828125 | val_loss : 8447.421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 586 | train_loss : 2784.458984375 | val_loss : 6464.2255859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 587 | train_loss : 3878.46337890625 | val_loss : 9126.369140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 588 | train_loss : 3594.3876953125 | val_loss : 5540.98681640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 589 | train_loss : 3113.517578125 | val_loss : 9073.71484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 590 | train_loss : 3593.0380859375 | val_loss : 5749.6689453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 591 | train_loss : 3304.637451171875 | val_loss : 9011.1044921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 592 | train_loss : 3415.54052734375 | val_loss : 5170.28759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 593 | train_loss : 2962.77001953125 | val_loss : 9135.3876953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 594 | train_loss : 3733.57470703125 | val_loss : 6442.90673828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 595 | train_loss : 3693.0830078125 | val_loss : 8110.548828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 596 | train_loss : 3062.81689453125 | val_loss : 5116.88134765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 597 | train_loss : 2948.09228515625 | val_loss : 8182.10205078125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 598 | train_loss : 2847.308349609375 | val_loss : 4769.7177734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 599 | train_loss : 3548.827392578125 | val_loss : 8767.29296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 600 | train_loss : 3752.745849609375 | val_loss : 6121.2744140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 601 | train_loss : 3952.88623046875 | val_loss : 8906.53515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 602 | train_loss : 3448.783447265625 | val_loss : 4313.99609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 603 | train_loss : 2525.170654296875 | val_loss : 7824.431640625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 604 | train_loss : 2016.1973876953125 | val_loss : 5441.49365234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 605 | train_loss : 3416.093994140625 | val_loss : 7670.62744140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 606 | train_loss : 2387.699462890625 | val_loss : 4980.955078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 607 | train_loss : 2859.321533203125 | val_loss : 7234.236328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 608 | train_loss : 1904.889892578125 | val_loss : 4848.39013671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 609 | train_loss : 2723.19091796875 | val_loss : 7720.16064453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 610 | train_loss : 2499.325927734375 | val_loss : 4568.51171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 611 | train_loss : 2612.028564453125 | val_loss : 7212.0185546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 612 | train_loss : 1764.6195068359375 | val_loss : 6032.97119140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 613 | train_loss : 3415.2412109375 | val_loss : 8167.375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 614 | train_loss : 2601.12939453125 | val_loss : 5617.93359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 615 | train_loss : 2947.927490234375 | val_loss : 7970.92578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 616 | train_loss : 2771.863037109375 | val_loss : 4587.794921875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 617 | train_loss : 2362.9677734375 | val_loss : 7257.794921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 618 | train_loss : 2275.705810546875 | val_loss : 4604.34326171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 619 | train_loss : 2759.601806640625 | val_loss : 7085.96044921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 620 | train_loss : 1885.00830078125 | val_loss : 4421.62890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 621 | train_loss : 3050.860595703125 | val_loss : 7517.056640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 622 | train_loss : 2290.05810546875 | val_loss : 4877.98583984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 623 | train_loss : 2892.593994140625 | val_loss : 7559.322265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 624 | train_loss : 2042.2716064453125 | val_loss : 4931.88818359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 625 | train_loss : 3288.1650390625 | val_loss : 7807.65869140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 626 | train_loss : 2515.022705078125 | val_loss : 4753.02392578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 627 | train_loss : 2721.9296875 | val_loss : 7388.74609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 628 | train_loss : 2118.94287109375 | val_loss : 5199.78759765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 629 | train_loss : 2931.23876953125 | val_loss : 6760.05517578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 630 | train_loss : 1580.003173828125 | val_loss : 4849.32080078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 631 | train_loss : 2220.80615234375 | val_loss : 7940.17041015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 632 | train_loss : 2431.268798828125 | val_loss : 5171.33935546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 633 | train_loss : 2734.3837890625 | val_loss : 7292.8779296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 634 | train_loss : 2417.16943359375 | val_loss : 4987.37939453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 635 | train_loss : 2786.762451171875 | val_loss : 8229.0751953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 636 | train_loss : 2853.528076171875 | val_loss : 5268.498046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 637 | train_loss : 3067.92724609375 | val_loss : 9087.0712890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 638 | train_loss : 3590.037109375 | val_loss : 6332.50830078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 639 | train_loss : 3573.833740234375 | val_loss : 9094.4052734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 640 | train_loss : 3505.311767578125 | val_loss : 5957.4248046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 641 | train_loss : 3483.372802734375 | val_loss : 9175.5048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 642 | train_loss : 3339.68896484375 | val_loss : 6263.06298828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 643 | train_loss : 3659.476318359375 | val_loss : 9505.5791015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 644 | train_loss : 3741.785888671875 | val_loss : 6498.255859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 645 | train_loss : 3418.128662109375 | val_loss : 8980.2802734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 646 | train_loss : 3297.539306640625 | val_loss : 5115.232421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 647 | train_loss : 2659.8603515625 | val_loss : 8731.3369140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 648 | train_loss : 3064.29541015625 | val_loss : 5706.01708984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 649 | train_loss : 3553.907470703125 | val_loss : 9139.62890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 650 | train_loss : 3520.046875 | val_loss : 5864.93798828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 651 | train_loss : 2915.77685546875 | val_loss : 9137.13671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 652 | train_loss : 3190.7099609375 | val_loss : 5730.75 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 653 | train_loss : 3201.980712890625 | val_loss : 8979.982421875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 654 | train_loss : 3297.453857421875 | val_loss : 6255.2841796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 655 | train_loss : 3544.418701171875 | val_loss : 8438.9951171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 656 | train_loss : 2989.095947265625 | val_loss : 4620.3681640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 657 | train_loss : 2470.964599609375 | val_loss : 6902.4189453125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 658 | train_loss : 1488.536865234375 | val_loss : 5683.90771484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 659 | train_loss : 3030.171875 | val_loss : 7110.48583984375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 660 | train_loss : 1651.7869873046875 | val_loss : 5021.9248046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 661 | train_loss : 2830.220703125 | val_loss : 7536.95751953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 662 | train_loss : 1804.5615234375 | val_loss : 5556.30517578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 663 | train_loss : 2858.419677734375 | val_loss : 8404.6318359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 664 | train_loss : 2582.43408203125 | val_loss : 6701.85546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 665 | train_loss : 3625.46630859375 | val_loss : 11006.294921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 666 | train_loss : 3907.468017578125 | val_loss : 11232.1904296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 667 | train_loss : 9267.9375 | val_loss : 26540.953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 668 | train_loss : 14656.08203125 | val_loss : 10290.7158203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 669 | train_loss : 7918.326171875 | val_loss : 19130.20703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 670 | train_loss : 9468.40625 | val_loss : 13249.357421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 671 | train_loss : 10278.4345703125 | val_loss : 21664.755859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 672 | train_loss : 12644.4658203125 | val_loss : 12289.7451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 673 | train_loss : 8386.15234375 | val_loss : 22345.310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 674 | train_loss : 12077.6640625 | val_loss : 17381.828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 675 | train_loss : 14043.982421875 | val_loss : 18902.33984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 676 | train_loss : 10766.48046875 | val_loss : 12499.3095703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 677 | train_loss : 8031.517578125 | val_loss : 14742.552734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 678 | train_loss : 7754.63671875 | val_loss : 11506.9501953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 679 | train_loss : 5694.93310546875 | val_loss : 10752.30078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 680 | train_loss : 5329.65673828125 | val_loss : 7392.8173828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 681 | train_loss : 3806.737548828125 | val_loss : 8933.3095703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 682 | train_loss : 3046.107177734375 | val_loss : 5490.357421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 683 | train_loss : 3188.84619140625 | val_loss : 9120.875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 684 | train_loss : 3173.77099609375 | val_loss : 5293.69140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 685 | train_loss : 2724.3564453125 | val_loss : 7773.0751953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 686 | train_loss : 2525.178955078125 | val_loss : 5958.4326171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 687 | train_loss : 3464.851318359375 | val_loss : 8084.09130859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 688 | train_loss : 2927.023193359375 | val_loss : 5411.55126953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 689 | train_loss : 2939.388671875 | val_loss : 7261.197265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 690 | train_loss : 1847.42333984375 | val_loss : 6955.1845703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 691 | train_loss : 3355.1640625 | val_loss : 7095.10888671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 692 | train_loss : 1830.649169921875 | val_loss : 5694.58935546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 693 | train_loss : 3041.090576171875 | val_loss : 7853.4306640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 694 | train_loss : 2349.2099609375 | val_loss : 5460.46044921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 695 | train_loss : 2772.506591796875 | val_loss : 7741.5625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 696 | train_loss : 2245.370361328125 | val_loss : 4980.95947265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 697 | train_loss : 2556.701904296875 | val_loss : 7766.0224609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 698 | train_loss : 2285.84521484375 | val_loss : 5030.37646484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 699 | train_loss : 2340.43896484375 | val_loss : 7094.3251953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 700 | train_loss : 2009.0159912109375 | val_loss : 4799.9091796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 701 | train_loss : 3105.641845703125 | val_loss : 8324.5341796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 702 | train_loss : 2794.6318359375 | val_loss : 5352.6181640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 703 | train_loss : 3116.0322265625 | val_loss : 9529.9453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 704 | train_loss : 4414.44775390625 | val_loss : 6790.646484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 705 | train_loss : 4468.3544921875 | val_loss : 11662.9365234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 706 | train_loss : 7465.67431640625 | val_loss : 14661.5703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 707 | train_loss : 9386.322265625 | val_loss : 10694.5654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 708 | train_loss : 5300.6376953125 | val_loss : 15507.7373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 709 | train_loss : 9101.90625 | val_loss : 11960.513671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 710 | train_loss : 5319.1669921875 | val_loss : 7770.998046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 711 | train_loss : 4606.06396484375 | val_loss : 13803.6953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 712 | train_loss : 5723.998046875 | val_loss : 14460.0009765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 713 | train_loss : 13703.322265625 | val_loss : 24763.421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 714 | train_loss : 13036.3203125 | val_loss : 10713.044921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 715 | train_loss : 6869.44140625 | val_loss : 15507.0615234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 716 | train_loss : 6646.22998046875 | val_loss : 11921.455078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 717 | train_loss : 7768.26611328125 | val_loss : 16533.109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 718 | train_loss : 7428.61376953125 | val_loss : 11926.794921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 719 | train_loss : 7463.9736328125 | val_loss : 15040.27734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 720 | train_loss : 6846.125 | val_loss : 10890.580078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 721 | train_loss : 6697.24072265625 | val_loss : 13139.1962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 722 | train_loss : 5530.6513671875 | val_loss : 16907.001953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 723 | train_loss : 16054.1884765625 | val_loss : 41654.71875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 724 | train_loss : 26029.3203125 | val_loss : 8403.869140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 725 | train_loss : 4819.57958984375 | val_loss : 17788.73828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 726 | train_loss : 7695.92822265625 | val_loss : 6529.08544921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 727 | train_loss : 3779.803955078125 | val_loss : 12721.09765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 728 | train_loss : 3711.242919921875 | val_loss : 5664.701171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 729 | train_loss : 3373.244384765625 | val_loss : 8531.673828125 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 730 | train_loss : 2008.8582763671875 | val_loss : 5460.427734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 731 | train_loss : 3527.279296875 | val_loss : 9600.791015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 732 | train_loss : 3168.700927734375 | val_loss : 3712.574951171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 733 | train_loss : 2921.611328125 | val_loss : 8716.03515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 734 | train_loss : 2668.64501953125 | val_loss : 3440.0029296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 735 | train_loss : 3086.70556640625 | val_loss : 8158.30615234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 736 | train_loss : 2638.170654296875 | val_loss : 3313.656005859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 737 | train_loss : 2496.081787109375 | val_loss : 7621.09619140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 738 | train_loss : 2239.375 | val_loss : 3238.66064453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 739 | train_loss : 2811.689453125 | val_loss : 7055.927734375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 740 | train_loss : 2307.173828125 | val_loss : 3208.60302734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 741 | train_loss : 2497.167236328125 | val_loss : 6576.64501953125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 742 | train_loss : 1997.621826171875 | val_loss : 3297.417724609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 743 | train_loss : 2526.34423828125 | val_loss : 6094.458984375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 744 | train_loss : 1250.877685546875 | val_loss : 4485.93701171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 745 | train_loss : 2235.757568359375 | val_loss : 7248.9306640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 746 | train_loss : 2290.653076171875 | val_loss : 4806.8984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 747 | train_loss : 2154.546630859375 | val_loss : 7362.716796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 748 | train_loss : 2400.451171875 | val_loss : 5069.23681640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 749 | train_loss : 2131.59130859375 | val_loss : 6258.0048828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 750 | train_loss : 1719.3857421875 | val_loss : 6429.728515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 751 | train_loss : 3573.415283203125 | val_loss : 7595.1455078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 752 | train_loss : 2660.87060546875 | val_loss : 5559.43896484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 753 | train_loss : 3274.66845703125 | val_loss : 8073.5439453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 754 | train_loss : 3351.433349609375 | val_loss : 5830.240234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 755 | train_loss : 4347.91162109375 | val_loss : 9179.6044921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 756 | train_loss : 4459.44140625 | val_loss : 7650.28857421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 757 | train_loss : 4748.01513671875 | val_loss : 9188.6328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 758 | train_loss : 4180.8681640625 | val_loss : 6819.39697265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 759 | train_loss : 4044.62060546875 | val_loss : 8520.9765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 760 | train_loss : 2760.09619140625 | val_loss : 5193.5361328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 761 | train_loss : 2260.387451171875 | val_loss : 7715.48828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 762 | train_loss : 2160.9833984375 | val_loss : 5371.13623046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 763 | train_loss : 2677.44677734375 | val_loss : 7769.15673828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 764 | train_loss : 1924.0484619140625 | val_loss : 5807.76611328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 765 | train_loss : 2895.153076171875 | val_loss : 7907.6318359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 766 | train_loss : 2077.722900390625 | val_loss : 5025.6015625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 767 | train_loss : 2559.695068359375 | val_loss : 7368.18017578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 768 | train_loss : 1728.030029296875 | val_loss : 5049.34521484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 769 | train_loss : 2724.607421875 | val_loss : 7637.07177734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 770 | train_loss : 1869.6781005859375 | val_loss : 4958.40380859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 771 | train_loss : 2679.101318359375 | val_loss : 7703.3544921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 772 | train_loss : 2003.61669921875 | val_loss : 5422.7470703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 773 | train_loss : 2730.6044921875 | val_loss : 7626.72314453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 774 | train_loss : 1984.72412109375 | val_loss : 4651.208984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 775 | train_loss : 2516.69775390625 | val_loss : 7377.73046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 776 | train_loss : 1919.14013671875 | val_loss : 4855.0439453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 777 | train_loss : 2518.531005859375 | val_loss : 7399.03173828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 778 | train_loss : 1973.1466064453125 | val_loss : 4519.7744140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 779 | train_loss : 2320.93603515625 | val_loss : 7257.7470703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 780 | train_loss : 1936.569580078125 | val_loss : 4710.7236328125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 781 | train_loss : 2466.69677734375 | val_loss : 7408.97998046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 782 | train_loss : 2006.8087158203125 | val_loss : 4376.86767578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 783 | train_loss : 2263.3251953125 | val_loss : 7266.55615234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 784 | train_loss : 1966.5777587890625 | val_loss : 4569.36572265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 785 | train_loss : 2416.73486328125 | val_loss : 7427.77734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 786 | train_loss : 2039.1591796875 | val_loss : 4567.87255859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 787 | train_loss : 2247.530517578125 | val_loss : 7468.5361328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 788 | train_loss : 2117.440673828125 | val_loss : 4342.755859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 789 | train_loss : 2146.26025390625 | val_loss : 7900.54638671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 790 | train_loss : 2243.23681640625 | val_loss : 4495.931640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 791 | train_loss : 2181.111328125 | val_loss : 6953.083984375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 792 | train_loss : 1759.8297119140625 | val_loss : 4202.841796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 793 | train_loss : 2968.31005859375 | val_loss : 7228.125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 794 | train_loss : 1949.1650390625 | val_loss : 4500.23583984375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 795 | train_loss : 2410.60107421875 | val_loss : 7600.4013671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 796 | train_loss : 2081.804931640625 | val_loss : 4151.8857421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 797 | train_loss : 2206.323486328125 | val_loss : 7358.716796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 798 | train_loss : 2042.185791015625 | val_loss : 4257.595703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 799 | train_loss : 2240.9814453125 | val_loss : 7783.71435546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 6 | epoch : 800 | train_loss : 2167.929443359375 | val_loss : 4114.1435546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 7 | epoch : 1 | train_loss : 391091.625 | val_loss : 840677.125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 2 | train_loss : 715719.5 | val_loss : 823173.6875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 3 | train_loss : 800928.9375 | val_loss : 608119.625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 4 | train_loss : 674494.1875 | val_loss : 196023.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 5 | train_loss : 196491.984375 | val_loss : 268205.875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 6 | train_loss : 189426.453125 | val_loss : 278388.8125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 7 | train_loss : 255705.953125 | val_loss : 228244.796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 8 | train_loss : 187442.578125 | val_loss : 172779.015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 9 | train_loss : 200445.734375 | val_loss : 171081.921875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 10 | train_loss : 179022.3125 | val_loss : 380866.15625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 11 | train_loss : 308646.1875 | val_loss : 533786.8125 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 12 | train_loss : 500497.125 | val_loss : 521054.09375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 13 | train_loss : 552149.4375 | val_loss : 134663.40625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 14 | train_loss : 157954.90625 | val_loss : 154587.84375 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 15 | train_loss : 170523.734375 | val_loss : 117105.34375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 16 | train_loss : 99893.140625 | val_loss : 204320.546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 17 | train_loss : 214009.078125 | val_loss : 163942.0 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 18 | train_loss : 228925.703125 | val_loss : 113205.0234375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 19 | train_loss : 171711.359375 | val_loss : 171937.34375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 20 | train_loss : 145032.125 | val_loss : 229983.484375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 21 | train_loss : 206746.640625 | val_loss : 199678.859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 22 | train_loss : 228867.578125 | val_loss : 174593.875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 23 | train_loss : 239551.21875 | val_loss : 83303.2578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 24 | train_loss : 125871.9296875 | val_loss : 272919.375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 25 | train_loss : 221290.078125 | val_loss : 37666.78515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 26 | train_loss : 41188.828125 | val_loss : 89548.15625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 27 | train_loss : 89049.59375 | val_loss : 89961.7578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 28 | train_loss : 118169.53125 | val_loss : 117739.1796875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 29 | train_loss : 125291.671875 | val_loss : 168324.484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 30 | train_loss : 169573.375 | val_loss : 274096.03125 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 31 | train_loss : 244820.6875 | val_loss : 166402.453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 32 | train_loss : 194399.0 | val_loss : 215390.578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 33 | train_loss : 227665.765625 | val_loss : 79552.453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 34 | train_loss : 83257.4296875 | val_loss : 89679.3515625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 35 | train_loss : 99558.03125 | val_loss : 189872.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 36 | train_loss : 175139.359375 | val_loss : 87046.6875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 37 | train_loss : 99637.9765625 | val_loss : 62161.9609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 38 | train_loss : 108537.9765625 | val_loss : 281066.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 39 | train_loss : 221276.421875 | val_loss : 183827.0625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 40 | train_loss : 186700.515625 | val_loss : 89991.2265625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 41 | train_loss : 71423.375 | val_loss : 166956.375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 42 | train_loss : 171902.1875 | val_loss : 43147.2109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 43 | train_loss : 71970.1484375 | val_loss : 113101.9609375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 44 | train_loss : 95632.4296875 | val_loss : 80961.5390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 45 | train_loss : 122914.828125 | val_loss : 136212.6875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 46 | train_loss : 117474.609375 | val_loss : 97805.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 47 | train_loss : 156900.3125 | val_loss : 125678.609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 48 | train_loss : 105706.5390625 | val_loss : 49402.40625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 49 | train_loss : 64117.0234375 | val_loss : 75203.9140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 50 | train_loss : 80520.53125 | val_loss : 72119.3359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 51 | train_loss : 79730.0703125 | val_loss : 169151.3125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 52 | train_loss : 157636.78125 | val_loss : 61902.8359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 53 | train_loss : 76163.765625 | val_loss : 67715.921875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 54 | train_loss : 117314.1328125 | val_loss : 245593.015625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 55 | train_loss : 188800.515625 | val_loss : 158801.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 56 | train_loss : 160998.71875 | val_loss : 16413.939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 57 | train_loss : 30836.841796875 | val_loss : 98540.8671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 58 | train_loss : 82926.4296875 | val_loss : 21950.41796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 59 | train_loss : 36963.94140625 | val_loss : 91317.296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 60 | train_loss : 75765.5625 | val_loss : 73329.1171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 61 | train_loss : 121489.8125 | val_loss : 34154.64453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 62 | train_loss : 30672.984375 | val_loss : 56768.921875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 63 | train_loss : 97661.5625 | val_loss : 169510.359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 64 | train_loss : 121535.59375 | val_loss : 129573.7578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 65 | train_loss : 137866.890625 | val_loss : 70361.78125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 66 | train_loss : 86456.703125 | val_loss : 69790.9765625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 67 | train_loss : 120630.6015625 | val_loss : 149442.1875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 68 | train_loss : 109206.7734375 | val_loss : 53911.26171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 69 | train_loss : 41993.734375 | val_loss : 15821.0908203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 70 | train_loss : 37308.51171875 | val_loss : 92599.3984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 71 | train_loss : 77459.2734375 | val_loss : 21217.015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 72 | train_loss : 34033.53515625 | val_loss : 71459.8828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 73 | train_loss : 68203.2265625 | val_loss : 63220.48828125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 74 | train_loss : 112848.25 | val_loss : 187945.046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 75 | train_loss : 144202.96875 | val_loss : 139046.25 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 76 | train_loss : 126755.2421875 | val_loss : 27617.044921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 77 | train_loss : 56624.546875 | val_loss : 95544.8828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 78 | train_loss : 75677.71875 | val_loss : 19596.146484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 79 | train_loss : 45789.9140625 | val_loss : 104905.71875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 80 | train_loss : 77852.4921875 | val_loss : 71463.6484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 81 | train_loss : 109430.2890625 | val_loss : 59895.76171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 82 | train_loss : 88392.40625 | val_loss : 134293.84375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 83 | train_loss : 109370.296875 | val_loss : 97198.546875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 84 | train_loss : 107440.7421875 | val_loss : 74916.59375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 85 | train_loss : 86902.65625 | val_loss : 17873.806640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 86 | train_loss : 40727.49609375 | val_loss : 95871.390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 87 | train_loss : 63471.3046875 | val_loss : 15002.603515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 88 | train_loss : 37762.73828125 | val_loss : 113970.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 89 | train_loss : 86421.0625 | val_loss : 12824.5498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 90 | train_loss : 20941.1953125 | val_loss : 42143.76171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 91 | train_loss : 42574.2734375 | val_loss : 41559.7578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 92 | train_loss : 81206.28125 | val_loss : 58834.8203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 93 | train_loss : 43248.18359375 | val_loss : 15533.025390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 94 | train_loss : 39680.38671875 | val_loss : 131676.15625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 95 | train_loss : 100852.90625 | val_loss : 46658.5390625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 96 | train_loss : 36985.7109375 | val_loss : 10004.7548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 97 | train_loss : 29292.240234375 | val_loss : 92451.3984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 98 | train_loss : 73324.2578125 | val_loss : 18430.0078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 99 | train_loss : 32966.1640625 | val_loss : 56676.0 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 100 | train_loss : 59724.00390625 | val_loss : 24143.267578125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 101 | train_loss : 53075.8359375 | val_loss : 163952.765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 102 | train_loss : 118360.2734375 | val_loss : 67681.8671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 103 | train_loss : 56634.890625 | val_loss : 53855.71875 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 104 | train_loss : 73314.3671875 | val_loss : 68901.3125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 105 | train_loss : 89226.5625 | val_loss : 65774.296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 106 | train_loss : 74567.2578125 | val_loss : 21774.685546875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 107 | train_loss : 45277.31640625 | val_loss : 57456.78125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 108 | train_loss : 48075.92578125 | val_loss : 13911.927734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 109 | train_loss : 36230.68359375 | val_loss : 75757.046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 110 | train_loss : 59766.6640625 | val_loss : 5252.5224609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 111 | train_loss : 15614.3837890625 | val_loss : 49626.015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 112 | train_loss : 42572.51953125 | val_loss : 30521.259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 113 | train_loss : 45246.6640625 | val_loss : 84583.0 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 114 | train_loss : 83858.9375 | val_loss : 46225.73046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 115 | train_loss : 35703.07421875 | val_loss : 83027.6015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 116 | train_loss : 89015.9765625 | val_loss : 26504.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 117 | train_loss : 42262.1953125 | val_loss : 81764.9609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 118 | train_loss : 63967.953125 | val_loss : 13722.1279296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 119 | train_loss : 15480.8896484375 | val_loss : 7788.68115234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 120 | train_loss : 20398.595703125 | val_loss : 45478.30078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 121 | train_loss : 43263.12109375 | val_loss : 46487.58984375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 122 | train_loss : 85735.171875 | val_loss : 79897.8125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 123 | train_loss : 61551.65625 | val_loss : 25244.962890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 124 | train_loss : 35470.73828125 | val_loss : 9792.05859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 125 | train_loss : 23226.20703125 | val_loss : 64386.2109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 126 | train_loss : 54231.57421875 | val_loss : 52640.94140625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 127 | train_loss : 97106.2265625 | val_loss : 101380.7109375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 128 | train_loss : 82736.9453125 | val_loss : 49448.42578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 129 | train_loss : 54930.0703125 | val_loss : 37353.1640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 130 | train_loss : 75644.421875 | val_loss : 76938.0234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 131 | train_loss : 58221.12890625 | val_loss : 9665.3623046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 132 | train_loss : 18123.482421875 | val_loss : 37954.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 133 | train_loss : 42060.62109375 | val_loss : 69996.6875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 134 | train_loss : 76550.53125 | val_loss : 69740.2890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 135 | train_loss : 85178.546875 | val_loss : 33818.1015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 136 | train_loss : 33394.5234375 | val_loss : 75377.71875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 137 | train_loss : 74340.4375 | val_loss : 27726.244140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 138 | train_loss : 29828.509765625 | val_loss : 63383.48046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 139 | train_loss : 65042.73828125 | val_loss : 36822.2109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 140 | train_loss : 44426.6484375 | val_loss : 37188.25390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 141 | train_loss : 41424.84765625 | val_loss : 35485.078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 142 | train_loss : 42949.078125 | val_loss : 89395.4609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 143 | train_loss : 83138.265625 | val_loss : 36790.9765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 144 | train_loss : 25473.1015625 | val_loss : 14277.611328125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 145 | train_loss : 35122.640625 | val_loss : 48524.01953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 146 | train_loss : 46307.26171875 | val_loss : 35649.70703125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 147 | train_loss : 64575.046875 | val_loss : 112320.0703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 148 | train_loss : 82269.46875 | val_loss : 35733.37109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 149 | train_loss : 36178.41015625 | val_loss : 29288.349609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 150 | train_loss : 62934.984375 | val_loss : 44880.91015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 151 | train_loss : 32642.1875 | val_loss : 12014.7548828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 152 | train_loss : 27835.08203125 | val_loss : 107112.4609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 153 | train_loss : 82564.90625 | val_loss : 34555.6875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 154 | train_loss : 29209.376953125 | val_loss : 9528.01953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 155 | train_loss : 25373.587890625 | val_loss : 71106.5078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 156 | train_loss : 57917.0 | val_loss : 10528.0029296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 157 | train_loss : 21452.412109375 | val_loss : 41302.74609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 158 | train_loss : 42259.83984375 | val_loss : 30644.390625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 159 | train_loss : 60164.8359375 | val_loss : 70221.9921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 160 | train_loss : 53287.0390625 | val_loss : 2498.969482421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 161 | train_loss : 10150.2353515625 | val_loss : 22678.16015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 162 | train_loss : 23840.359375 | val_loss : 38860.88671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 163 | train_loss : 56625.4140625 | val_loss : 78013.84375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 164 | train_loss : 73341.2265625 | val_loss : 38818.234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 165 | train_loss : 33054.62890625 | val_loss : 26397.439453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 166 | train_loss : 47300.80078125 | val_loss : 56730.21875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 167 | train_loss : 44098.9765625 | val_loss : 15215.125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 168 | train_loss : 31746.70703125 | val_loss : 40887.4296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 169 | train_loss : 43622.125 | val_loss : 34491.48046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 170 | train_loss : 68775.6171875 | val_loss : 47988.6640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 171 | train_loss : 36749.6015625 | val_loss : 9129.37109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 172 | train_loss : 21541.724609375 | val_loss : 61344.1640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 173 | train_loss : 55016.30859375 | val_loss : 13130.275390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 174 | train_loss : 23023.794921875 | val_loss : 73582.1484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 175 | train_loss : 69444.4375 | val_loss : 38540.06640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 176 | train_loss : 25957.947265625 | val_loss : 42717.2890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 177 | train_loss : 54140.87109375 | val_loss : 36633.87890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 178 | train_loss : 47823.12109375 | val_loss : 39484.02734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 179 | train_loss : 39606.76171875 | val_loss : 14791.81640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 180 | train_loss : 23820.787109375 | val_loss : 47704.69140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 181 | train_loss : 46982.84375 | val_loss : 26724.125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 182 | train_loss : 25029.744140625 | val_loss : 48889.9296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 183 | train_loss : 53185.8515625 | val_loss : 29398.119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 184 | train_loss : 32598.755859375 | val_loss : 60017.94921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 185 | train_loss : 56973.83984375 | val_loss : 25699.240234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 186 | train_loss : 18767.3984375 | val_loss : 20659.935546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 187 | train_loss : 29271.33203125 | val_loss : 45133.375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 188 | train_loss : 54639.38671875 | val_loss : 68090.1328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 189 | train_loss : 65863.5390625 | val_loss : 21384.19921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 190 | train_loss : 23030.970703125 | val_loss : 32110.064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 191 | train_loss : 49244.90625 | val_loss : 55631.25 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 192 | train_loss : 55164.53125 | val_loss : 19901.921875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 193 | train_loss : 29643.140625 | val_loss : 48277.6484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 194 | train_loss : 50129.98046875 | val_loss : 16226.9423828125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 195 | train_loss : 35665.07421875 | val_loss : 73036.71875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 196 | train_loss : 60356.42578125 | val_loss : 19157.279296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 197 | train_loss : 26190.02734375 | val_loss : 57385.296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 198 | train_loss : 60764.94140625 | val_loss : 47554.75 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 199 | train_loss : 81046.0546875 | val_loss : 101221.96875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 200 | train_loss : 75740.28125 | val_loss : 40728.9453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 201 | train_loss : 36061.28125 | val_loss : 17044.158203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 202 | train_loss : 35987.390625 | val_loss : 34703.96484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 203 | train_loss : 31533.2265625 | val_loss : 22666.267578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 204 | train_loss : 48610.87890625 | val_loss : 34275.5390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 205 | train_loss : 26938.1953125 | val_loss : 8582.890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 206 | train_loss : 21678.984375 | val_loss : 55678.6484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 207 | train_loss : 50607.12109375 | val_loss : 6022.39501953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 208 | train_loss : 11127.19140625 | val_loss : 33121.91796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 209 | train_loss : 34850.70703125 | val_loss : 34038.92578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 210 | train_loss : 31787.2265625 | val_loss : 52932.90625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 211 | train_loss : 59588.58984375 | val_loss : 16814.1875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 212 | train_loss : 20505.1328125 | val_loss : 44613.88671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 213 | train_loss : 50660.6484375 | val_loss : 23807.740234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 214 | train_loss : 24496.587890625 | val_loss : 44539.06640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 215 | train_loss : 50215.60546875 | val_loss : 15317.134765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 216 | train_loss : 15776.9990234375 | val_loss : 22073.1953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 217 | train_loss : 26783.46484375 | val_loss : 25823.9296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 218 | train_loss : 27595.01171875 | val_loss : 45387.80859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 219 | train_loss : 46502.265625 | val_loss : 19591.01953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 220 | train_loss : 16621.9765625 | val_loss : 11100.1875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 221 | train_loss : 23493.89453125 | val_loss : 42675.2109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 222 | train_loss : 46356.609375 | val_loss : 73589.6875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 223 | train_loss : 60224.39453125 | val_loss : 43040.859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 224 | train_loss : 47206.9609375 | val_loss : 42870.07421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 225 | train_loss : 52610.19921875 | val_loss : 4613.79833984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 226 | train_loss : 19481.3984375 | val_loss : 25098.392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 227 | train_loss : 20905.724609375 | val_loss : 10725.65234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 228 | train_loss : 25394.150390625 | val_loss : 46561.37890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 229 | train_loss : 43156.82421875 | val_loss : 8127.55126953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 230 | train_loss : 12615.625 | val_loss : 28176.39453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 231 | train_loss : 31810.5390625 | val_loss : 26948.205078125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 232 | train_loss : 29085.060546875 | val_loss : 50872.6015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 233 | train_loss : 56290.43359375 | val_loss : 19592.169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 234 | train_loss : 17784.44921875 | val_loss : 28948.80078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 235 | train_loss : 36034.9296875 | val_loss : 18942.267578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 236 | train_loss : 21396.810546875 | val_loss : 42160.33984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 237 | train_loss : 46859.6796875 | val_loss : 18390.775390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 238 | train_loss : 15133.0498046875 | val_loss : 21251.650390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 239 | train_loss : 29165.8984375 | val_loss : 20302.67578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 240 | train_loss : 22905.60546875 | val_loss : 42744.69921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 241 | train_loss : 45477.42578125 | val_loss : 20689.876953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 242 | train_loss : 14882.9990234375 | val_loss : 10025.2626953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 243 | train_loss : 20211.73046875 | val_loss : 27008.33203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 244 | train_loss : 31835.158203125 | val_loss : 48966.75390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 245 | train_loss : 47691.44140625 | val_loss : 13089.3203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 246 | train_loss : 11454.2548828125 | val_loss : 4782.71923828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 247 | train_loss : 14668.7001953125 | val_loss : 38252.15625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 248 | train_loss : 25637.216796875 | val_loss : 5459.8154296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 249 | train_loss : 13741.6787109375 | val_loss : 33710.46875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 250 | train_loss : 32407.107421875 | val_loss : 8699.00390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 251 | train_loss : 15422.16015625 | val_loss : 34950.8515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 252 | train_loss : 39787.0859375 | val_loss : 26124.857421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 253 | train_loss : 24255.2109375 | val_loss : 44190.2734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 254 | train_loss : 50127.19140625 | val_loss : 17889.501953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 255 | train_loss : 16671.80078125 | val_loss : 24217.3515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 256 | train_loss : 32176.6796875 | val_loss : 16775.19140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 257 | train_loss : 18350.130859375 | val_loss : 31908.814453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 258 | train_loss : 37078.0859375 | val_loss : 17263.630859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 259 | train_loss : 15053.4853515625 | val_loss : 21595.1015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 260 | train_loss : 31960.162109375 | val_loss : 19079.890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 261 | train_loss : 19961.671875 | val_loss : 40364.69140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 262 | train_loss : 41715.13671875 | val_loss : 19853.197265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 263 | train_loss : 13314.798828125 | val_loss : 6498.17626953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 264 | train_loss : 14225.9814453125 | val_loss : 22361.75 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 265 | train_loss : 25408.751953125 | val_loss : 46718.80078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 266 | train_loss : 43837.32421875 | val_loss : 15296.59765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 267 | train_loss : 13331.474609375 | val_loss : 5308.45458984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 268 | train_loss : 14612.2451171875 | val_loss : 20414.591796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 269 | train_loss : 12342.103515625 | val_loss : 16413.751953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 270 | train_loss : 28651.29296875 | val_loss : 51096.546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 271 | train_loss : 43650.5546875 | val_loss : 5389.68359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 272 | train_loss : 7409.46875 | val_loss : 1141.197509765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 273 | train_loss : 6397.36669921875 | val_loss : 6355.56201171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 274 | train_loss : 6363.423828125 | val_loss : 5987.96044921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 275 | train_loss : 9445.2001953125 | val_loss : 22648.26953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 276 | train_loss : 31852.259765625 | val_loss : 42257.17578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 277 | train_loss : 46283.3046875 | val_loss : 15680.298828125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 278 | train_loss : 15320.98046875 | val_loss : 26145.498046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 279 | train_loss : 35274.3984375 | val_loss : 12961.419921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 280 | train_loss : 16961.20703125 | val_loss : 37052.09375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 281 | train_loss : 38062.44921875 | val_loss : 21621.345703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 282 | train_loss : 16299.3037109375 | val_loss : 25498.619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 283 | train_loss : 31276.150390625 | val_loss : 15789.2275390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 284 | train_loss : 17879.1171875 | val_loss : 26762.1015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 285 | train_loss : 30324.232421875 | val_loss : 16379.4970703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 286 | train_loss : 15257.9462890625 | val_loss : 24386.544921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 287 | train_loss : 28311.455078125 | val_loss : 23356.390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 288 | train_loss : 25394.8046875 | val_loss : 32095.775390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 289 | train_loss : 34185.5234375 | val_loss : 17289.9765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 290 | train_loss : 13947.611328125 | val_loss : 7918.748046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 291 | train_loss : 14615.650390625 | val_loss : 24508.8125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 292 | train_loss : 28595.994140625 | val_loss : 28838.654296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 293 | train_loss : 31587.0625 | val_loss : 13956.0048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 294 | train_loss : 11322.9111328125 | val_loss : 20077.32421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 295 | train_loss : 28218.421875 | val_loss : 32052.0546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 296 | train_loss : 29388.02734375 | val_loss : 40289.49609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 297 | train_loss : 41062.82421875 | val_loss : 11566.5048828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 298 | train_loss : 9991.4267578125 | val_loss : 2469.074951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 299 | train_loss : 11541.427734375 | val_loss : 13740.76953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 300 | train_loss : 10615.4404296875 | val_loss : 5066.74951171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 301 | train_loss : 14900.509765625 | val_loss : 20842.185546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 302 | train_loss : 17544.591796875 | val_loss : 14340.416015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 303 | train_loss : 29500.373046875 | val_loss : 31971.22265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 304 | train_loss : 24966.0078125 | val_loss : 7021.02880859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 305 | train_loss : 16217.6279296875 | val_loss : 32843.80078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 306 | train_loss : 26076.099609375 | val_loss : 8996.431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 307 | train_loss : 20054.671875 | val_loss : 25634.875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 308 | train_loss : 21496.5859375 | val_loss : 14171.6884765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 309 | train_loss : 37096.984375 | val_loss : 74015.25 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 310 | train_loss : 46620.35546875 | val_loss : 30462.115234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 311 | train_loss : 54043.82421875 | val_loss : 25183.794921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 312 | train_loss : 33212.9140625 | val_loss : 42054.03515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 313 | train_loss : 32971.609375 | val_loss : 715.0562744140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 314 | train_loss : 8497.615234375 | val_loss : 6428.37451171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 315 | train_loss : 6494.2529296875 | val_loss : 2443.7294921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 316 | train_loss : 6219.72021484375 | val_loss : 8059.5986328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 317 | train_loss : 15009.431640625 | val_loss : 30790.0078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 318 | train_loss : 33142.8515625 | val_loss : 20095.86328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 319 | train_loss : 17084.220703125 | val_loss : 24567.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 320 | train_loss : 29424.33203125 | val_loss : 16307.69921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 321 | train_loss : 18428.466796875 | val_loss : 27383.69921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 322 | train_loss : 32496.61328125 | val_loss : 13880.8125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 323 | train_loss : 15044.98046875 | val_loss : 21526.0859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 324 | train_loss : 26937.779296875 | val_loss : 15209.8203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 325 | train_loss : 17248.25 | val_loss : 20647.67578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 326 | train_loss : 24046.9453125 | val_loss : 18706.435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 327 | train_loss : 19341.408203125 | val_loss : 21018.5078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 328 | train_loss : 24999.5234375 | val_loss : 14664.509765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 329 | train_loss : 11990.4658203125 | val_loss : 12147.3720703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 330 | train_loss : 19262.5546875 | val_loss : 17009.154296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 331 | train_loss : 17513.82421875 | val_loss : 20252.931640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 332 | train_loss : 23464.091796875 | val_loss : 10342.3876953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 333 | train_loss : 11330.7578125 | val_loss : 16178.3408203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 334 | train_loss : 20167.955078125 | val_loss : 49664.921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 335 | train_loss : 51016.73046875 | val_loss : 56301.69140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 336 | train_loss : 60404.05078125 | val_loss : 8069.96875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 337 | train_loss : 8099.423828125 | val_loss : 39469.28515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 338 | train_loss : 57995.08984375 | val_loss : 126736.5 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 339 | train_loss : 91697.84375 | val_loss : 22073.2109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 340 | train_loss : 39237.4609375 | val_loss : 14100.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 341 | train_loss : 28798.181640625 | val_loss : 21542.32421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 342 | train_loss : 21071.845703125 | val_loss : 8780.42578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 343 | train_loss : 19051.689453125 | val_loss : 19085.828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 344 | train_loss : 19583.453125 | val_loss : 6826.21484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 345 | train_loss : 15846.3115234375 | val_loss : 20064.755859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 346 | train_loss : 19855.57421875 | val_loss : 5966.9130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 347 | train_loss : 12791.482421875 | val_loss : 14773.669921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 348 | train_loss : 17626.111328125 | val_loss : 6937.7607421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 349 | train_loss : 15395.9775390625 | val_loss : 15688.1845703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 350 | train_loss : 18627.712890625 | val_loss : 6965.60107421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 351 | train_loss : 14121.318359375 | val_loss : 13332.8935546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 352 | train_loss : 17692.8359375 | val_loss : 16228.1748046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 353 | train_loss : 18532.71484375 | val_loss : 21125.384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 354 | train_loss : 27131.0859375 | val_loss : 23338.60546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 355 | train_loss : 26436.26171875 | val_loss : 36870.8828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 356 | train_loss : 41728.84375 | val_loss : 10037.2177734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 357 | train_loss : 10496.4150390625 | val_loss : 10920.25 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 358 | train_loss : 18755.248046875 | val_loss : 14295.990234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 359 | train_loss : 17080.6171875 | val_loss : 16065.08984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 360 | train_loss : 21291.44921875 | val_loss : 18392.8125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 361 | train_loss : 16101.0810546875 | val_loss : 13444.8046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 362 | train_loss : 20123.60546875 | val_loss : 15897.2314453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 363 | train_loss : 15287.2958984375 | val_loss : 13285.2626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 364 | train_loss : 18066.802734375 | val_loss : 18939.8984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 365 | train_loss : 15420.525390625 | val_loss : 13660.7578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 366 | train_loss : 20074.79296875 | val_loss : 17114.6875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 367 | train_loss : 15018.9951171875 | val_loss : 17737.619140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 368 | train_loss : 21201.7109375 | val_loss : 16236.06640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 369 | train_loss : 13207.4462890625 | val_loss : 9751.0654296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 370 | train_loss : 15606.32421875 | val_loss : 18240.841796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 371 | train_loss : 17068.98046875 | val_loss : 14983.34375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 372 | train_loss : 20385.181640625 | val_loss : 17430.466796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 373 | train_loss : 15743.4873046875 | val_loss : 14399.947265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 374 | train_loss : 20049.234375 | val_loss : 17202.626953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 375 | train_loss : 15891.0234375 | val_loss : 16153.3798828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 376 | train_loss : 20270.091796875 | val_loss : 18754.185546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 377 | train_loss : 16211.193359375 | val_loss : 12831.2470703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 378 | train_loss : 17143.82421875 | val_loss : 16188.54296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 379 | train_loss : 14168.73828125 | val_loss : 9884.62890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 380 | train_loss : 15246.119140625 | val_loss : 17582.2578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 381 | train_loss : 16279.8662109375 | val_loss : 12764.259765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 382 | train_loss : 19442.462890625 | val_loss : 15167.7353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 383 | train_loss : 13891.2861328125 | val_loss : 10493.5634765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 384 | train_loss : 14897.568359375 | val_loss : 15154.31640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 385 | train_loss : 14067.583984375 | val_loss : 9227.4208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 386 | train_loss : 14068.3515625 | val_loss : 17375.650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 387 | train_loss : 15697.21875 | val_loss : 12427.0947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 388 | train_loss : 18157.60546875 | val_loss : 14971.330078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 389 | train_loss : 13611.974609375 | val_loss : 9561.708984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 390 | train_loss : 13982.740234375 | val_loss : 17179.79296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 391 | train_loss : 16793.185546875 | val_loss : 15899.10546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 392 | train_loss : 19171.919921875 | val_loss : 17806.943359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 393 | train_loss : 14804.8349609375 | val_loss : 24605.890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 394 | train_loss : 27450.921875 | val_loss : 17089.537109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 395 | train_loss : 17065.265625 | val_loss : 11601.1689453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 396 | train_loss : 18059.0078125 | val_loss : 15665.1552734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 397 | train_loss : 14719.4228515625 | val_loss : 15574.2177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 398 | train_loss : 19285.8515625 | val_loss : 18498.26171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 399 | train_loss : 16314.181640625 | val_loss : 11793.83984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 400 | train_loss : 16759.92578125 | val_loss : 16688.279296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 401 | train_loss : 14504.5986328125 | val_loss : 8598.865234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 402 | train_loss : 13865.7001953125 | val_loss : 15453.1376953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 403 | train_loss : 13801.59375 | val_loss : 8619.2470703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 404 | train_loss : 13338.7001953125 | val_loss : 16798.169921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 405 | train_loss : 14785.0439453125 | val_loss : 13026.712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 406 | train_loss : 17327.41015625 | val_loss : 51950.26171875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 407 | train_loss : 55480.28125 | val_loss : 49861.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 408 | train_loss : 50474.828125 | val_loss : 22396.51953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 409 | train_loss : 17569.21484375 | val_loss : 2912.09130859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 410 | train_loss : 11993.9521484375 | val_loss : 13246.1796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 411 | train_loss : 11178.875 | val_loss : 10419.8935546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 412 | train_loss : 20591.515625 | val_loss : 21033.09765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 413 | train_loss : 16222.9228515625 | val_loss : 7372.05517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 414 | train_loss : 17112.51171875 | val_loss : 17395.712890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 415 | train_loss : 13551.7138671875 | val_loss : 7814.921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 416 | train_loss : 16456.763671875 | val_loss : 21094.259765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 417 | train_loss : 15194.037109375 | val_loss : 7123.67919921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 418 | train_loss : 14744.017578125 | val_loss : 17915.62890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 419 | train_loss : 13345.4296875 | val_loss : 7554.60498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 420 | train_loss : 16457.578125 | val_loss : 16871.423828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 421 | train_loss : 12251.9365234375 | val_loss : 5607.0595703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 422 | train_loss : 13036.0625 | val_loss : 15015.1875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 423 | train_loss : 10538.212890625 | val_loss : 4226.7861328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 424 | train_loss : 8873.4443359375 | val_loss : 9027.224609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 425 | train_loss : 6798.70263671875 | val_loss : 2127.157470703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 426 | train_loss : 5714.88427734375 | val_loss : 8260.7314453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 427 | train_loss : 6052.5341796875 | val_loss : 2484.66943359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 428 | train_loss : 6774.08642578125 | val_loss : 13742.0771484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 429 | train_loss : 8341.0634765625 | val_loss : 3464.79443359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 430 | train_loss : 8099.63134765625 | val_loss : 13601.0947265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 431 | train_loss : 8792.2509765625 | val_loss : 6178.79248046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 432 | train_loss : 12788.4599609375 | val_loss : 18743.234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 433 | train_loss : 13045.2099609375 | val_loss : 7207.4755859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 434 | train_loss : 14937.8310546875 | val_loss : 18559.669921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 435 | train_loss : 13505.97265625 | val_loss : 7820.2314453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 436 | train_loss : 15261.36328125 | val_loss : 16616.69921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 437 | train_loss : 11780.7998046875 | val_loss : 6200.13330078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 438 | train_loss : 12533.5537109375 | val_loss : 13609.8828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 439 | train_loss : 9713.3115234375 | val_loss : 3564.58251953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 440 | train_loss : 8922.7001953125 | val_loss : 11660.3837890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 441 | train_loss : 7566.30078125 | val_loss : 9240.20703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 442 | train_loss : 16541.1640625 | val_loss : 33256.4453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 443 | train_loss : 26360.1015625 | val_loss : 33401.00390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 444 | train_loss : 51618.9140625 | val_loss : 28686.21484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 445 | train_loss : 15194.15234375 | val_loss : 4266.6591796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 446 | train_loss : 9890.9775390625 | val_loss : 60131.93359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 447 | train_loss : 53776.921875 | val_loss : 39613.7265625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 448 | train_loss : 60810.49609375 | val_loss : 1520.47314453125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 449 | train_loss : 3839.445556640625 | val_loss : 478.8887634277344 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 450 | train_loss : 2719.551025390625 | val_loss : 1458.905029296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 451 | train_loss : 2479.750732421875 | val_loss : 581.5374755859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 452 | train_loss : 2226.110107421875 | val_loss : 1665.76318359375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 453 | train_loss : 2208.78466796875 | val_loss : 790.3343505859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 454 | train_loss : 2012.8199462890625 | val_loss : 1354.1256103515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 455 | train_loss : 2000.3980712890625 | val_loss : 1055.5318603515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 456 | train_loss : 2294.02587890625 | val_loss : 4280.53759765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 457 | train_loss : 3593.861572265625 | val_loss : 2038.800048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 458 | train_loss : 4970.642578125 | val_loss : 16667.845703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 459 | train_loss : 13000.1513671875 | val_loss : 15372.90234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 460 | train_loss : 16772.1640625 | val_loss : 15692.45703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 461 | train_loss : 15661.8984375 | val_loss : 16837.716796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 462 | train_loss : 17361.94921875 | val_loss : 14691.3974609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 463 | train_loss : 12965.8662109375 | val_loss : 10025.7998046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 464 | train_loss : 11887.4873046875 | val_loss : 17283.779296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 465 | train_loss : 16829.6640625 | val_loss : 11983.5751953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 466 | train_loss : 13884.19140625 | val_loss : 19935.853515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 467 | train_loss : 19101.486328125 | val_loss : 14267.7529296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 468 | train_loss : 16495.7890625 | val_loss : 14289.44921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 469 | train_loss : 11706.388671875 | val_loss : 4882.8642578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 470 | train_loss : 8412.4443359375 | val_loss : 14808.0546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 471 | train_loss : 13780.4970703125 | val_loss : 7410.62646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 472 | train_loss : 11585.87890625 | val_loss : 15986.4052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 473 | train_loss : 14629.7998046875 | val_loss : 8065.40380859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 474 | train_loss : 12534.6259765625 | val_loss : 13949.74609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 475 | train_loss : 12496.486328125 | val_loss : 7960.04931640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 476 | train_loss : 10798.5224609375 | val_loss : 14654.7275390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 477 | train_loss : 13378.576171875 | val_loss : 5517.6962890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 478 | train_loss : 9318.1123046875 | val_loss : 14848.2763671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 479 | train_loss : 14506.7900390625 | val_loss : 7760.8505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 480 | train_loss : 10593.326171875 | val_loss : 11543.5673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 481 | train_loss : 13512.53125 | val_loss : 8056.0673828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 482 | train_loss : 10135.00390625 | val_loss : 7980.22509765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 483 | train_loss : 8938.384765625 | val_loss : 3338.358154296875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 484 | train_loss : 6984.6005859375 | val_loss : 12962.5048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 485 | train_loss : 9468.1142578125 | val_loss : 3353.078857421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 486 | train_loss : 7382.888671875 | val_loss : 12072.95703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 487 | train_loss : 8869.5048828125 | val_loss : 3844.851806640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 488 | train_loss : 7434.830078125 | val_loss : 12634.392578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 489 | train_loss : 9576.125 | val_loss : 3684.063720703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 490 | train_loss : 6775.8125 | val_loss : 12818.517578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 491 | train_loss : 9352.19921875 | val_loss : 5631.29248046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 492 | train_loss : 8176.83642578125 | val_loss : 16911.71875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 493 | train_loss : 15991.8583984375 | val_loss : 8328.880859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 494 | train_loss : 10674.0087890625 | val_loss : 15281.72265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 495 | train_loss : 15773.7109375 | val_loss : 10262.9208984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 496 | train_loss : 13213.146484375 | val_loss : 13788.2998046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 497 | train_loss : 12595.1552734375 | val_loss : 2970.992431640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 498 | train_loss : 6638.83447265625 | val_loss : 10677.7099609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 499 | train_loss : 7991.49169921875 | val_loss : 2762.273681640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 500 | train_loss : 6533.60498046875 | val_loss : 11402.3154296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 501 | train_loss : 8658.83984375 | val_loss : 4643.27197265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 502 | train_loss : 7762.04736328125 | val_loss : 12848.4970703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 503 | train_loss : 10560.35546875 | val_loss : 4506.98876953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 504 | train_loss : 7759.22607421875 | val_loss : 20922.384765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 505 | train_loss : 16560.01171875 | val_loss : 16329.9970703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 506 | train_loss : 19340.279296875 | val_loss : 7362.3818359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 507 | train_loss : 7396.62451171875 | val_loss : 1431.795654296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 508 | train_loss : 5498.14990234375 | val_loss : 10141.8974609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 509 | train_loss : 6124.98681640625 | val_loss : 3388.621337890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 510 | train_loss : 5031.06787109375 | val_loss : 8137.341796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 511 | train_loss : 7092.27001953125 | val_loss : 7442.39306640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 512 | train_loss : 7268.5263671875 | val_loss : 8802.7626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 513 | train_loss : 12529.0439453125 | val_loss : 8098.07373046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 514 | train_loss : 8414.966796875 | val_loss : 11563.3291015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 515 | train_loss : 13992.7333984375 | val_loss : 8560.853515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 516 | train_loss : 9905.00390625 | val_loss : 12293.4560546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 517 | train_loss : 11087.673828125 | val_loss : 3423.1142578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 518 | train_loss : 8005.19140625 | val_loss : 9702.4423828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 519 | train_loss : 7321.591796875 | val_loss : 1974.2119140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 520 | train_loss : 5095.57080078125 | val_loss : 9848.0107421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 521 | train_loss : 6214.18505859375 | val_loss : 1814.9337158203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 522 | train_loss : 5311.21875 | val_loss : 9429.1083984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 523 | train_loss : 6230.01513671875 | val_loss : 1977.4200439453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 524 | train_loss : 5696.87890625 | val_loss : 9996.78515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 525 | train_loss : 6847.79638671875 | val_loss : 3029.987548828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 526 | train_loss : 6439.26953125 | val_loss : 10080.73046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 527 | train_loss : 6766.39697265625 | val_loss : 2881.951171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 528 | train_loss : 5348.73876953125 | val_loss : 9622.4794921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 529 | train_loss : 6655.9462890625 | val_loss : 3028.675048828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 530 | train_loss : 6039.646484375 | val_loss : 10015.9677734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 531 | train_loss : 7130.78271484375 | val_loss : 3455.27197265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 532 | train_loss : 6492.31884765625 | val_loss : 11115.3525390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 533 | train_loss : 7886.98583984375 | val_loss : 4168.43798828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 534 | train_loss : 6352.271484375 | val_loss : 13454.0400390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 535 | train_loss : 11336.84765625 | val_loss : 4988.29931640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 536 | train_loss : 7416.82763671875 | val_loss : 12411.9599609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 537 | train_loss : 11537.2822265625 | val_loss : 3317.1767578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 538 | train_loss : 7095.2880859375 | val_loss : 9564.556640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 539 | train_loss : 6225.82861328125 | val_loss : 1682.5174560546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 540 | train_loss : 4020.13134765625 | val_loss : 9560.5732421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 541 | train_loss : 5955.45703125 | val_loss : 2091.581787109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 542 | train_loss : 4795.0439453125 | val_loss : 11049.0947265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 543 | train_loss : 7088.390625 | val_loss : 2241.077392578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 544 | train_loss : 5575.044921875 | val_loss : 10034.291015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 545 | train_loss : 6848.8173828125 | val_loss : 2796.564453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 546 | train_loss : 6304.1298828125 | val_loss : 10010.123046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 547 | train_loss : 6611.32421875 | val_loss : 1798.87255859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 548 | train_loss : 5174.07568359375 | val_loss : 10213.359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 549 | train_loss : 6717.2529296875 | val_loss : 3026.4375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 550 | train_loss : 5632.22802734375 | val_loss : 10397.48828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 551 | train_loss : 7012.39208984375 | val_loss : 2517.467529296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 552 | train_loss : 5724.07666015625 | val_loss : 9628.40234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 553 | train_loss : 6328.81103515625 | val_loss : 1678.5537109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 554 | train_loss : 4939.86083984375 | val_loss : 10485.9453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 555 | train_loss : 7173.35009765625 | val_loss : 2997.260009765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 556 | train_loss : 5936.4375 | val_loss : 9633.3154296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 557 | train_loss : 6556.12744140625 | val_loss : 2649.914306640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 558 | train_loss : 5681.6806640625 | val_loss : 9750.2119140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 559 | train_loss : 6809.17236328125 | val_loss : 3770.137451171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 560 | train_loss : 6499.38818359375 | val_loss : 9043.28515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 561 | train_loss : 6433.34375 | val_loss : 19028.435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 562 | train_loss : 20626.322265625 | val_loss : 21117.3359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 563 | train_loss : 22121.3046875 | val_loss : 13098.875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 564 | train_loss : 15787.30078125 | val_loss : 7733.28759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 565 | train_loss : 8685.7880859375 | val_loss : 3509.510009765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 566 | train_loss : 5652.9482421875 | val_loss : 6669.7880859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 567 | train_loss : 5741.64013671875 | val_loss : 2671.650634765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 568 | train_loss : 4228.205078125 | val_loss : 6651.14013671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 569 | train_loss : 4770.41552734375 | val_loss : 2137.206787109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 570 | train_loss : 3455.532470703125 | val_loss : 5221.435546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 571 | train_loss : 4489.93115234375 | val_loss : 3039.8681640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 572 | train_loss : 3714.260986328125 | val_loss : 2604.72119140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 573 | train_loss : 3806.31689453125 | val_loss : 2047.427490234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 574 | train_loss : 3127.546630859375 | val_loss : 6108.04833984375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 575 | train_loss : 4590.21435546875 | val_loss : 1536.9569091796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 576 | train_loss : 3438.67626953125 | val_loss : 8471.673828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 577 | train_loss : 5295.974609375 | val_loss : 1923.4837646484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 578 | train_loss : 4626.02978515625 | val_loss : 8882.734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 579 | train_loss : 5665.154296875 | val_loss : 2854.234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 580 | train_loss : 4589.318359375 | val_loss : 9616.6025390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 581 | train_loss : 5988.78076171875 | val_loss : 2317.255615234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 582 | train_loss : 4576.232421875 | val_loss : 10575.857421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 583 | train_loss : 7047.4658203125 | val_loss : 2842.886962890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 584 | train_loss : 5328.04052734375 | val_loss : 10073.306640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 585 | train_loss : 7050.7529296875 | val_loss : 3327.060546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 586 | train_loss : 5971.18798828125 | val_loss : 9169.7060546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 587 | train_loss : 6186.80517578125 | val_loss : 1633.85498046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 588 | train_loss : 4889.5654296875 | val_loss : 7536.66943359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 589 | train_loss : 4491.04833984375 | val_loss : 1056.2587890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 590 | train_loss : 4031.851806640625 | val_loss : 7140.873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 591 | train_loss : 3684.0302734375 | val_loss : 1142.93505859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 592 | train_loss : 4022.083740234375 | val_loss : 7491.02685546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 593 | train_loss : 4253.25 | val_loss : 1207.748779296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 594 | train_loss : 4077.173828125 | val_loss : 7497.44189453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 595 | train_loss : 4362.76806640625 | val_loss : 1270.1400146484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 596 | train_loss : 4354.287109375 | val_loss : 7105.47119140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 597 | train_loss : 3707.649658203125 | val_loss : 631.8543701171875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 598 | train_loss : 3014.788818359375 | val_loss : 8946.4208984375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 599 | train_loss : 4014.741943359375 | val_loss : 309.8324890136719 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 600 | train_loss : 2474.9951171875 | val_loss : 8305.94921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 601 | train_loss : 3562.45166015625 | val_loss : 779.510009765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 602 | train_loss : 2540.367919921875 | val_loss : 7781.45166015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 603 | train_loss : 3664.701171875 | val_loss : 886.451904296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 604 | train_loss : 3295.05322265625 | val_loss : 7331.97509765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 605 | train_loss : 3519.639404296875 | val_loss : 675.8574829101562 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 606 | train_loss : 2796.772705078125 | val_loss : 8036.2158203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 607 | train_loss : 3501.73291015625 | val_loss : 592.326904296875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 608 | train_loss : 2446.845703125 | val_loss : 8992.0205078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 609 | train_loss : 3835.355712890625 | val_loss : 728.796875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 610 | train_loss : 2342.7880859375 | val_loss : 7441.7236328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 611 | train_loss : 3195.094970703125 | val_loss : 854.7224731445312 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 612 | train_loss : 2602.653564453125 | val_loss : 7814.03515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 613 | train_loss : 3660.168701171875 | val_loss : 792.2781372070312 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 614 | train_loss : 3085.851806640625 | val_loss : 7944.171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 615 | train_loss : 3933.534423828125 | val_loss : 2051.456298828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 616 | train_loss : 4252.509765625 | val_loss : 8069.9033203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 617 | train_loss : 5030.92578125 | val_loss : 1461.923095703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 618 | train_loss : 4093.889892578125 | val_loss : 7384.03076171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 619 | train_loss : 4391.52734375 | val_loss : 1325.5819091796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 620 | train_loss : 4288.3447265625 | val_loss : 7015.85888671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 621 | train_loss : 4297.37890625 | val_loss : 592.6018676757812 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 622 | train_loss : 3589.93115234375 | val_loss : 7033.46630859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 623 | train_loss : 3542.83740234375 | val_loss : 255.2762451171875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 624 | train_loss : 2660.19384765625 | val_loss : 8726.6455078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 625 | train_loss : 4122.3173828125 | val_loss : 522.041259765625 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 626 | train_loss : 2636.880615234375 | val_loss : 7354.3349609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 627 | train_loss : 3514.314697265625 | val_loss : 554.7125244140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 628 | train_loss : 2155.336181640625 | val_loss : 3769.560546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 629 | train_loss : 2387.18798828125 | val_loss : 647.3487548828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 630 | train_loss : 2022.65771484375 | val_loss : 4178.67919921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 631 | train_loss : 2645.383056640625 | val_loss : 849.7037353515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 632 | train_loss : 3030.755859375 | val_loss : 8265.1826171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 633 | train_loss : 4505.48779296875 | val_loss : 795.3056030273438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 634 | train_loss : 3531.345947265625 | val_loss : 7275.380859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 635 | train_loss : 3887.547607421875 | val_loss : 1378.9393310546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 636 | train_loss : 4198.47509765625 | val_loss : 7400.4267578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 637 | train_loss : 4425.0498046875 | val_loss : 1844.03125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 638 | train_loss : 4702.49609375 | val_loss : 7870.37744140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 639 | train_loss : 4487.78076171875 | val_loss : 1647.6474609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 640 | train_loss : 4179.66064453125 | val_loss : 8296.556640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 641 | train_loss : 5030.0693359375 | val_loss : 1824.3787841796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 642 | train_loss : 4877.62841796875 | val_loss : 8822.3427734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 643 | train_loss : 5217.1904296875 | val_loss : 1562.2119140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 644 | train_loss : 3632.331787109375 | val_loss : 8656.47265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 645 | train_loss : 4527.33935546875 | val_loss : 1455.653076171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 646 | train_loss : 3568.73291015625 | val_loss : 8667.3466796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 647 | train_loss : 4554.2236328125 | val_loss : 1480.5394287109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 648 | train_loss : 4401.69921875 | val_loss : 7588.66259765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 649 | train_loss : 4376.58056640625 | val_loss : 1960.31005859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 650 | train_loss : 4999.4794921875 | val_loss : 7721.36865234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 651 | train_loss : 4747.74951171875 | val_loss : 1950.255615234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 652 | train_loss : 5156.599609375 | val_loss : 8229.0625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 653 | train_loss : 4299.5625 | val_loss : 3622.203857421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 654 | train_loss : 6669.65380859375 | val_loss : 18603.265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 655 | train_loss : 9497.0283203125 | val_loss : 10673.18359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 656 | train_loss : 18186.390625 | val_loss : 18796.216796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 657 | train_loss : 11419.337890625 | val_loss : 9268.2177734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 658 | train_loss : 16505.89453125 | val_loss : 19313.310546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 659 | train_loss : 11969.01171875 | val_loss : 9669.2646484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 660 | train_loss : 17235.953125 | val_loss : 17650.03515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 661 | train_loss : 11478.9677734375 | val_loss : 8568.6640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 662 | train_loss : 15847.34375 | val_loss : 15597.77734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 663 | train_loss : 10451.1552734375 | val_loss : 7135.537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 664 | train_loss : 13218.5458984375 | val_loss : 12878.2333984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 665 | train_loss : 9071.28515625 | val_loss : 5401.4873046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 666 | train_loss : 10990.15625 | val_loss : 9117.173828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 667 | train_loss : 5345.37353515625 | val_loss : 1976.7099609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 668 | train_loss : 5147.13330078125 | val_loss : 10197.26171875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 669 | train_loss : 6079.08447265625 | val_loss : 2981.999267578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 670 | train_loss : 6251.98046875 | val_loss : 10609.3271484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 671 | train_loss : 5881.5625 | val_loss : 2106.045654296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 672 | train_loss : 6041.88134765625 | val_loss : 8652.7001953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 673 | train_loss : 5085.83154296875 | val_loss : 2183.57177734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 674 | train_loss : 5369.13818359375 | val_loss : 10245.9990234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 675 | train_loss : 5733.60009765625 | val_loss : 2823.66748046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 676 | train_loss : 5035.89990234375 | val_loss : 9605.791015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 677 | train_loss : 5143.5029296875 | val_loss : 2781.706298828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 678 | train_loss : 5949.79248046875 | val_loss : 9300.4658203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 679 | train_loss : 4923.37939453125 | val_loss : 2358.358642578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 680 | train_loss : 5032.95361328125 | val_loss : 9653.82421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 681 | train_loss : 5261.20458984375 | val_loss : 2764.951904296875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 682 | train_loss : 5735.83203125 | val_loss : 8521.87109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 683 | train_loss : 4677.2216796875 | val_loss : 2532.67626953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 684 | train_loss : 4403.43701171875 | val_loss : 9601.8447265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 685 | train_loss : 4997.46630859375 | val_loss : 2297.2744140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 686 | train_loss : 5445.90576171875 | val_loss : 8518.3681640625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 687 | train_loss : 4331.11962890625 | val_loss : 3112.0380859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 688 | train_loss : 5090.81396484375 | val_loss : 11530.5263671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 689 | train_loss : 5940.486328125 | val_loss : 3527.603759765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 690 | train_loss : 6705.169921875 | val_loss : 13331.9873046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 691 | train_loss : 7268.36767578125 | val_loss : 6272.0 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 692 | train_loss : 10600.5341796875 | val_loss : 11998.0859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 693 | train_loss : 6471.36328125 | val_loss : 3420.408203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 694 | train_loss : 6554.626953125 | val_loss : 11616.982421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 695 | train_loss : 6414.65625 | val_loss : 3854.251220703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 696 | train_loss : 6928.951171875 | val_loss : 11330.8701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 697 | train_loss : 6307.3681640625 | val_loss : 4066.3525390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 698 | train_loss : 7493.7685546875 | val_loss : 13392.91796875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 699 | train_loss : 7565.36572265625 | val_loss : 6589.20556640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 700 | train_loss : 11433.7138671875 | val_loss : 12937.9072265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 701 | train_loss : 7789.56396484375 | val_loss : 6725.048828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 702 | train_loss : 12137.46484375 | val_loss : 11757.33203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 703 | train_loss : 7407.958984375 | val_loss : 2396.483642578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 704 | train_loss : 5660.1181640625 | val_loss : 9659.37890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 705 | train_loss : 5138.30859375 | val_loss : 1846.96875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 706 | train_loss : 4381.86181640625 | val_loss : 10162.72265625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 707 | train_loss : 5473.02978515625 | val_loss : 2057.15185546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 708 | train_loss : 4527.43017578125 | val_loss : 9857.6240234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 709 | train_loss : 4985.52685546875 | val_loss : 2260.431884765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 710 | train_loss : 4539.84228515625 | val_loss : 8257.2578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 711 | train_loss : 4603.47021484375 | val_loss : 2711.280517578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 712 | train_loss : 6034.931640625 | val_loss : 7872.970703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 713 | train_loss : 4489.39990234375 | val_loss : 2481.2919921875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 714 | train_loss : 4967.669921875 | val_loss : 8133.482421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 715 | train_loss : 4165.22705078125 | val_loss : 2005.6331787109375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 716 | train_loss : 4282.52880859375 | val_loss : 8016.9482421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 717 | train_loss : 4180.97509765625 | val_loss : 2180.68505859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 718 | train_loss : 5335.64697265625 | val_loss : 8843.8662109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 719 | train_loss : 4488.2880859375 | val_loss : 3021.6455078125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 720 | train_loss : 4606.81201171875 | val_loss : 8441.3408203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 721 | train_loss : 4493.033203125 | val_loss : 2717.111328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 722 | train_loss : 4970.0419921875 | val_loss : 7857.427734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 723 | train_loss : 4273.205078125 | val_loss : 2098.048828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 724 | train_loss : 5127.0615234375 | val_loss : 8181.240234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 725 | train_loss : 4226.9248046875 | val_loss : 2738.503662109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 726 | train_loss : 4851.6884765625 | val_loss : 9822.0439453125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 727 | train_loss : 4932.04052734375 | val_loss : 2142.126953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 728 | train_loss : 4630.75390625 | val_loss : 8193.5654296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 729 | train_loss : 4232.27197265625 | val_loss : 2712.9736328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 730 | train_loss : 4793.56396484375 | val_loss : 10815.625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 731 | train_loss : 5260.78125 | val_loss : 3164.616943359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 732 | train_loss : 6045.1689453125 | val_loss : 9936.2685546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 733 | train_loss : 4998.14697265625 | val_loss : 3408.361328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 734 | train_loss : 6009.06494140625 | val_loss : 11511.0048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 735 | train_loss : 6071.43359375 | val_loss : 38995.234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 736 | train_loss : 64653.0703125 | val_loss : 112038.9609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 737 | train_loss : 64515.25 | val_loss : 30507.837890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 738 | train_loss : 34774.25390625 | val_loss : 12582.6259765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 739 | train_loss : 12694.662109375 | val_loss : 2666.38134765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 740 | train_loss : 7701.45068359375 | val_loss : 8811.0224609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 741 | train_loss : 6237.28515625 | val_loss : 917.6537475585938 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 742 | train_loss : 4021.342529296875 | val_loss : 8145.80615234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 743 | train_loss : 5080.79833984375 | val_loss : 1811.8031005859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 744 | train_loss : 4061.641845703125 | val_loss : 8502.5126953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 745 | train_loss : 5443.97509765625 | val_loss : 13070.474609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 746 | train_loss : 14402.205078125 | val_loss : 21019.908203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 747 | train_loss : 23621.681640625 | val_loss : 12035.5087890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 748 | train_loss : 14898.169921875 | val_loss : 16581.05078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 749 | train_loss : 18086.79296875 | val_loss : 16452.8515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 750 | train_loss : 16318.4384765625 | val_loss : 6407.3837890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 751 | train_loss : 5299.9931640625 | val_loss : 1454.6968994140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 752 | train_loss : 3211.419921875 | val_loss : 3835.9013671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 753 | train_loss : 2782.2412109375 | val_loss : 716.1412353515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 754 | train_loss : 2586.7392578125 | val_loss : 7485.70166015625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 755 | train_loss : 3718.191162109375 | val_loss : 398.9337463378906 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 756 | train_loss : 2403.930908203125 | val_loss : 8119.9404296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 757 | train_loss : 3393.86083984375 | val_loss : 549.431884765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 758 | train_loss : 1995.002685546875 | val_loss : 4239.91796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 759 | train_loss : 1917.149658203125 | val_loss : 417.94000244140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 760 | train_loss : 1428.699951171875 | val_loss : 3970.465087890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 761 | train_loss : 1831.14794921875 | val_loss : 722.2793579101562 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 762 | train_loss : 1944.94775390625 | val_loss : 7083.6513671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 763 | train_loss : 3320.383056640625 | val_loss : 1112.6700439453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 764 | train_loss : 3426.970947265625 | val_loss : 6060.58544921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 765 | train_loss : 2949.501220703125 | val_loss : 512.02001953125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 766 | train_loss : 2350.845703125 | val_loss : 7235.30859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 767 | train_loss : 2946.751953125 | val_loss : 632.98876953125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 768 | train_loss : 2161.33544921875 | val_loss : 6065.5654296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 769 | train_loss : 2554.17431640625 | val_loss : 822.8306274414062 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 770 | train_loss : 2211.33837890625 | val_loss : 5573.427734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 771 | train_loss : 2752.287109375 | val_loss : 975.2256469726562 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 772 | train_loss : 2601.902587890625 | val_loss : 6833.4091796875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 773 | train_loss : 3004.023681640625 | val_loss : 685.5462646484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 774 | train_loss : 2295.81103515625 | val_loss : 7205.77685546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 775 | train_loss : 3124.329345703125 | val_loss : 964.813720703125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 776 | train_loss : 2584.778076171875 | val_loss : 6793.251953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 777 | train_loss : 3023.3701171875 | val_loss : 566.7100219726562 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 778 | train_loss : 2071.277587890625 | val_loss : 6893.453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 779 | train_loss : 2957.12646484375 | val_loss : 577.109375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 780 | train_loss : 2117.429443359375 | val_loss : 7290.95068359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 781 | train_loss : 3113.9208984375 | val_loss : 676.7675170898438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 782 | train_loss : 2286.925537109375 | val_loss : 6851.54296875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 783 | train_loss : 2948.340576171875 | val_loss : 779.4343872070312 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 784 | train_loss : 2144.881591796875 | val_loss : 7553.349609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 785 | train_loss : 3613.60302734375 | val_loss : 967.8200073242188 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 786 | train_loss : 3108.37744140625 | val_loss : 6410.49169921875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 787 | train_loss : 3070.3564453125 | val_loss : 596.974365234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 788 | train_loss : 1898.1590576171875 | val_loss : 3208.619384765625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 789 | train_loss : 1602.7359619140625 | val_loss : 502.989990234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 790 | train_loss : 1124.786376953125 | val_loss : 948.6962280273438 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 791 | train_loss : 1072.2862548828125 | val_loss : 642.8812255859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 792 | train_loss : 1752.20751953125 | val_loss : 6899.28271484375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 793 | train_loss : 4195.9580078125 | val_loss : 1578.2774658203125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 794 | train_loss : 3960.4013671875 | val_loss : 5672.88232421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 795 | train_loss : 3986.60791015625 | val_loss : 1389.6962890625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 796 | train_loss : 3925.85302734375 | val_loss : 8092.2919921875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 797 | train_loss : 5550.78857421875 | val_loss : 4437.96728515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 798 | train_loss : 6944.83984375 | val_loss : 8115.89013671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 799 | train_loss : 8216.224609375 | val_loss : 3777.05322265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 7 | epoch : 800 | train_loss : 4966.6162109375 | val_loss : 6331.77734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 8 | epoch : 1 | train_loss : 789130.1875 | val_loss : 531782.375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 2 | train_loss : 468240.96875 | val_loss : 725806.1875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 3 | train_loss : 652557.9375 | val_loss : 808208.875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 4 | train_loss : 841807.625 | val_loss : 96374.5 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 5 | train_loss : 104156.203125 | val_loss : 312488.46875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 6 | train_loss : 308402.90625 | val_loss : 436815.375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 7 | train_loss : 331501.96875 | val_loss : 425899.84375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 8 | train_loss : 391390.71875 | val_loss : 313671.4375 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 9 | train_loss : 358479.84375 | val_loss : 131299.984375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 10 | train_loss : 138682.453125 | val_loss : 90388.71875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 11 | train_loss : 99200.078125 | val_loss : 109801.9609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 12 | train_loss : 119364.0078125 | val_loss : 162952.546875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 13 | train_loss : 131992.625 | val_loss : 130037.1171875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 14 | train_loss : 184392.34375 | val_loss : 149896.921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 15 | train_loss : 270934.46875 | val_loss : 153535.65625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 16 | train_loss : 215377.90625 | val_loss : 190034.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 17 | train_loss : 191017.90625 | val_loss : 262212.4375 | test_acc : 0.08 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 18 | train_loss : 204558.375 | val_loss : 201653.765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 19 | train_loss : 222587.140625 | val_loss : 131846.984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 20 | train_loss : 201181.015625 | val_loss : 71080.1484375 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 21 | train_loss : 64579.61328125 | val_loss : 140387.625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 22 | train_loss : 135897.9375 | val_loss : 63231.62890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 23 | train_loss : 76798.53125 | val_loss : 61425.8203125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 24 | train_loss : 44296.4609375 | val_loss : 31826.875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 25 | train_loss : 53212.28515625 | val_loss : 42341.98046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 26 | train_loss : 34264.703125 | val_loss : 70216.4296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 27 | train_loss : 81742.96875 | val_loss : 29697.322265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 28 | train_loss : 26902.849609375 | val_loss : 90093.9609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 29 | train_loss : 95748.7109375 | val_loss : 14036.3671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 30 | train_loss : 26879.123046875 | val_loss : 64626.90625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 31 | train_loss : 60635.265625 | val_loss : 54534.10546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 32 | train_loss : 96448.9921875 | val_loss : 53918.8046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 33 | train_loss : 111032.9296875 | val_loss : 69395.203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 34 | train_loss : 55847.80078125 | val_loss : 46348.41015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 35 | train_loss : 80715.5546875 | val_loss : 94215.4609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 36 | train_loss : 94368.6875 | val_loss : 118639.21875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 37 | train_loss : 86238.2421875 | val_loss : 33916.12890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 38 | train_loss : 71160.875 | val_loss : 96736.0625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 39 | train_loss : 74212.328125 | val_loss : 102109.1328125 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 40 | train_loss : 132271.796875 | val_loss : 71196.5078125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 41 | train_loss : 150402.40625 | val_loss : 53287.30078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 42 | train_loss : 61671.375 | val_loss : 59899.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 43 | train_loss : 79914.9921875 | val_loss : 53720.41015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 44 | train_loss : 77815.5390625 | val_loss : 150388.609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 45 | train_loss : 126055.7890625 | val_loss : 116354.2421875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 46 | train_loss : 112265.1875 | val_loss : 36346.11328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 47 | train_loss : 62228.5234375 | val_loss : 59809.58984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 48 | train_loss : 86657.640625 | val_loss : 92706.2578125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 49 | train_loss : 87333.71875 | val_loss : 76789.578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 50 | train_loss : 98986.2890625 | val_loss : 62140.984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 51 | train_loss : 120665.3828125 | val_loss : 124560.71875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 52 | train_loss : 127966.3125 | val_loss : 35049.734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 53 | train_loss : 72364.6328125 | val_loss : 33120.40234375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 54 | train_loss : 44067.76171875 | val_loss : 82274.46875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 55 | train_loss : 105682.5625 | val_loss : 28124.4296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 56 | train_loss : 34553.55859375 | val_loss : 71120.4453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 57 | train_loss : 93807.453125 | val_loss : 113068.5390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 58 | train_loss : 127421.921875 | val_loss : 46256.67578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 59 | train_loss : 36597.27734375 | val_loss : 33830.6171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 60 | train_loss : 64716.68359375 | val_loss : 147886.734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 61 | train_loss : 108371.7265625 | val_loss : 37765.67578125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 62 | train_loss : 39899.1484375 | val_loss : 67355.8515625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 63 | train_loss : 100531.8984375 | val_loss : 82155.265625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 64 | train_loss : 114340.9609375 | val_loss : 69416.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 65 | train_loss : 50257.44140625 | val_loss : 22787.376953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 66 | train_loss : 39853.46875 | val_loss : 28108.98046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 67 | train_loss : 30954.7109375 | val_loss : 73353.03125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 68 | train_loss : 109241.921875 | val_loss : 72162.8671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 69 | train_loss : 109868.6171875 | val_loss : 79970.34375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 70 | train_loss : 67400.734375 | val_loss : 42798.1015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 71 | train_loss : 58561.140625 | val_loss : 42589.859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 72 | train_loss : 60323.453125 | val_loss : 18330.82421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 73 | train_loss : 37995.73046875 | val_loss : 38949.7265625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 74 | train_loss : 35397.26171875 | val_loss : 34860.609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 75 | train_loss : 60932.921875 | val_loss : 31252.140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 76 | train_loss : 32947.94921875 | val_loss : 59882.2734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 77 | train_loss : 69040.0234375 | val_loss : 56997.53125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 78 | train_loss : 87358.8828125 | val_loss : 46548.80859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 79 | train_loss : 73717.9921875 | val_loss : 119798.9375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 80 | train_loss : 97913.6328125 | val_loss : 41388.421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 81 | train_loss : 51546.03125 | val_loss : 79766.2109375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 82 | train_loss : 82168.671875 | val_loss : 54863.73828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 83 | train_loss : 104042.5625 | val_loss : 37768.9921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 84 | train_loss : 62930.3359375 | val_loss : 36168.17578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 85 | train_loss : 49847.58984375 | val_loss : 43063.0703125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 86 | train_loss : 44788.1015625 | val_loss : 33680.31640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 87 | train_loss : 53465.05078125 | val_loss : 40466.234375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 88 | train_loss : 36331.01953125 | val_loss : 31549.16015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 89 | train_loss : 45829.93359375 | val_loss : 12652.6396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 90 | train_loss : 21569.470703125 | val_loss : 40775.41796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 91 | train_loss : 54613.37109375 | val_loss : 25094.982421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 92 | train_loss : 42990.48046875 | val_loss : 84552.078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 93 | train_loss : 94810.921875 | val_loss : 8617.474609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 94 | train_loss : 17945.453125 | val_loss : 59352.44140625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 95 | train_loss : 65460.7265625 | val_loss : 33569.375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 96 | train_loss : 63963.7890625 | val_loss : 18454.845703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 97 | train_loss : 26490.03515625 | val_loss : 19095.755859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 98 | train_loss : 23969.16796875 | val_loss : 85338.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 99 | train_loss : 91137.046875 | val_loss : 63963.16015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 100 | train_loss : 98767.9296875 | val_loss : 29705.30078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 101 | train_loss : 48419.0234375 | val_loss : 5174.71728515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 102 | train_loss : 19354.4921875 | val_loss : 22901.58203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 103 | train_loss : 26406.373046875 | val_loss : 37791.3359375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 104 | train_loss : 69011.125 | val_loss : 61274.390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 105 | train_loss : 114893.3828125 | val_loss : 102971.1015625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 106 | train_loss : 108588.328125 | val_loss : 26995.408203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 107 | train_loss : 60985.23046875 | val_loss : 14964.6123046875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 108 | train_loss : 24764.498046875 | val_loss : 38525.98046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 109 | train_loss : 62503.26953125 | val_loss : 28196.88671875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 110 | train_loss : 25859.3046875 | val_loss : 24866.337890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 111 | train_loss : 40449.1015625 | val_loss : 69817.5390625 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 112 | train_loss : 54791.69921875 | val_loss : 14213.33984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 113 | train_loss : 32244.619140625 | val_loss : 93367.4375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 114 | train_loss : 70477.453125 | val_loss : 21678.310546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 115 | train_loss : 30204.845703125 | val_loss : 20516.6484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 116 | train_loss : 34451.61328125 | val_loss : 56348.2109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 117 | train_loss : 74642.2265625 | val_loss : 35607.30078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 118 | train_loss : 58040.1015625 | val_loss : 64061.19921875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 119 | train_loss : 58273.9765625 | val_loss : 22763.052734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 120 | train_loss : 36599.6171875 | val_loss : 41599.40234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 121 | train_loss : 59498.5390625 | val_loss : 9356.232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 122 | train_loss : 22749.80078125 | val_loss : 18836.02734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 123 | train_loss : 25497.091796875 | val_loss : 67480.65625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 124 | train_loss : 75769.171875 | val_loss : 13356.6845703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 125 | train_loss : 24374.89453125 | val_loss : 59831.37890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 126 | train_loss : 70672.25 | val_loss : 20683.765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 127 | train_loss : 36423.44921875 | val_loss : 63780.21875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 128 | train_loss : 71409.5234375 | val_loss : 23479.3359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 129 | train_loss : 31136.349609375 | val_loss : 63567.19140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 130 | train_loss : 83291.0546875 | val_loss : 17186.28515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 131 | train_loss : 30055.099609375 | val_loss : 71059.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 132 | train_loss : 64814.28515625 | val_loss : 57939.703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 133 | train_loss : 81754.046875 | val_loss : 27143.810546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 134 | train_loss : 56642.078125 | val_loss : 65411.69140625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 135 | train_loss : 52762.23828125 | val_loss : 13821.3671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 136 | train_loss : 27495.3359375 | val_loss : 32603.564453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 137 | train_loss : 32894.265625 | val_loss : 23268.033203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 138 | train_loss : 38148.7734375 | val_loss : 14682.302734375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 139 | train_loss : 22332.640625 | val_loss : 42166.0 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 140 | train_loss : 50314.6640625 | val_loss : 41959.11328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 141 | train_loss : 66074.28125 | val_loss : 13711.6875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 142 | train_loss : 21838.796875 | val_loss : 17487.869140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 143 | train_loss : 25881.11328125 | val_loss : 65109.0546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 144 | train_loss : 62220.234375 | val_loss : 53610.93359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 145 | train_loss : 68378.6328125 | val_loss : 12374.357421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 146 | train_loss : 28113.8359375 | val_loss : 20681.78515625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 147 | train_loss : 24120.982421875 | val_loss : 25081.33984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 148 | train_loss : 46095.73046875 | val_loss : 91757.8984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 149 | train_loss : 74250.046875 | val_loss : 34961.42578125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 150 | train_loss : 49032.36328125 | val_loss : 15690.8125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 151 | train_loss : 30271.677734375 | val_loss : 26472.595703125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 152 | train_loss : 29880.0 | val_loss : 56748.66015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 153 | train_loss : 72198.7734375 | val_loss : 38664.515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 154 | train_loss : 71489.71875 | val_loss : 52576.03125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 155 | train_loss : 56415.4296875 | val_loss : 28754.580078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 156 | train_loss : 56422.33984375 | val_loss : 4334.54248046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 157 | train_loss : 15709.8974609375 | val_loss : 26101.337890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 158 | train_loss : 23067.927734375 | val_loss : 27565.07421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 159 | train_loss : 39909.1796875 | val_loss : 23018.380859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 160 | train_loss : 30223.52734375 | val_loss : 45413.5234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 161 | train_loss : 57775.3359375 | val_loss : 12355.2197265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 162 | train_loss : 23379.88671875 | val_loss : 34259.2734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 163 | train_loss : 47710.6953125 | val_loss : 39417.86328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 164 | train_loss : 48996.28515625 | val_loss : 47764.3203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 165 | train_loss : 69052.71875 | val_loss : 9247.302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 166 | train_loss : 16789.619140625 | val_loss : 22227.54296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 167 | train_loss : 28394.849609375 | val_loss : 66134.9375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 168 | train_loss : 79085.8671875 | val_loss : 46590.30078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 169 | train_loss : 93843.0 | val_loss : 38788.4609375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 170 | train_loss : 64101.265625 | val_loss : 16536.970703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 171 | train_loss : 43080.78125 | val_loss : 62412.41015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 172 | train_loss : 52065.55859375 | val_loss : 19936.55078125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 173 | train_loss : 26827.39453125 | val_loss : 13988.3974609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 174 | train_loss : 24986.330078125 | val_loss : 38753.05078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 175 | train_loss : 50579.1796875 | val_loss : 6116.49755859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 176 | train_loss : 9978.2333984375 | val_loss : 21939.71484375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 177 | train_loss : 27973.966796875 | val_loss : 34549.6875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 178 | train_loss : 40133.98828125 | val_loss : 38717.4375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 179 | train_loss : 53803.91015625 | val_loss : 12248.0654296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 180 | train_loss : 23944.79296875 | val_loss : 32220.1171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 181 | train_loss : 47125.125 | val_loss : 8363.91796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 182 | train_loss : 15823.677734375 | val_loss : 25612.125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 183 | train_loss : 33283.05859375 | val_loss : 26525.1484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 184 | train_loss : 32458.275390625 | val_loss : 36039.27734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 185 | train_loss : 55578.265625 | val_loss : 9530.59765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 186 | train_loss : 18704.38671875 | val_loss : 19695.197265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 187 | train_loss : 24100.259765625 | val_loss : 19357.23046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 188 | train_loss : 33369.27734375 | val_loss : 44313.109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 189 | train_loss : 36660.26171875 | val_loss : 10775.28515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 190 | train_loss : 19776.001953125 | val_loss : 33804.28125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 191 | train_loss : 31900.279296875 | val_loss : 25791.2109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 192 | train_loss : 36628.80859375 | val_loss : 4072.177490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 193 | train_loss : 12549.943359375 | val_loss : 11760.7998046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 194 | train_loss : 18492.22265625 | val_loss : 21954.060546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 195 | train_loss : 27025.2734375 | val_loss : 36071.8515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 196 | train_loss : 50006.6015625 | val_loss : 3761.4150390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 197 | train_loss : 11611.5849609375 | val_loss : 22345.927734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 198 | train_loss : 22592.177734375 | val_loss : 25333.794921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 199 | train_loss : 38771.73046875 | val_loss : 2557.909912109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 200 | train_loss : 8488.7900390625 | val_loss : 9904.9599609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 201 | train_loss : 9017.0400390625 | val_loss : 30346.544921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 202 | train_loss : 36811.27734375 | val_loss : 38092.96875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 203 | train_loss : 59332.21484375 | val_loss : 13299.25 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 204 | train_loss : 24586.6171875 | val_loss : 23498.123046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 205 | train_loss : 27434.509765625 | val_loss : 25339.76953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 206 | train_loss : 37707.80078125 | val_loss : 10945.1396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 207 | train_loss : 11944.5458984375 | val_loss : 26143.8828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 208 | train_loss : 30962.599609375 | val_loss : 17870.1875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 209 | train_loss : 26161.5234375 | val_loss : 43292.421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 210 | train_loss : 51186.17578125 | val_loss : 16735.302734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 211 | train_loss : 21572.5546875 | val_loss : 35557.2734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 212 | train_loss : 43741.8046875 | val_loss : 15382.8203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 213 | train_loss : 24441.046875 | val_loss : 30298.47265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 214 | train_loss : 39195.28515625 | val_loss : 20230.443359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 215 | train_loss : 28038.205078125 | val_loss : 28242.79296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 216 | train_loss : 41741.78125 | val_loss : 10184.107421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 217 | train_loss : 15379.666015625 | val_loss : 25004.626953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 218 | train_loss : 33003.046875 | val_loss : 97218.171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 219 | train_loss : 104089.578125 | val_loss : 58380.4609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 220 | train_loss : 96396.96875 | val_loss : 33618.7265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 221 | train_loss : 51380.2734375 | val_loss : 4691.017578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 222 | train_loss : 20630.630859375 | val_loss : 33908.140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 223 | train_loss : 28030.765625 | val_loss : 22316.466796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 224 | train_loss : 29251.9375 | val_loss : 13173.8896484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 225 | train_loss : 20917.3125 | val_loss : 25132.455078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 226 | train_loss : 32770.671875 | val_loss : 18135.189453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 227 | train_loss : 24028.875 | val_loss : 26470.232421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 228 | train_loss : 36229.2421875 | val_loss : 9906.724609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 229 | train_loss : 13275.99609375 | val_loss : 17977.52734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 230 | train_loss : 20649.390625 | val_loss : 26510.255859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 231 | train_loss : 36356.71484375 | val_loss : 24850.775390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 232 | train_loss : 39967.64453125 | val_loss : 10690.740234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 233 | train_loss : 10695.1845703125 | val_loss : 5442.83984375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 234 | train_loss : 13839.568359375 | val_loss : 14324.2646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 235 | train_loss : 15910.1552734375 | val_loss : 14661.58203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 236 | train_loss : 20714.57421875 | val_loss : 19770.373046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 237 | train_loss : 28078.33984375 | val_loss : 17000.037109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 238 | train_loss : 14807.2197265625 | val_loss : 17846.384765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 239 | train_loss : 21604.404296875 | val_loss : 7859.5126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 240 | train_loss : 14641.7451171875 | val_loss : 19929.4375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 241 | train_loss : 24401.259765625 | val_loss : 18721.44921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 242 | train_loss : 24956.404296875 | val_loss : 29257.470703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 243 | train_loss : 37257.74609375 | val_loss : 15668.6123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 244 | train_loss : 23883.560546875 | val_loss : 20758.72265625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 245 | train_loss : 28902.7265625 | val_loss : 14119.2802734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 246 | train_loss : 20070.060546875 | val_loss : 20893.82421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 247 | train_loss : 28876.9921875 | val_loss : 12379.0302734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 248 | train_loss : 19701.34375 | val_loss : 18414.505859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 249 | train_loss : 27003.7734375 | val_loss : 8375.1279296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 250 | train_loss : 13357.67578125 | val_loss : 17147.744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 251 | train_loss : 22375.94921875 | val_loss : 16037.04296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 252 | train_loss : 25736.8828125 | val_loss : 22752.669921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 253 | train_loss : 36186.13671875 | val_loss : 32091.796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 254 | train_loss : 41723.6796875 | val_loss : 57385.78125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 255 | train_loss : 56766.5390625 | val_loss : 15702.8603515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 256 | train_loss : 21066.962890625 | val_loss : 29389.1953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 257 | train_loss : 24188.150390625 | val_loss : 22914.595703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 258 | train_loss : 27803.6796875 | val_loss : 10986.9248046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 259 | train_loss : 16615.734375 | val_loss : 16700.16796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 260 | train_loss : 20675.18359375 | val_loss : 22931.283203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 261 | train_loss : 27770.2109375 | val_loss : 24606.517578125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 262 | train_loss : 36302.9921875 | val_loss : 11372.525390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 263 | train_loss : 11929.474609375 | val_loss : 14283.72265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 264 | train_loss : 19633.927734375 | val_loss : 15742.33203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 265 | train_loss : 22597.64453125 | val_loss : 16391.26953125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 266 | train_loss : 25323.072265625 | val_loss : 12709.66015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 267 | train_loss : 14505.0546875 | val_loss : 18590.328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 268 | train_loss : 24505.44921875 | val_loss : 13391.91015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 269 | train_loss : 19985.66015625 | val_loss : 15677.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 270 | train_loss : 24394.32421875 | val_loss : 9264.7451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 271 | train_loss : 12382.6201171875 | val_loss : 20180.939453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 272 | train_loss : 26057.517578125 | val_loss : 15355.8896484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 273 | train_loss : 22220.1328125 | val_loss : 17542.453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 274 | train_loss : 28990.3515625 | val_loss : 5612.1826171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 275 | train_loss : 7666.046875 | val_loss : 12369.705078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 276 | train_loss : 14098.6376953125 | val_loss : 21269.943359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 277 | train_loss : 26273.142578125 | val_loss : 19868.560546875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 278 | train_loss : 35181.81640625 | val_loss : 13169.9921875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 279 | train_loss : 14432.5 | val_loss : 27428.767578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 280 | train_loss : 35512.078125 | val_loss : 9341.85546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 281 | train_loss : 19697.8828125 | val_loss : 14303.677734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 282 | train_loss : 17694.388671875 | val_loss : 16101.22265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 283 | train_loss : 19599.494140625 | val_loss : 17495.69921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 284 | train_loss : 26264.998046875 | val_loss : 9557.3046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 285 | train_loss : 9838.8740234375 | val_loss : 12329.1796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 286 | train_loss : 19006.64453125 | val_loss : 18584.650390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 287 | train_loss : 16115.33984375 | val_loss : 13999.7470703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 288 | train_loss : 21585.212890625 | val_loss : 13964.77734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 289 | train_loss : 12650.2197265625 | val_loss : 15386.447265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 290 | train_loss : 20551.10546875 | val_loss : 11548.080078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 291 | train_loss : 17216.51953125 | val_loss : 12338.79296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 292 | train_loss : 19731.767578125 | val_loss : 10196.08984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 293 | train_loss : 13218.3779296875 | val_loss : 14370.0498046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 294 | train_loss : 20216.744140625 | val_loss : 9179.1474609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 295 | train_loss : 13156.794921875 | val_loss : 15204.125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 296 | train_loss : 19682.13671875 | val_loss : 11499.517578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 297 | train_loss : 16551.755859375 | val_loss : 13352.5302734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 298 | train_loss : 21628.404296875 | val_loss : 9999.0751953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 299 | train_loss : 11958.3251953125 | val_loss : 13251.052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 300 | train_loss : 17645.3984375 | val_loss : 119687.7265625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 301 | train_loss : 115698.8671875 | val_loss : 60033.48046875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 302 | train_loss : 82961.8671875 | val_loss : 15854.6962890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 303 | train_loss : 20866.7421875 | val_loss : 5854.0126953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 304 | train_loss : 8723.1376953125 | val_loss : 10249.072265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 305 | train_loss : 10352.4365234375 | val_loss : 13168.1826171875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 306 | train_loss : 14113.35546875 | val_loss : 13748.5498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 307 | train_loss : 16671.373046875 | val_loss : 21167.27734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 308 | train_loss : 18275.01953125 | val_loss : 20936.6015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 309 | train_loss : 24952.0078125 | val_loss : 16195.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 310 | train_loss : 21421.740234375 | val_loss : 10381.5029296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 311 | train_loss : 14944.90234375 | val_loss : 17493.359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 312 | train_loss : 14529.8173828125 | val_loss : 10409.8076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 313 | train_loss : 15754.07421875 | val_loss : 10249.66796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 314 | train_loss : 14142.3671875 | val_loss : 13731.91015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 315 | train_loss : 17999.248046875 | val_loss : 11882.08984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 316 | train_loss : 19142.16015625 | val_loss : 10852.23046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 317 | train_loss : 16507.623046875 | val_loss : 10411.9873046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 318 | train_loss : 15944.505859375 | val_loss : 13064.75 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 319 | train_loss : 18981.91796875 | val_loss : 10914.0654296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 320 | train_loss : 14966.3623046875 | val_loss : 12652.08203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 321 | train_loss : 17218.62109375 | val_loss : 9834.16796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 322 | train_loss : 15006.2021484375 | val_loss : 10881.5048828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 323 | train_loss : 15089.3037109375 | val_loss : 9618.3251953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 324 | train_loss : 12978.3408203125 | val_loss : 11446.650390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 325 | train_loss : 15446.5048828125 | val_loss : 11138.22265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 326 | train_loss : 13767.669921875 | val_loss : 11332.28515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 327 | train_loss : 16289.5654296875 | val_loss : 9756.900390625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 328 | train_loss : 13317.7783203125 | val_loss : 11073.9501953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 329 | train_loss : 15141.400390625 | val_loss : 11796.349609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 330 | train_loss : 14546.474609375 | val_loss : 11960.9775390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 331 | train_loss : 16472.947265625 | val_loss : 9709.64453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 332 | train_loss : 14314.0927734375 | val_loss : 11084.6572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 333 | train_loss : 15440.607421875 | val_loss : 11467.697265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 334 | train_loss : 12259.9189453125 | val_loss : 15238.95703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 335 | train_loss : 19830.306640625 | val_loss : 17693.115234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 336 | train_loss : 20742.880859375 | val_loss : 9507.427734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 337 | train_loss : 16928.7421875 | val_loss : 8175.81982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 338 | train_loss : 11845.806640625 | val_loss : 10661.4375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 339 | train_loss : 14207.333984375 | val_loss : 9582.65234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 340 | train_loss : 13811.802734375 | val_loss : 11420.1875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 341 | train_loss : 15004.3349609375 | val_loss : 10461.6748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 342 | train_loss : 13695.357421875 | val_loss : 10383.6220703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 343 | train_loss : 15531.7373046875 | val_loss : 10154.3203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 344 | train_loss : 12450.5087890625 | val_loss : 9876.8046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 345 | train_loss : 14284.0771484375 | val_loss : 12699.017578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 346 | train_loss : 13873.23046875 | val_loss : 19600.11328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 347 | train_loss : 28374.025390625 | val_loss : 20561.96484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 348 | train_loss : 22127.86328125 | val_loss : 8905.5634765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 349 | train_loss : 17512.76953125 | val_loss : 14744.1728515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 350 | train_loss : 11942.6533203125 | val_loss : 11441.7509765625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 351 | train_loss : 20538.9296875 | val_loss : 29136.240234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 352 | train_loss : 22859.30078125 | val_loss : 10148.982421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 353 | train_loss : 16804.662109375 | val_loss : 6963.65771484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 354 | train_loss : 13772.63671875 | val_loss : 7743.138671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 355 | train_loss : 12009.1689453125 | val_loss : 7805.705078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 356 | train_loss : 11117.0322265625 | val_loss : 8368.375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 357 | train_loss : 11605.302734375 | val_loss : 8705.3251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 358 | train_loss : 12416.505859375 | val_loss : 8503.431640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 359 | train_loss : 13009.478515625 | val_loss : 16723.994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 360 | train_loss : 19855.7109375 | val_loss : 17397.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 361 | train_loss : 24513.560546875 | val_loss : 9277.4453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 362 | train_loss : 14700.6435546875 | val_loss : 7537.97509765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 363 | train_loss : 11828.0966796875 | val_loss : 8321.60546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 364 | train_loss : 8651.287109375 | val_loss : 8005.6474609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 365 | train_loss : 12160.9287109375 | val_loss : 9376.7373046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 366 | train_loss : 10212.7890625 | val_loss : 8775.5673828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 367 | train_loss : 12212.9326171875 | val_loss : 9016.2998046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 368 | train_loss : 10398.681640625 | val_loss : 9750.1171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 369 | train_loss : 13267.1748046875 | val_loss : 9007.572265625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 370 | train_loss : 13271.3173828125 | val_loss : 7701.3388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 371 | train_loss : 12707.84375 | val_loss : 9074.974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 372 | train_loss : 11570.88671875 | val_loss : 9013.771484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 373 | train_loss : 12513.4697265625 | val_loss : 10686.4375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 374 | train_loss : 12222.44921875 | val_loss : 8714.2802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 375 | train_loss : 13044.3173828125 | val_loss : 11629.8828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 376 | train_loss : 12462.853515625 | val_loss : 8711.1650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 377 | train_loss : 12610.3779296875 | val_loss : 11970.2841796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 378 | train_loss : 11956.49609375 | val_loss : 8742.0048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 379 | train_loss : 13110.26953125 | val_loss : 10869.9326171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 380 | train_loss : 12463.1298828125 | val_loss : 7150.29736328125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 381 | train_loss : 10986.5009765625 | val_loss : 11998.53125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 382 | train_loss : 10162.2529296875 | val_loss : 6969.6123046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 383 | train_loss : 11796.103515625 | val_loss : 14197.736328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 384 | train_loss : 12531.017578125 | val_loss : 10577.4814453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 385 | train_loss : 16661.759765625 | val_loss : 18780.998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 386 | train_loss : 14351.2685546875 | val_loss : 8571.30859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 387 | train_loss : 14387.080078125 | val_loss : 16501.87890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 388 | train_loss : 14681.4404296875 | val_loss : 11330.669921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 389 | train_loss : 18175.779296875 | val_loss : 13788.302734375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 390 | train_loss : 13223.0458984375 | val_loss : 6675.458984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 391 | train_loss : 10751.8359375 | val_loss : 8708.677734375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 392 | train_loss : 7505.7255859375 | val_loss : 2636.7138671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 393 | train_loss : 8766.64453125 | val_loss : 6846.43017578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 394 | train_loss : 6496.37353515625 | val_loss : 3446.683837890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 395 | train_loss : 8096.1025390625 | val_loss : 10057.5947265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 396 | train_loss : 8955.044921875 | val_loss : 5062.333984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 397 | train_loss : 10635.912109375 | val_loss : 7726.85986328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 398 | train_loss : 9490.1748046875 | val_loss : 7428.853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 399 | train_loss : 9862.1884765625 | val_loss : 9523.60546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 400 | train_loss : 9243.02734375 | val_loss : 5999.38232421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 401 | train_loss : 10305.3984375 | val_loss : 9243.8623046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 402 | train_loss : 7468.72509765625 | val_loss : 3287.340087890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 403 | train_loss : 8545.943359375 | val_loss : 8841.3076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 404 | train_loss : 6797.88623046875 | val_loss : 3255.597412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 405 | train_loss : 8697.14453125 | val_loss : 10379.962890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 406 | train_loss : 9003.041015625 | val_loss : 6459.9873046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 407 | train_loss : 9723.3310546875 | val_loss : 9054.2197265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 408 | train_loss : 11727.87890625 | val_loss : 6537.23388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 409 | train_loss : 10408.8720703125 | val_loss : 12562.7861328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 410 | train_loss : 13596.4873046875 | val_loss : 7749.31005859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 411 | train_loss : 12112.6396484375 | val_loss : 8312.3720703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 412 | train_loss : 11712.16796875 | val_loss : 6859.85888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 413 | train_loss : 10282.5859375 | val_loss : 13211.3154296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 414 | train_loss : 11938.7216796875 | val_loss : 5646.51123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 415 | train_loss : 11096.22265625 | val_loss : 7247.02978515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 416 | train_loss : 7100.2373046875 | val_loss : 4204.326171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 417 | train_loss : 7631.9970703125 | val_loss : 9697.3779296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 418 | train_loss : 8905.208984375 | val_loss : 6179.46240234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 419 | train_loss : 12018.47265625 | val_loss : 7219.28515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 420 | train_loss : 9153.3916015625 | val_loss : 5899.47607421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 421 | train_loss : 10175.5830078125 | val_loss : 8468.982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 422 | train_loss : 8637.4716796875 | val_loss : 6304.833984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 423 | train_loss : 11241.55859375 | val_loss : 8207.9697265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 424 | train_loss : 9161.2255859375 | val_loss : 6414.263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 425 | train_loss : 10735.1513671875 | val_loss : 7928.6748046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 426 | train_loss : 8001.71484375 | val_loss : 6489.65234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 427 | train_loss : 11712.2001953125 | val_loss : 7924.65771484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 428 | train_loss : 10193.861328125 | val_loss : 5210.12353515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 429 | train_loss : 9458.4033203125 | val_loss : 8521.7470703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 430 | train_loss : 7994.169921875 | val_loss : 3861.794921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 431 | train_loss : 7985.81103515625 | val_loss : 8829.1728515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 432 | train_loss : 6397.82958984375 | val_loss : 1742.0087890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 433 | train_loss : 6747.65771484375 | val_loss : 10669.240234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 434 | train_loss : 7318.3564453125 | val_loss : 1749.5863037109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 435 | train_loss : 5530.50244140625 | val_loss : 8853.1640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 436 | train_loss : 6565.5380859375 | val_loss : 1745.7462158203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 437 | train_loss : 5099.7099609375 | val_loss : 10194.2412109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 438 | train_loss : 6570.34814453125 | val_loss : 397.2550048828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 439 | train_loss : 6843.39501953125 | val_loss : 9993.51953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 440 | train_loss : 6931.83642578125 | val_loss : 2144.594970703125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 441 | train_loss : 6297.177734375 | val_loss : 11477.5615234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 442 | train_loss : 7955.20703125 | val_loss : 1736.1424560546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 443 | train_loss : 4891.720703125 | val_loss : 9890.1240234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 444 | train_loss : 6864.20556640625 | val_loss : 617.4924926757812 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 445 | train_loss : 6689.0361328125 | val_loss : 6830.64111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 446 | train_loss : 5237.5888671875 | val_loss : 2625.56494140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 447 | train_loss : 5685.5576171875 | val_loss : 16424.68359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 448 | train_loss : 9791.5341796875 | val_loss : 2026.6700439453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 449 | train_loss : 8871.7451171875 | val_loss : 22000.80078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 450 | train_loss : 14017.1171875 | val_loss : 3305.887451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 451 | train_loss : 8234.724609375 | val_loss : 19650.625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 452 | train_loss : 14449.9111328125 | val_loss : 9618.4111328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 453 | train_loss : 26101.462890625 | val_loss : 3803.097412109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 454 | train_loss : 7875.8857421875 | val_loss : 8428.11328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 455 | train_loss : 9374.0126953125 | val_loss : 12449.23828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 456 | train_loss : 16444.3046875 | val_loss : 8893.6435546875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 457 | train_loss : 13155.47265625 | val_loss : 17121.564453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 458 | train_loss : 18703.904296875 | val_loss : 10149.0703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 459 | train_loss : 11209.0947265625 | val_loss : 14195.865234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 460 | train_loss : 16679.0390625 | val_loss : 9481.9599609375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 461 | train_loss : 10535.0009765625 | val_loss : 17454.015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 462 | train_loss : 17753.638671875 | val_loss : 6103.12744140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 463 | train_loss : 7860.6787109375 | val_loss : 9660.0146484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 464 | train_loss : 11642.1875 | val_loss : 6751.8125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 465 | train_loss : 6828.490234375 | val_loss : 7319.46484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 466 | train_loss : 11488.8837890625 | val_loss : 5691.15380859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 467 | train_loss : 5851.7373046875 | val_loss : 5628.3251953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 468 | train_loss : 8846.7060546875 | val_loss : 5806.65625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 469 | train_loss : 5192.61083984375 | val_loss : 4030.47119140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 470 | train_loss : 8233.333984375 | val_loss : 5485.4287109375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 471 | train_loss : 5044.8994140625 | val_loss : 4113.07763671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 472 | train_loss : 7465.7861328125 | val_loss : 6158.94140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 473 | train_loss : 5644.23193359375 | val_loss : 4605.080078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 474 | train_loss : 10104.1083984375 | val_loss : 5550.32763671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 475 | train_loss : 5311.48876953125 | val_loss : 5190.46484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 476 | train_loss : 9489.4560546875 | val_loss : 5802.55517578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 477 | train_loss : 6398.49609375 | val_loss : 7027.73876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 478 | train_loss : 11486.568359375 | val_loss : 5476.12744140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 479 | train_loss : 5171.66796875 | val_loss : 5225.2001953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 480 | train_loss : 9013.306640625 | val_loss : 6236.1298828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 481 | train_loss : 6911.64208984375 | val_loss : 7146.365234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 482 | train_loss : 12157.6298828125 | val_loss : 4514.3798828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 483 | train_loss : 5424.64013671875 | val_loss : 4782.97998046875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 484 | train_loss : 7782.4931640625 | val_loss : 5733.4873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 485 | train_loss : 4679.75048828125 | val_loss : 5109.3876953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 486 | train_loss : 7549.14111328125 | val_loss : 5543.0263671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 487 | train_loss : 4788.13134765625 | val_loss : 6064.34130859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 488 | train_loss : 11665.1826171875 | val_loss : 3923.052490234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 489 | train_loss : 3305.726318359375 | val_loss : 2518.532470703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 490 | train_loss : 5250.16259765625 | val_loss : 6353.90771484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 491 | train_loss : 5048.58544921875 | val_loss : 3858.6875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 492 | train_loss : 9746.724609375 | val_loss : 4509.31494140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 493 | train_loss : 4254.09326171875 | val_loss : 4918.1376953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 494 | train_loss : 8446.763671875 | val_loss : 5358.20361328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 495 | train_loss : 4720.857421875 | val_loss : 5721.65234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 496 | train_loss : 7703.1064453125 | val_loss : 6449.146484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 497 | train_loss : 5169.1318359375 | val_loss : 4798.5888671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 498 | train_loss : 9532.63671875 | val_loss : 5429.68505859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 499 | train_loss : 5330.15869140625 | val_loss : 4267.98388671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 500 | train_loss : 8208.80078125 | val_loss : 5154.05126953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 501 | train_loss : 4589.7216796875 | val_loss : 4180.6337890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 502 | train_loss : 8204.384765625 | val_loss : 5970.107421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 503 | train_loss : 5360.22705078125 | val_loss : 6566.07861328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 504 | train_loss : 11918.392578125 | val_loss : 12459.888671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 505 | train_loss : 17757.1484375 | val_loss : 49198.6015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 506 | train_loss : 40124.44140625 | val_loss : 6640.8173828125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 507 | train_loss : 4244.8076171875 | val_loss : 2407.257568359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 508 | train_loss : 5980.50927734375 | val_loss : 4998.572265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 509 | train_loss : 3394.773681640625 | val_loss : 2770.951171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 510 | train_loss : 4105.0087890625 | val_loss : 6156.08740234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 511 | train_loss : 3666.284912109375 | val_loss : 991.4025268554688 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 512 | train_loss : 5469.66552734375 | val_loss : 5173.955078125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 513 | train_loss : 2598.628662109375 | val_loss : 1282.762451171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 514 | train_loss : 3012.690673828125 | val_loss : 6154.8876953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 515 | train_loss : 3074.433349609375 | val_loss : 657.3875122070312 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 516 | train_loss : 5069.03173828125 | val_loss : 4637.96728515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 517 | train_loss : 2845.537841796875 | val_loss : 2033.6837158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 518 | train_loss : 3187.2646484375 | val_loss : 5456.330078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 519 | train_loss : 6638.87646484375 | val_loss : 6442.396484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 520 | train_loss : 13032.1025390625 | val_loss : 8643.7421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 521 | train_loss : 16370.0341796875 | val_loss : 18288.900390625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 522 | train_loss : 24101.720703125 | val_loss : 12680.552734375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 523 | train_loss : 19895.8828125 | val_loss : 6385.34228515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 524 | train_loss : 9938.1552734375 | val_loss : 5235.7900390625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 525 | train_loss : 6174.77392578125 | val_loss : 2396.916259765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 526 | train_loss : 5053.39697265625 | val_loss : 4901.705078125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 527 | train_loss : 5096.51416015625 | val_loss : 2611.5 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 528 | train_loss : 5454.076171875 | val_loss : 8452.3173828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 529 | train_loss : 6538.107421875 | val_loss : 1792.231201171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 530 | train_loss : 8068.32861328125 | val_loss : 22731.525390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 531 | train_loss : 14665.58984375 | val_loss : 3202.91748046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 532 | train_loss : 10781.9033203125 | val_loss : 19319.46875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 533 | train_loss : 12927.6904296875 | val_loss : 3551.885009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 534 | train_loss : 11586.6416015625 | val_loss : 11865.337890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 535 | train_loss : 10739.97265625 | val_loss : 2744.983642578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 536 | train_loss : 10330.318359375 | val_loss : 6431.54638671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 537 | train_loss : 9771.505859375 | val_loss : 4827.87109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 538 | train_loss : 8481.6123046875 | val_loss : 8455.8427734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 539 | train_loss : 11829.7314453125 | val_loss : 34695.84375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 540 | train_loss : 61571.828125 | val_loss : 15856.447265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 541 | train_loss : 14322.4453125 | val_loss : 1501.84375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 542 | train_loss : 12054.869140625 | val_loss : 5438.8564453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 543 | train_loss : 3685.641845703125 | val_loss : 2950.99755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 544 | train_loss : 3727.1240234375 | val_loss : 7609.66748046875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 545 | train_loss : 4263.017578125 | val_loss : 1581.0775146484375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 546 | train_loss : 4623.09423828125 | val_loss : 6428.884765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 547 | train_loss : 3076.63134765625 | val_loss : 2347.367431640625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 548 | train_loss : 2884.292236328125 | val_loss : 7098.06884765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 549 | train_loss : 3585.024658203125 | val_loss : 1033.1324462890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 550 | train_loss : 4895.0869140625 | val_loss : 4221.59765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 551 | train_loss : 3009.74365234375 | val_loss : 3931.851318359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 552 | train_loss : 5056.65576171875 | val_loss : 157335.3125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 553 | train_loss : 153810.796875 | val_loss : 67536.09375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 554 | train_loss : 89938.4921875 | val_loss : 25517.52734375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 555 | train_loss : 36037.53515625 | val_loss : 15196.6748046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 556 | train_loss : 26535.490234375 | val_loss : 26176.626953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 557 | train_loss : 21119.390625 | val_loss : 8864.5283203125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 558 | train_loss : 7117.11865234375 | val_loss : 11144.8935546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 559 | train_loss : 8011.6201171875 | val_loss : 9225.6435546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 560 | train_loss : 4930.22021484375 | val_loss : 2790.763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 561 | train_loss : 4842.65673828125 | val_loss : 7201.64111328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 562 | train_loss : 2892.648193359375 | val_loss : 3980.132568359375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 563 | train_loss : 1881.1195068359375 | val_loss : 6522.02490234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 564 | train_loss : 3002.679443359375 | val_loss : 3996.862548828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 565 | train_loss : 3933.50244140625 | val_loss : 8614.7373046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 566 | train_loss : 4396.435546875 | val_loss : 2971.71875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 567 | train_loss : 5572.8154296875 | val_loss : 5449.60107421875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 568 | train_loss : 2367.086669921875 | val_loss : 2433.896240234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 569 | train_loss : 3002.33935546875 | val_loss : 6353.1611328125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 570 | train_loss : 2723.28369140625 | val_loss : 2313.68115234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 571 | train_loss : 2401.0615234375 | val_loss : 6322.19140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 572 | train_loss : 2715.685302734375 | val_loss : 2762.4638671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 573 | train_loss : 3405.62939453125 | val_loss : 6500.64013671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 574 | train_loss : 5013.96826171875 | val_loss : 2475.628662109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 575 | train_loss : 4482.21875 | val_loss : 6963.97607421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 576 | train_loss : 5032.0263671875 | val_loss : 2847.52880859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 577 | train_loss : 4608.4267578125 | val_loss : 7475.2685546875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 578 | train_loss : 8500.517578125 | val_loss : 4099.47509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 579 | train_loss : 7711.26611328125 | val_loss : 11363.994140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 580 | train_loss : 11345.6435546875 | val_loss : 4032.702392578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 581 | train_loss : 8067.7255859375 | val_loss : 9132.87109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 582 | train_loss : 11418.724609375 | val_loss : 4397.75244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 583 | train_loss : 9052.5751953125 | val_loss : 7806.8798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 584 | train_loss : 10162.86328125 | val_loss : 2705.3212890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 585 | train_loss : 5501.47509765625 | val_loss : 10121.25390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 586 | train_loss : 6129.14453125 | val_loss : 2396.857421875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 587 | train_loss : 6452.10888671875 | val_loss : 6840.95751953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 588 | train_loss : 9576.7841796875 | val_loss : 3264.797607421875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 589 | train_loss : 5269.56298828125 | val_loss : 10965.7041015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 590 | train_loss : 11096.92578125 | val_loss : 2191.503662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 591 | train_loss : 7856.12451171875 | val_loss : 14522.669921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 592 | train_loss : 10924.4091796875 | val_loss : 1894.768798828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 593 | train_loss : 7774.728515625 | val_loss : 17510.849609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 594 | train_loss : 11829.2265625 | val_loss : 2142.0263671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 595 | train_loss : 8356.18359375 | val_loss : 13197.83984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 596 | train_loss : 8841.9033203125 | val_loss : 392.6875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 597 | train_loss : 5434.84326171875 | val_loss : 4377.0625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 598 | train_loss : 3898.7158203125 | val_loss : 1411.5987548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 599 | train_loss : 5139.0439453125 | val_loss : 5864.2060546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 600 | train_loss : 5674.830078125 | val_loss : 821.85498046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 601 | train_loss : 6083.00146484375 | val_loss : 4766.90478515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 602 | train_loss : 2942.66259765625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 603 | train_loss : 3299.859619140625 | val_loss : 4756.03271484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 604 | train_loss : 2359.202880859375 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 605 | train_loss : 3790.538330078125 | val_loss : 4622.94384765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 606 | train_loss : 2276.7080078125 | val_loss : 6334.53369140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 607 | train_loss : 11079.1865234375 | val_loss : 13974.423828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 608 | train_loss : 20338.181640625 | val_loss : 21339.130859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 609 | train_loss : 29256.107421875 | val_loss : 5769.14013671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 610 | train_loss : 3866.733642578125 | val_loss : 8542.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 611 | train_loss : 9260.677734375 | val_loss : 9244.822265625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 612 | train_loss : 9973.146484375 | val_loss : 5093.861328125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 613 | train_loss : 10617.3125 | val_loss : 5084.19482421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 614 | train_loss : 2973.0087890625 | val_loss : 4005.7724609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 615 | train_loss : 2804.9267578125 | val_loss : 6219.732421875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 616 | train_loss : 2809.00927734375 | val_loss : 2347.737548828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 617 | train_loss : 3676.586181640625 | val_loss : 5707.75146484375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 618 | train_loss : 1822.221435546875 | val_loss : 238587.125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 619 | train_loss : 166301.90625 | val_loss : 47786.73046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 620 | train_loss : 63315.234375 | val_loss : 131011.4375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 621 | train_loss : 101895.2734375 | val_loss : 17008.431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 622 | train_loss : 27105.662109375 | val_loss : 19262.671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 623 | train_loss : 14351.0947265625 | val_loss : 11000.0625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 624 | train_loss : 16164.7861328125 | val_loss : 10174.9033203125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 625 | train_loss : 4645.7314453125 | val_loss : 5243.64501953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 626 | train_loss : 4301.8564453125 | val_loss : 7979.97998046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 627 | train_loss : 3075.718017578125 | val_loss : 4600.93017578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 628 | train_loss : 2450.265869140625 | val_loss : 8628.4873046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 629 | train_loss : 3128.650634765625 | val_loss : 2835.482421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 630 | train_loss : 3358.918701171875 | val_loss : 6664.72607421875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 631 | train_loss : 2455.81689453125 | val_loss : 3436.91259765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 632 | train_loss : 2283.034912109375 | val_loss : 11384.53515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 633 | train_loss : 10400.318359375 | val_loss : 17931.900390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 634 | train_loss : 24472.10546875 | val_loss : 6169.3623046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 635 | train_loss : 10780.52734375 | val_loss : 3311.22509765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 636 | train_loss : 5620.70166015625 | val_loss : 6112.1689453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 637 | train_loss : 2702.249267578125 | val_loss : 3426.820068359375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 638 | train_loss : 5035.86279296875 | val_loss : 15188.759765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 639 | train_loss : 12104.2998046875 | val_loss : 2475.773681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 640 | train_loss : 10933.1572265625 | val_loss : 9397.2822265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 641 | train_loss : 7970.4560546875 | val_loss : 4710.8974609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 642 | train_loss : 4566.62109375 | val_loss : 7336.0185546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 643 | train_loss : 3604.1923828125 | val_loss : 3332.3486328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 644 | train_loss : 2730.456298828125 | val_loss : 6638.3486328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 645 | train_loss : 2738.12255859375 | val_loss : 2606.83251953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 646 | train_loss : 1974.685791015625 | val_loss : 5878.98876953125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 647 | train_loss : 2051.232666015625 | val_loss : 2967.333740234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 648 | train_loss : 1939.050048828125 | val_loss : 5891.98486328125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 649 | train_loss : 2077.339599609375 | val_loss : 3283.606201171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 650 | train_loss : 1946.2012939453125 | val_loss : 6148.20263671875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 651 | train_loss : 2396.5322265625 | val_loss : 2227.106201171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 652 | train_loss : 3467.41943359375 | val_loss : 5331.15380859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 653 | train_loss : 2347.6708984375 | val_loss : 2360.18505859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 654 | train_loss : 3078.7001953125 | val_loss : 5310.8173828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 655 | train_loss : 2310.068359375 | val_loss : 1227.0386962890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 656 | train_loss : 3397.646240234375 | val_loss : 4515.0439453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 657 | train_loss : 2124.630859375 | val_loss : 2653.697509765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 658 | train_loss : 1590.1668701171875 | val_loss : 4857.74755859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 659 | train_loss : 1644.1103515625 | val_loss : 1028.3912353515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 660 | train_loss : 2324.16796875 | val_loss : 4140.49609375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 661 | train_loss : 1562.438232421875 | val_loss : 2001.5487060546875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 662 | train_loss : 1695.7861328125 | val_loss : 4965.302734375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 663 | train_loss : 1452.2364501953125 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 664 | train_loss : 2738.485107421875 | val_loss : 4295.5625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 665 | train_loss : 1431.8951416015625 | val_loss : 2191.5263671875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 666 | train_loss : 1391.1856689453125 | val_loss : 5709.208984375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 667 | train_loss : 2021.5882568359375 | val_loss : 142.57374572753906 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 668 | train_loss : 3171.751220703125 | val_loss : 8203.0341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 669 | train_loss : 3285.078125 | val_loss : 88.30750274658203 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 670 | train_loss : 4416.71826171875 | val_loss : 13752.73828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 671 | train_loss : 6955.97314453125 | val_loss : 6476.43505859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 672 | train_loss : 18628.189453125 | val_loss : 14119.7890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 673 | train_loss : 7537.43359375 | val_loss : 1965.4761962890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 674 | train_loss : 4798.9033203125 | val_loss : 15690.5 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 675 | train_loss : 7759.58740234375 | val_loss : 1226.37744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 676 | train_loss : 7183.29931640625 | val_loss : 16549.47265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 677 | train_loss : 9134.2001953125 | val_loss : 1261.8499755859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 678 | train_loss : 7771.06103515625 | val_loss : 13636.384765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 679 | train_loss : 8946.4921875 | val_loss : 83.52874755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 680 | train_loss : 6054.04443359375 | val_loss : 5867.45751953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 681 | train_loss : 3654.2080078125 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 682 | train_loss : 3969.41650390625 | val_loss : 4203.56982421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 683 | train_loss : 2479.437744140625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 684 | train_loss : 2830.03564453125 | val_loss : 3228.447509765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 685 | train_loss : 1728.40087890625 | val_loss : 1324.438720703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 686 | train_loss : 1976.034423828125 | val_loss : 4407.701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 687 | train_loss : 2268.47509765625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 688 | train_loss : 3037.9609375 | val_loss : 3889.978759765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 689 | train_loss : 2058.70849609375 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 690 | train_loss : 2172.64599609375 | val_loss : 3521.885009765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 691 | train_loss : 1748.30615234375 | val_loss : 1346.5450439453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 692 | train_loss : 1298.9482421875 | val_loss : 4251.61376953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 693 | train_loss : 1976.537353515625 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 694 | train_loss : 2401.04296875 | val_loss : 3340.333740234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 695 | train_loss : 1459.1552734375 | val_loss : 0.0 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 696 | train_loss : 1989.7305908203125 | val_loss : 424115.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 697 | train_loss : 398772.46875 | val_loss : 68398.0859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 698 | train_loss : 90522.390625 | val_loss : 3913.657470703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 699 | train_loss : 3718.788818359375 | val_loss : 8308.23046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 700 | train_loss : 4922.60986328125 | val_loss : 9632.0390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 701 | train_loss : 20033.48046875 | val_loss : 26783.33984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 702 | train_loss : 18312.3828125 | val_loss : 20846.13671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 703 | train_loss : 33916.578125 | val_loss : 8297.4248046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 704 | train_loss : 4984.06884765625 | val_loss : 2324.87744140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 705 | train_loss : 7458.26171875 | val_loss : 14102.7451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 706 | train_loss : 12386.3046875 | val_loss : 5843.240234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 707 | train_loss : 11304.580078125 | val_loss : 7601.521484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 708 | train_loss : 9768.1083984375 | val_loss : 5992.65625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 709 | train_loss : 6522.2158203125 | val_loss : 8577.65625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 710 | train_loss : 10163.630859375 | val_loss : 3263.4912109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 711 | train_loss : 5522.533203125 | val_loss : 5224.26513671875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 712 | train_loss : 5511.171875 | val_loss : 1000.2462768554688 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 713 | train_loss : 3786.054931640625 | val_loss : 4580.34375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 714 | train_loss : 2515.5478515625 | val_loss : 1384.052490234375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 715 | train_loss : 2126.050048828125 | val_loss : 3944.8525390625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 716 | train_loss : 1702.57666015625 | val_loss : 825.3925170898438 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 717 | train_loss : 2133.425048828125 | val_loss : 4028.847412109375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 718 | train_loss : 1432.91748046875 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 719 | train_loss : 2288.365478515625 | val_loss : 3075.57373046875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 720 | train_loss : 1339.362548828125 | val_loss : 1200.1812744140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 721 | train_loss : 1423.306396484375 | val_loss : 4275.60986328125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 722 | train_loss : 1536.2652587890625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 723 | train_loss : 2484.77880859375 | val_loss : 2947.927490234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 724 | train_loss : 989.1943969726562 | val_loss : 30787.48828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 725 | train_loss : 51809.49609375 | val_loss : 87682.4375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 726 | train_loss : 68515.65625 | val_loss : 34549.14453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 727 | train_loss : 38723.3828125 | val_loss : 4011.590087890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 728 | train_loss : 8937.0751953125 | val_loss : 12924.576171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 729 | train_loss : 5828.111328125 | val_loss : 5599.15380859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 730 | train_loss : 2696.31494140625 | val_loss : 6393.30859375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 731 | train_loss : 2315.03759765625 | val_loss : 3601.797607421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 732 | train_loss : 1930.33642578125 | val_loss : 6322.8076171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 733 | train_loss : 2231.46142578125 | val_loss : 2654.0048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 734 | train_loss : 1896.20703125 | val_loss : 5895.875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 735 | train_loss : 2013.0289306640625 | val_loss : 1839.5350341796875 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 736 | train_loss : 1763.6483154296875 | val_loss : 4543.03369140625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 737 | train_loss : 1322.54541015625 | val_loss : 2907.5048828125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 738 | train_loss : 1250.09521484375 | val_loss : 4856.55517578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 739 | train_loss : 1456.701904296875 | val_loss : 3450.27001953125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 740 | train_loss : 1555.92919921875 | val_loss : 6783.34765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 741 | train_loss : 2549.64306640625 | val_loss : 2105.0712890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 742 | train_loss : 2638.9169921875 | val_loss : 9117.5341796875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 743 | train_loss : 4357.28076171875 | val_loss : 1256.668701171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 744 | train_loss : 3380.22119140625 | val_loss : 6287.115234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 745 | train_loss : 3053.470947265625 | val_loss : 3054.532470703125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 746 | train_loss : 1671.55126953125 | val_loss : 5676.80517578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 747 | train_loss : 2029.5704345703125 | val_loss : 4106.18896484375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 748 | train_loss : 1028.8536376953125 | val_loss : 5689.884765625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 749 | train_loss : 1597.6754150390625 | val_loss : 2779.858642578125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 750 | train_loss : 1086.3565673828125 | val_loss : 4877.92236328125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 751 | train_loss : 914.6482543945312 | val_loss : 2008.7750244140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 752 | train_loss : 1058.4871826171875 | val_loss : 4616.03515625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 753 | train_loss : 888.1196899414062 | val_loss : 1925.78125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 754 | train_loss : 956.9356079101562 | val_loss : 4153.87744140625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 755 | train_loss : 682.0093994140625 | val_loss : 2429.6337890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 756 | train_loss : 932.7837524414062 | val_loss : 4724.20263671875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 757 | train_loss : 702.2076416015625 | val_loss : 1924.16748046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 758 | train_loss : 1085.3204345703125 | val_loss : 4385.74853515625 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 759 | train_loss : 1115.0921630859375 | val_loss : 737.5387573242188 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 760 | train_loss : 1840.447998046875 | val_loss : 3784.201171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 761 | train_loss : 1125.2763671875 | val_loss : 2595.034912109375 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 762 | train_loss : 651.7714233398438 | val_loss : 4278.7939453125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 763 | train_loss : 1018.963623046875 | val_loss : 310.51251220703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 764 | train_loss : 1613.5550537109375 | val_loss : 3305.179931640625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 765 | train_loss : 476.6065673828125 | val_loss : 2504.423828125 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 766 | train_loss : 526.63720703125 | val_loss : 4592.91748046875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 767 | train_loss : 1513.8082275390625 | val_loss : 532.9724731445312 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 768 | train_loss : 1734.678466796875 | val_loss : 3604.0263671875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 769 | train_loss : 1033.650146484375 | val_loss : 2418.16748046875 | test_acc : 1.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 770 | train_loss : 694.8612670898438 | val_loss : 4423.30615234375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 771 | train_loss : 1381.0631103515625 | val_loss : 434.36749267578125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 772 | train_loss : 1814.0396728515625 | val_loss : 3757.558837890625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 773 | train_loss : 1154.2471923828125 | val_loss : 452.6099853515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 774 | train_loss : 1331.741455078125 | val_loss : 2998.55126953125 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 775 | train_loss : 560.0248413085938 | val_loss : 1719.2449951171875 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 776 | train_loss : 534.7471923828125 | val_loss : 3438.887451171875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 777 | train_loss : 651.62451171875 | val_loss : 174.09124755859375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 778 | train_loss : 1495.5684814453125 | val_loss : 2900.794921875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 779 | train_loss : 443.5892333984375 | val_loss : 696.2150268554688 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 780 | train_loss : 815.01513671875 | val_loss : 2904.53759765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 781 | train_loss : 384.8974914550781 | val_loss : 750.5275268554688 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 782 | train_loss : 745.2765502929688 | val_loss : 2972.875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 783 | train_loss : 453.0201416015625 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 784 | train_loss : 1291.213134765625 | val_loss : 2060.298828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 785 | train_loss : 237.7645263671875 | val_loss : 2059.550048828125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 786 | train_loss : 162.3117218017578 | val_loss : 3142.77880859375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 787 | train_loss : 426.0626525878906 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 788 | train_loss : 1386.9429931640625 | val_loss : 2420.77490234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 789 | train_loss : 235.14093017578125 | val_loss : 1518.186279296875 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 790 | train_loss : 282.0843811035156 | val_loss : 3276.583740234375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 791 | train_loss : 866.0654907226562 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 792 | train_loss : 1515.4910888671875 | val_loss : 1986.1337890625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 793 | train_loss : 203.1728057861328 | val_loss : 2442.5849609375 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 794 | train_loss : 166.56875610351562 | val_loss : 999.5999755859375 | test_acc : 0.92 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 795 | train_loss : 595.841552734375 | val_loss : 3082.36865234375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 796 | train_loss : 583.1487426757812 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 797 | train_loss : 1536.77294921875 | val_loss : 2365.688720703125 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 798 | train_loss : 313.2611083984375 | val_loss : 0.0 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 799 | train_loss : 853.8535766601562 | val_loss : 2116.19384765625 | test_acc : 0.96 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 8 | epoch : 800 | train_loss : 433.9898376464844 | val_loss : 0.0 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "Transfering Model to devicecuda\n",
      "Resetting parameters\n",
      "Lazy Initialization of Model\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Resetting SAGEConv\n",
      "Synchronizing GPU\n",
      "Starting Training\n",
      "fold : 9 | epoch : 1 | train_loss : 349666.46875 | val_loss : 421692.84375 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 2 | train_loss : 469727.75 | val_loss : 438736.875 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 3 | train_loss : 436882.875 | val_loss : 322528.625 | test_acc : 0.0 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 4 | train_loss : 418292.46875 | val_loss : 209397.953125 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 5 | train_loss : 168815.359375 | val_loss : 334053.75 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 6 | train_loss : 286127.75 | val_loss : 434998.5625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 7 | train_loss : 349175.625 | val_loss : 487777.1875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 8 | train_loss : 527097.625 | val_loss : 470350.15625 | test_acc : 0.12 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 9 | train_loss : 406656.5625 | val_loss : 89201.9765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 10 | train_loss : 63451.71484375 | val_loss : 95834.296875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 11 | train_loss : 112291.0234375 | val_loss : 306857.8125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 12 | train_loss : 197962.28125 | val_loss : 200586.953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 13 | train_loss : 191776.046875 | val_loss : 245108.984375 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 14 | train_loss : 238706.90625 | val_loss : 258027.8125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 15 | train_loss : 217614.90625 | val_loss : 347189.59375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 16 | train_loss : 252449.921875 | val_loss : 186297.140625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 17 | train_loss : 198183.71875 | val_loss : 178164.71875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 18 | train_loss : 207721.203125 | val_loss : 132118.328125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 19 | train_loss : 88111.75 | val_loss : 196581.015625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 20 | train_loss : 144221.796875 | val_loss : 56490.609375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 21 | train_loss : 100540.34375 | val_loss : 135839.59375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 22 | train_loss : 125236.2734375 | val_loss : 107643.8203125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 23 | train_loss : 82460.0625 | val_loss : 39292.59375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 24 | train_loss : 49348.2265625 | val_loss : 169924.796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 25 | train_loss : 151175.53125 | val_loss : 133269.609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 26 | train_loss : 92850.1484375 | val_loss : 73572.3203125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 27 | train_loss : 131921.8125 | val_loss : 241801.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 28 | train_loss : 217110.140625 | val_loss : 138806.34375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 29 | train_loss : 123193.453125 | val_loss : 142279.28125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 30 | train_loss : 96176.609375 | val_loss : 105227.84375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 31 | train_loss : 153150.765625 | val_loss : 154140.59375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 32 | train_loss : 171307.9375 | val_loss : 96292.140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 33 | train_loss : 84048.5 | val_loss : 134517.296875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 34 | train_loss : 101405.8203125 | val_loss : 27305.994140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 35 | train_loss : 46512.61328125 | val_loss : 145513.765625 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 36 | train_loss : 101080.0625 | val_loss : 199882.453125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 37 | train_loss : 157948.046875 | val_loss : 156067.046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 38 | train_loss : 208496.140625 | val_loss : 115048.2578125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 39 | train_loss : 106764.4921875 | val_loss : 85191.1328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 40 | train_loss : 62683.08984375 | val_loss : 173985.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 41 | train_loss : 137911.890625 | val_loss : 110528.3671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 42 | train_loss : 149773.65625 | val_loss : 93895.9375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 43 | train_loss : 68870.9296875 | val_loss : 117553.5703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 44 | train_loss : 110513.71875 | val_loss : 261465.734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 45 | train_loss : 192259.484375 | val_loss : 65299.00390625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 46 | train_loss : 81365.0234375 | val_loss : 78045.1484375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 47 | train_loss : 54834.07421875 | val_loss : 132593.9375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 48 | train_loss : 101251.0390625 | val_loss : 38529.23828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 49 | train_loss : 63215.296875 | val_loss : 164425.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 50 | train_loss : 128006.75 | val_loss : 112583.84375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 51 | train_loss : 85891.4609375 | val_loss : 86920.296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 52 | train_loss : 116072.2734375 | val_loss : 120440.921875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 53 | train_loss : 88764.921875 | val_loss : 136149.453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 54 | train_loss : 121278.4375 | val_loss : 48238.3046875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 55 | train_loss : 41185.51171875 | val_loss : 122528.3203125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 56 | train_loss : 88790.2265625 | val_loss : 50123.08984375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 57 | train_loss : 65074.05859375 | val_loss : 74901.03125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 58 | train_loss : 45989.30859375 | val_loss : 29933.330078125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 59 | train_loss : 59861.7890625 | val_loss : 41583.421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 60 | train_loss : 30520.443359375 | val_loss : 55496.98046875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 61 | train_loss : 48365.5546875 | val_loss : 170026.3125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 62 | train_loss : 131396.90625 | val_loss : 34656.94140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 63 | train_loss : 26022.572265625 | val_loss : 66780.65625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 64 | train_loss : 58004.734375 | val_loss : 124447.109375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 65 | train_loss : 97181.90625 | val_loss : 20075.73828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 66 | train_loss : 27099.845703125 | val_loss : 107419.34375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 67 | train_loss : 68347.6015625 | val_loss : 27782.64453125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 68 | train_loss : 55099.796875 | val_loss : 30481.880859375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 69 | train_loss : 13537.5654296875 | val_loss : 56601.375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 70 | train_loss : 48346.484375 | val_loss : 39931.58984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 71 | train_loss : 39012.65234375 | val_loss : 120950.8984375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 72 | train_loss : 100426.8125 | val_loss : 17673.849609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 73 | train_loss : 11236.423828125 | val_loss : 43901.5703125 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 74 | train_loss : 37525.7734375 | val_loss : 115031.1171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 75 | train_loss : 98983.5 | val_loss : 68414.8515625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 76 | train_loss : 46506.015625 | val_loss : 18573.943359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 77 | train_loss : 19038.3203125 | val_loss : 65811.59375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 78 | train_loss : 48277.125 | val_loss : 48183.26171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 79 | train_loss : 104477.390625 | val_loss : 131376.046875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 80 | train_loss : 119873.6796875 | val_loss : 103799.21875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 81 | train_loss : 101468.359375 | val_loss : 92827.0390625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 82 | train_loss : 60635.2265625 | val_loss : 36331.109375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 83 | train_loss : 68952.5234375 | val_loss : 43207.01171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 84 | train_loss : 53236.109375 | val_loss : 117890.3125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 85 | train_loss : 75327.0703125 | val_loss : 44946.5390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 86 | train_loss : 39280.84375 | val_loss : 60064.8203125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 87 | train_loss : 36460.2734375 | val_loss : 117686.59375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 88 | train_loss : 105018.1484375 | val_loss : 97393.5625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 89 | train_loss : 62893.890625 | val_loss : 54488.43359375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 90 | train_loss : 89042.6171875 | val_loss : 205601.953125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 91 | train_loss : 161449.859375 | val_loss : 127545.578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 92 | train_loss : 104100.0 | val_loss : 17346.36328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 93 | train_loss : 8692.4833984375 | val_loss : 32908.765625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 94 | train_loss : 20183.318359375 | val_loss : 68732.8046875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 95 | train_loss : 93113.9375 | val_loss : 108886.1328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 96 | train_loss : 98039.2578125 | val_loss : 62597.60546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 97 | train_loss : 42812.5859375 | val_loss : 51516.875 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 98 | train_loss : 52946.3203125 | val_loss : 48572.6015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 99 | train_loss : 32148.10546875 | val_loss : 29078.66015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 100 | train_loss : 38201.0078125 | val_loss : 85961.21875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 101 | train_loss : 77083.21875 | val_loss : 59574.87109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 102 | train_loss : 47048.98828125 | val_loss : 129880.921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 103 | train_loss : 102331.7890625 | val_loss : 22489.716796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 104 | train_loss : 21405.4140625 | val_loss : 65428.046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 105 | train_loss : 45430.51953125 | val_loss : 31634.9453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 106 | train_loss : 61534.51953125 | val_loss : 99726.421875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 107 | train_loss : 75208.84375 | val_loss : 106238.6484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 108 | train_loss : 90898.359375 | val_loss : 61453.14453125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 109 | train_loss : 45792.265625 | val_loss : 73668.2421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 110 | train_loss : 50687.91015625 | val_loss : 29189.740234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 111 | train_loss : 43757.8203125 | val_loss : 82251.1328125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 112 | train_loss : 49131.94921875 | val_loss : 33535.5703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 113 | train_loss : 32045.265625 | val_loss : 93381.203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 114 | train_loss : 57819.6015625 | val_loss : 63171.2890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 115 | train_loss : 63079.9453125 | val_loss : 106515.21875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 116 | train_loss : 66324.1328125 | val_loss : 50317.09375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 117 | train_loss : 100714.1328125 | val_loss : 89388.5234375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 118 | train_loss : 101637.359375 | val_loss : 70832.796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 119 | train_loss : 38630.5703125 | val_loss : 54993.26953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 120 | train_loss : 45705.44140625 | val_loss : 33048.96875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 121 | train_loss : 16194.3486328125 | val_loss : 58400.05859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 122 | train_loss : 50868.12109375 | val_loss : 35723.62109375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 123 | train_loss : 32199.58203125 | val_loss : 117672.171875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 124 | train_loss : 92876.328125 | val_loss : 19866.216796875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 125 | train_loss : 16211.1201171875 | val_loss : 62507.25390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 126 | train_loss : 44667.67578125 | val_loss : 46304.3203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 127 | train_loss : 91021.3203125 | val_loss : 135637.78125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 128 | train_loss : 112827.5703125 | val_loss : 99851.8203125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 129 | train_loss : 89059.84375 | val_loss : 52869.1640625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 130 | train_loss : 42422.6484375 | val_loss : 75359.1875 | test_acc : 0.2 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 131 | train_loss : 68140.9375 | val_loss : 85832.15625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 132 | train_loss : 63408.015625 | val_loss : 24322.509765625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 133 | train_loss : 39769.28515625 | val_loss : 57283.9765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 134 | train_loss : 33213.66796875 | val_loss : 58172.2265625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 135 | train_loss : 74866.671875 | val_loss : 91930.1171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 136 | train_loss : 90910.4609375 | val_loss : 112669.9765625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 137 | train_loss : 75331.953125 | val_loss : 43361.171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 138 | train_loss : 90900.3515625 | val_loss : 117538.3125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 139 | train_loss : 101602.96875 | val_loss : 77684.2890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 140 | train_loss : 75915.9921875 | val_loss : 61771.1953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 141 | train_loss : 37322.8046875 | val_loss : 31700.92578125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 142 | train_loss : 58620.671875 | val_loss : 24554.744140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 143 | train_loss : 21320.5234375 | val_loss : 65087.828125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 144 | train_loss : 39853.51171875 | val_loss : 50597.44140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 145 | train_loss : 61721.28515625 | val_loss : 127984.9609375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 146 | train_loss : 84974.546875 | val_loss : 33829.640625 | test_acc : 0.24 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 147 | train_loss : 52794.57421875 | val_loss : 41084.2890625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 148 | train_loss : 38687.18359375 | val_loss : 95057.890625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 149 | train_loss : 60640.6796875 | val_loss : 46235.828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 150 | train_loss : 47036.609375 | val_loss : 59341.12109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 151 | train_loss : 36712.2265625 | val_loss : 66596.453125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 152 | train_loss : 55421.05078125 | val_loss : 33980.61328125 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 153 | train_loss : 45828.62890625 | val_loss : 88190.0234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 154 | train_loss : 57080.44921875 | val_loss : 58631.6484375 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 155 | train_loss : 72519.546875 | val_loss : 100371.84375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 156 | train_loss : 99941.8984375 | val_loss : 143316.734375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 157 | train_loss : 95594.546875 | val_loss : 40644.609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 158 | train_loss : 79286.328125 | val_loss : 121250.6796875 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 159 | train_loss : 89674.1796875 | val_loss : 77223.640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 160 | train_loss : 61010.046875 | val_loss : 27673.7421875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 161 | train_loss : 24866.5703125 | val_loss : 81448.5078125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 162 | train_loss : 50143.2109375 | val_loss : 44342.28515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 163 | train_loss : 44901.10546875 | val_loss : 54877.44921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 164 | train_loss : 28779.20703125 | val_loss : 43498.59375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 165 | train_loss : 39858.1953125 | val_loss : 50651.11328125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 166 | train_loss : 26361.634765625 | val_loss : 32010.0703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 167 | train_loss : 39397.390625 | val_loss : 91187.5625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 168 | train_loss : 52781.3203125 | val_loss : 30613.98828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 169 | train_loss : 28808.419921875 | val_loss : 62590.44140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 170 | train_loss : 35398.078125 | val_loss : 65187.05859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 171 | train_loss : 54656.73046875 | val_loss : 19921.296875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 172 | train_loss : 13121.2021484375 | val_loss : 44723.86328125 | test_acc : 0.36 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 173 | train_loss : 37997.21875 | val_loss : 82766.046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 174 | train_loss : 70809.359375 | val_loss : 42311.36328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 175 | train_loss : 25616.203125 | val_loss : 29493.08984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 176 | train_loss : 23669.0546875 | val_loss : 63075.1015625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 177 | train_loss : 51611.67578125 | val_loss : 25405.693359375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 178 | train_loss : 28125.5625 | val_loss : 87359.5234375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 179 | train_loss : 56996.91015625 | val_loss : 41047.30859375 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 180 | train_loss : 56628.25390625 | val_loss : 65568.7109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 181 | train_loss : 65320.26171875 | val_loss : 118099.078125 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 182 | train_loss : 78013.8203125 | val_loss : 32308.060546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 183 | train_loss : 60369.6796875 | val_loss : 33285.43359375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 184 | train_loss : 25957.88671875 | val_loss : 62277.5859375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 185 | train_loss : 52990.703125 | val_loss : 36306.375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 186 | train_loss : 35824.59375 | val_loss : 98069.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 187 | train_loss : 74791.4296875 | val_loss : 17434.494140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 188 | train_loss : 10259.9033203125 | val_loss : 27905.5078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 189 | train_loss : 19226.39453125 | val_loss : 48940.6015625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 190 | train_loss : 58223.109375 | val_loss : 75027.7734375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 191 | train_loss : 61588.671875 | val_loss : 33609.32421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 192 | train_loss : 25576.73046875 | val_loss : 68979.28125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 193 | train_loss : 52690.2734375 | val_loss : 23379.720703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 194 | train_loss : 23681.599609375 | val_loss : 49835.671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 195 | train_loss : 37808.6015625 | val_loss : 29879.775390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 196 | train_loss : 32151.3125 | val_loss : 62131.171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 197 | train_loss : 50479.65625 | val_loss : 27701.14453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 198 | train_loss : 18632.55078125 | val_loss : 52417.88671875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 199 | train_loss : 41018.76171875 | val_loss : 23247.86328125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 200 | train_loss : 24205.41015625 | val_loss : 50344.66015625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 201 | train_loss : 37308.5859375 | val_loss : 27723.02734375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 202 | train_loss : 34187.06640625 | val_loss : 44442.078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 203 | train_loss : 34953.484375 | val_loss : 22017.732421875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 204 | train_loss : 14288.556640625 | val_loss : 43987.9765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 205 | train_loss : 34727.57421875 | val_loss : 19239.666015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 206 | train_loss : 19092.23828125 | val_loss : 51560.5390625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 207 | train_loss : 34616.03125 | val_loss : 33427.9765625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 208 | train_loss : 42061.6015625 | val_loss : 55573.4296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 209 | train_loss : 48107.328125 | val_loss : 31064.9375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 210 | train_loss : 18690.232421875 | val_loss : 26827.810546875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 211 | train_loss : 34494.21875 | val_loss : 45406.609375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 212 | train_loss : 32126.07421875 | val_loss : 35801.625 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 213 | train_loss : 41539.50390625 | val_loss : 31258.8203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 214 | train_loss : 20273.830078125 | val_loss : 31954.1640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 215 | train_loss : 28060.23046875 | val_loss : 49749.421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 216 | train_loss : 43989.875 | val_loss : 28489.509765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 217 | train_loss : 14926.2939453125 | val_loss : 17537.029296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 218 | train_loss : 20208.189453125 | val_loss : 54983.78125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 219 | train_loss : 31549.787109375 | val_loss : 34001.17578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 220 | train_loss : 34317.46875 | val_loss : 58130.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 221 | train_loss : 31293.501953125 | val_loss : 27789.23046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 222 | train_loss : 35350.078125 | val_loss : 87526.4609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 223 | train_loss : 50524.3359375 | val_loss : 22012.58203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 224 | train_loss : 21235.265625 | val_loss : 59644.44140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 225 | train_loss : 34083.96484375 | val_loss : 41580.50390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 226 | train_loss : 35921.390625 | val_loss : 21160.6953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 227 | train_loss : 9411.791015625 | val_loss : 23247.4140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 228 | train_loss : 17779.701171875 | val_loss : 38944.44921875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 229 | train_loss : 43331.32421875 | val_loss : 68345.828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 230 | train_loss : 53791.2265625 | val_loss : 31036.220703125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 231 | train_loss : 23614.900390625 | val_loss : 63682.89453125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 232 | train_loss : 46152.60546875 | val_loss : 23673.322265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 233 | train_loss : 21693.669921875 | val_loss : 44738.25390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 234 | train_loss : 34302.15234375 | val_loss : 20978.75 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 235 | train_loss : 21433.640625 | val_loss : 46279.21875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 236 | train_loss : 30490.921875 | val_loss : 34647.203125 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 237 | train_loss : 40566.078125 | val_loss : 50291.21875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 238 | train_loss : 43443.4140625 | val_loss : 30447.966796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 239 | train_loss : 16800.294921875 | val_loss : 19277.44140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 240 | train_loss : 18044.3203125 | val_loss : 28834.4140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 241 | train_loss : 14330.568359375 | val_loss : 17375.681640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 242 | train_loss : 18849.369140625 | val_loss : 46998.13671875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 243 | train_loss : 25517.05078125 | val_loss : 28983.47265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 244 | train_loss : 31491.97265625 | val_loss : 67601.6875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 245 | train_loss : 37445.73046875 | val_loss : 21304.658203125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 246 | train_loss : 27512.8828125 | val_loss : 62564.37890625 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 247 | train_loss : 33980.24609375 | val_loss : 21258.931640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 248 | train_loss : 27323.322265625 | val_loss : 68077.90625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 249 | train_loss : 37967.79296875 | val_loss : 25645.58984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 250 | train_loss : 28521.931640625 | val_loss : 61247.33984375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 251 | train_loss : 32454.47265625 | val_loss : 19770.375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 252 | train_loss : 22573.466796875 | val_loss : 54873.546875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 253 | train_loss : 28858.58984375 | val_loss : 21998.94921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 254 | train_loss : 29011.94921875 | val_loss : 60470.66015625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 255 | train_loss : 31412.501953125 | val_loss : 20964.0703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 256 | train_loss : 24392.857421875 | val_loss : 58301.96484375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 257 | train_loss : 30408.0859375 | val_loss : 20306.994140625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 258 | train_loss : 28098.322265625 | val_loss : 53846.01171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 259 | train_loss : 27260.115234375 | val_loss : 23189.58984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 260 | train_loss : 25380.474609375 | val_loss : 56235.0 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 261 | train_loss : 28756.279296875 | val_loss : 27309.779296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 262 | train_loss : 25536.685546875 | val_loss : 35513.0 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 263 | train_loss : 16332.759765625 | val_loss : 34526.578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 264 | train_loss : 29511.287109375 | val_loss : 19475.693359375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 265 | train_loss : 10498.134765625 | val_loss : 27321.412109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 266 | train_loss : 17499.98046875 | val_loss : 26683.4609375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 267 | train_loss : 27109.296875 | val_loss : 41374.6015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 268 | train_loss : 35195.93359375 | val_loss : 17048.306640625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 269 | train_loss : 8137.23193359375 | val_loss : 20870.76171875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 270 | train_loss : 8594.4873046875 | val_loss : 20284.599609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 271 | train_loss : 21000.341796875 | val_loss : 48102.59375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 272 | train_loss : 35508.98828125 | val_loss : 24858.6796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 273 | train_loss : 29276.6640625 | val_loss : 48181.69921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 274 | train_loss : 34110.671875 | val_loss : 33116.33984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 275 | train_loss : 30140.70703125 | val_loss : 60020.18359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 276 | train_loss : 45913.234375 | val_loss : 20695.9921875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 277 | train_loss : 16288.822265625 | val_loss : 41908.99609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 278 | train_loss : 28405.005859375 | val_loss : 26166.474609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 279 | train_loss : 28323.8046875 | val_loss : 46369.4765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 280 | train_loss : 36001.671875 | val_loss : 18266.265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 281 | train_loss : 10219.0283203125 | val_loss : 26272.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 282 | train_loss : 17160.224609375 | val_loss : 30356.154296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 283 | train_loss : 32553.30078125 | val_loss : 56375.89453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 284 | train_loss : 45344.3359375 | val_loss : 18911.26953125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 285 | train_loss : 11618.30859375 | val_loss : 20764.619140625 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 286 | train_loss : 16675.1640625 | val_loss : 31223.107421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 287 | train_loss : 27576.822265625 | val_loss : 16982.244140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 288 | train_loss : 9673.3740234375 | val_loss : 24351.80078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 289 | train_loss : 18919.400390625 | val_loss : 23247.703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 290 | train_loss : 21830.392578125 | val_loss : 43524.90625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 291 | train_loss : 37055.078125 | val_loss : 19366.162109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 292 | train_loss : 12849.583984375 | val_loss : 33689.609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 293 | train_loss : 23535.13671875 | val_loss : 27821.529296875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 294 | train_loss : 27844.474609375 | val_loss : 42538.80078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 295 | train_loss : 35696.2265625 | val_loss : 20989.140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 296 | train_loss : 11439.2041015625 | val_loss : 27587.662109375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 297 | train_loss : 20564.0 | val_loss : 24475.125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 298 | train_loss : 24939.962890625 | val_loss : 46316.23828125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 299 | train_loss : 36730.421875 | val_loss : 22083.03515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 300 | train_loss : 14185.4609375 | val_loss : 31458.697265625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 301 | train_loss : 23852.857421875 | val_loss : 24080.904296875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 302 | train_loss : 23018.5625 | val_loss : 42436.48828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 303 | train_loss : 33468.546875 | val_loss : 20663.396484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 304 | train_loss : 12548.01953125 | val_loss : 26981.60546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 305 | train_loss : 20051.0234375 | val_loss : 22070.177734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 306 | train_loss : 19882.78515625 | val_loss : 122982.2578125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 307 | train_loss : 101213.0703125 | val_loss : 24058.9765625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 308 | train_loss : 35495.7734375 | val_loss : 51053.17578125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 309 | train_loss : 26559.95703125 | val_loss : 23224.244140625 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 310 | train_loss : 27854.720703125 | val_loss : 32675.2890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 311 | train_loss : 30373.7578125 | val_loss : 25463.0625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 312 | train_loss : 11682.4365234375 | val_loss : 12530.8427734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 313 | train_loss : 19135.703125 | val_loss : 34685.21484375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 314 | train_loss : 16521.892578125 | val_loss : 28797.4453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 315 | train_loss : 36770.328125 | val_loss : 81458.296875 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 316 | train_loss : 46639.60546875 | val_loss : 14491.6484375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 317 | train_loss : 21638.724609375 | val_loss : 27692.162109375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 318 | train_loss : 10997.8876953125 | val_loss : 11317.6845703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 319 | train_loss : 9680.8017578125 | val_loss : 47155.91015625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 320 | train_loss : 25323.7265625 | val_loss : 28714.515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 321 | train_loss : 36491.078125 | val_loss : 59448.87109375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 322 | train_loss : 31498.859375 | val_loss : 16955.875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 323 | train_loss : 28097.537109375 | val_loss : 42934.74609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 324 | train_loss : 20623.095703125 | val_loss : 21606.48046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 325 | train_loss : 20825.0625 | val_loss : 29589.681640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 326 | train_loss : 15057.869140625 | val_loss : 23061.46484375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 327 | train_loss : 22885.720703125 | val_loss : 32282.10546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 328 | train_loss : 14672.6728515625 | val_loss : 24516.32421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 329 | train_loss : 23528.6640625 | val_loss : 27036.76953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 330 | train_loss : 12997.2734375 | val_loss : 26383.341796875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 331 | train_loss : 31114.7890625 | val_loss : 62644.09375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 332 | train_loss : 33835.3828125 | val_loss : 138852.9375 | test_acc : 0.44 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 333 | train_loss : 169987.140625 | val_loss : 195064.859375 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 334 | train_loss : 126875.34375 | val_loss : 78107.796875 | test_acc : 0.32 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 335 | train_loss : 70441.8125 | val_loss : 81402.9453125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 336 | train_loss : 59579.625 | val_loss : 108234.0390625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 337 | train_loss : 180763.234375 | val_loss : 162380.96875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 338 | train_loss : 133784.203125 | val_loss : 56319.171875 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 339 | train_loss : 30324.57421875 | val_loss : 29734.83984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 340 | train_loss : 49947.1640625 | val_loss : 28915.0859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 341 | train_loss : 22780.466796875 | val_loss : 31487.984375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 342 | train_loss : 17842.376953125 | val_loss : 27448.52734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 343 | train_loss : 25491.279296875 | val_loss : 17909.20703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 344 | train_loss : 13481.888671875 | val_loss : 25952.98046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 345 | train_loss : 20100.1796875 | val_loss : 52262.1953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 346 | train_loss : 60084.73046875 | val_loss : 62660.17578125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 347 | train_loss : 51703.71875 | val_loss : 27767.4140625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 348 | train_loss : 15441.22265625 | val_loss : 13335.431640625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 349 | train_loss : 15177.40234375 | val_loss : 26496.802734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 350 | train_loss : 12796.7890625 | val_loss : 15589.0263671875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 351 | train_loss : 17890.302734375 | val_loss : 36581.8359375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 352 | train_loss : 18940.685546875 | val_loss : 18293.744140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 353 | train_loss : 18044.755859375 | val_loss : 30715.51953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 354 | train_loss : 15936.6748046875 | val_loss : 21249.689453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 355 | train_loss : 20477.64453125 | val_loss : 23784.3125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 356 | train_loss : 11972.9609375 | val_loss : 22565.375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 357 | train_loss : 21413.0 | val_loss : 19835.517578125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 358 | train_loss : 10489.0087890625 | val_loss : 18558.099609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 359 | train_loss : 16530.126953125 | val_loss : 17756.79296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 360 | train_loss : 12451.81640625 | val_loss : 20492.1484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 361 | train_loss : 17600.060546875 | val_loss : 18139.0703125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 362 | train_loss : 14585.9326171875 | val_loss : 23871.4453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 363 | train_loss : 19516.83203125 | val_loss : 18062.546875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 364 | train_loss : 15186.55078125 | val_loss : 22441.025390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 365 | train_loss : 18943.662109375 | val_loss : 18196.568359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 366 | train_loss : 16152.9775390625 | val_loss : 23130.572265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 367 | train_loss : 19717.6484375 | val_loss : 19766.4296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 368 | train_loss : 17331.623046875 | val_loss : 25553.052734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 369 | train_loss : 21343.20703125 | val_loss : 16664.369140625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 370 | train_loss : 12531.7666015625 | val_loss : 21352.765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 371 | train_loss : 16446.724609375 | val_loss : 16959.369140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 372 | train_loss : 12269.4560546875 | val_loss : 20267.080078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 373 | train_loss : 17566.1953125 | val_loss : 16958.52734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 374 | train_loss : 12453.93359375 | val_loss : 20485.42578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 375 | train_loss : 16532.044921875 | val_loss : 17638.71484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 376 | train_loss : 12526.5478515625 | val_loss : 21270.330078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 377 | train_loss : 18083.92578125 | val_loss : 114534.9921875 | test_acc : 0.16 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 378 | train_loss : 99436.8828125 | val_loss : 120320.796875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 379 | train_loss : 94326.140625 | val_loss : 80067.4921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 380 | train_loss : 62487.375 | val_loss : 43855.5390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 381 | train_loss : 35463.703125 | val_loss : 11374.197265625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 382 | train_loss : 8926.7666015625 | val_loss : 19496.998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 383 | train_loss : 11317.9345703125 | val_loss : 20157.021484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 384 | train_loss : 21949.83984375 | val_loss : 48975.75 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 385 | train_loss : 28372.61328125 | val_loss : 14921.396484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 386 | train_loss : 14907.6787109375 | val_loss : 29672.115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 387 | train_loss : 17719.318359375 | val_loss : 22159.60546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 388 | train_loss : 22274.572265625 | val_loss : 33786.63671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 389 | train_loss : 18644.7109375 | val_loss : 17707.2890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 390 | train_loss : 17881.310546875 | val_loss : 29264.625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 391 | train_loss : 16034.62109375 | val_loss : 17512.12109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 392 | train_loss : 17862.0234375 | val_loss : 27422.73046875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 393 | train_loss : 14803.45703125 | val_loss : 18242.3046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 394 | train_loss : 18309.564453125 | val_loss : 28103.0859375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 395 | train_loss : 15110.0283203125 | val_loss : 19114.23046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 396 | train_loss : 18895.828125 | val_loss : 24581.69921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 397 | train_loss : 11735.4990234375 | val_loss : 17306.58984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 398 | train_loss : 16537.04296875 | val_loss : 26376.630859375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 399 | train_loss : 12493.40234375 | val_loss : 16762.47265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 400 | train_loss : 16024.48046875 | val_loss : 28565.76171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 401 | train_loss : 13340.6474609375 | val_loss : 15824.1064453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 402 | train_loss : 14685.53125 | val_loss : 24546.302734375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 403 | train_loss : 10374.8359375 | val_loss : 14146.5009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 404 | train_loss : 11894.02734375 | val_loss : 22395.720703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 405 | train_loss : 9436.1591796875 | val_loss : 14515.767578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 406 | train_loss : 12429.6572265625 | val_loss : 21670.7109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 407 | train_loss : 8685.1826171875 | val_loss : 13125.1572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 408 | train_loss : 10590.853515625 | val_loss : 18837.921875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 409 | train_loss : 6364.033203125 | val_loss : 11733.7265625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 410 | train_loss : 9182.7529296875 | val_loss : 17349.783203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 411 | train_loss : 5598.078125 | val_loss : 10111.19921875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 412 | train_loss : 5668.2548828125 | val_loss : 16968.90234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 413 | train_loss : 5662.58984375 | val_loss : 9895.4345703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 414 | train_loss : 7707.63671875 | val_loss : 16876.41796875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 415 | train_loss : 5957.3330078125 | val_loss : 11402.5166015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 416 | train_loss : 9681.365234375 | val_loss : 17265.046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 417 | train_loss : 6172.66796875 | val_loss : 11259.4111328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 418 | train_loss : 9359.1748046875 | val_loss : 17500.4453125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 419 | train_loss : 6692.38916015625 | val_loss : 14631.9345703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 420 | train_loss : 13361.05078125 | val_loss : 24238.765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 421 | train_loss : 12112.5576171875 | val_loss : 20902.48046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 422 | train_loss : 17586.974609375 | val_loss : 21768.884765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 423 | train_loss : 11966.615234375 | val_loss : 34087.453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 424 | train_loss : 25060.53515625 | val_loss : 19300.08984375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 425 | train_loss : 10506.8759765625 | val_loss : 24909.169921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 426 | train_loss : 17835.5625 | val_loss : 17110.724609375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 427 | train_loss : 15941.2548828125 | val_loss : 37970.81640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 428 | train_loss : 25966.0546875 | val_loss : 11810.724609375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 429 | train_loss : 8831.5302734375 | val_loss : 17545.400390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 430 | train_loss : 7227.52490234375 | val_loss : 14529.8603515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 431 | train_loss : 8376.6845703125 | val_loss : 20640.201171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 432 | train_loss : 15115.40625 | val_loss : 21163.375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 433 | train_loss : 14739.04296875 | val_loss : 60936.48828125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 434 | train_loss : 49298.08984375 | val_loss : 29181.5546875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 435 | train_loss : 28203.0078125 | val_loss : 41887.15234375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 436 | train_loss : 29415.875 | val_loss : 20258.66796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 437 | train_loss : 13008.517578125 | val_loss : 26434.626953125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 438 | train_loss : 20723.953125 | val_loss : 20301.1171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 439 | train_loss : 10080.9150390625 | val_loss : 23913.83984375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 440 | train_loss : 19094.734375 | val_loss : 19642.134765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 441 | train_loss : 8862.9013671875 | val_loss : 17299.845703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 442 | train_loss : 12955.5126953125 | val_loss : 24029.05078125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 443 | train_loss : 13375.9501953125 | val_loss : 25893.830078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 444 | train_loss : 22221.310546875 | val_loss : 16749.435546875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 445 | train_loss : 7527.6318359375 | val_loss : 18349.9296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 446 | train_loss : 12426.84765625 | val_loss : 16097.71484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 447 | train_loss : 10940.4111328125 | val_loss : 33948.0078125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 448 | train_loss : 24158.25 | val_loss : 11706.9345703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 449 | train_loss : 8034.107421875 | val_loss : 12426.087890625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 450 | train_loss : 5011.2431640625 | val_loss : 10298.9521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 451 | train_loss : 5834.017578125 | val_loss : 14507.23046875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 452 | train_loss : 7193.7939453125 | val_loss : 13348.849609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 453 | train_loss : 5989.2216796875 | val_loss : 10997.00390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 454 | train_loss : 9615.685546875 | val_loss : 17315.9609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 455 | train_loss : 11227.8935546875 | val_loss : 32996.50390625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 456 | train_loss : 27833.630859375 | val_loss : 16077.9677734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 457 | train_loss : 8131.27001953125 | val_loss : 16704.82421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 458 | train_loss : 13702.583984375 | val_loss : 18419.79296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 459 | train_loss : 10681.6748046875 | val_loss : 21281.55078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 460 | train_loss : 19225.07421875 | val_loss : 17414.2265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 461 | train_loss : 8552.7578125 | val_loss : 15207.0810546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 462 | train_loss : 13255.416015625 | val_loss : 18822.5546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 463 | train_loss : 10066.705078125 | val_loss : 19747.525390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 464 | train_loss : 18021.3203125 | val_loss : 17262.25390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 465 | train_loss : 8931.10546875 | val_loss : 17403.23828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 466 | train_loss : 13851.62890625 | val_loss : 17314.068359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 467 | train_loss : 12299.431640625 | val_loss : 30566.0703125 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 468 | train_loss : 22074.349609375 | val_loss : 18739.529296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 469 | train_loss : 13187.552734375 | val_loss : 19981.359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 470 | train_loss : 16217.14453125 | val_loss : 15104.7275390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 471 | train_loss : 8614.9375 | val_loss : 15694.5908203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 472 | train_loss : 13284.177734375 | val_loss : 14199.7666015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 473 | train_loss : 8335.9169921875 | val_loss : 12772.9853515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 474 | train_loss : 9975.220703125 | val_loss : 12268.8095703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 475 | train_loss : 8209.28515625 | val_loss : 12151.8486328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 476 | train_loss : 8846.884765625 | val_loss : 13742.7158203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 477 | train_loss : 10033.40234375 | val_loss : 15423.0400390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 478 | train_loss : 13540.869140625 | val_loss : 11723.5849609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 479 | train_loss : 8677.91015625 | val_loss : 11646.232421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 480 | train_loss : 8099.607421875 | val_loss : 13054.7412109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 481 | train_loss : 7946.560546875 | val_loss : 14696.9697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 482 | train_loss : 12242.1845703125 | val_loss : 13984.677734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 483 | train_loss : 10032.5322265625 | val_loss : 17277.390625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 484 | train_loss : 14672.3623046875 | val_loss : 17040.515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 485 | train_loss : 9491.7265625 | val_loss : 17395.54296875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 486 | train_loss : 14253.259765625 | val_loss : 21616.341796875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 487 | train_loss : 11491.3662109375 | val_loss : 19909.05078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 488 | train_loss : 16867.119140625 | val_loss : 21722.130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 489 | train_loss : 10831.205078125 | val_loss : 17203.892578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 490 | train_loss : 15314.2626953125 | val_loss : 22273.474609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 491 | train_loss : 11114.6591796875 | val_loss : 16615.037109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 492 | train_loss : 14574.9462890625 | val_loss : 21524.998046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 493 | train_loss : 10531.5751953125 | val_loss : 15060.6015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 494 | train_loss : 13462.79296875 | val_loss : 19669.283203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 495 | train_loss : 9129.8251953125 | val_loss : 14773.0283203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 496 | train_loss : 12952.2861328125 | val_loss : 20247.087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 497 | train_loss : 10019.2216796875 | val_loss : 59465.609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 498 | train_loss : 45052.71484375 | val_loss : 274731.96875 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 499 | train_loss : 322141.25 | val_loss : 93981.1796875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 500 | train_loss : 70960.7109375 | val_loss : 42603.0390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 501 | train_loss : 21220.357421875 | val_loss : 27540.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 502 | train_loss : 26587.224609375 | val_loss : 21505.345703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 503 | train_loss : 10238.755859375 | val_loss : 19457.962890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 504 | train_loss : 18499.248046875 | val_loss : 21738.83984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 505 | train_loss : 10136.53515625 | val_loss : 16872.71484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 506 | train_loss : 15876.9775390625 | val_loss : 20569.767578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 507 | train_loss : 9732.60546875 | val_loss : 16023.0947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 508 | train_loss : 13629.552734375 | val_loss : 14291.0576171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 509 | train_loss : 6375.46826171875 | val_loss : 11907.7646484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 510 | train_loss : 9076.666015625 | val_loss : 12012.4541015625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 511 | train_loss : 9443.365234375 | val_loss : 13071.1240234375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 512 | train_loss : 8600.5458984375 | val_loss : 12944.994140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 513 | train_loss : 12573.125 | val_loss : 39251.484375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 514 | train_loss : 32077.0 | val_loss : 17916.341796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 515 | train_loss : 31329.107421875 | val_loss : 19016.5546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 516 | train_loss : 9364.859375 | val_loss : 14855.099609375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 517 | train_loss : 5561.41357421875 | val_loss : 7224.6767578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 518 | train_loss : 6557.2763671875 | val_loss : 16289.619140625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 519 | train_loss : 7038.90673828125 | val_loss : 9137.82421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 520 | train_loss : 9017.8955078125 | val_loss : 19709.77734375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 521 | train_loss : 9305.1015625 | val_loss : 14893.3779296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 522 | train_loss : 15161.7509765625 | val_loss : 25133.4453125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 523 | train_loss : 13121.1748046875 | val_loss : 12320.0703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 524 | train_loss : 13036.62890625 | val_loss : 24348.21484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 525 | train_loss : 11582.5078125 | val_loss : 13329.087890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 526 | train_loss : 12838.3515625 | val_loss : 22661.2109375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 527 | train_loss : 10995.5078125 | val_loss : 13147.337890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 528 | train_loss : 13056.412109375 | val_loss : 23323.91015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 529 | train_loss : 10983.4873046875 | val_loss : 13055.458984375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 530 | train_loss : 12643.53515625 | val_loss : 20592.453125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 531 | train_loss : 9466.4296875 | val_loss : 12848.1376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 532 | train_loss : 12926.474609375 | val_loss : 22062.939453125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 533 | train_loss : 9219.0810546875 | val_loss : 10050.767578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 534 | train_loss : 9139.556640625 | val_loss : 20720.220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 535 | train_loss : 8346.478515625 | val_loss : 10572.3203125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 536 | train_loss : 9777.416015625 | val_loss : 19177.2109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 537 | train_loss : 7477.06298828125 | val_loss : 9008.2255859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 538 | train_loss : 8386.6259765625 | val_loss : 15549.6953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 539 | train_loss : 5320.7783203125 | val_loss : 6993.369140625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 540 | train_loss : 5755.87744140625 | val_loss : 15044.9013671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 541 | train_loss : 4607.18896484375 | val_loss : 6502.35693359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 542 | train_loss : 4925.87353515625 | val_loss : 14416.3173828125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 543 | train_loss : 4693.53173828125 | val_loss : 6007.7626953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 544 | train_loss : 4671.13623046875 | val_loss : 13658.0771484375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 545 | train_loss : 4397.9931640625 | val_loss : 5976.306640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 546 | train_loss : 5137.01611328125 | val_loss : 15149.537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 547 | train_loss : 5161.64013671875 | val_loss : 5957.06396484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 548 | train_loss : 5464.72265625 | val_loss : 13790.2900390625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 549 | train_loss : 4951.02734375 | val_loss : 6851.505859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 550 | train_loss : 6478.296875 | val_loss : 14192.2724609375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 551 | train_loss : 4767.39208984375 | val_loss : 5443.87353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 552 | train_loss : 4899.720703125 | val_loss : 12133.2353515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 553 | train_loss : 4340.2861328125 | val_loss : 6619.1123046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 554 | train_loss : 6355.8857421875 | val_loss : 13675.3154296875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 555 | train_loss : 4990.583984375 | val_loss : 8235.662109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 556 | train_loss : 7863.33740234375 | val_loss : 62204.03125 | test_acc : 0.28 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 557 | train_loss : 41834.6015625 | val_loss : 57966.26171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 558 | train_loss : 45552.23828125 | val_loss : 32146.029296875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 559 | train_loss : 26070.14453125 | val_loss : 25860.890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 560 | train_loss : 14472.8623046875 | val_loss : 17483.306640625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 561 | train_loss : 27273.482421875 | val_loss : 61501.08984375 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 562 | train_loss : 36672.16796875 | val_loss : 10358.6591796875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 563 | train_loss : 16692.126953125 | val_loss : 39018.390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 564 | train_loss : 21067.1953125 | val_loss : 12850.0927734375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 565 | train_loss : 18430.658203125 | val_loss : 29278.3671875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 566 | train_loss : 13807.0703125 | val_loss : 11131.9521484375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 567 | train_loss : 11844.1337890625 | val_loss : 38254.30859375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 568 | train_loss : 18967.228515625 | val_loss : 15254.1015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 569 | train_loss : 17705.26171875 | val_loss : 29444.53515625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 570 | train_loss : 13477.1953125 | val_loss : 10712.107421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 571 | train_loss : 10225.7275390625 | val_loss : 20107.48046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 572 | train_loss : 8702.3623046875 | val_loss : 9451.505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 573 | train_loss : 8393.77734375 | val_loss : 15479.4326171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 574 | train_loss : 5450.63134765625 | val_loss : 6187.92041015625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 575 | train_loss : 4980.19384765625 | val_loss : 13120.0771484375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 576 | train_loss : 3828.974365234375 | val_loss : 5132.06005859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 577 | train_loss : 3031.3037109375 | val_loss : 10982.7451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 578 | train_loss : 3138.8701171875 | val_loss : 4808.12060546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 579 | train_loss : 3178.27880859375 | val_loss : 11368.4111328125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 580 | train_loss : 3241.947265625 | val_loss : 4379.39697265625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 581 | train_loss : 2829.33251953125 | val_loss : 10915.0947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 582 | train_loss : 3160.90087890625 | val_loss : 3966.998779296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 583 | train_loss : 2748.719970703125 | val_loss : 10014.5009765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 584 | train_loss : 2995.678466796875 | val_loss : 3479.91943359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 585 | train_loss : 2639.6376953125 | val_loss : 9376.1767578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 586 | train_loss : 2862.79150390625 | val_loss : 3057.3994140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 587 | train_loss : 2526.322509765625 | val_loss : 9531.6533203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 588 | train_loss : 3031.985107421875 | val_loss : 3122.27001953125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 589 | train_loss : 3120.8505859375 | val_loss : 10387.447265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 590 | train_loss : 3448.451171875 | val_loss : 2481.35498046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 591 | train_loss : 2608.249267578125 | val_loss : 8647.470703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 592 | train_loss : 2933.6298828125 | val_loss : 2003.59619140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 593 | train_loss : 2258.93408203125 | val_loss : 6777.3212890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 594 | train_loss : 2439.453125 | val_loss : 1685.24560546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 595 | train_loss : 2286.282958984375 | val_loss : 6328.49169921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 596 | train_loss : 2467.091796875 | val_loss : 1447.550048828125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 597 | train_loss : 3287.042724609375 | val_loss : 35295.59765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 598 | train_loss : 17868.486328125 | val_loss : 5552.10009765625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 599 | train_loss : 14401.7841796875 | val_loss : 14269.087890625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 600 | train_loss : 5927.8974609375 | val_loss : 4361.1357421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 601 | train_loss : 4992.00048828125 | val_loss : 12883.33203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 602 | train_loss : 5383.76171875 | val_loss : 7231.93994140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 603 | train_loss : 7387.7119140625 | val_loss : 17141.16015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 604 | train_loss : 8503.6845703125 | val_loss : 12621.7998046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 605 | train_loss : 13077.943359375 | val_loss : 24787.28515625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 606 | train_loss : 12462.65234375 | val_loss : 14444.0947265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 607 | train_loss : 13512.826171875 | val_loss : 22451.775390625 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 608 | train_loss : 16624.4296875 | val_loss : 45107.7890625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 609 | train_loss : 29860.82421875 | val_loss : 8108.9462890625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 610 | train_loss : 5941.48876953125 | val_loss : 12579.0625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 611 | train_loss : 7292.00048828125 | val_loss : 10147.1572265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 612 | train_loss : 7944.63232421875 | val_loss : 12883.0283203125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 613 | train_loss : 9037.5498046875 | val_loss : 15342.697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 614 | train_loss : 8879.5009765625 | val_loss : 11957.1953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 615 | train_loss : 9749.2685546875 | val_loss : 257568.15625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 616 | train_loss : 289449.40625 | val_loss : 85605.96875 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 617 | train_loss : 60296.09375 | val_loss : 18537.474609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 618 | train_loss : 21040.224609375 | val_loss : 28549.001953125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 619 | train_loss : 14747.9384765625 | val_loss : 12359.3701171875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 620 | train_loss : 18122.60546875 | val_loss : 31922.55078125 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 621 | train_loss : 16340.8564453125 | val_loss : 9713.4384765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 622 | train_loss : 10400.0126953125 | val_loss : 21425.720703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 623 | train_loss : 10299.0595703125 | val_loss : 11019.2236328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 624 | train_loss : 11121.767578125 | val_loss : 21476.490234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 625 | train_loss : 10760.2490234375 | val_loss : 9381.7705078125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 626 | train_loss : 10010.787109375 | val_loss : 16162.83984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 627 | train_loss : 6910.5986328125 | val_loss : 7554.478515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 628 | train_loss : 7497.9580078125 | val_loss : 10901.287109375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 629 | train_loss : 4429.951171875 | val_loss : 5007.41943359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 630 | train_loss : 4971.27490234375 | val_loss : 9393.353515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 631 | train_loss : 3493.9755859375 | val_loss : 3790.030029296875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 632 | train_loss : 3303.711181640625 | val_loss : 8719.884765625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 633 | train_loss : 3228.960693359375 | val_loss : 3826.7763671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 634 | train_loss : 3278.8974609375 | val_loss : 7959.306640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 635 | train_loss : 3384.175537109375 | val_loss : 4647.40576171875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 636 | train_loss : 3239.523193359375 | val_loss : 7190.16748046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 637 | train_loss : 3232.629150390625 | val_loss : 4615.349609375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 638 | train_loss : 3219.3701171875 | val_loss : 5168.3310546875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 639 | train_loss : 3211.911865234375 | val_loss : 7748.033203125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 640 | train_loss : 3566.917236328125 | val_loss : 3667.851806640625 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 641 | train_loss : 2892.168212890625 | val_loss : 5464.0908203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 642 | train_loss : 2543.628173828125 | val_loss : 3418.7607421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 643 | train_loss : 2387.675048828125 | val_loss : 4097.3125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 644 | train_loss : 2162.447509765625 | val_loss : 2718.818115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 645 | train_loss : 2330.8115234375 | val_loss : 5257.06103515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 646 | train_loss : 2392.9404296875 | val_loss : 2965.01806640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 647 | train_loss : 1759.9129638671875 | val_loss : 3897.032470703125 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 648 | train_loss : 2119.7529296875 | val_loss : 2333.918212890625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 649 | train_loss : 1856.938232421875 | val_loss : 2837.7138671875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 650 | train_loss : 1732.5032958984375 | val_loss : 2084.7236328125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 651 | train_loss : 1987.06640625 | val_loss : 4772.853515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 652 | train_loss : 2297.767578125 | val_loss : 1739.0093994140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 653 | train_loss : 1791.0855712890625 | val_loss : 4201.66015625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 654 | train_loss : 1991.849365234375 | val_loss : 1487.66943359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 655 | train_loss : 1509.1590576171875 | val_loss : 3441.43994140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 656 | train_loss : 1832.2816162109375 | val_loss : 1314.434326171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 657 | train_loss : 1673.0458984375 | val_loss : 3862.17431640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 658 | train_loss : 1952.30419921875 | val_loss : 1261.4012451171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 659 | train_loss : 1576.3740234375 | val_loss : 3102.418212890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 660 | train_loss : 1883.531982421875 | val_loss : 1133.438720703125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 661 | train_loss : 1642.9775390625 | val_loss : 4395.17578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 662 | train_loss : 2176.771484375 | val_loss : 1020.0856323242188 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 663 | train_loss : 1716.12939453125 | val_loss : 3340.726806640625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 664 | train_loss : 1946.98486328125 | val_loss : 1389.5518798828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 665 | train_loss : 1843.6043701171875 | val_loss : 4648.8623046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 666 | train_loss : 2504.385009765625 | val_loss : 50180.1640625 | test_acc : 0.4 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 667 | train_loss : 52005.890625 | val_loss : 88021.921875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 668 | train_loss : 64597.109375 | val_loss : 35970.06640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 669 | train_loss : 32957.62890625 | val_loss : 13705.0927734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 670 | train_loss : 10994.9638671875 | val_loss : 7040.35791015625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 671 | train_loss : 11223.13671875 | val_loss : 22795.94921875 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 672 | train_loss : 18021.1953125 | val_loss : 28009.70703125 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 673 | train_loss : 23498.91015625 | val_loss : 23929.490234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 674 | train_loss : 18973.390625 | val_loss : 14852.0478515625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 675 | train_loss : 9736.13671875 | val_loss : 16872.115234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 676 | train_loss : 14364.0546875 | val_loss : 77590.3671875 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 677 | train_loss : 66182.21875 | val_loss : 59963.3515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 678 | train_loss : 47560.55078125 | val_loss : 6518.98681640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 679 | train_loss : 6844.94384765625 | val_loss : 5491.70263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 680 | train_loss : 3805.218505859375 | val_loss : 3099.961181640625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 681 | train_loss : 5865.91064453125 | val_loss : 6093.34765625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 682 | train_loss : 5345.15234375 | val_loss : 4485.3818359375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 683 | train_loss : 9431.9404296875 | val_loss : 6712.71142578125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 684 | train_loss : 6230.60791015625 | val_loss : 6170.03515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 685 | train_loss : 12808.130859375 | val_loss : 7689.203125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 686 | train_loss : 7192.0986328125 | val_loss : 6669.93115234375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 687 | train_loss : 11333.3427734375 | val_loss : 4441.5107421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 688 | train_loss : 4510.0556640625 | val_loss : 6166.64697265625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 689 | train_loss : 6267.7744140625 | val_loss : 3665.991943359375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 690 | train_loss : 3890.034912109375 | val_loss : 7658.38818359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 691 | train_loss : 4127.55126953125 | val_loss : 4896.5810546875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 692 | train_loss : 5281.873046875 | val_loss : 12026.39453125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 693 | train_loss : 6433.49853515625 | val_loss : 9325.130859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 694 | train_loss : 8722.28515625 | val_loss : 23690.9921875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 695 | train_loss : 13150.6025390625 | val_loss : 8228.765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 696 | train_loss : 8114.53173828125 | val_loss : 17155.0234375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 697 | train_loss : 8995.2421875 | val_loss : 9642.220703125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 698 | train_loss : 9007.9482421875 | val_loss : 15234.0224609375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 699 | train_loss : 7248.93701171875 | val_loss : 6431.10693359375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 700 | train_loss : 6011.60693359375 | val_loss : 9994.94140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 701 | train_loss : 3891.909423828125 | val_loss : 4988.54833984375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 702 | train_loss : 4267.18017578125 | val_loss : 7475.45947265625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 703 | train_loss : 2931.3642578125 | val_loss : 4478.50732421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 704 | train_loss : 2892.33740234375 | val_loss : 6172.79296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 705 | train_loss : 2462.99169921875 | val_loss : 4065.58740234375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 706 | train_loss : 2628.359619140625 | val_loss : 4869.16064453125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 707 | train_loss : 2127.349609375 | val_loss : 5331.275390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 708 | train_loss : 2361.37353515625 | val_loss : 3484.64306640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 709 | train_loss : 1767.8475341796875 | val_loss : 4573.52734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 710 | train_loss : 1784.021240234375 | val_loss : 3057.862548828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 711 | train_loss : 2073.20068359375 | val_loss : 5254.16259765625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 712 | train_loss : 2011.443115234375 | val_loss : 2944.48193359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 713 | train_loss : 1662.4425048828125 | val_loss : 6475.482421875 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 714 | train_loss : 3607.14697265625 | val_loss : 13180.9375 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 715 | train_loss : 13869.173828125 | val_loss : 45045.24609375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 716 | train_loss : 29122.515625 | val_loss : 3385.344482421875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 717 | train_loss : 5672.474609375 | val_loss : 7422.2451171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 718 | train_loss : 4238.546875 | val_loss : 3502.206298828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 719 | train_loss : 6098.6298828125 | val_loss : 16029.4677734375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 720 | train_loss : 8081.86767578125 | val_loss : 9732.138671875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 721 | train_loss : 9827.1376953125 | val_loss : 27659.7734375 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 722 | train_loss : 15329.041015625 | val_loss : 7958.81298828125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 723 | train_loss : 8614.8134765625 | val_loss : 22934.650390625 | test_acc : 0.68 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 724 | train_loss : 11934.7041015625 | val_loss : 7775.3251953125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 725 | train_loss : 8625.115234375 | val_loss : 21147.462890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 726 | train_loss : 10718.005859375 | val_loss : 7911.4892578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 727 | train_loss : 8433.744140625 | val_loss : 17363.837890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 728 | train_loss : 7894.10205078125 | val_loss : 6417.0498046875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 729 | train_loss : 6763.25048828125 | val_loss : 11770.0126953125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 730 | train_loss : 4974.9619140625 | val_loss : 5284.65234375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 731 | train_loss : 5778.99365234375 | val_loss : 9766.2158203125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 732 | train_loss : 3782.806640625 | val_loss : 2869.813232421875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 733 | train_loss : 3191.47119140625 | val_loss : 7410.57373046875 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 734 | train_loss : 2814.078857421875 | val_loss : 2216.722412109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 735 | train_loss : 2647.864990234375 | val_loss : 7629.2880859375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 736 | train_loss : 2733.401611328125 | val_loss : 2006.15869140625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 737 | train_loss : 2365.289794921875 | val_loss : 5303.46728515625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 738 | train_loss : 2032.6754150390625 | val_loss : 2415.519287109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 739 | train_loss : 2026.0643310546875 | val_loss : 4107.18017578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 740 | train_loss : 2048.30859375 | val_loss : 2980.95068359375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 741 | train_loss : 2033.1956787109375 | val_loss : 3049.775634765625 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 742 | train_loss : 1873.8553466796875 | val_loss : 2391.671142578125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 743 | train_loss : 1921.162353515625 | val_loss : 3477.9951171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 744 | train_loss : 1693.1064453125 | val_loss : 1841.4862060546875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 745 | train_loss : 1981.5621337890625 | val_loss : 4723.45751953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 746 | train_loss : 2086.5908203125 | val_loss : 1730.4749755859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 747 | train_loss : 2053.265380859375 | val_loss : 4808.1962890625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 748 | train_loss : 2120.60009765625 | val_loss : 1615.76123046875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 749 | train_loss : 1555.3634033203125 | val_loss : 2569.123046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 750 | train_loss : 1574.662841796875 | val_loss : 1490.0675048828125 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 751 | train_loss : 1742.71435546875 | val_loss : 2684.311767578125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 752 | train_loss : 1610.635009765625 | val_loss : 9362.3076171875 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 753 | train_loss : 9472.55859375 | val_loss : 49780.78515625 | test_acc : 0.6 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 754 | train_loss : 37519.65234375 | val_loss : 4214.24365234375 | test_acc : 0.64 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 755 | train_loss : 7094.9892578125 | val_loss : 5591.66455078125 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 756 | train_loss : 3210.353759765625 | val_loss : 1289.59130859375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 757 | train_loss : 3689.633056640625 | val_loss : 5545.53369140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 758 | train_loss : 2843.27099609375 | val_loss : 1045.572509765625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 759 | train_loss : 1671.1522216796875 | val_loss : 1646.2850341796875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 760 | train_loss : 1834.869873046875 | val_loss : 982.1856079101562 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 761 | train_loss : 2066.781005859375 | val_loss : 2742.903076171875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 762 | train_loss : 2073.1787109375 | val_loss : 916.703125 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 763 | train_loss : 1841.70849609375 | val_loss : 1909.8218994140625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 764 | train_loss : 1828.009033203125 | val_loss : 881.6099853515625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 765 | train_loss : 2101.95556640625 | val_loss : 4019.64501953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 766 | train_loss : 2375.166259765625 | val_loss : 783.5531005859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 767 | train_loss : 2288.028076171875 | val_loss : 3970.263671875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 768 | train_loss : 2203.151123046875 | val_loss : 753.5562744140625 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 769 | train_loss : 1762.5675048828125 | val_loss : 30959.224609375 | test_acc : 0.56 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 770 | train_loss : 19843.591796875 | val_loss : 22125.380859375 | test_acc : 0.48 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 771 | train_loss : 41088.49609375 | val_loss : 57256.953125 | test_acc : 0.52 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 772 | train_loss : 29656.482421875 | val_loss : 3688.156982421875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 773 | train_loss : 3642.87939453125 | val_loss : 8057.35986328125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 774 | train_loss : 3305.94677734375 | val_loss : 4127.4404296875 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 775 | train_loss : 4052.80224609375 | val_loss : 7503.1376953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 776 | train_loss : 2843.093505859375 | val_loss : 2593.79443359375 | test_acc : 0.88 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 777 | train_loss : 3155.141357421875 | val_loss : 6861.76806640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 778 | train_loss : 2620.6240234375 | val_loss : 1955.862548828125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 779 | train_loss : 1864.1572265625 | val_loss : 4419.037109375 | test_acc : 0.72 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 780 | train_loss : 2286.9287109375 | val_loss : 2621.17431640625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 781 | train_loss : 1939.6915283203125 | val_loss : 2996.83251953125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 782 | train_loss : 2060.470703125 | val_loss : 2398.530517578125 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 783 | train_loss : 2280.07568359375 | val_loss : 3854.766357421875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 784 | train_loss : 2304.863037109375 | val_loss : 2251.18505859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 785 | train_loss : 2135.1650390625 | val_loss : 4067.441162109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 786 | train_loss : 2202.651611328125 | val_loss : 1359.1624755859375 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 787 | train_loss : 1981.826904296875 | val_loss : 4382.53369140625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 788 | train_loss : 2272.8701171875 | val_loss : 1285.7818603515625 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 789 | train_loss : 1682.9537353515625 | val_loss : 3628.211181640625 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 790 | train_loss : 1976.3638916015625 | val_loss : 1197.7918701171875 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 791 | train_loss : 1676.4437255859375 | val_loss : 2757.925537109375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 792 | train_loss : 1835.595947265625 | val_loss : 1123.4449462890625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 793 | train_loss : 1828.81201171875 | val_loss : 2638.72998046875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 794 | train_loss : 1660.0291748046875 | val_loss : 1050.4144287109375 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 795 | train_loss : 1661.1473388671875 | val_loss : 2093.204345703125 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 796 | train_loss : 1513.4866943359375 | val_loss : 982.9293823242188 | test_acc : 0.84 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 797 | train_loss : 1728.7869873046875 | val_loss : 3381.523193359375 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 798 | train_loss : 1868.59130859375 | val_loss : 920.0006103515625 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 799 | train_loss : 1781.4425048828125 | val_loss : 3778.778076171875 | test_acc : 0.76 | \n",
      "--------------------------------------------------------------------------------\n",
      "fold : 9 | epoch : 800 | train_loss : 1925.4136962890625 | val_loss : 995.8099975585938 | test_acc : 0.8 | \n",
      "--------------------------------------------------------------------------------\n",
      "Val Loss: 1592.5314, Test Accuracy: 0.896 ± 0.085, Average Duration per fold: 4.245 mins\n"
     ]
    }
   ],
   "source": [
    "loss_mean, acc_mean, models = cross_val(\n",
    "     dataset=H_5,\n",
    "    model=model_5,\n",
    "    folds=10,\n",
    "    epochs=800,\n",
    "    lr=0.02,\n",
    "    device=device,\n",
    "    weight_decay=0.0005,\n",
    "    lr_decay_factor=0.5,\n",
    "    exp_factor=1,\n",
    "    lr_decay_step_size=50\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 3, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted, mask = voting(models, H_5, device=device)\n",
    "\n",
    "predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(y_true=lb.inverse_transform(H_5['MIDI'].y[mask].to('cpu')), y_pred=lb.inverse_transform(predicted),\n",
    "                                                cmap='bone', normalize='true')\n",
    "\n",
    "disp.ax_.set_title('SLAC Genre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved at .\\slac\\models_5\\\n"
     ]
    }
   ],
   "source": [
    "save_models(models, '.\\\\slac\\\\models_5\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = pyg_models.GraphSAGE(in_channels=-1, hidden_channels=64, num_layers=2, out_channels=len(set(lb.classes_)))\n",
    "model_5 = to_hetero(model_5, H_5.metadata(), aggr='sum')\n",
    "models_5 = load_models('.\\\\slac\\\\models_5\\\\', folds=10, model=model_5,)\n",
    "models_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
