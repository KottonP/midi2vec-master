{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n",
      "3.6.2\n",
      "2.8.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import timeit\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "print(scipy.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_graph(input_path) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Compile all edgelists in input_path directory into a nx.Graph instance.\n",
    "\n",
    "    :param input_path: Directory containing the edgelists to compile.\n",
    "    :return: Complete graph specified by the edgelists.\n",
    "    \"\"\"\n",
    "    edgelists = [qf for qf in os.listdir(input_path)\n",
    "                 if qf.endswith('.edgelist') and not qf.startswith('_')]\n",
    "    g = None\n",
    "\n",
    "    print('loading edgelists...')\n",
    "    for eg in edgelists:\n",
    "        print('- ' + eg)\n",
    "        h = nx.read_edgelist(os.path.join(input_path, eg), nodetype=str, create_using=nx.DiGraph(), delimiter=' ')\n",
    "        for edge in h.edges():\n",
    "            h[edge[0]][edge[1]]['weight'] = 1\n",
    "\n",
    "        g = h if g is None else nx.compose(g, h)\n",
    "\n",
    "    g = g.to_undirected()\n",
    "\n",
    "    print('Nodes: %d' % nx.number_of_nodes(g))\n",
    "    print('Edges: %d' % nx.number_of_edges(g))\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading edgelists...\n",
      "- full_edgelist.edgelist\n",
      "- notes.edgelist\n",
      "- program.edgelist\n",
      "- tempo.edgelist\n",
      "- time.signature.edgelist\n",
      "Nodes: 2703\n",
      "Edges: 19366\n"
     ]
    }
   ],
   "source": [
    "G = complete_graph(\".\\slac\\embeddings\\Test Edgelists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame((list(G.nodes)), columns=['name'])\n",
    "edges = pd.DataFrame(np.array(list(G.edges)), columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11', '6', '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_groups = [n for n in nodes['name'] if n[0] == 'g' and n[1] in [str(i) for i in range(10)] + ['-'] ]\n",
    "\n",
    "not_group_nodes = [n for n in nodes['name'] if n not in note_groups]\n",
    "\n",
    "url = [n for n in not_group_nodes if n[:4] == 'http']\n",
    "program_nodes = []\n",
    "note_nodes = []\n",
    "for u in url:\n",
    "    if \"programs\" in u:\n",
    "        program_nodes.append(u)\n",
    "    elif \"notes\" in u:\n",
    "        note_nodes.append(u)\n",
    "    else:\n",
    "        print(u)\n",
    "\n",
    "name_nodes = [n for n in not_group_nodes if n[0] == '-']\n",
    "dur_nodes = [n for n in not_group_nodes if n[:3] == 'dur']\n",
    "vel_nodes = [n for n in not_group_nodes if n[:3] == 'vel']\n",
    "time_nodes = [n for n in not_group_nodes if n[:4] == 'time']\n",
    "tempo_nodes = [n for n in not_group_nodes if n not in set(dur_nodes).union(vel_nodes, time_nodes, name_nodes, url)]\n",
    "\n",
    "tempo_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['note_group', 'pitch', 'program', 'MIDI', 'duration', 'velocity', 'time_sig', 'tempo'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_categories = {\"note_group\": note_groups,\n",
    "                    \"pitch\": note_nodes,\n",
    "                    \"program\": program_nodes,\n",
    "                    \"MIDI\": name_nodes,\n",
    "                    \"duration\": dur_nodes,\n",
    "                    \"velocity\": vel_nodes,\n",
    "                    \"time_sig\": time_nodes,\n",
    "                    \"tempo\": tempo_nodes\n",
    "                   }\n",
    "\n",
    "node_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_edge_types = [\"MIDI__has__tempo\",\n",
    "                   \"MIDI__in__time_sig\",\n",
    "                   \"MIDI__has__program\",\n",
    "                   \"MIDI__has__note_group\",\n",
    "                   \"note_group__has__velocity\",\n",
    "                   \"note_group__has__duration\",\n",
    "                   \"note_group__contains__pitch\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_edge(df: pd.DataFrame, row: int, inplace: bool = False) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Reverse the source and target of a single edge(row) in the edge dataframe.\"\"\"\n",
    "    if inplace:\n",
    "        df.iloc[row]['source'], df.iloc[row]['target'] = df.iloc[row]['target'], df.iloc[row]['source']\n",
    "        return None\n",
    "    elif not inplace:\n",
    "        tmp = df.copy()\n",
    "        tmp.iloc[row]['source'], tmp.iloc[row]['target'] = tmp.iloc[row]['target'], tmp.iloc[row]['source']\n",
    "        return tmp\n",
    "\n",
    "\n",
    "def format_edge_name(source: str, target: str) -> str:\n",
    "    \"\"\"Combine source and target names in the correct form.\"\"\"\n",
    "    edge_name = \"\"\n",
    "\n",
    "    if source == \"MIDI\":\n",
    "        if target == \"tempo\":\n",
    "            edge_name = source + \"__has__\" + target\n",
    "        elif target == \"time_sig\":\n",
    "            edge_name = source + \"__in__\" + target\n",
    "        elif target == \"program\":\n",
    "            edge_name = source + \"__has__\" + target\n",
    "        elif target == \"note_group\":\n",
    "            edge_name = source + \"__has__\" + target\n",
    "    elif source == \"note_group\":\n",
    "        if target == \"velocity\":\n",
    "            edge_name = source + \"__has__\" + target\n",
    "        elif target == \"duration\":\n",
    "            edge_name = source + \"__has__\" + target\n",
    "        elif target == \"pitch\":\n",
    "            edge_name = source + \"__contains__\" + target\n",
    "    else:\n",
    "        edge_name = source + \"__?__\" + target\n",
    "        print(\"Not known edge detected: \" + edge_name)\n",
    "        return edge_name\n",
    "\n",
    "    return edge_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(nodes_df: pd.DataFrame, node_cat: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return input node Dataframe with a new column named \"node_type\", which specifies the type of the node.\n",
    "\n",
    "    :param nodes_df: Dataframe containing the original node Dataframe (without type column).\n",
    "    :param node_cat: Dictionary with keys: node names, values: nodes of specified category.\n",
    "    :return: Node Dataframe with the new \"node_type\" column.\n",
    "    \"\"\"\n",
    "    node_type = []\n",
    "    augmented_nodes_df = nodes_df.copy()\n",
    "    for i in range(len(nodes_df.index)):\n",
    "        for key in node_cat.keys():\n",
    "            if nodes.iloc[i]['name'] in node_cat[key]:\n",
    "                node_type.append(key)\n",
    "    augmented_nodes_df['node_type'] = node_type\n",
    "    \n",
    "    return augmented_nodes_df\n",
    "\n",
    "\n",
    "def add_edge_type(edges_df: pd.DataFrame, node_cat: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return input edge Dataframe with a new column named \"edge_type\", which specifies the type of the edge.\n",
    "\n",
    "    :param edges_df: Dataframe containing the original edge Dataframe (without type column).\n",
    "    :param node_cat: Dictionary with keys: node names, values: nodes of specified category.\n",
    "    :return: Edge Dataframe with the new \"edge_type\" column.\n",
    "    \"\"\"\n",
    "    edge_type = []\n",
    "\n",
    "    edge_name_source = \"\"\n",
    "    edge_name_target = \"\"\n",
    "\n",
    "    augmented_edges_df = edges_df.copy()\n",
    "\n",
    "    for i in range(len(edges_df.index)):\n",
    "        for name in node_cat.keys():\n",
    "            if edges_df.iloc[i]['source'] in node_cat[name]:\n",
    "                edge_name_source = name\n",
    "                break\n",
    "        for name in node_cat.keys():\n",
    "            if edges_df.iloc[i]['target'] in node_cat[name]:\n",
    "                edge_name_target = name\n",
    "                break\n",
    "\n",
    "        if (edge_name_source not in (\"MIDI\", \"note_group\")) or (edge_name_source == \"note_group\" and edge_name_target == \"MIDI\"):\n",
    "            reverse_edge(augmented_edges_df, row=i, inplace=True)\n",
    "            edge_name_source, edge_name_target = edge_name_target, edge_name_source\n",
    "\n",
    "        edge_name = format_edge_name(edge_name_source, edge_name_target)\n",
    "        edge_type.append(edge_name)\n",
    "\n",
    "    augmented_edges_df['edge_type'] = edge_type\n",
    "    return augmented_edges_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_types(nodes_df: pd.DataFrame, edges_df: pd.DataFrame, node_cat: dict) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Execute add_node_type and add_edge_type, and return a tuple of the new Dataframes.\"\"\"\n",
    "    return add_node_type(nodes_df, node_cat), add_edge_type(edges_df, node_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_f, edges_f = add_types(nodes, edges, node_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_edge_categories = node_categories.copy()\n",
    "node_edge_categories['node_types'] = list(node_categories.keys())\n",
    "node_edge_categories['main_edge_types'] = main_edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['note_group',\n",
       " 'pitch',\n",
       " 'program',\n",
       " 'MIDI',\n",
       " 'duration',\n",
       " 'velocity',\n",
       " 'time_sig',\n",
       " 'tempo']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_edge_categories['node_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = OneHotEncoder()  \n",
    "# categories=[node_edge_categories[key] \n",
    "#for key in node_edge_categories.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2703x2711 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5406 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh.fit_transform(nodes_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- edge_type\n- source\n- target\nFeature names seen at fit time, yet now missing:\n- name\n- node_type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7972\\648978766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\midi2vec\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\midi2vec\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[1;34m\"infrequent_if_exist\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         }\n\u001b[1;32m--> 857\u001b[1;33m         X_int, X_mask = self._transform(\n\u001b[0m\u001b[0;32m    858\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\midi2vec\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_on_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     ):\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         X_list, n_samples, n_features = self._check_X(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\midi2vec\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 )\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     def _validate_data(\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- edge_type\n- source\n- target\nFeature names seen at fit time, yet now missing:\n- name\n- node_type\n"
     ]
    }
   ],
   "source": [
    "oh.transform(edges_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2604\\185963996.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnodes_ten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "nodes_ten = torch.tensor(nodes_f.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2604\\3282452279.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert the nodes dataframe to a PyTorch tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnodes_ten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Convert the edges dataframe to a PyTorch tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0medges_ten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# Convert the nodes dataframe to a PyTorch tensor\n",
    "nodes_ten = torch.tensor(nodes_f.values)\n",
    "\n",
    "# Convert the edges dataframe to a PyTorch tensor\n",
    "edges_ten = torch.tensor(edges_f.values)\n",
    "\n",
    "# Get the source and target indices from the edges tensor\n",
    "edge_index = edges[:, :2]\n",
    "\n",
    "# Get the edge types from the edges tensor\n",
    "edge_type = edges[:, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Functions; Not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_type2(edges_pd: pd.DataFrame, node_cat: dict) -> pd.DataFrame:\n",
    "    \"\"\"Not working correctly (making more types than wanted); Do not use\"\"\"\n",
    "    edge_type = []\n",
    "\n",
    "    edge_name_source = None\n",
    "    edge_name_target = None\n",
    "\n",
    "    augmented_edges_pd = edges_pd.copy()\n",
    "\n",
    "    for i in range(len(edges.index)):\n",
    "        for name in node_cat.keys():\n",
    "            if edges.iloc[i]['source'] in node_cat[name]:\n",
    "                edge_name_source = name + \"__\"\n",
    "                break\n",
    "        for name in node_cat.keys():\n",
    "            if edges.iloc[i]['target'] in node_cat[name]:\n",
    "                edge_name_target = name\n",
    "                break\n",
    "\n",
    "        edge_name = edge_name_source + edge_name_target\n",
    "        edge_type.append(edge_name)\n",
    "\n",
    "    augmented_edges_pd['edge_type'] = edge_type\n",
    "    return augmented_edges_pd\n",
    "\n",
    "\n",
    "def add_types2(nodes_df: pd.DataFrame, edges_df: pd.DataFrame, node_cat: dict) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \"\"\"Too long to execute; do not use.\"\"\"\n",
    "    edge_type = []\n",
    "\n",
    "    augmented_nodes_df = add_node_type(nodes_df, node_cat)  # Node dataframe with the categories column\n",
    "    augmented_edges_df = edges_df.copy() # Edge dataframe with the categories column\n",
    "\n",
    "    for i in range(len(edges_df.index)):\n",
    "        source = edges_df.iloc[i]['source']\n",
    "        edge_name_source = augmented_nodes_df.loc[augmented_nodes_df['name'] == source, ['node_type']].iloc[0]['node_type']\n",
    "\n",
    "        target = edges_df.iloc[i]['target']\n",
    "        edge_name_target = augmented_nodes_df.loc[augmented_nodes_df['name'] == target, ['node_type']].iloc[0]['node_type']\n",
    "\n",
    "        if (edge_name_source not in (\"MIDI\", \"note_group\")) or (edge_name_source == \"note_group\" and edge_name_target == \"MIDI\"):\n",
    "            reverse_edge(augmented_edges_df, row=i, inplace=True)\n",
    "            edge_name_source, edge_name_target = edge_name_target, edge_name_source\n",
    "\n",
    "        edge_name = format_edge_name(edge_name_source, edge_name_target)\n",
    "        edge_type.append(edge_name)\n",
    "\n",
    "    augmented_edges_df['edge_type'] = edge_type\n",
    "    return augmented_nodes_df, augmented_edges_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_test = add_edge_type2(edges, node_categories)\n",
    "\n",
    "edges_test.loc[edges_test['edge_type'] == 'MIDI__program', ['source', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double iteration function:  3.470187100000203\n",
      "Nodes and check function:  21.959933399999954\n"
     ]
    }
   ],
   "source": [
    "print(\"Double iteration function: \", timeit.timeit(lambda: add_types(nodes, edges, node_categories), number=1))\n",
    "print(\"Nodes and check function: \", timeit.timeit(lambda: add_types2(nodes, edges, node_categories), number=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
